{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 25.0MB/s]                    \n",
      "2024-12-09 18:40:01 INFO: Downloaded file to C:\\Users\\maric\\stanza_resources\\resources.json\n",
      "2024-12-09 18:40:01 INFO: Downloading default packages for language: en (English) ...\n",
      "2024-12-09 18:40:02 INFO: File exists: C:\\Users\\maric\\stanza_resources\\en\\default.zip\n",
      "2024-12-09 18:40:07 INFO: Finished downloading models and saved to C:\\Users\\maric\\stanza_resources\n",
      "2024-12-09 18:40:07 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.9.0.json: 392kB [00:00, 32.0MB/s]                    \n",
      "2024-12-09 18:40:07 INFO: Downloaded file to C:\\Users\\maric\\stanza_resources\\resources.json\n",
      "2024-12-09 18:40:08 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2024-12-09 18:40:08 INFO: Using device: cpu\n",
      "2024-12-09 18:40:08 INFO: Loading: tokenize\n",
      "2024-12-09 18:40:08 INFO: Loading: mwt\n",
      "c:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\stanza\\models\\mwt\\trainer.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(filename, lambda storage, loc: storage)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import ast\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.util import ngrams\n",
    "from typing import List, Set\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "from nltk.chunk import RegexpParser\n",
    "import copy\n",
    "\n",
    "from nltk.corpus import wordnet_ic\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import stanza\n",
    "\n",
    "\n",
    "stanza.download('en')\n",
    "nlp_stanza = stanza.Pipeline('en', processors='tokenize,mwt,pos,lemma,depparse', tokenize_pretokenized=True)\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet_ic')\n",
    "\n",
    "brown_ic = wordnet_ic.ic('ic-brown.dat')\n",
    "\n",
    "# Download required resource\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "\n",
    "# Add the project directory to the Python path\n",
    "project_dir = Path.cwd().parent\n",
    "sys.path.append(str(project_dir))\n",
    "\n",
    "from Preprocessing.preprocessingUtils import TextPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>gs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['But', 'other', 'sources', 'close', 'to', 'th...</td>\n",
       "      <td>['But', 'other', 'sources', 'close', 'to', 'th...</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Micron', 'has', 'declared', 'its', 'first', ...</td>\n",
       "      <td>['Micron', \"'s\", 'numbers', 'also', 'marked', ...</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['The', 'fines', 'are', 'part', 'of', 'failed'...</td>\n",
       "      <td>['Perry', 'said', 'he', 'backs', 'the', 'Senat...</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['The', 'American', 'Anglican', 'Council', ','...</td>\n",
       "      <td>['The', 'American', 'Anglican', 'Council', ','...</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['The', 'tech-loaded', 'Nasdaq', 'composite', ...</td>\n",
       "      <td>['The', 'technology-laced', 'Nasdaq', 'Composi...</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  ['But', 'other', 'sources', 'close', 'to', 'th...   \n",
       "1  ['Micron', 'has', 'declared', 'its', 'first', ...   \n",
       "2  ['The', 'fines', 'are', 'part', 'of', 'failed'...   \n",
       "3  ['The', 'American', 'Anglican', 'Council', ','...   \n",
       "4  ['The', 'tech-loaded', 'Nasdaq', 'composite', ...   \n",
       "\n",
       "                                                   1    gs  \n",
       "0  ['But', 'other', 'sources', 'close', 'to', 'th...  4.00  \n",
       "1  ['Micron', \"'s\", 'numbers', 'also', 'marked', ...  3.75  \n",
       "2  ['Perry', 'said', 'he', 'backs', 'the', 'Senat...  2.80  \n",
       "3  ['The', 'American', 'Anglican', 'Council', ','...  3.40  \n",
       "4  ['The', 'technology-laced', 'Nasdaq', 'Composi...  2.40  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "train_token_df = pd.read_csv('../Preprocessing/STS_train.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "train_token_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[But, other, sources, close, to, the, sale, sa...</td>\n",
       "      <td>[But, other, sources, close, to, the, sale, sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Micron, has, declared, its, first, quarterly,...</td>\n",
       "      <td>[Micron, 's, numbers, also, marked, the, first...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, fines, are, part, of, failed, Republican...</td>\n",
       "      <td>[Perry, said, he, backs, the, Senate, 's, effo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, tech-loaded, Nasdaq, composite, rose, 20...</td>\n",
       "      <td>[The, technology-laced, Nasdaq, Composite, Ind...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [But, other, sources, close, to, the, sale, sa...   \n",
       "1  [Micron, has, declared, its, first, quarterly,...   \n",
       "2  [The, fines, are, part, of, failed, Republican...   \n",
       "3  [The, American, Anglican, Council, ,, which, r...   \n",
       "4  [The, tech-loaded, Nasdaq, composite, rose, 20...   \n",
       "\n",
       "                                                   1  \n",
       "0  [But, other, sources, close, to, the, sale, sa...  \n",
       "1  [Micron, 's, numbers, also, marked, the, first...  \n",
       "2  [Perry, said, he, backs, the, Senate, 's, effo...  \n",
       "3  [The, American, Anglican, Council, ,, which, r...  \n",
       "4  [The, technology-laced, Nasdaq, Composite, Ind...  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the 2 first columns from strings to actual lists of strings\n",
    "\n",
    "train_df = pd.DataFrame(columns=['0','1'], index=range(2234))\n",
    "train_df.iloc[:, :2] = train_token_df.iloc[:, :2].map(ast.literal_eval)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(But, CC), (other, JJ), (sources, NNS), (clos...</td>\n",
       "      <td>[(But, CC), (other, JJ), (sources, NNS), (clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(Micron, NNP), (has, VBZ), (declared, VBN), (...</td>\n",
       "      <td>[(Micron, NNP), (s, NN), (numbers, NNS), (also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(The, DT), (fines, NNS), (are, VBP), (part, N...</td>\n",
       "      <td>[(Perry, NNP), (said, VBD), (he, PRP), (backs,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(The, DT), (American, JJ), (Anglican, NNP), (...</td>\n",
       "      <td>[(The, DT), (American, JJ), (Anglican, NNP), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(The, DT), (tech-loaded, JJ), (Nasdaq, NNP), ...</td>\n",
       "      <td>[(The, DT), (technology-laced, JJ), (Nasdaq, N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [(But, CC), (other, JJ), (sources, NNS), (clos...   \n",
       "1  [(Micron, NNP), (has, VBZ), (declared, VBN), (...   \n",
       "2  [(The, DT), (fines, NNS), (are, VBP), (part, N...   \n",
       "3  [(The, DT), (American, JJ), (Anglican, NNP), (...   \n",
       "4  [(The, DT), (tech-loaded, JJ), (Nasdaq, NNP), ...   \n",
       "\n",
       "                                                   1  \n",
       "0  [(But, CC), (other, JJ), (sources, NNS), (clos...  \n",
       "1  [(Micron, NNP), (s, NN), (numbers, NNS), (also...  \n",
       "2  [(Perry, NNP), (said, VBD), (he, PRP), (backs,...  \n",
       "3  [(The, DT), (American, JJ), (Anglican, NNP), (...  \n",
       "4  [(The, DT), (technology-laced, JJ), (Nasdaq, N...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the TextPreprocessor\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "# Remove punctuation\n",
    "train_df = preprocessor.remove_punctuation(train_df)\n",
    "train_df = preprocessor.remove_empty_strings(train_df)\n",
    "\n",
    "# POS-tagging the words\n",
    "n=len(train_df)\n",
    "train_df_POS = pd.DataFrame(columns=['0','1'])\n",
    "\n",
    "for i in range(n):\n",
    "    train_df_POS.loc[i,'0'] = nltk.pos_tag(train_df.loc[i,'0']) \n",
    "    train_df_POS.loc[i,'1'] = nltk.pos_tag(train_df.loc[i,'1']) \n",
    "\n",
    "train_df_POS.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(other, JJ), (sources, NNS), (close, RB), (to...</td>\n",
       "      <td>[(other, JJ), (sources, NNS), (close, RB), (to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(Micron, NNP), (has, VBZ), (declared, VBN), (...</td>\n",
       "      <td>[(Micron, NNP), (s, NN), (numbers, NNS), (also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(fines, NNS), (are, VBP), (part, NN), (failed...</td>\n",
       "      <td>[(Perry, NNP), (said, VBD), (he, PRP), (backs,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(American, JJ), (Anglican, NNP), (Council, NN...</td>\n",
       "      <td>[(American, JJ), (Anglican, NNP), (Council, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(tech-loaded, JJ), (Nasdaq, NNP), (composite,...</td>\n",
       "      <td>[(technology-laced, JJ), (Nasdaq, NNP), (Compo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [(other, JJ), (sources, NNS), (close, RB), (to...   \n",
       "1  [(Micron, NNP), (has, VBZ), (declared, VBN), (...   \n",
       "2  [(fines, NNS), (are, VBP), (part, NN), (failed...   \n",
       "3  [(American, JJ), (Anglican, NNP), (Council, NN...   \n",
       "4  [(tech-loaded, JJ), (Nasdaq, NNP), (composite,...   \n",
       "\n",
       "                                                   1  \n",
       "0  [(other, JJ), (sources, NNS), (close, RB), (to...  \n",
       "1  [(Micron, NNP), (s, NN), (numbers, NNS), (also...  \n",
       "2  [(Perry, NNP), (said, VBD), (he, PRP), (backs,...  \n",
       "3  [(American, JJ), (Anglican, NNP), (Council, NN...  \n",
       "4  [(technology-laced, JJ), (Nasdaq, NNP), (Compo...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the function words (prepositions, conjunctions, articles) carry less semantics than content words \n",
    "# and thus removing them might eliminate the noise and provide a more accurate estimate of semantic similarity.\n",
    "\n",
    "function_words_tag = {'IN', 'CC', 'DT', 'PDT', 'WDT'}\n",
    "\n",
    "# Create a deep copy of the DataFrame\n",
    "train_df_POS_bis = copy.deepcopy(train_df_POS)\n",
    "\n",
    "# Iterate through the rows and modify columns '0' and '1'\n",
    "for i in range(n):\n",
    "    for tag in function_words_tag:\n",
    "        # Extract, modify, and reassign the list in column '0'\n",
    "        col_0 = train_df_POS_bis.at[i, '0']\n",
    "        train_df_POS_bis.at[i, '0'] = [item for item in col_0 if item[1] != tag]\n",
    "\n",
    "        # Extract, modify, and reassign the list in column '1'\n",
    "        col_1 = train_df_POS_bis.at[i, '1']\n",
    "        train_df_POS_bis.at[i, '1'] = [item for item in col_1 if item[1] != tag]\n",
    "\n",
    "train_df_POS_bis.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'gs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gs'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m         sentence\u001b[38;5;241m.\u001b[39mappend(train_df_POS_bis\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m][k][\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     11\u001b[0m     train_df_1\u001b[38;5;241m.\u001b[39mloc[i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39msentence\n\u001b[1;32m---> 13\u001b[0m train_df_1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m train_df_1\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gs'"
     ]
    }
   ],
   "source": [
    "train_df_1 = pd.DataFrame(columns=['0','1','gs'])\n",
    "\n",
    "for i in range(n):\n",
    "    sentence=[]\n",
    "    for j in range(len(train_df_POS_bis.loc[i,'0'])):\n",
    "        sentence.append(train_df_POS_bis.loc[i,'0'][j][0])\n",
    "    train_df_1.loc[i,'0']=sentence\n",
    "    sentence=[]\n",
    "    for k in range(len(train_df_POS_bis.loc[i,'1'])):\n",
    "        sentence.append(train_df_POS_bis.loc[i,'1'][k][0])\n",
    "    train_df_1.loc[i,'1']=sentence\n",
    "\n",
    "train_df_1['gs'] = train_df['gs']\n",
    "train_df_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_overlap(tokens1: List[str], tokens2: List[str], n: int) -> float:\n",
    "    \"\"\"\n",
    "    Computes the n-gram overlap between two tokenized sentences.\n",
    "\n",
    "    Parameters:\n",
    "        tokens1 (List[str]): Tokenized first sentence as a list of strings.\n",
    "        tokens2 (List[str]): Tokenized second sentence as a list of strings.\n",
    "        n (int): The size of n-grams.\n",
    "\n",
    "    Returns:\n",
    "        float: The n-gram overlap ratio.\n",
    "    \"\"\"\n",
    "    def generate_ngrams(tokens: List[str], n: int) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Generates n-grams for a given list of tokens.\n",
    "\n",
    "        \"\"\"\n",
    "        return set([' '.join(tokens[i:i+n]) for i in range(len(tokens) - n + 1)])\n",
    "\n",
    "    # Generate n-grams for both token lists\n",
    "    ngrams_s1 = generate_ngrams(tokens1, n)\n",
    "    ngrams_s2 = generate_ngrams(tokens2, n)\n",
    "\n",
    "    # Compute the intersection \n",
    "    intersection = ngrams_s1.intersection(ngrams_s2)\n",
    "\n",
    "    # Compute the n gram overlap when posible\n",
    "    if len(intersection)==0:\n",
    "        ngo=0\n",
    "    else:\n",
    "        ngo=2/((len(ngrams_s1)+len(ngrams_s2))/len(intersection))\n",
    "\n",
    "    return float(ngo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS_tagging_unigrams</th>\n",
       "      <th>POS_tagging_bigrams</th>\n",
       "      <th>POS_tagging_trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POS_tagging_unigrams  POS_tagging_bigrams  POS_tagging_trigrams\n",
       "0              0.702703             0.594595              0.514286\n",
       "1              0.571429             0.421053              0.352941\n",
       "2              0.500000             0.250000              0.090909\n",
       "3              0.777778             0.764706              0.750000\n",
       "4              0.230769             0.000000              0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntactic_features=pd.DataFrame(columns=['POS_tagging_unigrams','POS_tagging_bigrams','POS_tagging_trigrams'])\n",
    "\n",
    "for i in range(n):\n",
    "    # unigrams\n",
    "    syntactic_features.loc[i,'POS_tagging_unigrams'] = n_gram_overlap(train_df_1.loc[i,'0'],train_df_1.loc[i,'1'],1)\n",
    "    # bigrams\n",
    "    syntactic_features.loc[i,'POS_tagging_bigrams'] = n_gram_overlap(train_df_1.loc[i,'0'],train_df_1.loc[i,'1'],2)\n",
    "    # trigrams\n",
    "    syntactic_features.loc[i,'POS_tagging_trigrams'] = n_gram_overlap(train_df_1.loc[i,'0'],train_df_1.loc[i,'1'],3)\n",
    "\n",
    "\n",
    "# Convert all columns in a DataFrame to numeric, coercing errors into NaN.\n",
    "syntactic_features['POS_tagging_unigrams'] = pd.to_numeric(syntactic_features['POS_tagging_unigrams'], errors='coerce') \n",
    "syntactic_features['POS_tagging_bigrams'] = pd.to_numeric(syntactic_features['POS_tagging_bigrams'], errors='coerce') \n",
    "syntactic_features['POS_tagging_trigrams'] = pd.to_numeric(syntactic_features['POS_tagging_trigrams'], errors='coerce') \n",
    "\n",
    "syntactic_features.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_chunks(pos_tagged):\n",
    "    \"\"\"\n",
    "    Extract chunks from a tokenized sentence using NLTK.\n",
    "    \n",
    "    \"\"\"\n",
    "    grammar = r\"\"\"\n",
    "    # Verb phrase components\n",
    "    p: \n",
    "        {<VBD><VBG>}              # Past progressive (e.g., \"was eating\")\n",
    "        {<VBZ><VBG>}                    # Progressive form (e.g., \"is eating\")\n",
    "        {<VBZ><VBN>}                    # Passive form (e.g., \"is eaten\")\n",
    "        {<VBZ><JJ>}                     # Copular construction (e.g., \"is happy\")\n",
    "        {<VBN>}                   # Perfect construction (e.g., \"has driven\")\n",
    "        {<VBD><VBN>}              # Past perfect (e.g., \"had driven\")\n",
    "        {<MD>?<VB.*><RB>*}              # Modal + verb + optional adverb\n",
    "        {<VB.*><RP>?}                   # Verb with optional particle\n",
    "\n",
    "    # Subject (typically occurs before VP)\n",
    "    # Noun phrase components\n",
    "    s:\n",
    "        {<DT>?<JJ.*>*<NN.*>+}           # Basic noun phrase\n",
    "        {<PRP>}                         # Pronouns\n",
    "        {<NNP>+}                        # Proper nouns\n",
    "        }<p>{\n",
    "        \n",
    "\n",
    "    # Object (must follow VP)\n",
    "    o:\n",
    "        }<p>{  \n",
    "        {<DT>?<JJ.*>*<NN.*>+}           # Basic noun phrase\n",
    "        {<PRP>}                         # Pronouns\n",
    "        {<NNP>+}                        # Proper nouns\n",
    "        {<IN><s>}                      # Prepositional object\n",
    "        {<TO><s>}                      # 'To' prepositional phrase\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a chunk parser with our grammar\n",
    "    chunk_parser = RegexpParser(grammar)\n",
    "\n",
    "    # Perform chunking\n",
    "    chunked = chunk_parser.parse(pos_tagged)\n",
    "    \n",
    "    # Extract chunks into a more readable format\n",
    "    chunks = []\n",
    "    for subtree in chunked.subtrees(filter=lambda t: t.label() != 'S'):\n",
    "        words = [word for word, tag in subtree.leaves()]\n",
    "        chunks.append((subtree.label(), words))\n",
    "        #chunks.append(words)\n",
    "        \n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(s, [other, sources]), (o, [to, the, sale]), ...</td>\n",
       "      <td>[(s, [other, sources]), (o, [to, the, sale]), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(s, [Micron]), (p, [has, declared]), (s, [fir...</td>\n",
       "      <td>[(s, [Micron, s, numbers]), (p, [marked]), (s,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(s, [The, fines]), (p, [are]), (s, [part]), (...</td>\n",
       "      <td>[(s, [Perry]), (p, [said]), (s, [he]), (p, [ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(s, [The, American, Anglican, Council]), (p, ...</td>\n",
       "      <td>[(s, [The, American, Anglican, Council]), (p, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(s, [The, tech-loaded, Nasdaq, composite]), (...</td>\n",
       "      <td>[(s, [The, technology-laced, Nasdaq, Composite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [(s, [other, sources]), (o, [to, the, sale]), ...   \n",
       "1  [(s, [Micron]), (p, [has, declared]), (s, [fir...   \n",
       "2  [(s, [The, fines]), (p, [are]), (s, [part]), (...   \n",
       "3  [(s, [The, American, Anglican, Council]), (p, ...   \n",
       "4  [(s, [The, tech-loaded, Nasdaq, composite]), (...   \n",
       "\n",
       "                                                   1  \n",
       "0  [(s, [other, sources]), (o, [to, the, sale]), ...  \n",
       "1  [(s, [Micron, s, numbers]), (p, [marked]), (s,...  \n",
       "2  [(s, [Perry]), (p, [said]), (s, [he]), (p, [ba...  \n",
       "3  [(s, [The, American, Anglican, Council]), (p, ...  \n",
       "4  [(s, [The, technology-laced, Nasdaq, Composite...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the sets of chunks of the first and the second sentence\n",
    "\n",
    "train_df_chunks = pd.DataFrame(columns=['0','1'])\n",
    "\n",
    "for i in range(n):\n",
    "    train_df_chunks.loc[i,'0'] = get_sentence_chunks(train_df_POS.loc[i,'0'])\n",
    "    train_df_chunks.loc[i,'1'] = get_sentence_chunks(train_df_POS.loc[i,'1'])\n",
    "\n",
    "train_df_chunks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordnet tags\n",
    "d = {'NN': 'n', 'NNS': 'n',\n",
    "       'JJ': 'a', 'JJR': 'a', 'JJS': 'a',\n",
    "       'VB': 'v', 'VBD': 'v', 'VBG': 'v', 'VBN': 'v', 'VBP': 'v', 'VBZ': 'v',\n",
    "       'RB': 'r', 'RBR': 'r', 'RBS': 'r'}\n",
    "\n",
    "\n",
    "# function to obtain a synset from a word.\n",
    "def extract_synset(w):\n",
    "  pair=nltk.pos_tag([w])\n",
    "  if pair[0][1] in d.keys(): # Check if has a wordnet tag\n",
    "    word_synsets = wn.synsets(w,d[pair[0][1]])\n",
    "    return word_synsets[0]\n",
    "  \n",
    "  else:\n",
    "    print('The word ',w,' has no wordnet tag.')\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunksim(c1,c2):\n",
    "    # compute lin similarity first\n",
    "    sim_score=0\n",
    "    for l1 in c1:\n",
    "        for l2 in c2:\n",
    "            synset_l1=extract_synset(l1)\n",
    "            synset_l2=extract_synset(l2)\n",
    "            if synset_l1.pos()==synset_l2.pos():\n",
    "\n",
    "                # Calculate Lin Similarity\n",
    "                sim_score += synset_l1.lin_similarity(synset_l2, brown_ic)\n",
    "    if sim_score==0:\n",
    "        return 0\n",
    "    else:\n",
    "        ckn1=sim_score/len(c1)\n",
    "        ckn2=sim_score/len(c2)\n",
    "\n",
    "        return 2*ckn1*ckn2/(ckn1+ckn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for k in range(n):\n",
    "k=0    \n",
    "predicates_0=[]\n",
    "\n",
    "for tupla in train_df_chunks.loc[k,'0']:\n",
    "    if tupla[0]=='p':\n",
    "        predicates_0.append(tupla[1])\n",
    "\n",
    "\n",
    "predicates_1=[]\n",
    "\n",
    "for tupla in train_df_chunks.loc[k,'1']:\n",
    "    if tupla[0]=='p':\n",
    "        predicates_1.append(tupla[1])\n",
    "\n",
    "len0=len(predicates_0)\n",
    "len1=len(predicates_1)\n",
    "\n",
    "linsim_ = np.zeros((len0,len1))\n",
    "for i in range(len0):\n",
    "    for j in range(len1):\n",
    "        linsim_[i,j] = chunksim(predicates_0[i],predicates_1[j])\n",
    "\n",
    "if len0 > len1:\n",
    "    max_val=np.zeros(len1)\n",
    "    # si el numero de filas es mayor que el numero de columnas, tomo el maximo de cada columna\n",
    "    for j in range(len1):\n",
    "        # Encuentra el valor máximo en la columna j\n",
    "        max_val[j] = np.max(linsim_[:, j])\n",
    "\n",
    "\n",
    "        # Encuentra la fila donde ocurre el valor máximo\n",
    "        i = np.argmax(linsim_[:, j])\n",
    "else:\n",
    "    #tomo el maximo de cada fila\n",
    "    max_val=np.zeros(len0)\n",
    "    # si el numero de filas es mayor que el numero de columnas, tomo el maximo de cada columna\n",
    "    for i in range(len0):\n",
    "        # Encuentra el valor máximo en la columna j\n",
    "        max_val[i] = np.max(linsim_[i, :])\n",
    "\n",
    "\n",
    "        # Encuentra la fila donde ocurre el valor máximo\n",
    "        j = np.argmax(linsim_[i, :])\n",
    "\n",
    "max_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFY WORDS IN SET OF 's','p' or 'o'\n",
    "\n",
    "def classify_syntactic_roles(doc):\n",
    "    roles = {'p': [], 's': [], 'o': []}  # Initialize lists for multiple sets of p, s, o   \n",
    "    for sentence in doc.sentences:        \n",
    "        # Initialize temporary sets for predicates, subjects, and objects\n",
    "        temp_p = set()  # predicates\n",
    "        subject_sets = []  # List of sets for subjects\n",
    "        object_sets = []  # List of sets for objects\n",
    "        \n",
    "        prep_objs = {}  # To store prepositional objects linked to the same predicate\n",
    "        \n",
    "        # Process each word in the sentence\n",
    "        for word in sentence.words:\n",
    "            if word.deprel == 'root':  # The predicate (main verb)\n",
    "                temp_p.add(word.text)\n",
    "            elif word.deprel in ['nsubj', 'nsubjpass']:  # Subject\n",
    "                # Check if it belongs to an existing set\n",
    "                head_text = sentence.words[word.head - 1].text if word.head > 0 else None\n",
    "                added = False\n",
    "                for s_set in subject_sets:\n",
    "                    if any(head_text == sentence.words[s.head - 1].text for s in sentence.words if s.text in s_set):\n",
    "                        s_set.add(word.text)\n",
    "                        added = True\n",
    "                        break\n",
    "                if not added:\n",
    "                    subject_sets.append({word.text})  # Create a new set\n",
    "            elif word.deprel in ['obj', 'dobj', 'obl', 'case']:  # Object\n",
    "                object_sets.append({word.text})  # Create a set for this object\n",
    "            elif word.deprel == 'conj':  # Conjunction linking words\n",
    "                head = sentence.words[word.head - 1].text  # The word it is conjoined with\n",
    "                # If head is a subject, add the conjunct word to the subject set\n",
    "                for s_set in subject_sets:\n",
    "                    if head in s_set:\n",
    "                        s_set.add(word.text)\n",
    "                        break\n",
    "                # If head is an object, add the conjunct word to the object set\n",
    "                for obj_set in object_sets:\n",
    "                    if head in obj_set:\n",
    "                        obj_set.add(word.text)\n",
    "                        break\n",
    "                # If head is a predicate, add the conjunct word to the predicate set\n",
    "                if head in temp_p: # coordinated structure\n",
    "                    temp_p.add(word.text)\n",
    "            elif word.deprel == 'ccomp': # subordinate clausures\n",
    "                head = sentence.words[word.head - 1].text  # The word it is conjoined with\n",
    "                if head in temp_p:\n",
    "                    temp_p.add(word.text)\n",
    "\n",
    "        # EXTRA: Merge object sets based on the specified rules\n",
    "        merged_object_sets = []\n",
    "        while object_sets:\n",
    "            current_set = object_sets.pop(0)\n",
    "            merged = False\n",
    "            for other_set in object_sets:\n",
    "                # Rule 1: Check if any 'case' word's head is in another set\n",
    "                for word in current_set:\n",
    "                    for other_word in sentence.words:\n",
    "                        if other_word.text == word and other_word.deprel == 'case':\n",
    "                            head_word = sentence.words[other_word.head - 1] if other_word.head > 0 else None\n",
    "                            if head_word and any(head_word.text in s for s in object_sets):\n",
    "                                other_set.update(current_set)\n",
    "                                merged = True\n",
    "                                break\n",
    "                    if merged:\n",
    "                        break\n",
    "                if merged:\n",
    "                    break\n",
    "                # Check if two words in different sets share the same head\n",
    "                for word1 in current_set:\n",
    "                    for word2 in other_set:\n",
    "                        word1_head = next((w.head for w in sentence.words if w.text == word1), None)\n",
    "                        word2_head = next((w.head for w in sentence.words if w.text == word2), None)\n",
    "                        if word1_head and word2_head and word1_head == word2_head:\n",
    "                            other_set.update(current_set)\n",
    "                            merged = True\n",
    "                            break\n",
    "                if merged:\n",
    "                    break\n",
    "            if not merged:\n",
    "                merged_object_sets.append(current_set)\n",
    "\n",
    "        # Assign to the roles dictionary\n",
    "        for predicate in temp_p:\n",
    "            roles['p'].append({predicate})  # Create a set for each predicate\n",
    "        \n",
    "        for s_set in subject_sets:\n",
    "            roles['s'].append(s_set)  # Group subjects as their respective sets\n",
    "        \n",
    "        for obj_set in merged_object_sets:\n",
    "            roles['o'].append(obj_set)  # Group objects as their respective sets\n",
    "    \n",
    "        return roles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But other sources close to the sale said Vivendi was keeping the door open to further bids and hoped to see bidders interested in individual assets team up'\n",
      "Word: But, Deprel: cc, Head: said\n",
      "Word: other, Deprel: amod, Head: sources\n",
      "Word: sources, Deprel: nsubj, Head: said\n",
      "Word: close, Deprel: amod, Head: sources\n",
      "Word: to, Deprel: case, Head: sale\n",
      "Word: the, Deprel: det, Head: sale\n",
      "Word: sale, Deprel: obl, Head: close\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Vivendi, Deprel: nsubj, Head: keeping\n",
      "Word: was, Deprel: aux, Head: keeping\n",
      "Word: keeping, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: door\n",
      "Word: door, Deprel: obj, Head: keeping\n",
      "Word: open, Deprel: xcomp, Head: keeping\n",
      "Word: to, Deprel: case, Head: bids\n",
      "Word: further, Deprel: amod, Head: bids\n",
      "Word: bids, Deprel: obl, Head: open\n",
      "Word: and, Deprel: cc, Head: hoped\n",
      "Word: hoped, Deprel: conj, Head: keeping\n",
      "Word: to, Deprel: mark, Head: see\n",
      "Word: see, Deprel: xcomp, Head: hoped\n",
      "Word: bidders, Deprel: obj, Head: see\n",
      "Word: interested, Deprel: xcomp, Head: see\n",
      "Word: in, Deprel: case, Head: team\n",
      "Word: individual, Deprel: amod, Head: assets\n",
      "Word: assets, Deprel: compound, Head: team\n",
      "Word: team, Deprel: obl, Head: interested\n",
      "Word: up, Deprel: advmod, Head: interested\n",
      "\n",
      "Dependencies for Sentence: 'But other sources close to the sale said Vivendi was keeping the door open for further bids in the next day or two'\n",
      "Word: But, Deprel: cc, Head: said\n",
      "Word: other, Deprel: amod, Head: sources\n",
      "Word: sources, Deprel: nsubj, Head: said\n",
      "Word: close, Deprel: amod, Head: sources\n",
      "Word: to, Deprel: case, Head: sale\n",
      "Word: the, Deprel: det, Head: sale\n",
      "Word: sale, Deprel: obl, Head: close\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Vivendi, Deprel: nsubj, Head: keeping\n",
      "Word: was, Deprel: aux, Head: keeping\n",
      "Word: keeping, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: door\n",
      "Word: door, Deprel: obj, Head: keeping\n",
      "Word: open, Deprel: xcomp, Head: keeping\n",
      "Word: for, Deprel: case, Head: bids\n",
      "Word: further, Deprel: amod, Head: bids\n",
      "Word: bids, Deprel: obl, Head: open\n",
      "Word: in, Deprel: case, Head: day\n",
      "Word: the, Deprel: det, Head: day\n",
      "Word: next, Deprel: amod, Head: day\n",
      "Word: day, Deprel: obl, Head: keeping\n",
      "Word: or, Deprel: cc, Head: two\n",
      "Word: two, Deprel: conj, Head: day\n",
      "\n",
      "Dependencies for Sentence: 'Micron has declared its first quarterly profit for three years'\n",
      "Word: Micron, Deprel: nsubj, Head: declared\n",
      "Word: has, Deprel: aux, Head: declared\n",
      "Word: declared, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: profit\n",
      "Word: first, Deprel: amod, Head: profit\n",
      "Word: quarterly, Deprel: amod, Head: profit\n",
      "Word: profit, Deprel: obj, Head: declared\n",
      "Word: for, Deprel: case, Head: years\n",
      "Word: three, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl, Head: declared\n",
      "\n",
      "Dependencies for Sentence: 'Micron s numbers also marked the first quarterly profit in three years for the DRAM manufacturer'\n",
      "Word: Micron, Deprel: nmod:poss, Head: numbers\n",
      "Word: s, Deprel: case, Head: Micron\n",
      "Word: numbers, Deprel: nsubj, Head: marked\n",
      "Word: also, Deprel: advmod, Head: marked\n",
      "Word: marked, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: profit\n",
      "Word: first, Deprel: amod, Head: profit\n",
      "Word: quarterly, Deprel: amod, Head: profit\n",
      "Word: profit, Deprel: obj, Head: marked\n",
      "Word: in, Deprel: case, Head: years\n",
      "Word: three, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl, Head: marked\n",
      "Word: for, Deprel: case, Head: manufacturer\n",
      "Word: the, Deprel: det, Head: manufacturer\n",
      "Word: DRAM, Deprel: compound, Head: manufacturer\n",
      "Word: manufacturer, Deprel: nmod, Head: years\n",
      "\n",
      "Dependencies for Sentence: 'The fines are part of failed Republican efforts to force or entice the Democrats to return'\n",
      "Word: The, Deprel: det, Head: fines\n",
      "Word: fines, Deprel: nsubj, Head: part\n",
      "Word: are, Deprel: cop, Head: part\n",
      "Word: part, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: efforts\n",
      "Word: failed, Deprel: amod, Head: efforts\n",
      "Word: Republican, Deprel: amod, Head: efforts\n",
      "Word: efforts, Deprel: nmod, Head: part\n",
      "Word: to, Deprel: mark, Head: force\n",
      "Word: force, Deprel: acl, Head: efforts\n",
      "Word: or, Deprel: cc, Head: entice\n",
      "Word: entice, Deprel: conj, Head: force\n",
      "Word: the, Deprel: det, Head: Democrats\n",
      "Word: Democrats, Deprel: obj, Head: force\n",
      "Word: to, Deprel: mark, Head: return\n",
      "Word: return, Deprel: xcomp, Head: force\n",
      "\n",
      "Dependencies for Sentence: 'Perry said he backs the Senate s efforts including the fines to force the Democrats to return'\n",
      "Word: Perry, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: backs\n",
      "Word: backs, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: Senate\n",
      "Word: Senate, Deprel: nmod:poss, Head: efforts\n",
      "Word: s, Deprel: case, Head: Senate\n",
      "Word: efforts, Deprel: obj, Head: backs\n",
      "Word: including, Deprel: case, Head: fines\n",
      "Word: the, Deprel: det, Head: fines\n",
      "Word: fines, Deprel: nmod, Head: efforts\n",
      "Word: to, Deprel: mark, Head: force\n",
      "Word: force, Deprel: advcl, Head: backs\n",
      "Word: the, Deprel: det, Head: Democrats\n",
      "Word: Democrats, Deprel: obj, Head: force\n",
      "Word: to, Deprel: mark, Head: return\n",
      "Word: return, Deprel: xcomp, Head: force\n",
      "\n",
      "Dependencies for Sentence: 'The American Anglican Council which represents Episcopalian conservatives said it will seek authorization to create a separate group'\n",
      "Word: The, Deprel: det, Head: Council\n",
      "Word: American, Deprel: amod, Head: Council\n",
      "Word: Anglican, Deprel: amod, Head: Council\n",
      "Word: Council, Deprel: nsubj, Head: said\n",
      "Word: which, Deprel: nsubj, Head: represents\n",
      "Word: represents, Deprel: acl:relcl, Head: Council\n",
      "Word: Episcopalian, Deprel: amod, Head: conservatives\n",
      "Word: conservatives, Deprel: obj, Head: represents\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: seek\n",
      "Word: will, Deprel: aux, Head: seek\n",
      "Word: seek, Deprel: ccomp, Head: said\n",
      "Word: authorization, Deprel: obj, Head: seek\n",
      "Word: to, Deprel: mark, Head: create\n",
      "Word: create, Deprel: acl, Head: authorization\n",
      "Word: a, Deprel: det, Head: group\n",
      "Word: separate, Deprel: amod, Head: group\n",
      "Word: group, Deprel: obj, Head: create\n",
      "\n",
      "Dependencies for Sentence: 'The American Anglican Council which represents Episcopalian conservatives said it will seek authorization to create a separate province in North America because of last week s actions'\n",
      "Word: The, Deprel: det, Head: Council\n",
      "Word: American, Deprel: amod, Head: Council\n",
      "Word: Anglican, Deprel: amod, Head: Council\n",
      "Word: Council, Deprel: nsubj, Head: said\n",
      "Word: which, Deprel: nsubj, Head: represents\n",
      "Word: represents, Deprel: acl:relcl, Head: Council\n",
      "Word: Episcopalian, Deprel: amod, Head: conservatives\n",
      "Word: conservatives, Deprel: obj, Head: represents\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: seek\n",
      "Word: will, Deprel: aux, Head: seek\n",
      "Word: seek, Deprel: ccomp, Head: said\n",
      "Word: authorization, Deprel: obj, Head: seek\n",
      "Word: to, Deprel: mark, Head: create\n",
      "Word: create, Deprel: acl, Head: authorization\n",
      "Word: a, Deprel: det, Head: province\n",
      "Word: separate, Deprel: amod, Head: province\n",
      "Word: province, Deprel: obj, Head: create\n",
      "Word: in, Deprel: case, Head: America\n",
      "Word: North, Deprel: compound, Head: America\n",
      "Word: America, Deprel: nmod, Head: province\n",
      "Word: because, Deprel: case, Head: actions\n",
      "Word: of, Deprel: fixed, Head: because\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: nmod:poss, Head: actions\n",
      "Word: s, Deprel: case, Head: week\n",
      "Word: actions, Deprel: obl, Head: create\n",
      "\n",
      "Dependencies for Sentence: 'The tech-loaded Nasdaq composite rose 20.96 points to 1595.91 ending at its highest level for 12 months'\n",
      "Word: The, Deprel: det, Head: composite\n",
      "Word: tech-loaded, Deprel: amod, Head: composite\n",
      "Word: Nasdaq, Deprel: compound, Head: composite\n",
      "Word: composite, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 20.96, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: rose\n",
      "Word: to, Deprel: case, Head: 1595.91\n",
      "Word: 1595.91, Deprel: obl, Head: rose\n",
      "Word: ending, Deprel: advcl, Head: rose\n",
      "Word: at, Deprel: case, Head: level\n",
      "Word: its, Deprel: nmod:poss, Head: level\n",
      "Word: highest, Deprel: amod, Head: level\n",
      "Word: level, Deprel: obl, Head: ending\n",
      "Word: for, Deprel: case, Head: months\n",
      "Word: 12, Deprel: nummod, Head: months\n",
      "Word: months, Deprel: obl, Head: ending\n",
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index IXIC climbed 19.11 points or 1.2 percent to 1,615.02'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-laced, Deprel: amod, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: climbed\n",
      "Word: climbed, Deprel: root, Head: ROOT\n",
      "Word: 19.11, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: climbed\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.2, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,615.02\n",
      "Word: 1,615.02, Deprel: obl, Head: climbed\n",
      "\n",
      "Dependencies for Sentence: 'Amgen shares gained 93 cents or 1.45 percent to 65.05 in afternoon trading on Nasdaq'\n",
      "Word: Amgen, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: gained\n",
      "Word: gained, Deprel: root, Head: ROOT\n",
      "Word: 93, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obj, Head: gained\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.45, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: cents\n",
      "Word: to, Deprel: case, Head: 65.05\n",
      "Word: 65.05, Deprel: obl, Head: gained\n",
      "Word: in, Deprel: case, Head: trading\n",
      "Word: afternoon, Deprel: compound, Head: trading\n",
      "Word: trading, Deprel: obl, Head: gained\n",
      "Word: on, Deprel: case, Head: Nasdaq\n",
      "Word: Nasdaq, Deprel: nmod, Head: trading\n",
      "\n",
      "Dependencies for Sentence: 'Shares of Allergan were up 14 cents at 78.40 in late trading on the New York Stock Exchange'\n",
      "Word: Shares, Deprel: nsubj, Head: up\n",
      "Word: of, Deprel: case, Head: Allergan\n",
      "Word: Allergan, Deprel: nmod, Head: Shares\n",
      "Word: were, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: 14, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: up\n",
      "Word: at, Deprel: case, Head: 78.40\n",
      "Word: 78.40, Deprel: obl, Head: up\n",
      "Word: in, Deprel: case, Head: trading\n",
      "Word: late, Deprel: amod, Head: trading\n",
      "Word: trading, Deprel: obl, Head: up\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: up\n",
      "\n",
      "Dependencies for Sentence: 'U.S prosecutors have arrested more than 130 individuals and have seized more than 17 million in a continuing crackdown on Internet fraud and abuse'\n",
      "Word: U.S, Deprel: compound, Head: prosecutors\n",
      "Word: prosecutors, Deprel: nsubj, Head: arrested\n",
      "Word: have, Deprel: aux, Head: arrested\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: more, Deprel: advmod, Head: 130\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 130, Deprel: nummod, Head: individuals\n",
      "Word: individuals, Deprel: obj, Head: arrested\n",
      "Word: and, Deprel: cc, Head: seized\n",
      "Word: have, Deprel: aux, Head: seized\n",
      "Word: seized, Deprel: conj, Head: arrested\n",
      "Word: more, Deprel: advmod, Head: 17\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 17, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: seized\n",
      "Word: in, Deprel: case, Head: crackdown\n",
      "Word: a, Deprel: det, Head: crackdown\n",
      "Word: continuing, Deprel: amod, Head: crackdown\n",
      "Word: crackdown, Deprel: obl, Head: seized\n",
      "Word: on, Deprel: case, Head: fraud\n",
      "Word: Internet, Deprel: compound, Head: fraud\n",
      "Word: fraud, Deprel: nmod, Head: crackdown\n",
      "Word: and, Deprel: cc, Head: abuse\n",
      "Word: abuse, Deprel: conj, Head: fraud\n",
      "\n",
      "Dependencies for Sentence: 'More than 130 people have been arrested and 17 million worth of property seized in an Internet fraud sweep announced Friday by three U.S government agencies'\n",
      "Word: More, Deprel: advmod, Head: 130\n",
      "Word: than, Deprel: fixed, Head: More\n",
      "Word: 130, Deprel: nummod, Head: people\n",
      "Word: people, Deprel: nsubj:pass, Head: arrested\n",
      "Word: have, Deprel: aux, Head: arrested\n",
      "Word: been, Deprel: aux:pass, Head: arrested\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: seized\n",
      "Word: 17, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: nummod, Head: worth\n",
      "Word: worth, Deprel: nsubj:pass, Head: seized\n",
      "Word: of, Deprel: case, Head: property\n",
      "Word: property, Deprel: nmod, Head: worth\n",
      "Word: seized, Deprel: conj, Head: arrested\n",
      "Word: in, Deprel: case, Head: sweep\n",
      "Word: an, Deprel: det, Head: sweep\n",
      "Word: Internet, Deprel: compound, Head: fraud\n",
      "Word: fraud, Deprel: compound, Head: sweep\n",
      "Word: sweep, Deprel: obl, Head: seized\n",
      "Word: announced, Deprel: acl, Head: sweep\n",
      "Word: Friday, Deprel: obl:tmod, Head: announced\n",
      "Word: by, Deprel: case, Head: agencies\n",
      "Word: three, Deprel: nummod, Head: agencies\n",
      "Word: U.S, Deprel: compound, Head: agencies\n",
      "Word: government, Deprel: compound, Head: agencies\n",
      "Word: agencies, Deprel: obl, Head: announced\n",
      "\n",
      "Dependencies for Sentence: 'Chavez said investigators feel confident they ve got at least one of the fires resolved in that regard'\n",
      "Word: Chavez, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: investigators, Deprel: nsubj, Head: feel\n",
      "Word: feel, Deprel: ccomp, Head: said\n",
      "Word: confident, Deprel: xcomp, Head: feel\n",
      "Word: they, Deprel: nsubj, Head: got\n",
      "Word: ve, Deprel: aux, Head: got\n",
      "Word: got, Deprel: ccomp, Head: confident\n",
      "Word: at, Deprel: case, Head: least\n",
      "Word: least, Deprel: nmod, Head: one\n",
      "Word: one, Deprel: obj, Head: got\n",
      "Word: of, Deprel: case, Head: fires\n",
      "Word: the, Deprel: det, Head: fires\n",
      "Word: fires, Deprel: nmod, Head: one\n",
      "Word: resolved, Deprel: acl, Head: fires\n",
      "Word: in, Deprel: case, Head: regard\n",
      "Word: that, Deprel: det, Head: regard\n",
      "Word: regard, Deprel: obl, Head: resolved\n",
      "\n",
      "Dependencies for Sentence: 'Albuquerque Mayor Martin Chavez said investigators felt confident that with the arrests they had at least one of the fires resolved'\n",
      "Word: Albuquerque, Deprel: compound, Head: Mayor\n",
      "Word: Mayor, Deprel: compound, Head: Martin\n",
      "Word: Martin, Deprel: nsubj, Head: said\n",
      "Word: Chavez, Deprel: flat, Head: Martin\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: investigators, Deprel: nsubj, Head: felt\n",
      "Word: felt, Deprel: ccomp, Head: said\n",
      "Word: confident, Deprel: xcomp, Head: felt\n",
      "Word: that, Deprel: mark, Head: resolved\n",
      "Word: with, Deprel: case, Head: arrests\n",
      "Word: the, Deprel: det, Head: arrests\n",
      "Word: arrests, Deprel: obl, Head: resolved\n",
      "Word: they, Deprel: nsubj, Head: had\n",
      "Word: had, Deprel: ccomp, Head: confident\n",
      "Word: at, Deprel: case, Head: least\n",
      "Word: least, Deprel: nmod, Head: one\n",
      "Word: one, Deprel: nsubj, Head: resolved\n",
      "Word: of, Deprel: case, Head: fires\n",
      "Word: the, Deprel: det, Head: fires\n",
      "Word: fires, Deprel: nmod, Head: one\n",
      "Word: resolved, Deprel: ccomp, Head: confident\n",
      "\n",
      "Dependencies for Sentence: 'Authorities said the scientist properly quarantined himself at home after he developed SARS symptoms Dec 10'\n",
      "Word: Authorities, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: scientist\n",
      "Word: scientist, Deprel: nsubj, Head: quarantined\n",
      "Word: properly, Deprel: advmod, Head: quarantined\n",
      "Word: quarantined, Deprel: ccomp, Head: said\n",
      "Word: himself, Deprel: obj, Head: quarantined\n",
      "Word: at, Deprel: case, Head: home\n",
      "Word: home, Deprel: obl, Head: quarantined\n",
      "Word: after, Deprel: mark, Head: developed\n",
      "Word: he, Deprel: nsubj, Head: developed\n",
      "Word: developed, Deprel: advcl, Head: quarantined\n",
      "Word: SARS, Deprel: compound, Head: symptoms\n",
      "Word: symptoms, Deprel: obj, Head: developed\n",
      "Word: Dec, Deprel: appos, Head: symptoms\n",
      "Word: 10, Deprel: nummod, Head: Dec\n",
      "\n",
      "Dependencies for Sentence: 'The scientist also quarantined himself at home as soon as he developed SARS symptoms officials said'\n",
      "Word: The, Deprel: det, Head: scientist\n",
      "Word: scientist, Deprel: nsubj, Head: quarantined\n",
      "Word: also, Deprel: advmod, Head: quarantined\n",
      "Word: quarantined, Deprel: root, Head: ROOT\n",
      "Word: himself, Deprel: obj, Head: quarantined\n",
      "Word: at, Deprel: case, Head: home\n",
      "Word: home, Deprel: obl, Head: quarantined\n",
      "Word: as, Deprel: advmod, Head: soon\n",
      "Word: soon, Deprel: advmod, Head: quarantined\n",
      "Word: as, Deprel: mark, Head: developed\n",
      "Word: he, Deprel: nsubj, Head: developed\n",
      "Word: developed, Deprel: advcl, Head: soon\n",
      "Word: SARS, Deprel: compound, Head: symptoms\n",
      "Word: symptoms, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: quarantined\n",
      "\n",
      "Dependencies for Sentence: 'The support will come as a free software upgrade called WebVPN for current customers that have support contracts'\n",
      "Word: The, Deprel: det, Head: support\n",
      "Word: support, Deprel: nsubj, Head: come\n",
      "Word: will, Deprel: aux, Head: come\n",
      "Word: come, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: case, Head: upgrade\n",
      "Word: a, Deprel: det, Head: upgrade\n",
      "Word: free, Deprel: amod, Head: upgrade\n",
      "Word: software, Deprel: compound, Head: upgrade\n",
      "Word: upgrade, Deprel: obl, Head: come\n",
      "Word: called, Deprel: acl, Head: upgrade\n",
      "Word: WebVPN, Deprel: xcomp, Head: called\n",
      "Word: for, Deprel: case, Head: customers\n",
      "Word: current, Deprel: amod, Head: customers\n",
      "Word: customers, Deprel: nmod, Head: WebVPN\n",
      "Word: that, Deprel: nsubj, Head: have\n",
      "Word: have, Deprel: acl:relcl, Head: upgrade\n",
      "Word: support, Deprel: compound, Head: contracts\n",
      "Word: contracts, Deprel: obj, Head: have\n",
      "\n",
      "Dependencies for Sentence: 'The upgrade will be available as a free download for current customers with SmarNet support in January 2004'\n",
      "Word: The, Deprel: det, Head: upgrade\n",
      "Word: upgrade, Deprel: nsubj, Head: available\n",
      "Word: will, Deprel: aux, Head: available\n",
      "Word: be, Deprel: cop, Head: available\n",
      "Word: available, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: case, Head: download\n",
      "Word: a, Deprel: det, Head: download\n",
      "Word: free, Deprel: amod, Head: download\n",
      "Word: download, Deprel: obl, Head: available\n",
      "Word: for, Deprel: case, Head: customers\n",
      "Word: current, Deprel: amod, Head: customers\n",
      "Word: customers, Deprel: nmod, Head: download\n",
      "Word: with, Deprel: case, Head: support\n",
      "Word: SmarNet, Deprel: compound, Head: support\n",
      "Word: support, Deprel: nmod, Head: download\n",
      "Word: in, Deprel: case, Head: January\n",
      "Word: January, Deprel: obl, Head: available\n",
      "Word: 2004, Deprel: nummod, Head: January\n",
      "\n",
      "Dependencies for Sentence: 'The man accused of using fake grenades to commandeer a Cuban plane that landed in Key West in April was sentenced Friday to 20 years in prison'\n",
      "Word: The, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj:pass, Head: sentenced\n",
      "Word: accused, Deprel: acl, Head: man\n",
      "Word: of, Deprel: mark, Head: using\n",
      "Word: using, Deprel: advcl, Head: accused\n",
      "Word: fake, Deprel: amod, Head: grenades\n",
      "Word: grenades, Deprel: obj, Head: using\n",
      "Word: to, Deprel: mark, Head: commandeer\n",
      "Word: commandeer, Deprel: advcl, Head: using\n",
      "Word: a, Deprel: det, Head: plane\n",
      "Word: Cuban, Deprel: amod, Head: plane\n",
      "Word: plane, Deprel: obj, Head: commandeer\n",
      "Word: that, Deprel: nsubj, Head: landed\n",
      "Word: landed, Deprel: acl:relcl, Head: plane\n",
      "Word: in, Deprel: case, Head: West\n",
      "Word: Key, Deprel: compound, Head: West\n",
      "Word: West, Deprel: obl, Head: landed\n",
      "Word: in, Deprel: case, Head: April\n",
      "Word: April, Deprel: obl, Head: landed\n",
      "Word: was, Deprel: aux:pass, Head: sentenced\n",
      "Word: sentenced, Deprel: root, Head: ROOT\n",
      "Word: Friday, Deprel: obl:tmod, Head: sentenced\n",
      "Word: to, Deprel: case, Head: years\n",
      "Word: 20, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl, Head: sentenced\n",
      "Word: in, Deprel: case, Head: prison\n",
      "Word: prison, Deprel: nmod, Head: years\n",
      "\n",
      "Dependencies for Sentence: 'A Cuban architect was sentenced to 20 years in prison Friday for using two fake grenades to hijack a passenger plane from Cuba to Florida in April'\n",
      "Word: A, Deprel: det, Head: architect\n",
      "Word: Cuban, Deprel: amod, Head: architect\n",
      "Word: architect, Deprel: nsubj:pass, Head: sentenced\n",
      "Word: was, Deprel: aux:pass, Head: sentenced\n",
      "Word: sentenced, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: years\n",
      "Word: 20, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl, Head: sentenced\n",
      "Word: in, Deprel: case, Head: prison\n",
      "Word: prison, Deprel: nmod, Head: years\n",
      "Word: Friday, Deprel: obl:tmod, Head: sentenced\n",
      "Word: for, Deprel: mark, Head: using\n",
      "Word: using, Deprel: advcl, Head: sentenced\n",
      "Word: two, Deprel: nummod, Head: grenades\n",
      "Word: fake, Deprel: amod, Head: grenades\n",
      "Word: grenades, Deprel: obj, Head: using\n",
      "Word: to, Deprel: mark, Head: hijack\n",
      "Word: hijack, Deprel: advcl, Head: using\n",
      "Word: a, Deprel: det, Head: plane\n",
      "Word: passenger, Deprel: compound, Head: plane\n",
      "Word: plane, Deprel: obj, Head: hijack\n",
      "Word: from, Deprel: case, Head: Cuba\n",
      "Word: Cuba, Deprel: obl, Head: hijack\n",
      "Word: to, Deprel: case, Head: Florida\n",
      "Word: Florida, Deprel: obl, Head: hijack\n",
      "Word: in, Deprel: case, Head: April\n",
      "Word: April, Deprel: obl, Head: hijack\n",
      "\n",
      "Dependencies for Sentence: 'Jim Williams director of the US-VISIT project said that by the middle of November many arriving passengers in Atlanta will be fingerprinted and photographed'\n",
      "Word: Jim, Deprel: nsubj, Head: said\n",
      "Word: Williams, Deprel: flat, Head: Jim\n",
      "Word: director, Deprel: nsubj, Head: said\n",
      "Word: of, Deprel: case, Head: project\n",
      "Word: the, Deprel: det, Head: project\n",
      "Word: US-VISIT, Deprel: compound, Head: project\n",
      "Word: project, Deprel: nmod, Head: director\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: fingerprinted\n",
      "Word: by, Deprel: case, Head: middle\n",
      "Word: the, Deprel: det, Head: middle\n",
      "Word: middle, Deprel: obl, Head: fingerprinted\n",
      "Word: of, Deprel: case, Head: November\n",
      "Word: November, Deprel: nmod, Head: middle\n",
      "Word: many, Deprel: amod, Head: passengers\n",
      "Word: arriving, Deprel: amod, Head: passengers\n",
      "Word: passengers, Deprel: nsubj:pass, Head: fingerprinted\n",
      "Word: in, Deprel: case, Head: Atlanta\n",
      "Word: Atlanta, Deprel: nmod, Head: passengers\n",
      "Word: will, Deprel: aux, Head: fingerprinted\n",
      "Word: be, Deprel: aux:pass, Head: fingerprinted\n",
      "Word: fingerprinted, Deprel: ccomp, Head: said\n",
      "Word: and, Deprel: cc, Head: photographed\n",
      "Word: photographed, Deprel: conj, Head: fingerprinted\n",
      "\n",
      "Dependencies for Sentence: 'Jim Williams director of the US-VISIT project said that by the middle of November inspectors will be fingerprinting and photographing many foreign passengers arriving in Atlanta'\n",
      "Word: Jim, Deprel: nsubj, Head: said\n",
      "Word: Williams, Deprel: flat, Head: Jim\n",
      "Word: director, Deprel: nsubj, Head: said\n",
      "Word: of, Deprel: case, Head: project\n",
      "Word: the, Deprel: det, Head: project\n",
      "Word: US-VISIT, Deprel: compound, Head: project\n",
      "Word: project, Deprel: nmod, Head: director\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: fingerprinting\n",
      "Word: by, Deprel: case, Head: middle\n",
      "Word: the, Deprel: det, Head: middle\n",
      "Word: middle, Deprel: obl, Head: fingerprinting\n",
      "Word: of, Deprel: case, Head: November\n",
      "Word: November, Deprel: nmod, Head: middle\n",
      "Word: inspectors, Deprel: nsubj, Head: fingerprinting\n",
      "Word: will, Deprel: aux, Head: fingerprinting\n",
      "Word: be, Deprel: aux, Head: fingerprinting\n",
      "Word: fingerprinting, Deprel: ccomp, Head: said\n",
      "Word: and, Deprel: cc, Head: photographing\n",
      "Word: photographing, Deprel: conj, Head: fingerprinting\n",
      "Word: many, Deprel: amod, Head: passengers\n",
      "Word: foreign, Deprel: amod, Head: passengers\n",
      "Word: passengers, Deprel: obj, Head: fingerprinting\n",
      "Word: arriving, Deprel: acl, Head: passengers\n",
      "Word: in, Deprel: case, Head: Atlanta\n",
      "Word: Atlanta, Deprel: obl, Head: arriving\n",
      "\n",
      "Dependencies for Sentence: 'The hearing occurred a day after the Pentagon for the first time singled out an officer Dallager for not addressing the scandal'\n",
      "Word: The, Deprel: det, Head: hearing\n",
      "Word: hearing, Deprel: nsubj, Head: occurred\n",
      "Word: occurred, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: day\n",
      "Word: day, Deprel: obl:tmod, Head: occurred\n",
      "Word: after, Deprel: mark, Head: singled\n",
      "Word: the, Deprel: det, Head: Pentagon\n",
      "Word: Pentagon, Deprel: nsubj, Head: singled\n",
      "Word: for, Deprel: case, Head: time\n",
      "Word: the, Deprel: det, Head: time\n",
      "Word: first, Deprel: amod, Head: time\n",
      "Word: time, Deprel: obl, Head: singled\n",
      "Word: singled, Deprel: advcl, Head: occurred\n",
      "Word: out, Deprel: compound:prt, Head: singled\n",
      "Word: an, Deprel: det, Head: Dallager\n",
      "Word: officer, Deprel: compound, Head: Dallager\n",
      "Word: Dallager, Deprel: obj, Head: singled\n",
      "Word: for, Deprel: mark, Head: addressing\n",
      "Word: not, Deprel: advmod, Head: addressing\n",
      "Word: addressing, Deprel: advcl, Head: singled\n",
      "Word: the, Deprel: det, Head: scandal\n",
      "Word: scandal, Deprel: obj, Head: addressing\n",
      "\n",
      "Dependencies for Sentence: 'The hearing came one day after the Pentagon for the first time singled out an officer Dallager for failing to address the scandal'\n",
      "Word: The, Deprel: det, Head: hearing\n",
      "Word: hearing, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: root, Head: ROOT\n",
      "Word: one, Deprel: nummod, Head: day\n",
      "Word: day, Deprel: obl:tmod, Head: came\n",
      "Word: after, Deprel: mark, Head: singled\n",
      "Word: the, Deprel: det, Head: Pentagon\n",
      "Word: Pentagon, Deprel: nsubj, Head: singled\n",
      "Word: for, Deprel: case, Head: time\n",
      "Word: the, Deprel: det, Head: time\n",
      "Word: first, Deprel: amod, Head: time\n",
      "Word: time, Deprel: obl, Head: singled\n",
      "Word: singled, Deprel: advcl, Head: came\n",
      "Word: out, Deprel: compound:prt, Head: singled\n",
      "Word: an, Deprel: det, Head: Dallager\n",
      "Word: officer, Deprel: compound, Head: Dallager\n",
      "Word: Dallager, Deprel: obj, Head: singled\n",
      "Word: for, Deprel: mark, Head: failing\n",
      "Word: failing, Deprel: advcl, Head: singled\n",
      "Word: to, Deprel: mark, Head: address\n",
      "Word: address, Deprel: xcomp, Head: failing\n",
      "Word: the, Deprel: det, Head: scandal\n",
      "Word: scandal, Deprel: obj, Head: address\n",
      "\n",
      "Dependencies for Sentence: 'The Episcopal Church is alienating itself from the Anglican Communion said the Very Rev Peter Karanja provost of the All Saints Cathedral in Nairobi'\n",
      "Word: The, Deprel: det, Head: Church\n",
      "Word: Episcopal, Deprel: amod, Head: Church\n",
      "Word: Church, Deprel: nsubj, Head: alienating\n",
      "Word: is, Deprel: aux, Head: alienating\n",
      "Word: alienating, Deprel: root, Head: ROOT\n",
      "Word: itself, Deprel: obj, Head: alienating\n",
      "Word: from, Deprel: case, Head: Communion\n",
      "Word: the, Deprel: det, Head: Communion\n",
      "Word: Anglican, Deprel: amod, Head: Communion\n",
      "Word: Communion, Deprel: obl, Head: alienating\n",
      "Word: said, Deprel: parataxis, Head: alienating\n",
      "Word: the, Deprel: det, Head: Rev\n",
      "Word: Very, Deprel: amod, Head: Rev\n",
      "Word: Rev, Deprel: nsubj, Head: said\n",
      "Word: Peter, Deprel: flat, Head: Rev\n",
      "Word: Karanja, Deprel: flat, Head: Rev\n",
      "Word: provost, Deprel: appos, Head: Rev\n",
      "Word: of, Deprel: case, Head: Cathedral\n",
      "Word: the, Deprel: det, Head: Cathedral\n",
      "Word: All, Deprel: det, Head: Saints\n",
      "Word: Saints, Deprel: compound, Head: Cathedral\n",
      "Word: Cathedral, Deprel: nmod, Head: provost\n",
      "Word: in, Deprel: case, Head: Nairobi\n",
      "Word: Nairobi, Deprel: nmod, Head: Cathedral\n",
      "\n",
      "Dependencies for Sentence: 'In Nairobi the provost of All Saints Cathedral the Very Reverend Peter Karanja said the US Episcopal Church was alienating itself from the Anglican Communion'\n",
      "Word: In, Deprel: case, Head: Nairobi\n",
      "Word: Nairobi, Deprel: obl, Head: said\n",
      "Word: the, Deprel: det, Head: provost\n",
      "Word: provost, Deprel: nsubj, Head: said\n",
      "Word: of, Deprel: case, Head: Cathedral\n",
      "Word: All, Deprel: det, Head: Cathedral\n",
      "Word: Saints, Deprel: compound, Head: Cathedral\n",
      "Word: Cathedral, Deprel: nmod, Head: provost\n",
      "Word: the, Deprel: det, Head: Reverend\n",
      "Word: Very, Deprel: amod, Head: Reverend\n",
      "Word: Reverend, Deprel: appos, Head: Cathedral\n",
      "Word: Peter, Deprel: appos, Head: Reverend\n",
      "Word: Karanja, Deprel: flat, Head: Peter\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: Church\n",
      "Word: US, Deprel: compound, Head: Church\n",
      "Word: Episcopal, Deprel: amod, Head: Church\n",
      "Word: Church, Deprel: nsubj, Head: alienating\n",
      "Word: was, Deprel: aux, Head: alienating\n",
      "Word: alienating, Deprel: ccomp, Head: said\n",
      "Word: itself, Deprel: obj, Head: alienating\n",
      "Word: from, Deprel: case, Head: Communion\n",
      "Word: the, Deprel: det, Head: Communion\n",
      "Word: Anglican, Deprel: amod, Head: Communion\n",
      "Word: Communion, Deprel: obl, Head: alienating\n",
      "\n",
      "Dependencies for Sentence: 'Counties with population declines will be Vermillion Posey and Madison'\n",
      "Word: Counties, Deprel: nsubj, Head: Vermillion\n",
      "Word: with, Deprel: case, Head: declines\n",
      "Word: population, Deprel: compound, Head: declines\n",
      "Word: declines, Deprel: nmod, Head: Counties\n",
      "Word: will, Deprel: aux, Head: Vermillion\n",
      "Word: be, Deprel: cop, Head: Vermillion\n",
      "Word: Vermillion, Deprel: root, Head: ROOT\n",
      "Word: Posey, Deprel: flat, Head: Vermillion\n",
      "Word: and, Deprel: cc, Head: Madison\n",
      "Word: Madison, Deprel: conj, Head: Posey\n",
      "\n",
      "Dependencies for Sentence: 'Vermillion Posey and Madison County populations will decline'\n",
      "Word: Vermillion, Deprel: compound, Head: Posey\n",
      "Word: Posey, Deprel: nsubj, Head: decline\n",
      "Word: and, Deprel: cc, Head: populations\n",
      "Word: Madison, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: populations\n",
      "Word: populations, Deprel: conj, Head: Posey\n",
      "Word: will, Deprel: aux, Head: decline\n",
      "Word: decline, Deprel: root, Head: ROOT\n",
      "\n",
      "Dependencies for Sentence: 'Swartz indicted in February had argued that New Hampshire was the wrong place to charge him'\n",
      "Word: Swartz, Deprel: nsubj, Head: argued\n",
      "Word: indicted, Deprel: acl, Head: Swartz\n",
      "Word: in, Deprel: case, Head: February\n",
      "Word: February, Deprel: obl, Head: indicted\n",
      "Word: had, Deprel: aux, Head: argued\n",
      "Word: argued, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: place\n",
      "Word: New, Deprel: amod, Head: Hampshire\n",
      "Word: Hampshire, Deprel: nsubj, Head: place\n",
      "Word: was, Deprel: cop, Head: place\n",
      "Word: the, Deprel: det, Head: place\n",
      "Word: wrong, Deprel: amod, Head: place\n",
      "Word: place, Deprel: ccomp, Head: argued\n",
      "Word: to, Deprel: mark, Head: charge\n",
      "Word: charge, Deprel: acl, Head: place\n",
      "Word: him, Deprel: obj, Head: charge\n",
      "\n",
      "Dependencies for Sentence: 'Swartz had sought to have the charges dismissed saying New Hampshire was the wrong place to charge him'\n",
      "Word: Swartz, Deprel: nsubj, Head: sought\n",
      "Word: had, Deprel: aux, Head: sought\n",
      "Word: sought, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: have\n",
      "Word: have, Deprel: xcomp, Head: sought\n",
      "Word: the, Deprel: det, Head: charges\n",
      "Word: charges, Deprel: obj, Head: have\n",
      "Word: dismissed, Deprel: xcomp, Head: have\n",
      "Word: saying, Deprel: advcl, Head: dismissed\n",
      "Word: New, Deprel: amod, Head: Hampshire\n",
      "Word: Hampshire, Deprel: nsubj, Head: place\n",
      "Word: was, Deprel: cop, Head: place\n",
      "Word: the, Deprel: det, Head: place\n",
      "Word: wrong, Deprel: amod, Head: place\n",
      "Word: place, Deprel: ccomp, Head: saying\n",
      "Word: to, Deprel: mark, Head: charge\n",
      "Word: charge, Deprel: acl, Head: place\n",
      "Word: him, Deprel: obj, Head: charge\n",
      "\n",
      "Dependencies for Sentence: 'The last time the survey was conducted in 1995 those numbers matched'\n",
      "Word: The, Deprel: det, Head: time\n",
      "Word: last, Deprel: amod, Head: time\n",
      "Word: time, Deprel: obl:tmod, Head: matched\n",
      "Word: the, Deprel: det, Head: survey\n",
      "Word: survey, Deprel: nsubj:pass, Head: conducted\n",
      "Word: was, Deprel: aux:pass, Head: conducted\n",
      "Word: conducted, Deprel: acl:relcl, Head: time\n",
      "Word: in, Deprel: case, Head: 1995\n",
      "Word: 1995, Deprel: obl, Head: conducted\n",
      "Word: those, Deprel: det, Head: numbers\n",
      "Word: numbers, Deprel: nsubj, Head: matched\n",
      "Word: matched, Deprel: root, Head: ROOT\n",
      "\n",
      "Dependencies for Sentence: 'In 1995 the last survey those numbers were equal'\n",
      "Word: In, Deprel: case, Head: 1995\n",
      "Word: 1995, Deprel: obl, Head: equal\n",
      "Word: the, Deprel: det, Head: survey\n",
      "Word: last, Deprel: amod, Head: survey\n",
      "Word: survey, Deprel: nsubj, Head: equal\n",
      "Word: those, Deprel: det, Head: numbers\n",
      "Word: numbers, Deprel: nsubj, Head: equal\n",
      "Word: were, Deprel: cop, Head: equal\n",
      "Word: equal, Deprel: root, Head: ROOT\n",
      "\n",
      "Dependencies for Sentence: 'Higher courts have ruled that the tablets broke the constitutional separation of church and state'\n",
      "Word: Higher, Deprel: amod, Head: courts\n",
      "Word: courts, Deprel: nsubj, Head: ruled\n",
      "Word: have, Deprel: aux, Head: ruled\n",
      "Word: ruled, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: broke\n",
      "Word: the, Deprel: det, Head: tablets\n",
      "Word: tablets, Deprel: nsubj, Head: broke\n",
      "Word: broke, Deprel: ccomp, Head: ruled\n",
      "Word: the, Deprel: det, Head: separation\n",
      "Word: constitutional, Deprel: amod, Head: separation\n",
      "Word: separation, Deprel: obj, Head: broke\n",
      "Word: of, Deprel: case, Head: church\n",
      "Word: church, Deprel: nmod, Head: separation\n",
      "Word: and, Deprel: cc, Head: state\n",
      "Word: state, Deprel: conj, Head: church\n",
      "\n",
      "Dependencies for Sentence: 'The federal courts have ruled that the monument violates the constitutional ban against state-established religion'\n",
      "Word: The, Deprel: det, Head: courts\n",
      "Word: federal, Deprel: amod, Head: courts\n",
      "Word: courts, Deprel: nsubj, Head: ruled\n",
      "Word: have, Deprel: aux, Head: ruled\n",
      "Word: ruled, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: violates\n",
      "Word: the, Deprel: det, Head: monument\n",
      "Word: monument, Deprel: nsubj, Head: violates\n",
      "Word: violates, Deprel: ccomp, Head: ruled\n",
      "Word: the, Deprel: det, Head: ban\n",
      "Word: constitutional, Deprel: amod, Head: ban\n",
      "Word: ban, Deprel: obj, Head: violates\n",
      "Word: against, Deprel: case, Head: religion\n",
      "Word: state-established, Deprel: amod, Head: religion\n",
      "Word: religion, Deprel: nmod, Head: ban\n",
      "\n",
      "Dependencies for Sentence: 'They were at Raffles Hospital over the weekend for further evaluation'\n",
      "Word: They, Deprel: nsubj, Head: Hospital\n",
      "Word: were, Deprel: cop, Head: Hospital\n",
      "Word: at, Deprel: case, Head: Hospital\n",
      "Word: Raffles, Deprel: compound, Head: Hospital\n",
      "Word: Hospital, Deprel: root, Head: ROOT\n",
      "Word: over, Deprel: case, Head: weekend\n",
      "Word: the, Deprel: det, Head: weekend\n",
      "Word: weekend, Deprel: obl, Head: Hospital\n",
      "Word: for, Deprel: case, Head: evaluation\n",
      "Word: further, Deprel: amod, Head: evaluation\n",
      "Word: evaluation, Deprel: obl, Head: Hospital\n",
      "\n",
      "Dependencies for Sentence: 'They underwent more tests over the weekend and are now warded at Raffles Hospital'\n",
      "Word: They, Deprel: nsubj, Head: underwent\n",
      "Word: underwent, Deprel: root, Head: ROOT\n",
      "Word: more, Deprel: amod, Head: tests\n",
      "Word: tests, Deprel: obj, Head: underwent\n",
      "Word: over, Deprel: case, Head: weekend\n",
      "Word: the, Deprel: det, Head: weekend\n",
      "Word: weekend, Deprel: obl, Head: underwent\n",
      "Word: and, Deprel: cc, Head: warded\n",
      "Word: are, Deprel: aux:pass, Head: warded\n",
      "Word: now, Deprel: advmod, Head: warded\n",
      "Word: warded, Deprel: conj, Head: underwent\n",
      "Word: at, Deprel: case, Head: Hospital\n",
      "Word: Raffles, Deprel: compound, Head: Hospital\n",
      "Word: Hospital, Deprel: obl, Head: warded\n",
      "\n",
      "Dependencies for Sentence: 'When the bomb exploded at the Casa de España customers were eating dinner and playing bingo'\n",
      "Word: When, Deprel: advmod, Head: exploded\n",
      "Word: the, Deprel: det, Head: bomb\n",
      "Word: bomb, Deprel: nsubj, Head: exploded\n",
      "Word: exploded, Deprel: advcl, Head: eating\n",
      "Word: at, Deprel: case, Head: customers\n",
      "Word: the, Deprel: det, Head: customers\n",
      "Word: Casa, Deprel: compound, Head: customers\n",
      "Word: de, Deprel: compound, Head: España\n",
      "Word: España, Deprel: flat, Head: Casa\n",
      "Word: customers, Deprel: obl, Head: exploded\n",
      "Word: were, Deprel: aux, Head: eating\n",
      "Word: eating, Deprel: root, Head: ROOT\n",
      "Word: dinner, Deprel: obj, Head: eating\n",
      "Word: and, Deprel: cc, Head: playing\n",
      "Word: playing, Deprel: conj, Head: eating\n",
      "Word: bingo, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'At the Casa de Espaa customers were eating dinner and playing bingo when a bomb went off'\n",
      "Word: At, Deprel: case, Head: customers\n",
      "Word: the, Deprel: det, Head: customers\n",
      "Word: Casa, Deprel: compound, Head: customers\n",
      "Word: de, Deprel: flat, Head: Casa\n",
      "Word: Espaa, Deprel: flat, Head: Casa\n",
      "Word: customers, Deprel: obl, Head: eating\n",
      "Word: were, Deprel: aux, Head: eating\n",
      "Word: eating, Deprel: root, Head: ROOT\n",
      "Word: dinner, Deprel: obj, Head: eating\n",
      "Word: and, Deprel: cc, Head: playing\n",
      "Word: playing, Deprel: conj, Head: eating\n",
      "Word: bingo, Deprel: obj, Head: playing\n",
      "Word: when, Deprel: advmod, Head: went\n",
      "Word: a, Deprel: det, Head: bomb\n",
      "Word: bomb, Deprel: nsubj, Head: went\n",
      "Word: went, Deprel: advcl, Head: playing\n",
      "Word: off, Deprel: advmod, Head: went\n",
      "\n",
      "Dependencies for Sentence: 'Plofsky said the commission wo n't investigate because the three-year statute of limitations has expired'\n",
      "Word: Plofsky, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: commission\n",
      "Word: commission, Deprel: nsubj, Head: investigate\n",
      "Word: wo, Deprel: aux, Head: investigate\n",
      "Word: n't, Deprel: advmod, Head: investigate\n",
      "Word: investigate, Deprel: ccomp, Head: said\n",
      "Word: because, Deprel: mark, Head: expired\n",
      "Word: the, Deprel: det, Head: statute\n",
      "Word: three-year, Deprel: amod, Head: statute\n",
      "Word: statute, Deprel: nsubj, Head: expired\n",
      "Word: of, Deprel: case, Head: limitations\n",
      "Word: limitations, Deprel: nmod, Head: statute\n",
      "Word: has, Deprel: aux, Head: expired\n",
      "Word: expired, Deprel: advcl, Head: investigate\n",
      "\n",
      "Dependencies for Sentence: 'The panel will not begin a formal investigation because the statute of limitations has expired Plofsky said'\n",
      "Word: The, Deprel: det, Head: panel\n",
      "Word: panel, Deprel: nsubj, Head: begin\n",
      "Word: will, Deprel: aux, Head: begin\n",
      "Word: not, Deprel: advmod, Head: begin\n",
      "Word: begin, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: investigation\n",
      "Word: formal, Deprel: amod, Head: investigation\n",
      "Word: investigation, Deprel: obj, Head: begin\n",
      "Word: because, Deprel: mark, Head: expired\n",
      "Word: the, Deprel: det, Head: statute\n",
      "Word: statute, Deprel: nsubj, Head: expired\n",
      "Word: of, Deprel: case, Head: limitations\n",
      "Word: limitations, Deprel: nmod, Head: statute\n",
      "Word: has, Deprel: aux, Head: expired\n",
      "Word: expired, Deprel: advcl, Head: begin\n",
      "Word: Plofsky, Deprel: obj, Head: expired\n",
      "Word: said, Deprel: xcomp, Head: expired\n",
      "\n",
      "Dependencies for Sentence: 'In two weeks he ll probably send out Peace Rules in the Preakness'\n",
      "Word: In, Deprel: case, Head: weeks\n",
      "Word: two, Deprel: nummod, Head: weeks\n",
      "Word: weeks, Deprel: obl, Head: send\n",
      "Word: he, Deprel: nsubj, Head: send\n",
      "Word: ll, Deprel: aux, Head: send\n",
      "Word: probably, Deprel: advmod, Head: send\n",
      "Word: send, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: compound:prt, Head: send\n",
      "Word: Peace, Deprel: compound, Head: Rules\n",
      "Word: Rules, Deprel: obj, Head: send\n",
      "Word: in, Deprel: case, Head: Preakness\n",
      "Word: the, Deprel: det, Head: Preakness\n",
      "Word: Preakness, Deprel: obl, Head: send\n",
      "\n",
      "Dependencies for Sentence: 'Frankel said Peace Rules will run in the Preakness Stakes on May 17'\n",
      "Word: Frankel, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Peace, Deprel: compound, Head: Rules\n",
      "Word: Rules, Deprel: nsubj, Head: run\n",
      "Word: will, Deprel: aux, Head: run\n",
      "Word: run, Deprel: ccomp, Head: said\n",
      "Word: in, Deprel: case, Head: Stakes\n",
      "Word: the, Deprel: det, Head: Stakes\n",
      "Word: Preakness, Deprel: compound, Head: Stakes\n",
      "Word: Stakes, Deprel: obl, Head: run\n",
      "Word: on, Deprel: case, Head: 17\n",
      "Word: May, Deprel: compound, Head: 17\n",
      "Word: 17, Deprel: obl, Head: run\n",
      "\n",
      "Dependencies for Sentence: 'If convicted of the spying charges he could face the death penalty'\n",
      "Word: If, Deprel: mark, Head: convicted\n",
      "Word: convicted, Deprel: advcl, Head: face\n",
      "Word: of, Deprel: case, Head: charges\n",
      "Word: the, Deprel: det, Head: charges\n",
      "Word: spying, Deprel: compound, Head: charges\n",
      "Word: charges, Deprel: obl, Head: convicted\n",
      "Word: he, Deprel: nsubj, Head: face\n",
      "Word: could, Deprel: aux, Head: face\n",
      "Word: face, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: penalty\n",
      "Word: death, Deprel: compound, Head: penalty\n",
      "Word: penalty, Deprel: obj, Head: face\n",
      "\n",
      "Dependencies for Sentence: 'The charges of espionage and aiding the enemy can carry the death penalty'\n",
      "Word: The, Deprel: det, Head: charges\n",
      "Word: charges, Deprel: nsubj, Head: carry\n",
      "Word: of, Deprel: case, Head: espionage\n",
      "Word: espionage, Deprel: nmod, Head: charges\n",
      "Word: and, Deprel: cc, Head: aiding\n",
      "Word: aiding, Deprel: conj, Head: espionage\n",
      "Word: the, Deprel: det, Head: enemy\n",
      "Word: enemy, Deprel: obj, Head: aiding\n",
      "Word: can, Deprel: aux, Head: carry\n",
      "Word: carry, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: penalty\n",
      "Word: death, Deprel: compound, Head: penalty\n",
      "Word: penalty, Deprel: obj, Head: carry\n",
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index was up 7.60 points or 0.46 percent at 1,653.62'\n",
      "Word: The, Deprel: det, Head: Index\n",
      "Word: technology-laced, Deprel: amod, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: nsubj, Head: up\n",
      "Word: was, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: 7.60, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: up\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.46, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 1,653.62\n",
      "Word: 1,653.62, Deprel: obl, Head: up\n",
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index SPX shed 2.38 points or 0.24 percent at 995.10'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broader, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: s\n",
      "Word: Poor, Deprel: amod, Head: s\n",
      "Word: s, Deprel: compound, Head: SPX\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: shed\n",
      "Word: shed, Deprel: root, Head: ROOT\n",
      "Word: 2.38, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: shed\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.24, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 995.10\n",
      "Word: 995.10, Deprel: obl, Head: shed\n",
      "\n",
      "Dependencies for Sentence: 'Hilsenrath and Klarman each were indicted on three counts of securities fraud'\n",
      "Word: Hilsenrath, Deprel: nsubj:pass, Head: indicted\n",
      "Word: and, Deprel: cc, Head: Klarman\n",
      "Word: Klarman, Deprel: conj, Head: Hilsenrath\n",
      "Word: each, Deprel: nsubj:pass, Head: indicted\n",
      "Word: were, Deprel: aux:pass, Head: indicted\n",
      "Word: indicted, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: counts\n",
      "Word: three, Deprel: nummod, Head: counts\n",
      "Word: counts, Deprel: obl, Head: indicted\n",
      "Word: of, Deprel: case, Head: fraud\n",
      "Word: securities, Deprel: compound, Head: fraud\n",
      "Word: fraud, Deprel: nmod, Head: counts\n",
      "\n",
      "Dependencies for Sentence: 'Klarman was charged with 16 counts of wire fraud'\n",
      "Word: Klarman, Deprel: nsubj:pass, Head: charged\n",
      "Word: was, Deprel: aux:pass, Head: charged\n",
      "Word: charged, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: counts\n",
      "Word: 16, Deprel: nummod, Head: counts\n",
      "Word: counts, Deprel: obl, Head: charged\n",
      "Word: of, Deprel: case, Head: fraud\n",
      "Word: wire, Deprel: compound, Head: fraud\n",
      "Word: fraud, Deprel: nmod, Head: counts\n",
      "\n",
      "Dependencies for Sentence: 'Entrenched interests are positioning themselves to control the network s chokepoints and they are lobbying the FCC to aid and abet them'\n",
      "Word: Entrenched, Deprel: amod, Head: interests\n",
      "Word: interests, Deprel: nsubj, Head: positioning\n",
      "Word: are, Deprel: aux, Head: positioning\n",
      "Word: positioning, Deprel: root, Head: ROOT\n",
      "Word: themselves, Deprel: obj, Head: positioning\n",
      "Word: to, Deprel: mark, Head: control\n",
      "Word: control, Deprel: advcl, Head: positioning\n",
      "Word: the, Deprel: det, Head: network\n",
      "Word: network, Deprel: nmod:poss, Head: chokepoints\n",
      "Word: s, Deprel: case, Head: network\n",
      "Word: chokepoints, Deprel: obj, Head: control\n",
      "Word: and, Deprel: cc, Head: lobbying\n",
      "Word: they, Deprel: nsubj, Head: lobbying\n",
      "Word: are, Deprel: aux, Head: lobbying\n",
      "Word: lobbying, Deprel: conj, Head: positioning\n",
      "Word: the, Deprel: det, Head: FCC\n",
      "Word: FCC, Deprel: obj, Head: lobbying\n",
      "Word: to, Deprel: mark, Head: aid\n",
      "Word: aid, Deprel: xcomp, Head: lobbying\n",
      "Word: and, Deprel: cc, Head: abet\n",
      "Word: abet, Deprel: conj, Head: aid\n",
      "Word: them, Deprel: obj, Head: aid\n",
      "\n",
      "Dependencies for Sentence: 'It may be dying because entrenched interests are positioning themselves to control the Internet s choke-points and they are lobbying the FCC to aid and abet them'\n",
      "Word: It, Deprel: nsubj, Head: dying\n",
      "Word: may, Deprel: aux, Head: dying\n",
      "Word: be, Deprel: cop, Head: dying\n",
      "Word: dying, Deprel: root, Head: ROOT\n",
      "Word: because, Deprel: mark, Head: positioning\n",
      "Word: entrenched, Deprel: amod, Head: interests\n",
      "Word: interests, Deprel: nsubj, Head: positioning\n",
      "Word: are, Deprel: aux, Head: positioning\n",
      "Word: positioning, Deprel: advcl, Head: dying\n",
      "Word: themselves, Deprel: obj, Head: positioning\n",
      "Word: to, Deprel: mark, Head: control\n",
      "Word: control, Deprel: advcl, Head: positioning\n",
      "Word: the, Deprel: det, Head: Internet\n",
      "Word: Internet, Deprel: nmod:poss, Head: choke-points\n",
      "Word: s, Deprel: case, Head: Internet\n",
      "Word: choke-points, Deprel: obj, Head: control\n",
      "Word: and, Deprel: cc, Head: lobbying\n",
      "Word: they, Deprel: nsubj, Head: lobbying\n",
      "Word: are, Deprel: aux, Head: lobbying\n",
      "Word: lobbying, Deprel: conj, Head: dying\n",
      "Word: the, Deprel: det, Head: FCC\n",
      "Word: FCC, Deprel: obj, Head: lobbying\n",
      "Word: to, Deprel: mark, Head: aid\n",
      "Word: aid, Deprel: xcomp, Head: lobbying\n",
      "Word: and, Deprel: cc, Head: abet\n",
      "Word: abet, Deprel: conj, Head: aid\n",
      "Word: them, Deprel: obj, Head: aid\n",
      "\n",
      "Dependencies for Sentence: 'But church members and observers say they expect that the decision could be problematic for many Episcopalians'\n",
      "Word: But, Deprel: cc, Head: say\n",
      "Word: church, Deprel: compound, Head: members\n",
      "Word: members, Deprel: nsubj, Head: say\n",
      "Word: and, Deprel: cc, Head: observers\n",
      "Word: observers, Deprel: conj, Head: members\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: they, Deprel: nsubj, Head: expect\n",
      "Word: expect, Deprel: ccomp, Head: say\n",
      "Word: that, Deprel: mark, Head: problematic\n",
      "Word: the, Deprel: det, Head: decision\n",
      "Word: decision, Deprel: nsubj, Head: problematic\n",
      "Word: could, Deprel: aux, Head: problematic\n",
      "Word: be, Deprel: cop, Head: problematic\n",
      "Word: problematic, Deprel: ccomp, Head: expect\n",
      "Word: for, Deprel: case, Head: Episcopalians\n",
      "Word: many, Deprel: amod, Head: Episcopalians\n",
      "Word: Episcopalians, Deprel: obl, Head: problematic\n",
      "\n",
      "Dependencies for Sentence: 'But church members and observers say they anticipate that the decision here could pose doctrinal problems for some Episcopalians who believe the Bible prohibits homosexuality'\n",
      "Word: But, Deprel: cc, Head: say\n",
      "Word: church, Deprel: compound, Head: members\n",
      "Word: members, Deprel: nsubj, Head: say\n",
      "Word: and, Deprel: cc, Head: observers\n",
      "Word: observers, Deprel: conj, Head: members\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: they, Deprel: nsubj, Head: anticipate\n",
      "Word: anticipate, Deprel: ccomp, Head: say\n",
      "Word: that, Deprel: mark, Head: pose\n",
      "Word: the, Deprel: det, Head: decision\n",
      "Word: decision, Deprel: nsubj, Head: pose\n",
      "Word: here, Deprel: advmod, Head: decision\n",
      "Word: could, Deprel: aux, Head: pose\n",
      "Word: pose, Deprel: ccomp, Head: anticipate\n",
      "Word: doctrinal, Deprel: amod, Head: problems\n",
      "Word: problems, Deprel: obj, Head: pose\n",
      "Word: for, Deprel: case, Head: Episcopalians\n",
      "Word: some, Deprel: det, Head: Episcopalians\n",
      "Word: Episcopalians, Deprel: nmod, Head: problems\n",
      "Word: who, Deprel: nsubj, Head: believe\n",
      "Word: believe, Deprel: acl:relcl, Head: Episcopalians\n",
      "Word: the, Deprel: det, Head: Bible\n",
      "Word: Bible, Deprel: nsubj, Head: prohibits\n",
      "Word: prohibits, Deprel: ccomp, Head: believe\n",
      "Word: homosexuality, Deprel: obj, Head: prohibits\n",
      "\n",
      "Dependencies for Sentence: 'Squyres is principal investigator for the Athena payload a collection of science instruments carted by each rover'\n",
      "Word: Squyres, Deprel: nsubj, Head: investigator\n",
      "Word: is, Deprel: cop, Head: investigator\n",
      "Word: principal, Deprel: amod, Head: investigator\n",
      "Word: investigator, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: payload\n",
      "Word: the, Deprel: det, Head: payload\n",
      "Word: Athena, Deprel: compound, Head: payload\n",
      "Word: payload, Deprel: nmod, Head: investigator\n",
      "Word: a, Deprel: det, Head: collection\n",
      "Word: collection, Deprel: appos, Head: investigator\n",
      "Word: of, Deprel: case, Head: instruments\n",
      "Word: science, Deprel: compound, Head: instruments\n",
      "Word: instruments, Deprel: nmod, Head: collection\n",
      "Word: carted, Deprel: acl, Head: instruments\n",
      "Word: by, Deprel: case, Head: rover\n",
      "Word: each, Deprel: det, Head: rover\n",
      "Word: rover, Deprel: obl:agent, Head: carted\n",
      "\n",
      "Dependencies for Sentence: 'Steve Squyres a Cornell University scientist is principal investigator for the missions science instruments'\n",
      "Word: Steve, Deprel: nsubj, Head: investigator\n",
      "Word: Squyres, Deprel: flat, Head: Steve\n",
      "Word: a, Deprel: det, Head: scientist\n",
      "Word: Cornell, Deprel: compound, Head: University\n",
      "Word: University, Deprel: compound, Head: scientist\n",
      "Word: scientist, Deprel: appos, Head: Steve\n",
      "Word: is, Deprel: cop, Head: investigator\n",
      "Word: principal, Deprel: amod, Head: investigator\n",
      "Word: investigator, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: instruments\n",
      "Word: the, Deprel: det, Head: instruments\n",
      "Word: missions, Deprel: compound, Head: instruments\n",
      "Word: science, Deprel: compound, Head: instruments\n",
      "Word: instruments, Deprel: nmod, Head: investigator\n",
      "\n",
      "Dependencies for Sentence: 'The military said it had killed 12 rebels and captured nine in the campaign so far for the loss of six soldiers wounded'\n",
      "Word: The, Deprel: det, Head: military\n",
      "Word: military, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: killed\n",
      "Word: had, Deprel: aux, Head: killed\n",
      "Word: killed, Deprel: ccomp, Head: said\n",
      "Word: 12, Deprel: nummod, Head: rebels\n",
      "Word: rebels, Deprel: obj, Head: killed\n",
      "Word: and, Deprel: cc, Head: captured\n",
      "Word: captured, Deprel: conj, Head: killed\n",
      "Word: nine, Deprel: obj, Head: captured\n",
      "Word: in, Deprel: case, Head: campaign\n",
      "Word: the, Deprel: det, Head: campaign\n",
      "Word: campaign, Deprel: obl, Head: captured\n",
      "Word: so, Deprel: advmod, Head: far\n",
      "Word: far, Deprel: advmod, Head: captured\n",
      "Word: for, Deprel: case, Head: loss\n",
      "Word: the, Deprel: det, Head: loss\n",
      "Word: loss, Deprel: obl, Head: captured\n",
      "Word: of, Deprel: case, Head: soldiers\n",
      "Word: six, Deprel: nummod, Head: soldiers\n",
      "Word: soldiers, Deprel: nmod, Head: loss\n",
      "Word: wounded, Deprel: acl, Head: soldiers\n",
      "\n",
      "Dependencies for Sentence: 'The military said it had killed 16 rebels and captured nine in the campaign so far with one soldier killed and six wounded'\n",
      "Word: The, Deprel: det, Head: military\n",
      "Word: military, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: killed\n",
      "Word: had, Deprel: aux, Head: killed\n",
      "Word: killed, Deprel: ccomp, Head: said\n",
      "Word: 16, Deprel: nummod, Head: rebels\n",
      "Word: rebels, Deprel: obj, Head: killed\n",
      "Word: and, Deprel: cc, Head: captured\n",
      "Word: captured, Deprel: conj, Head: killed\n",
      "Word: nine, Deprel: obj, Head: captured\n",
      "Word: in, Deprel: case, Head: campaign\n",
      "Word: the, Deprel: det, Head: campaign\n",
      "Word: campaign, Deprel: obl, Head: captured\n",
      "Word: so, Deprel: advmod, Head: far\n",
      "Word: far, Deprel: advmod, Head: captured\n",
      "Word: with, Deprel: case, Head: soldier\n",
      "Word: one, Deprel: nummod, Head: soldier\n",
      "Word: soldier, Deprel: obl, Head: captured\n",
      "Word: killed, Deprel: acl, Head: soldier\n",
      "Word: and, Deprel: cc, Head: wounded\n",
      "Word: six, Deprel: nsubj, Head: wounded\n",
      "Word: wounded, Deprel: conj, Head: killed\n",
      "\n",
      "Dependencies for Sentence: 'The new sensor dubbed CANARY for cellular analysis and notification of antigen risks and yields hijacks this natural process with two important changes'\n",
      "Word: The, Deprel: det, Head: sensor\n",
      "Word: new, Deprel: amod, Head: sensor\n",
      "Word: sensor, Deprel: nsubj, Head: hijacks\n",
      "Word: dubbed, Deprel: acl, Head: sensor\n",
      "Word: CANARY, Deprel: xcomp, Head: dubbed\n",
      "Word: for, Deprel: case, Head: analysis\n",
      "Word: cellular, Deprel: amod, Head: analysis\n",
      "Word: analysis, Deprel: obl, Head: dubbed\n",
      "Word: and, Deprel: cc, Head: notification\n",
      "Word: notification, Deprel: conj, Head: analysis\n",
      "Word: of, Deprel: case, Head: risks\n",
      "Word: antigen, Deprel: compound, Head: risks\n",
      "Word: risks, Deprel: nmod, Head: analysis\n",
      "Word: and, Deprel: cc, Head: yields\n",
      "Word: yields, Deprel: conj, Head: risks\n",
      "Word: hijacks, Deprel: root, Head: ROOT\n",
      "Word: this, Deprel: det, Head: process\n",
      "Word: natural, Deprel: amod, Head: process\n",
      "Word: process, Deprel: obj, Head: hijacks\n",
      "Word: with, Deprel: case, Head: changes\n",
      "Word: two, Deprel: nummod, Head: changes\n",
      "Word: important, Deprel: amod, Head: changes\n",
      "Word: changes, Deprel: obl, Head: hijacks\n",
      "\n",
      "Dependencies for Sentence: 'The team has named the sensor Canary for cellular analysis and notification of antigen risks and yields'\n",
      "Word: The, Deprel: det, Head: team\n",
      "Word: team, Deprel: nsubj, Head: named\n",
      "Word: has, Deprel: aux, Head: named\n",
      "Word: named, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: sensor\n",
      "Word: sensor, Deprel: obj, Head: named\n",
      "Word: Canary, Deprel: appos, Head: sensor\n",
      "Word: for, Deprel: case, Head: analysis\n",
      "Word: cellular, Deprel: amod, Head: analysis\n",
      "Word: analysis, Deprel: nmod, Head: Canary\n",
      "Word: and, Deprel: cc, Head: notification\n",
      "Word: notification, Deprel: conj, Head: analysis\n",
      "Word: of, Deprel: case, Head: risks\n",
      "Word: antigen, Deprel: compound, Head: risks\n",
      "Word: risks, Deprel: nmod, Head: notification\n",
      "Word: and, Deprel: cc, Head: yields\n",
      "Word: yields, Deprel: conj, Head: risks\n",
      "\n",
      "Dependencies for Sentence: 'Express Scripts ESRX.O shares fell 3.6 percent to close at 66.89 on the Nasdaq'\n",
      "Word: Express, Deprel: compound, Head: Scripts\n",
      "Word: Scripts, Deprel: compound, Head: shares\n",
      "Word: ESRX.O, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 3.6, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: fell\n",
      "Word: to, Deprel: case, Head: close\n",
      "Word: close, Deprel: obl, Head: fell\n",
      "Word: at, Deprel: case, Head: 66.89\n",
      "Word: 66.89, Deprel: nmod, Head: close\n",
      "Word: on, Deprel: case, Head: Nasdaq\n",
      "Word: the, Deprel: det, Head: Nasdaq\n",
      "Word: Nasdaq, Deprel: obl, Head: fell\n",
      "\n",
      "Dependencies for Sentence: 'Shares of Express Scripts ESRX.O fell about 4 percent to 66.73 on the Nasdaq in late morning trade'\n",
      "Word: Shares, Deprel: nsubj, Head: fell\n",
      "Word: of, Deprel: case, Head: ESRX.O\n",
      "Word: Express, Deprel: compound, Head: Scripts\n",
      "Word: Scripts, Deprel: compound, Head: ESRX.O\n",
      "Word: ESRX.O, Deprel: nmod, Head: Shares\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: about, Deprel: advmod, Head: 4\n",
      "Word: 4, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: fell\n",
      "Word: to, Deprel: case, Head: 66.73\n",
      "Word: 66.73, Deprel: obl, Head: fell\n",
      "Word: on, Deprel: case, Head: Nasdaq\n",
      "Word: the, Deprel: det, Head: Nasdaq\n",
      "Word: Nasdaq, Deprel: obl, Head: fell\n",
      "Word: in, Deprel: case, Head: trade\n",
      "Word: late, Deprel: amod, Head: morning\n",
      "Word: morning, Deprel: compound, Head: trade\n",
      "Word: trade, Deprel: obl, Head: fell\n",
      "\n",
      "Dependencies for Sentence: 'One Fort Carson-based Sgt Ernest Bucklew 33 had been on his way home to attend his mother s funeral in Pennsylvania'\n",
      "Word: One, Deprel: nummod, Head: Sgt\n",
      "Word: Fort, Deprel: compound, Head: Sgt\n",
      "Word: Carson-based, Deprel: flat, Head: Fort\n",
      "Word: Sgt, Deprel: nsubj, Head: way\n",
      "Word: Ernest, Deprel: flat, Head: Sgt\n",
      "Word: Bucklew, Deprel: flat, Head: Ernest\n",
      "Word: 33, Deprel: flat, Head: Ernest\n",
      "Word: had, Deprel: aux, Head: way\n",
      "Word: been, Deprel: cop, Head: way\n",
      "Word: on, Deprel: case, Head: way\n",
      "Word: his, Deprel: nmod:poss, Head: way\n",
      "Word: way, Deprel: root, Head: ROOT\n",
      "Word: home, Deprel: advmod, Head: way\n",
      "Word: to, Deprel: mark, Head: attend\n",
      "Word: attend, Deprel: advcl, Head: way\n",
      "Word: his, Deprel: nmod:poss, Head: mother\n",
      "Word: mother, Deprel: nmod:poss, Head: funeral\n",
      "Word: s, Deprel: case, Head: mother\n",
      "Word: funeral, Deprel: obj, Head: attend\n",
      "Word: in, Deprel: case, Head: Pennsylvania\n",
      "Word: Pennsylvania, Deprel: nmod, Head: funeral\n",
      "\n",
      "Dependencies for Sentence: 'Sgt Ernest Bucklew 33 was coming home from Iraq to bury his mother in Pennsylvania'\n",
      "Word: Sgt, Deprel: nsubj, Head: coming\n",
      "Word: Ernest, Deprel: flat, Head: Sgt\n",
      "Word: Bucklew, Deprel: flat, Head: Sgt\n",
      "Word: 33, Deprel: flat, Head: Sgt\n",
      "Word: was, Deprel: aux, Head: coming\n",
      "Word: coming, Deprel: root, Head: ROOT\n",
      "Word: home, Deprel: advmod, Head: coming\n",
      "Word: from, Deprel: case, Head: Iraq\n",
      "Word: Iraq, Deprel: obl, Head: coming\n",
      "Word: to, Deprel: mark, Head: bury\n",
      "Word: bury, Deprel: advcl, Head: coming\n",
      "Word: his, Deprel: nmod:poss, Head: mother\n",
      "Word: mother, Deprel: obj, Head: bury\n",
      "Word: in, Deprel: case, Head: Pennsylvania\n",
      "Word: Pennsylvania, Deprel: nmod, Head: mother\n",
      "\n",
      "Dependencies for Sentence: 'Police launched an international hunt for Shevaun Pennington after she ran away with 31-year-old Toby Studabaker Saturday'\n",
      "Word: Police, Deprel: nsubj, Head: launched\n",
      "Word: launched, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: hunt\n",
      "Word: international, Deprel: amod, Head: hunt\n",
      "Word: hunt, Deprel: obj, Head: launched\n",
      "Word: for, Deprel: case, Head: Shevaun\n",
      "Word: Shevaun, Deprel: nmod, Head: hunt\n",
      "Word: Pennington, Deprel: flat, Head: Shevaun\n",
      "Word: after, Deprel: mark, Head: ran\n",
      "Word: she, Deprel: nsubj, Head: ran\n",
      "Word: ran, Deprel: advcl, Head: launched\n",
      "Word: away, Deprel: advmod, Head: ran\n",
      "Word: with, Deprel: case, Head: Saturday\n",
      "Word: 31-year-old, Deprel: amod, Head: Toby\n",
      "Word: Toby, Deprel: compound, Head: Saturday\n",
      "Word: Studabaker, Deprel: flat, Head: Toby\n",
      "Word: Saturday, Deprel: obl, Head: ran\n",
      "\n",
      "Dependencies for Sentence: 'Shevaun Pennington disappeared on Saturday morning after arranging to meet 31-year-old Toby Studabaker'\n",
      "Word: Shevaun, Deprel: nsubj, Head: disappeared\n",
      "Word: Pennington, Deprel: flat, Head: Shevaun\n",
      "Word: disappeared, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: morning\n",
      "Word: Saturday, Deprel: compound, Head: morning\n",
      "Word: morning, Deprel: obl, Head: disappeared\n",
      "Word: after, Deprel: mark, Head: arranging\n",
      "Word: arranging, Deprel: advcl, Head: disappeared\n",
      "Word: to, Deprel: mark, Head: meet\n",
      "Word: meet, Deprel: xcomp, Head: arranging\n",
      "Word: 31-year-old, Deprel: compound, Head: Toby\n",
      "Word: Toby, Deprel: obj, Head: meet\n",
      "Word: Studabaker, Deprel: flat, Head: Toby\n",
      "\n",
      "Dependencies for Sentence: 'Lawyers and others familiar with the federal investigation say it remains focused on Campbell though prosecutors declined to discuss the probe'\n",
      "Word: Lawyers, Deprel: nsubj, Head: say\n",
      "Word: and, Deprel: cc, Head: others\n",
      "Word: others, Deprel: conj, Head: Lawyers\n",
      "Word: familiar, Deprel: amod, Head: Lawyers\n",
      "Word: with, Deprel: case, Head: investigation\n",
      "Word: the, Deprel: det, Head: investigation\n",
      "Word: federal, Deprel: amod, Head: investigation\n",
      "Word: investigation, Deprel: obl, Head: familiar\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: remains\n",
      "Word: remains, Deprel: ccomp, Head: say\n",
      "Word: focused, Deprel: xcomp, Head: remains\n",
      "Word: on, Deprel: case, Head: Campbell\n",
      "Word: Campbell, Deprel: obl, Head: focused\n",
      "Word: though, Deprel: mark, Head: declined\n",
      "Word: prosecutors, Deprel: nsubj, Head: declined\n",
      "Word: declined, Deprel: advcl, Head: remains\n",
      "Word: to, Deprel: mark, Head: discuss\n",
      "Word: discuss, Deprel: xcomp, Head: declined\n",
      "Word: the, Deprel: det, Head: probe\n",
      "Word: probe, Deprel: obj, Head: discuss\n",
      "\n",
      "Dependencies for Sentence: 'While federal prosecutors refuse to discuss the investigation lawyers and others familiar with it say it remains focused on Campbell'\n",
      "Word: While, Deprel: mark, Head: refuse\n",
      "Word: federal, Deprel: amod, Head: prosecutors\n",
      "Word: prosecutors, Deprel: nsubj, Head: refuse\n",
      "Word: refuse, Deprel: advcl, Head: say\n",
      "Word: to, Deprel: mark, Head: discuss\n",
      "Word: discuss, Deprel: xcomp, Head: refuse\n",
      "Word: the, Deprel: det, Head: lawyers\n",
      "Word: investigation, Deprel: compound, Head: lawyers\n",
      "Word: lawyers, Deprel: obj, Head: discuss\n",
      "Word: and, Deprel: cc, Head: others\n",
      "Word: others, Deprel: conj, Head: lawyers\n",
      "Word: familiar, Deprel: amod, Head: others\n",
      "Word: with, Deprel: case, Head: it\n",
      "Word: it, Deprel: obl, Head: familiar\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: remains\n",
      "Word: remains, Deprel: ccomp, Head: say\n",
      "Word: focused, Deprel: xcomp, Head: remains\n",
      "Word: on, Deprel: case, Head: Campbell\n",
      "Word: Campbell, Deprel: obl, Head: focused\n",
      "\n",
      "Dependencies for Sentence: 'The Dow Jones industrial average DJI was off 58.69 points or 0.64 percent at 9,137.86'\n",
      "Word: The, Deprel: det, Head: DJI\n",
      "Word: Dow, Deprel: compound, Head: Jones\n",
      "Word: Jones, Deprel: compound, Head: average\n",
      "Word: industrial, Deprel: compound, Head: average\n",
      "Word: average, Deprel: compound, Head: DJI\n",
      "Word: DJI, Deprel: nsubj, Head: off\n",
      "Word: was, Deprel: cop, Head: off\n",
      "Word: off, Deprel: root, Head: ROOT\n",
      "Word: 58.69, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: off\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.64, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 9,137.86\n",
      "Word: 9,137.86, Deprel: obl, Head: off\n",
      "\n",
      "Dependencies for Sentence: 'The blue-chip Dow Jones industrial average DJI fell 86.56 points or 0.94 percent to 9,109.99 after giving up more than 1 percent earlier'\n",
      "Word: The, Deprel: det, Head: DJI\n",
      "Word: blue-chip, Deprel: compound, Head: DJI\n",
      "Word: Dow, Deprel: compound, Head: average\n",
      "Word: Jones, Deprel: flat, Head: Dow\n",
      "Word: industrial, Deprel: compound, Head: average\n",
      "Word: average, Deprel: compound, Head: DJI\n",
      "Word: DJI, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 86.56, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: fell\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.94, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 9,109.99\n",
      "Word: 9,109.99, Deprel: obl, Head: fell\n",
      "Word: after, Deprel: mark, Head: giving\n",
      "Word: giving, Deprel: advcl, Head: fell\n",
      "Word: up, Deprel: compound:prt, Head: giving\n",
      "Word: more, Deprel: advmod, Head: 1\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 1, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: giving\n",
      "Word: earlier, Deprel: advmod, Head: giving\n",
      "\n",
      "Dependencies for Sentence: 'Peace Rules defeated Funny Cide in the Louisiana Derby'\n",
      "Word: Peace, Deprel: compound, Head: Rules\n",
      "Word: Rules, Deprel: nsubj, Head: defeated\n",
      "Word: defeated, Deprel: root, Head: ROOT\n",
      "Word: Funny, Deprel: amod, Head: Cide\n",
      "Word: Cide, Deprel: obj, Head: defeated\n",
      "Word: in, Deprel: case, Head: Derby\n",
      "Word: the, Deprel: det, Head: Derby\n",
      "Word: Louisiana, Deprel: compound, Head: Derby\n",
      "Word: Derby, Deprel: obl, Head: defeated\n",
      "\n",
      "Dependencies for Sentence: 'But neither he nor Peace Rules could keep Funny Cide from drawing away'\n",
      "Word: But, Deprel: cc, Head: keep\n",
      "Word: neither, Deprel: det, Head: he\n",
      "Word: he, Deprel: nsubj, Head: keep\n",
      "Word: nor, Deprel: cc, Head: Rules\n",
      "Word: Peace, Deprel: compound, Head: Rules\n",
      "Word: Rules, Deprel: conj, Head: he\n",
      "Word: could, Deprel: aux, Head: keep\n",
      "Word: keep, Deprel: root, Head: ROOT\n",
      "Word: Funny, Deprel: amod, Head: Cide\n",
      "Word: Cide, Deprel: obj, Head: keep\n",
      "Word: from, Deprel: mark, Head: drawing\n",
      "Word: drawing, Deprel: advcl, Head: keep\n",
      "Word: away, Deprel: advmod, Head: drawing\n",
      "\n",
      "Dependencies for Sentence: 'Waksal has pleaded guilty to securities fraud and is to be sentenced next week'\n",
      "Word: Waksal, Deprel: nsubj, Head: pleaded\n",
      "Word: has, Deprel: aux, Head: pleaded\n",
      "Word: pleaded, Deprel: root, Head: ROOT\n",
      "Word: guilty, Deprel: obj, Head: pleaded\n",
      "Word: to, Deprel: case, Head: fraud\n",
      "Word: securities, Deprel: compound, Head: fraud\n",
      "Word: fraud, Deprel: obl, Head: pleaded\n",
      "Word: and, Deprel: cc, Head: sentenced\n",
      "Word: is, Deprel: aux, Head: sentenced\n",
      "Word: to, Deprel: mark, Head: sentenced\n",
      "Word: be, Deprel: aux:pass, Head: sentenced\n",
      "Word: sentenced, Deprel: conj, Head: pleaded\n",
      "Word: next, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: sentenced\n",
      "\n",
      "Dependencies for Sentence: 'Waksal pleaded guilty to insider trading charges last year and he is scheduled to be sentenced June 10'\n",
      "Word: Waksal, Deprel: nsubj, Head: pleaded\n",
      "Word: pleaded, Deprel: root, Head: ROOT\n",
      "Word: guilty, Deprel: obj, Head: pleaded\n",
      "Word: to, Deprel: case, Head: charges\n",
      "Word: insider, Deprel: compound, Head: trading\n",
      "Word: trading, Deprel: compound, Head: charges\n",
      "Word: charges, Deprel: obl, Head: pleaded\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: pleaded\n",
      "Word: and, Deprel: cc, Head: scheduled\n",
      "Word: he, Deprel: nsubj:pass, Head: scheduled\n",
      "Word: is, Deprel: aux:pass, Head: scheduled\n",
      "Word: scheduled, Deprel: conj, Head: pleaded\n",
      "Word: to, Deprel: mark, Head: sentenced\n",
      "Word: be, Deprel: aux:pass, Head: sentenced\n",
      "Word: sentenced, Deprel: xcomp, Head: scheduled\n",
      "Word: June, Deprel: obl:tmod, Head: sentenced\n",
      "Word: 10, Deprel: nummod, Head: June\n",
      "\n",
      "Dependencies for Sentence: 'He allowed two runs in seven innings and struck out six'\n",
      "Word: He, Deprel: nsubj, Head: allowed\n",
      "Word: allowed, Deprel: root, Head: ROOT\n",
      "Word: two, Deprel: nummod, Head: runs\n",
      "Word: runs, Deprel: obj, Head: allowed\n",
      "Word: in, Deprel: case, Head: innings\n",
      "Word: seven, Deprel: nummod, Head: innings\n",
      "Word: innings, Deprel: obl, Head: allowed\n",
      "Word: and, Deprel: cc, Head: struck\n",
      "Word: struck, Deprel: conj, Head: allowed\n",
      "Word: out, Deprel: compound:prt, Head: struck\n",
      "Word: six, Deprel: obj, Head: struck\n",
      "\n",
      "Dependencies for Sentence: 'Zambrano pitched seven innings and allowed two runs on five hits and four walks'\n",
      "Word: Zambrano, Deprel: nsubj, Head: pitched\n",
      "Word: pitched, Deprel: root, Head: ROOT\n",
      "Word: seven, Deprel: nummod, Head: innings\n",
      "Word: innings, Deprel: obj, Head: pitched\n",
      "Word: and, Deprel: cc, Head: allowed\n",
      "Word: allowed, Deprel: conj, Head: pitched\n",
      "Word: two, Deprel: nummod, Head: runs\n",
      "Word: runs, Deprel: obj, Head: allowed\n",
      "Word: on, Deprel: case, Head: hits\n",
      "Word: five, Deprel: nummod, Head: hits\n",
      "Word: hits, Deprel: obl, Head: allowed\n",
      "Word: and, Deprel: cc, Head: walks\n",
      "Word: four, Deprel: nummod, Head: walks\n",
      "Word: walks, Deprel: conj, Head: hits\n",
      "\n",
      "Dependencies for Sentence: 'Still he said I m absolutely confident we re going to have a bill'\n",
      "Word: Still, Deprel: advmod, Head: said\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: I, Deprel: nsubj, Head: confident\n",
      "Word: m, Deprel: cop, Head: confident\n",
      "Word: absolutely, Deprel: advmod, Head: confident\n",
      "Word: confident, Deprel: ccomp, Head: said\n",
      "Word: we, Deprel: nsubj, Head: going\n",
      "Word: re, Deprel: aux, Head: going\n",
      "Word: going, Deprel: ccomp, Head: confident\n",
      "Word: to, Deprel: mark, Head: have\n",
      "Word: have, Deprel: xcomp, Head: going\n",
      "Word: a, Deprel: det, Head: bill\n",
      "Word: bill, Deprel: obj, Head: have\n",
      "\n",
      "Dependencies for Sentence: 'I m absolutely confident we re going to have a bill Frist R-Tenn said Thursday'\n",
      "Word: I, Deprel: nsubj, Head: confident\n",
      "Word: m, Deprel: cop, Head: confident\n",
      "Word: absolutely, Deprel: advmod, Head: confident\n",
      "Word: confident, Deprel: root, Head: ROOT\n",
      "Word: we, Deprel: nsubj, Head: going\n",
      "Word: re, Deprel: aux, Head: going\n",
      "Word: going, Deprel: ccomp, Head: confident\n",
      "Word: to, Deprel: mark, Head: have\n",
      "Word: have, Deprel: xcomp, Head: going\n",
      "Word: a, Deprel: det, Head: bill\n",
      "Word: bill, Deprel: obj, Head: have\n",
      "Word: Frist, Deprel: nsubj, Head: said\n",
      "Word: R-Tenn, Deprel: flat, Head: Frist\n",
      "Word: said, Deprel: acl:relcl, Head: bill\n",
      "Word: Thursday, Deprel: obl:tmod, Head: said\n",
      "\n",
      "Dependencies for Sentence: 'Boeing said the final agreement is expected to be signed during the next few weeks'\n",
      "Word: Boeing, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: agreement\n",
      "Word: final, Deprel: amod, Head: agreement\n",
      "Word: agreement, Deprel: nsubj:pass, Head: expected\n",
      "Word: is, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: ccomp, Head: said\n",
      "Word: to, Deprel: mark, Head: signed\n",
      "Word: be, Deprel: aux:pass, Head: signed\n",
      "Word: signed, Deprel: xcomp, Head: expected\n",
      "Word: during, Deprel: case, Head: weeks\n",
      "Word: the, Deprel: det, Head: weeks\n",
      "Word: next, Deprel: amod, Head: weeks\n",
      "Word: few, Deprel: amod, Head: weeks\n",
      "Word: weeks, Deprel: obl, Head: signed\n",
      "\n",
      "Dependencies for Sentence: 'The Korean Air deal is expected to be finalized in the next several weeks Boeing spokesman Bob Saling said'\n",
      "Word: The, Deprel: det, Head: deal\n",
      "Word: Korean, Deprel: amod, Head: Air\n",
      "Word: Air, Deprel: compound, Head: deal\n",
      "Word: deal, Deprel: nsubj:pass, Head: expected\n",
      "Word: is, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: finalized\n",
      "Word: be, Deprel: aux:pass, Head: finalized\n",
      "Word: finalized, Deprel: xcomp, Head: expected\n",
      "Word: in, Deprel: case, Head: weeks\n",
      "Word: the, Deprel: det, Head: weeks\n",
      "Word: next, Deprel: amod, Head: weeks\n",
      "Word: several, Deprel: amod, Head: weeks\n",
      "Word: weeks, Deprel: obl, Head: finalized\n",
      "Word: Boeing, Deprel: compound, Head: spokesman\n",
      "Word: spokesman, Deprel: compound, Head: Bob\n",
      "Word: Bob, Deprel: nsubj, Head: said\n",
      "Word: Saling, Deprel: flat, Head: Bob\n",
      "Word: said, Deprel: parataxis, Head: expected\n",
      "\n",
      "Dependencies for Sentence: 'Shares in EDS closed on Thursday at 18.51 a gain of 6 cents'\n",
      "Word: Shares, Deprel: nsubj, Head: closed\n",
      "Word: in, Deprel: case, Head: EDS\n",
      "Word: EDS, Deprel: nmod, Head: Shares\n",
      "Word: closed, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: closed\n",
      "Word: at, Deprel: case, Head: gain\n",
      "Word: 18.51, Deprel: nummod, Head: gain\n",
      "Word: a, Deprel: det, Head: gain\n",
      "Word: gain, Deprel: obl, Head: closed\n",
      "Word: of, Deprel: case, Head: cents\n",
      "Word: 6, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: nmod, Head: gain\n",
      "\n",
      "Dependencies for Sentence: 'Shares of EDS closed Thursday at 18.51 up 6 cents on the New York Stock Exchange'\n",
      "Word: Shares, Deprel: nsubj, Head: closed\n",
      "Word: of, Deprel: case, Head: EDS\n",
      "Word: EDS, Deprel: nmod, Head: Shares\n",
      "Word: closed, Deprel: root, Head: ROOT\n",
      "Word: Thursday, Deprel: obl:tmod, Head: closed\n",
      "Word: at, Deprel: case, Head: 18.51\n",
      "Word: 18.51, Deprel: obl, Head: closed\n",
      "Word: up, Deprel: advmod, Head: closed\n",
      "Word: 6, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: up\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: compound, Head: Exchange\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: closed\n",
      "\n",
      "Dependencies for Sentence: 'Nationally the federal Centers for Disease Control and Prevention recorded 4,156 cases of West Nile including 284 deaths'\n",
      "Word: Nationally, Deprel: advmod, Head: recorded\n",
      "Word: the, Deprel: det, Head: Centers\n",
      "Word: federal, Deprel: amod, Head: Centers\n",
      "Word: Centers, Deprel: nsubj, Head: recorded\n",
      "Word: for, Deprel: case, Head: Control\n",
      "Word: Disease, Deprel: compound, Head: Control\n",
      "Word: Control, Deprel: nmod, Head: Centers\n",
      "Word: and, Deprel: cc, Head: Prevention\n",
      "Word: Prevention, Deprel: conj, Head: Control\n",
      "Word: recorded, Deprel: root, Head: ROOT\n",
      "Word: 4,156, Deprel: nummod, Head: cases\n",
      "Word: cases, Deprel: obj, Head: recorded\n",
      "Word: of, Deprel: case, Head: Nile\n",
      "Word: West, Deprel: compound, Head: Nile\n",
      "Word: Nile, Deprel: nmod, Head: cases\n",
      "Word: including, Deprel: case, Head: deaths\n",
      "Word: 284, Deprel: nummod, Head: deaths\n",
      "Word: deaths, Deprel: obl, Head: recorded\n",
      "\n",
      "Dependencies for Sentence: 'There were 293 human cases of West Nile in Indiana in 2002 including 11 deaths statewide'\n",
      "Word: There, Deprel: expl, Head: were\n",
      "Word: were, Deprel: root, Head: ROOT\n",
      "Word: 293, Deprel: nummod, Head: cases\n",
      "Word: human, Deprel: amod, Head: cases\n",
      "Word: cases, Deprel: nsubj, Head: were\n",
      "Word: of, Deprel: case, Head: Nile\n",
      "Word: West, Deprel: compound, Head: Nile\n",
      "Word: Nile, Deprel: nmod, Head: cases\n",
      "Word: in, Deprel: case, Head: Indiana\n",
      "Word: Indiana, Deprel: nmod, Head: cases\n",
      "Word: in, Deprel: case, Head: 2002\n",
      "Word: 2002, Deprel: obl, Head: were\n",
      "Word: including, Deprel: case, Head: statewide\n",
      "Word: 11, Deprel: nummod, Head: deaths\n",
      "Word: deaths, Deprel: compound, Head: statewide\n",
      "Word: statewide, Deprel: obl, Head: were\n",
      "\n",
      "Dependencies for Sentence: 'A divided Supreme Court ruled Monday that Congress can force the nation s public libraries to equip computers with anti-pornography filters'\n",
      "Word: A, Deprel: det, Head: Court\n",
      "Word: divided, Deprel: amod, Head: Court\n",
      "Word: Supreme, Deprel: amod, Head: Court\n",
      "Word: Court, Deprel: nsubj, Head: ruled\n",
      "Word: ruled, Deprel: root, Head: ROOT\n",
      "Word: Monday, Deprel: obl:tmod, Head: ruled\n",
      "Word: that, Deprel: mark, Head: force\n",
      "Word: Congress, Deprel: nsubj, Head: force\n",
      "Word: can, Deprel: aux, Head: force\n",
      "Word: force, Deprel: ccomp, Head: ruled\n",
      "Word: the, Deprel: det, Head: nation\n",
      "Word: nation, Deprel: nmod:poss, Head: libraries\n",
      "Word: s, Deprel: case, Head: nation\n",
      "Word: public, Deprel: amod, Head: libraries\n",
      "Word: libraries, Deprel: obj, Head: force\n",
      "Word: to, Deprel: mark, Head: equip\n",
      "Word: equip, Deprel: xcomp, Head: force\n",
      "Word: computers, Deprel: obj, Head: equip\n",
      "Word: with, Deprel: case, Head: filters\n",
      "Word: anti-pornography, Deprel: compound, Head: filters\n",
      "Word: filters, Deprel: obl, Head: equip\n",
      "\n",
      "Dependencies for Sentence: 'The Supreme Court said Monday the government can require public libraries to equip computers with anti-pornography filters rejecting librarians complaints that the law amounts to censorship'\n",
      "Word: The, Deprel: det, Head: Court\n",
      "Word: Supreme, Deprel: amod, Head: Court\n",
      "Word: Court, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Monday, Deprel: obl:tmod, Head: said\n",
      "Word: the, Deprel: det, Head: government\n",
      "Word: government, Deprel: nsubj, Head: require\n",
      "Word: can, Deprel: aux, Head: require\n",
      "Word: require, Deprel: ccomp, Head: said\n",
      "Word: public, Deprel: amod, Head: libraries\n",
      "Word: libraries, Deprel: obj, Head: require\n",
      "Word: to, Deprel: mark, Head: equip\n",
      "Word: equip, Deprel: xcomp, Head: require\n",
      "Word: computers, Deprel: obj, Head: equip\n",
      "Word: with, Deprel: case, Head: filters\n",
      "Word: anti-pornography, Deprel: amod, Head: filters\n",
      "Word: filters, Deprel: nmod, Head: computers\n",
      "Word: rejecting, Deprel: acl, Head: filters\n",
      "Word: librarians, Deprel: compound, Head: complaints\n",
      "Word: complaints, Deprel: obj, Head: rejecting\n",
      "Word: that, Deprel: mark, Head: amounts\n",
      "Word: the, Deprel: det, Head: law\n",
      "Word: law, Deprel: nsubj, Head: amounts\n",
      "Word: amounts, Deprel: acl, Head: complaints\n",
      "Word: to, Deprel: case, Head: censorship\n",
      "Word: censorship, Deprel: obl, Head: amounts\n",
      "\n",
      "Dependencies for Sentence: 'The weakness exists in the way that VBA looks at the properties of documents passed to it when the document is opened by a host application'\n",
      "Word: The, Deprel: det, Head: weakness\n",
      "Word: weakness, Deprel: nsubj, Head: exists\n",
      "Word: exists, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: way\n",
      "Word: the, Deprel: det, Head: way\n",
      "Word: way, Deprel: obl, Head: exists\n",
      "Word: that, Deprel: mark, Head: looks\n",
      "Word: VBA, Deprel: nsubj, Head: looks\n",
      "Word: looks, Deprel: acl:relcl, Head: way\n",
      "Word: at, Deprel: case, Head: properties\n",
      "Word: the, Deprel: det, Head: properties\n",
      "Word: properties, Deprel: obl, Head: looks\n",
      "Word: of, Deprel: case, Head: documents\n",
      "Word: documents, Deprel: nmod, Head: properties\n",
      "Word: passed, Deprel: acl, Head: documents\n",
      "Word: to, Deprel: case, Head: it\n",
      "Word: it, Deprel: obl, Head: passed\n",
      "Word: when, Deprel: advmod, Head: opened\n",
      "Word: the, Deprel: det, Head: document\n",
      "Word: document, Deprel: nsubj:pass, Head: opened\n",
      "Word: is, Deprel: aux:pass, Head: opened\n",
      "Word: opened, Deprel: advcl, Head: looks\n",
      "Word: by, Deprel: case, Head: application\n",
      "Word: a, Deprel: det, Head: application\n",
      "Word: host, Deprel: compound, Head: application\n",
      "Word: application, Deprel: obl, Head: opened\n",
      "\n",
      "Dependencies for Sentence: 'The vulnerability exists in the way Microsoft s Visual Basic for Applications checks document properties passed to it when a document is opened'\n",
      "Word: The, Deprel: det, Head: vulnerability\n",
      "Word: vulnerability, Deprel: nsubj, Head: exists\n",
      "Word: exists, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: way\n",
      "Word: the, Deprel: det, Head: way\n",
      "Word: way, Deprel: obl, Head: exists\n",
      "Word: Microsoft, Deprel: nmod:poss, Head: Basic\n",
      "Word: s, Deprel: case, Head: Microsoft\n",
      "Word: Visual, Deprel: amod, Head: Basic\n",
      "Word: Basic, Deprel: nsubj, Head: checks\n",
      "Word: for, Deprel: case, Head: Applications\n",
      "Word: Applications, Deprel: nmod, Head: Basic\n",
      "Word: checks, Deprel: acl:relcl, Head: way\n",
      "Word: document, Deprel: compound, Head: properties\n",
      "Word: properties, Deprel: obj, Head: checks\n",
      "Word: passed, Deprel: acl, Head: properties\n",
      "Word: to, Deprel: case, Head: it\n",
      "Word: it, Deprel: obl, Head: passed\n",
      "Word: when, Deprel: advmod, Head: opened\n",
      "Word: a, Deprel: det, Head: document\n",
      "Word: document, Deprel: nsubj, Head: opened\n",
      "Word: is, Deprel: cop, Head: opened\n",
      "Word: opened, Deprel: advcl, Head: passed\n",
      "\n",
      "Dependencies for Sentence: 'Of 24 million phoned-in votes 50.28 percent were for Studdard putting him 130,000 votes ahead of Aiken'\n",
      "Word: Of, Deprel: case, Head: votes\n",
      "Word: 24, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: votes\n",
      "Word: phoned-in, Deprel: amod, Head: votes\n",
      "Word: votes, Deprel: obl, Head: putting\n",
      "Word: 50.28, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: nsubj, Head: Studdard\n",
      "Word: were, Deprel: cop, Head: Studdard\n",
      "Word: for, Deprel: case, Head: Studdard\n",
      "Word: Studdard, Deprel: nsubj, Head: putting\n",
      "Word: putting, Deprel: root, Head: ROOT\n",
      "Word: him, Deprel: iobj, Head: putting\n",
      "Word: 130,000, Deprel: nummod, Head: votes\n",
      "Word: votes, Deprel: obj, Head: putting\n",
      "Word: ahead, Deprel: advmod, Head: putting\n",
      "Word: of, Deprel: case, Head: Aiken\n",
      "Word: Aiken, Deprel: obl, Head: ahead\n",
      "\n",
      "Dependencies for Sentence: 'Of the 24 million phone votes cast Studdard was only 130,000 votes ahead of Aiken'\n",
      "Word: Of, Deprel: case, Head: votes\n",
      "Word: the, Deprel: det, Head: votes\n",
      "Word: 24, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: votes\n",
      "Word: phone, Deprel: compound, Head: votes\n",
      "Word: votes, Deprel: obl, Head: votes\n",
      "Word: cast, Deprel: acl, Head: votes\n",
      "Word: Studdard, Deprel: nsubj, Head: votes\n",
      "Word: was, Deprel: cop, Head: votes\n",
      "Word: only, Deprel: advmod, Head: 130,000\n",
      "Word: 130,000, Deprel: nummod, Head: votes\n",
      "Word: votes, Deprel: root, Head: ROOT\n",
      "Word: ahead, Deprel: advmod, Head: votes\n",
      "Word: of, Deprel: case, Head: Aiken\n",
      "Word: Aiken, Deprel: obl, Head: ahead\n",
      "\n",
      "Dependencies for Sentence: 'Consumers still would have to get a descrambling security card from their cable operator to plug into the set'\n",
      "Word: Consumers, Deprel: nsubj, Head: have\n",
      "Word: still, Deprel: advmod, Head: have\n",
      "Word: would, Deprel: aux, Head: have\n",
      "Word: have, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: get\n",
      "Word: get, Deprel: xcomp, Head: have\n",
      "Word: a, Deprel: det, Head: card\n",
      "Word: descrambling, Deprel: amod, Head: card\n",
      "Word: security, Deprel: compound, Head: card\n",
      "Word: card, Deprel: obj, Head: get\n",
      "Word: from, Deprel: case, Head: operator\n",
      "Word: their, Deprel: nmod:poss, Head: operator\n",
      "Word: cable, Deprel: compound, Head: operator\n",
      "Word: operator, Deprel: obl, Head: get\n",
      "Word: to, Deprel: mark, Head: plug\n",
      "Word: plug, Deprel: advcl, Head: get\n",
      "Word: into, Deprel: case, Head: set\n",
      "Word: the, Deprel: det, Head: set\n",
      "Word: set, Deprel: obl, Head: plug\n",
      "\n",
      "Dependencies for Sentence: 'To watch pay television consumers would insert into the set a security card provided by their cable service'\n",
      "Word: To, Deprel: mark, Head: watch\n",
      "Word: watch, Deprel: advcl, Head: insert\n",
      "Word: pay, Deprel: compound, Head: television\n",
      "Word: television, Deprel: compound, Head: consumers\n",
      "Word: consumers, Deprel: nsubj, Head: insert\n",
      "Word: would, Deprel: aux, Head: insert\n",
      "Word: insert, Deprel: root, Head: ROOT\n",
      "Word: into, Deprel: mark, Head: set\n",
      "Word: the, Deprel: det, Head: set\n",
      "Word: set, Deprel: obl, Head: insert\n",
      "Word: a, Deprel: det, Head: card\n",
      "Word: security, Deprel: compound, Head: card\n",
      "Word: card, Deprel: obj, Head: insert\n",
      "Word: provided, Deprel: acl, Head: card\n",
      "Word: by, Deprel: case, Head: service\n",
      "Word: their, Deprel: nmod:poss, Head: service\n",
      "Word: cable, Deprel: compound, Head: service\n",
      "Word: service, Deprel: obl:agent, Head: provided\n",
      "\n",
      "Dependencies for Sentence: 'However we have decided to opt for the European consortium s engine as the best overall solution and due to the substantial price efforts made'\n",
      "Word: However, Deprel: advmod, Head: decided\n",
      "Word: we, Deprel: nsubj, Head: decided\n",
      "Word: have, Deprel: aux, Head: decided\n",
      "Word: decided, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: opt\n",
      "Word: opt, Deprel: xcomp, Head: decided\n",
      "Word: for, Deprel: case, Head: engine\n",
      "Word: the, Deprel: det, Head: consortium\n",
      "Word: European, Deprel: amod, Head: consortium\n",
      "Word: consortium, Deprel: nmod:poss, Head: engine\n",
      "Word: s, Deprel: case, Head: consortium\n",
      "Word: engine, Deprel: obl, Head: opt\n",
      "Word: as, Deprel: case, Head: solution\n",
      "Word: the, Deprel: det, Head: solution\n",
      "Word: best, Deprel: amod, Head: solution\n",
      "Word: overall, Deprel: amod, Head: solution\n",
      "Word: solution, Deprel: obl, Head: opt\n",
      "Word: and, Deprel: cc, Head: efforts\n",
      "Word: due, Deprel: case, Head: efforts\n",
      "Word: to, Deprel: fixed, Head: due\n",
      "Word: the, Deprel: det, Head: efforts\n",
      "Word: substantial, Deprel: amod, Head: efforts\n",
      "Word: price, Deprel: compound, Head: efforts\n",
      "Word: efforts, Deprel: conj, Head: solution\n",
      "Word: made, Deprel: acl, Head: efforts\n",
      "\n",
      "Dependencies for Sentence: 'However we have decided to opt for the European consortium s engine as the best overall solution'\n",
      "Word: However, Deprel: advmod, Head: decided\n",
      "Word: we, Deprel: nsubj, Head: decided\n",
      "Word: have, Deprel: aux, Head: decided\n",
      "Word: decided, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: opt\n",
      "Word: opt, Deprel: xcomp, Head: decided\n",
      "Word: for, Deprel: case, Head: engine\n",
      "Word: the, Deprel: det, Head: consortium\n",
      "Word: European, Deprel: amod, Head: consortium\n",
      "Word: consortium, Deprel: nmod:poss, Head: engine\n",
      "Word: s, Deprel: case, Head: consortium\n",
      "Word: engine, Deprel: obl, Head: opt\n",
      "Word: as, Deprel: case, Head: solution\n",
      "Word: the, Deprel: det, Head: solution\n",
      "Word: best, Deprel: amod, Head: solution\n",
      "Word: overall, Deprel: amod, Head: solution\n",
      "Word: solution, Deprel: obl, Head: opt\n",
      "\n",
      "Dependencies for Sentence: 'The Food and Drug Administration rejected ImClone s 2001 application to sell Erbitux citing shoddy research'\n",
      "Word: The, Deprel: det, Head: Administration\n",
      "Word: Food, Deprel: compound, Head: Administration\n",
      "Word: and, Deprel: cc, Head: Drug\n",
      "Word: Drug, Deprel: conj, Head: Food\n",
      "Word: Administration, Deprel: nsubj, Head: rejected\n",
      "Word: rejected, Deprel: root, Head: ROOT\n",
      "Word: ImClone, Deprel: nmod:poss, Head: application\n",
      "Word: s, Deprel: case, Head: ImClone\n",
      "Word: 2001, Deprel: compound, Head: application\n",
      "Word: application, Deprel: obj, Head: rejected\n",
      "Word: to, Deprel: mark, Head: sell\n",
      "Word: sell, Deprel: acl, Head: application\n",
      "Word: Erbitux, Deprel: obj, Head: sell\n",
      "Word: citing, Deprel: xcomp, Head: sell\n",
      "Word: shoddy, Deprel: amod, Head: research\n",
      "Word: research, Deprel: obj, Head: citing\n",
      "\n",
      "Dependencies for Sentence: 'The U.S Food and Drug Administration rejected ImClone s original application in December 2001 saying the trial had been sloppily conducted'\n",
      "Word: The, Deprel: det, Head: Administration\n",
      "Word: U.S, Deprel: compound, Head: Administration\n",
      "Word: Food, Deprel: compound, Head: Administration\n",
      "Word: and, Deprel: cc, Head: Drug\n",
      "Word: Drug, Deprel: conj, Head: Food\n",
      "Word: Administration, Deprel: nsubj, Head: rejected\n",
      "Word: rejected, Deprel: root, Head: ROOT\n",
      "Word: ImClone, Deprel: nmod:poss, Head: application\n",
      "Word: s, Deprel: case, Head: ImClone\n",
      "Word: original, Deprel: amod, Head: application\n",
      "Word: application, Deprel: obj, Head: rejected\n",
      "Word: in, Deprel: case, Head: December\n",
      "Word: December, Deprel: obl, Head: rejected\n",
      "Word: 2001, Deprel: nummod, Head: December\n",
      "Word: saying, Deprel: advcl, Head: rejected\n",
      "Word: the, Deprel: det, Head: trial\n",
      "Word: trial, Deprel: nsubj:pass, Head: conducted\n",
      "Word: had, Deprel: aux, Head: conducted\n",
      "Word: been, Deprel: aux:pass, Head: conducted\n",
      "Word: sloppily, Deprel: advmod, Head: conducted\n",
      "Word: conducted, Deprel: ccomp, Head: saying\n",
      "\n",
      "Dependencies for Sentence: 'Critics say the law violates civil liberties something House Judiciary Committee Chairman James Sensenbrenner R-Wis says he is sensitive to'\n",
      "Word: Critics, Deprel: nsubj, Head: say\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: law\n",
      "Word: law, Deprel: nsubj, Head: violates\n",
      "Word: violates, Deprel: ccomp, Head: say\n",
      "Word: civil, Deprel: amod, Head: liberties\n",
      "Word: liberties, Deprel: obj, Head: violates\n",
      "Word: something, Deprel: obj, Head: violates\n",
      "Word: House, Deprel: compound, Head: Chairman\n",
      "Word: Judiciary, Deprel: amod, Head: Committee\n",
      "Word: Committee, Deprel: compound, Head: Chairman\n",
      "Word: Chairman, Deprel: nsubj, Head: says\n",
      "Word: James, Deprel: flat, Head: Chairman\n",
      "Word: Sensenbrenner, Deprel: flat, Head: Chairman\n",
      "Word: R-Wis, Deprel: flat, Head: Chairman\n",
      "Word: says, Deprel: acl:relcl, Head: something\n",
      "Word: he, Deprel: nsubj, Head: sensitive\n",
      "Word: is, Deprel: cop, Head: sensitive\n",
      "Word: sensitive, Deprel: ccomp, Head: says\n",
      "Word: to, Deprel: obl, Head: sensitive\n",
      "\n",
      "Dependencies for Sentence: 'House Judiciary Committee Chairman James Sensenbrenner R-Wis says he is sensitive to civil liberties complaints'\n",
      "Word: House, Deprel: compound, Head: Chairman\n",
      "Word: Judiciary, Deprel: amod, Head: Committee\n",
      "Word: Committee, Deprel: compound, Head: Chairman\n",
      "Word: Chairman, Deprel: nsubj, Head: says\n",
      "Word: James, Deprel: flat, Head: Chairman\n",
      "Word: Sensenbrenner, Deprel: flat, Head: Chairman\n",
      "Word: R-Wis, Deprel: flat, Head: Chairman\n",
      "Word: says, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: sensitive\n",
      "Word: is, Deprel: cop, Head: sensitive\n",
      "Word: sensitive, Deprel: ccomp, Head: says\n",
      "Word: to, Deprel: case, Head: complaints\n",
      "Word: civil, Deprel: amod, Head: liberties\n",
      "Word: liberties, Deprel: compound, Head: complaints\n",
      "Word: complaints, Deprel: obl, Head: sensitive\n",
      "\n",
      "Dependencies for Sentence: 'The Dodgers won their sixth consecutive game their longest win streak since 2001 as they edged Colorado 3-2 Wednesday in front of a crowd of 25,332 at Dodger Stadium'\n",
      "Word: The, Deprel: det, Head: Dodgers\n",
      "Word: Dodgers, Deprel: nsubj, Head: won\n",
      "Word: won, Deprel: root, Head: ROOT\n",
      "Word: their, Deprel: nmod:poss, Head: game\n",
      "Word: sixth, Deprel: amod, Head: game\n",
      "Word: consecutive, Deprel: amod, Head: game\n",
      "Word: game, Deprel: obj, Head: won\n",
      "Word: their, Deprel: nmod:poss, Head: streak\n",
      "Word: longest, Deprel: amod, Head: streak\n",
      "Word: win, Deprel: compound, Head: streak\n",
      "Word: streak, Deprel: obj, Head: won\n",
      "Word: since, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: won\n",
      "Word: as, Deprel: mark, Head: edged\n",
      "Word: they, Deprel: nsubj, Head: edged\n",
      "Word: edged, Deprel: advcl, Head: won\n",
      "Word: Colorado, Deprel: obj, Head: edged\n",
      "Word: 3-2, Deprel: nummod, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl:tmod, Head: edged\n",
      "Word: in, Deprel: case, Head: front\n",
      "Word: front, Deprel: obl, Head: edged\n",
      "Word: of, Deprel: case, Head: crowd\n",
      "Word: a, Deprel: det, Head: crowd\n",
      "Word: crowd, Deprel: nmod, Head: front\n",
      "Word: of, Deprel: case, Head: 25,332\n",
      "Word: 25,332, Deprel: nmod, Head: crowd\n",
      "Word: at, Deprel: case, Head: Stadium\n",
      "Word: Dodger, Deprel: compound, Head: Stadium\n",
      "Word: Stadium, Deprel: nmod, Head: crowd\n",
      "\n",
      "Dependencies for Sentence: 'The Dodgers won their sixth consecutive game and seventh in their last nine as they beat Colorado 3-2 on Wednesday in front of a crowd of 25,332 at Dodger Stadium'\n",
      "Word: The, Deprel: det, Head: Dodgers\n",
      "Word: Dodgers, Deprel: nsubj, Head: won\n",
      "Word: won, Deprel: root, Head: ROOT\n",
      "Word: their, Deprel: nmod:poss, Head: game\n",
      "Word: sixth, Deprel: amod, Head: game\n",
      "Word: consecutive, Deprel: amod, Head: game\n",
      "Word: game, Deprel: obj, Head: won\n",
      "Word: and, Deprel: cc, Head: seventh\n",
      "Word: seventh, Deprel: conj, Head: game\n",
      "Word: in, Deprel: case, Head: nine\n",
      "Word: their, Deprel: nmod:poss, Head: nine\n",
      "Word: last, Deprel: amod, Head: nine\n",
      "Word: nine, Deprel: obl, Head: seventh\n",
      "Word: as, Deprel: mark, Head: beat\n",
      "Word: they, Deprel: nsubj, Head: beat\n",
      "Word: beat, Deprel: advcl, Head: won\n",
      "Word: Colorado, Deprel: obj, Head: beat\n",
      "Word: 3-2, Deprel: obj, Head: beat\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: beat\n",
      "Word: in, Deprel: case, Head: front\n",
      "Word: front, Deprel: obl, Head: beat\n",
      "Word: of, Deprel: case, Head: crowd\n",
      "Word: a, Deprel: det, Head: crowd\n",
      "Word: crowd, Deprel: nmod, Head: front\n",
      "Word: of, Deprel: case, Head: 25,332\n",
      "Word: 25,332, Deprel: nmod, Head: crowd\n",
      "Word: at, Deprel: case, Head: Stadium\n",
      "Word: Dodger, Deprel: compound, Head: Stadium\n",
      "Word: Stadium, Deprel: nmod, Head: crowd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'So far they have searched Pennsylvania Ohio Michigan Illinois and Indiana authorities in those state said'\n",
      "Word: So, Deprel: advmod, Head: far\n",
      "Word: far, Deprel: advmod, Head: searched\n",
      "Word: they, Deprel: nsubj, Head: searched\n",
      "Word: have, Deprel: aux, Head: searched\n",
      "Word: searched, Deprel: root, Head: ROOT\n",
      "Word: Pennsylvania, Deprel: compound, Head: Ohio\n",
      "Word: Ohio, Deprel: compound, Head: Illinois\n",
      "Word: Michigan, Deprel: compound, Head: Illinois\n",
      "Word: Illinois, Deprel: obj, Head: searched\n",
      "Word: and, Deprel: cc, Head: authorities\n",
      "Word: Indiana, Deprel: compound, Head: authorities\n",
      "Word: authorities, Deprel: conj, Head: Illinois\n",
      "Word: in, Deprel: case, Head: state\n",
      "Word: those, Deprel: det, Head: state\n",
      "Word: state, Deprel: obl, Head: searched\n",
      "Word: said, Deprel: advcl, Head: searched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'So far authorities also have searched areas in Pennsylvania Ohio Indiana and Michigan'\n",
      "Word: So, Deprel: advmod, Head: far\n",
      "Word: far, Deprel: advmod, Head: searched\n",
      "Word: authorities, Deprel: nsubj, Head: searched\n",
      "Word: also, Deprel: advmod, Head: searched\n",
      "Word: have, Deprel: aux, Head: searched\n",
      "Word: searched, Deprel: root, Head: ROOT\n",
      "Word: areas, Deprel: obj, Head: searched\n",
      "Word: in, Deprel: case, Head: Indiana\n",
      "Word: Pennsylvania, Deprel: compound, Head: Ohio\n",
      "Word: Ohio, Deprel: compound, Head: Indiana\n",
      "Word: Indiana, Deprel: nmod, Head: areas\n",
      "Word: and, Deprel: cc, Head: Michigan\n",
      "Word: Michigan, Deprel: conj, Head: Indiana\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The 30-year bond US30YT=RR firmed 31/32 taking its yield to 4.16 percent another record low from 4.22 percent'\n",
      "Word: The, Deprel: det, Head: bond\n",
      "Word: 30-year, Deprel: amod, Head: bond\n",
      "Word: bond, Deprel: compound, Head: US30YT=RR\n",
      "Word: US30YT=RR, Deprel: nsubj, Head: firmed\n",
      "Word: firmed, Deprel: root, Head: ROOT\n",
      "Word: 31/32, Deprel: obj, Head: firmed\n",
      "Word: taking, Deprel: advcl, Head: firmed\n",
      "Word: its, Deprel: nmod:poss, Head: yield\n",
      "Word: yield, Deprel: obj, Head: taking\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 4.16, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n",
      "Word: another, Deprel: det, Head: low\n",
      "Word: record, Deprel: compound, Head: low\n",
      "Word: low, Deprel: obl:tmod, Head: taking\n",
      "Word: from, Deprel: case, Head: percent\n",
      "Word: 4.22, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The 30-year bond US30YT=RR firmed 24/32 taking its yield to 4.18 percent after hitting another record low of 4.16 percent'\n",
      "Word: The, Deprel: det, Head: bond\n",
      "Word: 30-year, Deprel: amod, Head: bond\n",
      "Word: bond, Deprel: compound, Head: US30YT=RR\n",
      "Word: US30YT=RR, Deprel: nsubj, Head: firmed\n",
      "Word: firmed, Deprel: root, Head: ROOT\n",
      "Word: 24/32, Deprel: obj, Head: firmed\n",
      "Word: taking, Deprel: advcl, Head: firmed\n",
      "Word: its, Deprel: nmod:poss, Head: yield\n",
      "Word: yield, Deprel: obj, Head: taking\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 4.18, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n",
      "Word: after, Deprel: mark, Head: hitting\n",
      "Word: hitting, Deprel: advcl, Head: taking\n",
      "Word: another, Deprel: det, Head: low\n",
      "Word: record, Deprel: amod, Head: low\n",
      "Word: low, Deprel: obj, Head: hitting\n",
      "Word: of, Deprel: case, Head: percent\n",
      "Word: 4.16, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: nmod, Head: low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Thursday a Washington Post article argued that a 50 basis point cut from the Fed was more likely contrary to the Wall Street Journal s line'\n",
      "Word: On, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: argued\n",
      "Word: a, Deprel: det, Head: article\n",
      "Word: Washington, Deprel: compound, Head: Post\n",
      "Word: Post, Deprel: compound, Head: article\n",
      "Word: article, Deprel: nsubj, Head: argued\n",
      "Word: argued, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: likely\n",
      "Word: a, Deprel: det, Head: cut\n",
      "Word: 50, Deprel: nummod, Head: basis\n",
      "Word: basis, Deprel: compound, Head: cut\n",
      "Word: point, Deprel: compound, Head: cut\n",
      "Word: cut, Deprel: nsubj, Head: likely\n",
      "Word: from, Deprel: case, Head: Fed\n",
      "Word: the, Deprel: det, Head: Fed\n",
      "Word: Fed, Deprel: nmod, Head: cut\n",
      "Word: was, Deprel: cop, Head: likely\n",
      "Word: more, Deprel: advmod, Head: likely\n",
      "Word: likely, Deprel: ccomp, Head: argued\n",
      "Word: contrary, Deprel: xcomp, Head: likely\n",
      "Word: to, Deprel: case, Head: line\n",
      "Word: the, Deprel: det, Head: Journal\n",
      "Word: Wall, Deprel: compound, Head: Street\n",
      "Word: Street, Deprel: compound, Head: Journal\n",
      "Word: Journal, Deprel: nmod:poss, Head: line\n",
      "Word: s, Deprel: case, Head: Journal\n",
      "Word: line, Deprel: obl, Head: contrary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Thursday a Post article argued that a 50 basis point cut from the Fed was more likely'\n",
      "Word: On, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: argued\n",
      "Word: a, Deprel: det, Head: article\n",
      "Word: Post, Deprel: compound, Head: article\n",
      "Word: article, Deprel: nsubj, Head: argued\n",
      "Word: argued, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: likely\n",
      "Word: a, Deprel: det, Head: cut\n",
      "Word: 50, Deprel: nummod, Head: basis\n",
      "Word: basis, Deprel: compound, Head: cut\n",
      "Word: point, Deprel: compound, Head: cut\n",
      "Word: cut, Deprel: nsubj, Head: likely\n",
      "Word: from, Deprel: case, Head: Fed\n",
      "Word: the, Deprel: det, Head: Fed\n",
      "Word: Fed, Deprel: nmod, Head: cut\n",
      "Word: was, Deprel: cop, Head: likely\n",
      "Word: more, Deprel: advmod, Head: likely\n",
      "Word: likely, Deprel: ccomp, Head: argued\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Heatley who suffered a broken jaw and torn knee ligaments faces several charges'\n",
      "Word: Mr, Deprel: nsubj, Head: faces\n",
      "Word: Heatley, Deprel: flat, Head: Mr\n",
      "Word: who, Deprel: nsubj, Head: suffered\n",
      "Word: suffered, Deprel: acl:relcl, Head: Mr\n",
      "Word: a, Deprel: det, Head: jaw\n",
      "Word: broken, Deprel: amod, Head: jaw\n",
      "Word: jaw, Deprel: obj, Head: suffered\n",
      "Word: and, Deprel: cc, Head: ligaments\n",
      "Word: torn, Deprel: amod, Head: ligaments\n",
      "Word: knee, Deprel: compound, Head: ligaments\n",
      "Word: ligaments, Deprel: conj, Head: jaw\n",
      "Word: faces, Deprel: root, Head: ROOT\n",
      "Word: several, Deprel: amod, Head: charges\n",
      "Word: charges, Deprel: obj, Head: faces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Heatley underwent surgery Saturday for a broken jaw and an MRI found two torn ligaments in his right knee'\n",
      "Word: Heatley, Deprel: nsubj, Head: underwent\n",
      "Word: underwent, Deprel: root, Head: ROOT\n",
      "Word: surgery, Deprel: obj, Head: underwent\n",
      "Word: Saturday, Deprel: obl:tmod, Head: underwent\n",
      "Word: for, Deprel: case, Head: jaw\n",
      "Word: a, Deprel: det, Head: jaw\n",
      "Word: broken, Deprel: amod, Head: jaw\n",
      "Word: jaw, Deprel: obl, Head: underwent\n",
      "Word: and, Deprel: cc, Head: found\n",
      "Word: an, Deprel: det, Head: MRI\n",
      "Word: MRI, Deprel: nsubj, Head: found\n",
      "Word: found, Deprel: conj, Head: underwent\n",
      "Word: two, Deprel: nummod, Head: ligaments\n",
      "Word: torn, Deprel: amod, Head: ligaments\n",
      "Word: ligaments, Deprel: obj, Head: found\n",
      "Word: in, Deprel: case, Head: knee\n",
      "Word: his, Deprel: nmod:poss, Head: knee\n",
      "Word: right, Deprel: amod, Head: knee\n",
      "Word: knee, Deprel: obl, Head: found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Lay had argued that handing over the documents would be a violation of his Fifth Amendment rights against self-incrimination'\n",
      "Word: Lay, Deprel: nsubj, Head: argued\n",
      "Word: had, Deprel: aux, Head: argued\n",
      "Word: argued, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: violation\n",
      "Word: handing, Deprel: csubj, Head: violation\n",
      "Word: over, Deprel: compound:prt, Head: handing\n",
      "Word: the, Deprel: det, Head: documents\n",
      "Word: documents, Deprel: obj, Head: handing\n",
      "Word: would, Deprel: aux, Head: violation\n",
      "Word: be, Deprel: cop, Head: violation\n",
      "Word: a, Deprel: det, Head: violation\n",
      "Word: violation, Deprel: ccomp, Head: argued\n",
      "Word: of, Deprel: case, Head: rights\n",
      "Word: his, Deprel: nmod:poss, Head: rights\n",
      "Word: Fifth, Deprel: amod, Head: Amendment\n",
      "Word: Amendment, Deprel: compound, Head: rights\n",
      "Word: rights, Deprel: nmod, Head: violation\n",
      "Word: against, Deprel: case, Head: self-incrimination\n",
      "Word: self-incrimination, Deprel: nmod, Head: rights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Lay had refused to turn over the papers asserting his Fifth Amendment right against self-incrimination'\n",
      "Word: Lay, Deprel: nsubj, Head: refused\n",
      "Word: had, Deprel: aux, Head: refused\n",
      "Word: refused, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: turn\n",
      "Word: turn, Deprel: xcomp, Head: refused\n",
      "Word: over, Deprel: compound:prt, Head: turn\n",
      "Word: the, Deprel: det, Head: papers\n",
      "Word: papers, Deprel: obj, Head: turn\n",
      "Word: asserting, Deprel: acl, Head: papers\n",
      "Word: his, Deprel: nmod:poss, Head: right\n",
      "Word: Fifth, Deprel: amod, Head: Amendment\n",
      "Word: Amendment, Deprel: compound, Head: right\n",
      "Word: right, Deprel: obj, Head: asserting\n",
      "Word: against, Deprel: case, Head: self-incrimination\n",
      "Word: self-incrimination, Deprel: nmod, Head: right\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Strayhorn said it was the first time in Texas history a comptroller had not certified the appropriations act'\n",
      "Word: Strayhorn, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: time\n",
      "Word: was, Deprel: cop, Head: time\n",
      "Word: the, Deprel: det, Head: time\n",
      "Word: first, Deprel: amod, Head: time\n",
      "Word: time, Deprel: ccomp, Head: said\n",
      "Word: in, Deprel: case, Head: history\n",
      "Word: Texas, Deprel: compound, Head: history\n",
      "Word: history, Deprel: nmod, Head: time\n",
      "Word: a, Deprel: det, Head: comptroller\n",
      "Word: comptroller, Deprel: nsubj, Head: certified\n",
      "Word: had, Deprel: aux, Head: certified\n",
      "Word: not, Deprel: advmod, Head: certified\n",
      "Word: certified, Deprel: acl:relcl, Head: time\n",
      "Word: the, Deprel: det, Head: act\n",
      "Word: appropriations, Deprel: compound, Head: act\n",
      "Word: act, Deprel: obj, Head: certified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In a news release Thursday Strayhorn said this was the first time a comptroller rejected a budget'\n",
      "Word: In, Deprel: case, Head: release\n",
      "Word: a, Deprel: det, Head: release\n",
      "Word: news, Deprel: compound, Head: release\n",
      "Word: release, Deprel: obl, Head: said\n",
      "Word: Thursday, Deprel: nmod:tmod, Head: release\n",
      "Word: Strayhorn, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: this, Deprel: nsubj, Head: time\n",
      "Word: was, Deprel: cop, Head: time\n",
      "Word: the, Deprel: det, Head: time\n",
      "Word: first, Deprel: amod, Head: time\n",
      "Word: time, Deprel: ccomp, Head: said\n",
      "Word: a, Deprel: det, Head: comptroller\n",
      "Word: comptroller, Deprel: nsubj, Head: rejected\n",
      "Word: rejected, Deprel: acl:relcl, Head: time\n",
      "Word: a, Deprel: det, Head: budget\n",
      "Word: budget, Deprel: obj, Head: rejected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Excluding the charges analysts on average expected a loss of 11 cents a share'\n",
      "Word: Excluding, Deprel: advcl, Head: expected\n",
      "Word: the, Deprel: det, Head: charges\n",
      "Word: charges, Deprel: compound, Head: analysts\n",
      "Word: analysts, Deprel: nsubj, Head: expected\n",
      "Word: on, Deprel: case, Head: average\n",
      "Word: average, Deprel: nmod, Head: analysts\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: loss\n",
      "Word: loss, Deprel: obj, Head: expected\n",
      "Word: of, Deprel: case, Head: cents\n",
      "Word: 11, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: nmod, Head: loss\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:npmod, Head: cents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Analysts polled by Thomson Financial First Call had been expected to see a loss of about 11 cents a share from continuing operations'\n",
      "Word: Analysts, Deprel: nsubj:pass, Head: expected\n",
      "Word: polled, Deprel: acl, Head: Analysts\n",
      "Word: by, Deprel: case, Head: Call\n",
      "Word: Thomson, Deprel: compound, Head: Financial\n",
      "Word: Financial, Deprel: compound, Head: Call\n",
      "Word: First, Deprel: amod, Head: Call\n",
      "Word: Call, Deprel: obl, Head: polled\n",
      "Word: had, Deprel: aux, Head: expected\n",
      "Word: been, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: see\n",
      "Word: see, Deprel: xcomp, Head: expected\n",
      "Word: a, Deprel: det, Head: loss\n",
      "Word: loss, Deprel: obj, Head: see\n",
      "Word: of, Deprel: case, Head: cents\n",
      "Word: about, Deprel: advmod, Head: 11\n",
      "Word: 11, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: nmod, Head: loss\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:tmod, Head: cents\n",
      "Word: from, Deprel: case, Head: operations\n",
      "Word: continuing, Deprel: compound, Head: operations\n",
      "Word: operations, Deprel: nmod, Head: loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Security experts are warning that a new mass-mailing worm is spreading widely across the Internet sometimes posing as e-mail from the Microsoft founder'\n",
      "Word: Security, Deprel: compound, Head: experts\n",
      "Word: experts, Deprel: nsubj, Head: warning\n",
      "Word: are, Deprel: aux, Head: warning\n",
      "Word: warning, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: spreading\n",
      "Word: a, Deprel: det, Head: worm\n",
      "Word: new, Deprel: amod, Head: worm\n",
      "Word: mass-mailing, Deprel: amod, Head: worm\n",
      "Word: worm, Deprel: nsubj, Head: spreading\n",
      "Word: is, Deprel: aux, Head: spreading\n",
      "Word: spreading, Deprel: ccomp, Head: warning\n",
      "Word: widely, Deprel: advmod, Head: spreading\n",
      "Word: across, Deprel: case, Head: Internet\n",
      "Word: the, Deprel: det, Head: Internet\n",
      "Word: Internet, Deprel: obl, Head: spreading\n",
      "Word: sometimes, Deprel: advmod, Head: posing\n",
      "Word: posing, Deprel: advcl, Head: spreading\n",
      "Word: as, Deprel: case, Head: e-mail\n",
      "Word: e-mail, Deprel: obl, Head: posing\n",
      "Word: from, Deprel: case, Head: founder\n",
      "Word: the, Deprel: det, Head: founder\n",
      "Word: Microsoft, Deprel: compound, Head: founder\n",
      "Word: founder, Deprel: nmod, Head: e-mail\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A new worm has been spreading rapidly across the Internet sometimes pretending to be an e-mail from Microsoft Chairman Bill Gates antivirus vendors said Monday'\n",
      "Word: A, Deprel: det, Head: worm\n",
      "Word: new, Deprel: amod, Head: worm\n",
      "Word: worm, Deprel: nsubj, Head: spreading\n",
      "Word: has, Deprel: aux, Head: spreading\n",
      "Word: been, Deprel: aux, Head: spreading\n",
      "Word: spreading, Deprel: ccomp, Head: said\n",
      "Word: rapidly, Deprel: advmod, Head: spreading\n",
      "Word: across, Deprel: case, Head: Internet\n",
      "Word: the, Deprel: det, Head: Internet\n",
      "Word: Internet, Deprel: obl, Head: spreading\n",
      "Word: sometimes, Deprel: advmod, Head: pretending\n",
      "Word: pretending, Deprel: advcl, Head: spreading\n",
      "Word: to, Deprel: mark, Head: e-mail\n",
      "Word: be, Deprel: cop, Head: e-mail\n",
      "Word: an, Deprel: det, Head: e-mail\n",
      "Word: e-mail, Deprel: xcomp, Head: pretending\n",
      "Word: from, Deprel: case, Head: vendors\n",
      "Word: Microsoft, Deprel: compound, Head: Chairman\n",
      "Word: Chairman, Deprel: compound, Head: vendors\n",
      "Word: Bill, Deprel: flat, Head: Chairman\n",
      "Word: Gates, Deprel: flat, Head: Bill\n",
      "Word: antivirus, Deprel: compound, Head: vendors\n",
      "Word: vendors, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Monday, Deprel: obj, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Sahel said police had identified the bodies of seven of the 14-strong cell believed to have carried out the five almost simultaneous attacks on Saturday'\n",
      "Word: Mr, Deprel: nsubj, Head: said\n",
      "Word: Sahel, Deprel: flat, Head: Mr\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: police, Deprel: nsubj, Head: identified\n",
      "Word: had, Deprel: aux, Head: identified\n",
      "Word: identified, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: bodies\n",
      "Word: bodies, Deprel: obj, Head: identified\n",
      "Word: of, Deprel: case, Head: seven\n",
      "Word: seven, Deprel: nmod, Head: bodies\n",
      "Word: of, Deprel: case, Head: cell\n",
      "Word: the, Deprel: det, Head: cell\n",
      "Word: 14-strong, Deprel: amod, Head: cell\n",
      "Word: cell, Deprel: nmod, Head: seven\n",
      "Word: believed, Deprel: acl, Head: cell\n",
      "Word: to, Deprel: mark, Head: carried\n",
      "Word: have, Deprel: aux, Head: carried\n",
      "Word: carried, Deprel: xcomp, Head: believed\n",
      "Word: out, Deprel: compound:prt, Head: carried\n",
      "Word: the, Deprel: det, Head: attacks\n",
      "Word: five, Deprel: nummod, Head: attacks\n",
      "Word: almost, Deprel: advmod, Head: simultaneous\n",
      "Word: simultaneous, Deprel: amod, Head: attacks\n",
      "Word: attacks, Deprel: obj, Head: carried\n",
      "Word: on, Deprel: case, Head: Saturday\n",
      "Word: Saturday, Deprel: nmod, Head: attacks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He said police had identified the bodies of seven of the 14 bombers who launched five almost simultaneous raids Friday night'\n",
      "Word: He, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: police, Deprel: nsubj, Head: identified\n",
      "Word: had, Deprel: aux, Head: identified\n",
      "Word: identified, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: bodies\n",
      "Word: bodies, Deprel: obj, Head: identified\n",
      "Word: of, Deprel: case, Head: seven\n",
      "Word: seven, Deprel: nmod, Head: bodies\n",
      "Word: of, Deprel: case, Head: bombers\n",
      "Word: the, Deprel: det, Head: bombers\n",
      "Word: 14, Deprel: nummod, Head: bombers\n",
      "Word: bombers, Deprel: nmod, Head: seven\n",
      "Word: who, Deprel: nsubj, Head: launched\n",
      "Word: launched, Deprel: acl:relcl, Head: bombers\n",
      "Word: five, Deprel: nummod, Head: raids\n",
      "Word: almost, Deprel: advmod, Head: simultaneous\n",
      "Word: simultaneous, Deprel: amod, Head: raids\n",
      "Word: raids, Deprel: obj, Head: launched\n",
      "Word: Friday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: launched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Only New Jersey now bans holders of learners permits or intermediate licenses from using cell phones pagers or other wireless devices while driving'\n",
      "Word: Only, Deprel: advmod, Head: Jersey\n",
      "Word: New, Deprel: amod, Head: Jersey\n",
      "Word: Jersey, Deprel: nsubj, Head: bans\n",
      "Word: now, Deprel: advmod, Head: bans\n",
      "Word: bans, Deprel: root, Head: ROOT\n",
      "Word: holders, Deprel: obj, Head: bans\n",
      "Word: of, Deprel: case, Head: permits\n",
      "Word: learners, Deprel: compound, Head: permits\n",
      "Word: permits, Deprel: nmod, Head: holders\n",
      "Word: or, Deprel: cc, Head: licenses\n",
      "Word: intermediate, Deprel: amod, Head: licenses\n",
      "Word: licenses, Deprel: conj, Head: permits\n",
      "Word: from, Deprel: mark, Head: using\n",
      "Word: using, Deprel: advcl, Head: bans\n",
      "Word: cell, Deprel: compound, Head: phones\n",
      "Word: phones, Deprel: compound, Head: pagers\n",
      "Word: pagers, Deprel: obj, Head: using\n",
      "Word: or, Deprel: cc, Head: devices\n",
      "Word: other, Deprel: amod, Head: devices\n",
      "Word: wireless, Deprel: amod, Head: devices\n",
      "Word: devices, Deprel: conj, Head: pagers\n",
      "Word: while, Deprel: mark, Head: driving\n",
      "Word: driving, Deprel: advcl, Head: using\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In addition the NTSB also recommended to NHTSA that state legislation be enacted to prohibit holders of learners permits and intermediate licenses from using mobile phones while driving'\n",
      "Word: In, Deprel: case, Head: addition\n",
      "Word: addition, Deprel: obl, Head: recommended\n",
      "Word: the, Deprel: det, Head: NTSB\n",
      "Word: NTSB, Deprel: nsubj, Head: recommended\n",
      "Word: also, Deprel: advmod, Head: recommended\n",
      "Word: recommended, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: NHTSA\n",
      "Word: NHTSA, Deprel: obl, Head: recommended\n",
      "Word: that, Deprel: mark, Head: enacted\n",
      "Word: state, Deprel: compound, Head: legislation\n",
      "Word: legislation, Deprel: nsubj:pass, Head: enacted\n",
      "Word: be, Deprel: aux:pass, Head: enacted\n",
      "Word: enacted, Deprel: ccomp, Head: recommended\n",
      "Word: to, Deprel: mark, Head: prohibit\n",
      "Word: prohibit, Deprel: advcl, Head: enacted\n",
      "Word: holders, Deprel: obj, Head: prohibit\n",
      "Word: of, Deprel: case, Head: permits\n",
      "Word: learners, Deprel: compound, Head: permits\n",
      "Word: permits, Deprel: nmod, Head: holders\n",
      "Word: and, Deprel: cc, Head: licenses\n",
      "Word: intermediate, Deprel: amod, Head: licenses\n",
      "Word: licenses, Deprel: conj, Head: permits\n",
      "Word: from, Deprel: mark, Head: using\n",
      "Word: using, Deprel: advcl, Head: prohibit\n",
      "Word: mobile, Deprel: amod, Head: phones\n",
      "Word: phones, Deprel: obj, Head: using\n",
      "Word: while, Deprel: mark, Head: driving\n",
      "Word: driving, Deprel: advcl, Head: using\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The University of Michigan released today a new admissions policy after the U.S Supreme Court struck down in June the way it previously admitted undergraduates'\n",
      "Word: The, Deprel: det, Head: University\n",
      "Word: University, Deprel: nsubj, Head: released\n",
      "Word: of, Deprel: case, Head: Michigan\n",
      "Word: Michigan, Deprel: nmod, Head: University\n",
      "Word: released, Deprel: root, Head: ROOT\n",
      "Word: today, Deprel: obl:tmod, Head: released\n",
      "Word: a, Deprel: det, Head: policy\n",
      "Word: new, Deprel: amod, Head: policy\n",
      "Word: admissions, Deprel: compound, Head: policy\n",
      "Word: policy, Deprel: obj, Head: released\n",
      "Word: after, Deprel: mark, Head: struck\n",
      "Word: the, Deprel: det, Head: Court\n",
      "Word: U.S, Deprel: compound, Head: Court\n",
      "Word: Supreme, Deprel: amod, Head: Court\n",
      "Word: Court, Deprel: nsubj, Head: struck\n",
      "Word: struck, Deprel: advcl, Head: released\n",
      "Word: down, Deprel: compound:prt, Head: struck\n",
      "Word: in, Deprel: case, Head: June\n",
      "Word: June, Deprel: obl, Head: struck\n",
      "Word: the, Deprel: det, Head: way\n",
      "Word: way, Deprel: obl:npmod, Head: struck\n",
      "Word: it, Deprel: nsubj, Head: admitted\n",
      "Word: previously, Deprel: advmod, Head: admitted\n",
      "Word: admitted, Deprel: acl:relcl, Head: way\n",
      "Word: undergraduates, Deprel: obj, Head: admitted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The University of Michigan plans to release a new undergraduate admissions policy Thursday after its acceptance requirements were rejected by the U.S Supreme Court in June'\n",
      "Word: The, Deprel: det, Head: University\n",
      "Word: University, Deprel: nsubj, Head: plans\n",
      "Word: of, Deprel: case, Head: Michigan\n",
      "Word: Michigan, Deprel: nmod, Head: University\n",
      "Word: plans, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: release\n",
      "Word: release, Deprel: xcomp, Head: plans\n",
      "Word: a, Deprel: det, Head: policy\n",
      "Word: new, Deprel: amod, Head: policy\n",
      "Word: undergraduate, Deprel: amod, Head: policy\n",
      "Word: admissions, Deprel: compound, Head: policy\n",
      "Word: policy, Deprel: obj, Head: release\n",
      "Word: Thursday, Deprel: obl:tmod, Head: release\n",
      "Word: after, Deprel: mark, Head: rejected\n",
      "Word: its, Deprel: nmod:poss, Head: requirements\n",
      "Word: acceptance, Deprel: compound, Head: requirements\n",
      "Word: requirements, Deprel: nsubj:pass, Head: rejected\n",
      "Word: were, Deprel: aux:pass, Head: rejected\n",
      "Word: rejected, Deprel: advcl, Head: release\n",
      "Word: by, Deprel: case, Head: Court\n",
      "Word: the, Deprel: det, Head: Court\n",
      "Word: U.S, Deprel: compound, Head: Court\n",
      "Word: Supreme, Deprel: amod, Head: Court\n",
      "Word: Court, Deprel: obl, Head: rejected\n",
      "Word: in, Deprel: case, Head: June\n",
      "Word: June, Deprel: nmod, Head: Court\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The audiotape aired last week by the Arab Al-Jazeera television network appears to be an effort to incite attacks'\n",
      "Word: The, Deprel: det, Head: audiotape\n",
      "Word: audiotape, Deprel: nsubj, Head: appears\n",
      "Word: aired, Deprel: acl, Head: audiotape\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: aired\n",
      "Word: by, Deprel: case, Head: network\n",
      "Word: the, Deprel: det, Head: network\n",
      "Word: Arab, Deprel: amod, Head: network\n",
      "Word: Al-Jazeera, Deprel: compound, Head: network\n",
      "Word: television, Deprel: compound, Head: network\n",
      "Word: network, Deprel: obl, Head: aired\n",
      "Word: appears, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: effort\n",
      "Word: be, Deprel: cop, Head: effort\n",
      "Word: an, Deprel: det, Head: effort\n",
      "Word: effort, Deprel: xcomp, Head: appears\n",
      "Word: to, Deprel: mark, Head: incite\n",
      "Word: incite, Deprel: acl, Head: effort\n",
      "Word: attacks, Deprel: obj, Head: incite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'An audiotape aired last week by the Arab al-Jazeera television network may be the strongest evidence yet that Saddam survived the war'\n",
      "Word: An, Deprel: det, Head: audiotape\n",
      "Word: audiotape, Deprel: nsubj, Head: evidence\n",
      "Word: aired, Deprel: acl, Head: audiotape\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: aired\n",
      "Word: by, Deprel: case, Head: network\n",
      "Word: the, Deprel: det, Head: network\n",
      "Word: Arab, Deprel: amod, Head: network\n",
      "Word: al-Jazeera, Deprel: compound, Head: network\n",
      "Word: television, Deprel: compound, Head: network\n",
      "Word: network, Deprel: obl, Head: aired\n",
      "Word: may, Deprel: aux, Head: evidence\n",
      "Word: be, Deprel: cop, Head: evidence\n",
      "Word: the, Deprel: det, Head: evidence\n",
      "Word: strongest, Deprel: amod, Head: evidence\n",
      "Word: evidence, Deprel: root, Head: ROOT\n",
      "Word: yet, Deprel: advmod, Head: evidence\n",
      "Word: that, Deprel: mark, Head: survived\n",
      "Word: Saddam, Deprel: nsubj, Head: survived\n",
      "Word: survived, Deprel: acl:relcl, Head: evidence\n",
      "Word: the, Deprel: det, Head: war\n",
      "Word: war, Deprel: obj, Head: survived\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Former company chief financial officer Franklyn M Bergonzi pleaded guilty to one count of conspiracy on June 5 and agreed to cooperate with prosecutors'\n",
      "Word: Former, Deprel: amod, Head: officer\n",
      "Word: company, Deprel: compound, Head: officer\n",
      "Word: chief, Deprel: amod, Head: officer\n",
      "Word: financial, Deprel: amod, Head: officer\n",
      "Word: officer, Deprel: compound, Head: Franklyn\n",
      "Word: Franklyn, Deprel: nsubj, Head: pleaded\n",
      "Word: M, Deprel: flat, Head: Franklyn\n",
      "Word: Bergonzi, Deprel: flat, Head: Franklyn\n",
      "Word: pleaded, Deprel: root, Head: ROOT\n",
      "Word: guilty, Deprel: obj, Head: pleaded\n",
      "Word: to, Deprel: case, Head: count\n",
      "Word: one, Deprel: nummod, Head: count\n",
      "Word: count, Deprel: obl, Head: pleaded\n",
      "Word: of, Deprel: case, Head: conspiracy\n",
      "Word: conspiracy, Deprel: nmod, Head: count\n",
      "Word: on, Deprel: case, Head: June\n",
      "Word: June, Deprel: nmod, Head: count\n",
      "Word: 5, Deprel: nummod, Head: June\n",
      "Word: and, Deprel: cc, Head: agreed\n",
      "Word: agreed, Deprel: conj, Head: pleaded\n",
      "Word: to, Deprel: mark, Head: cooperate\n",
      "Word: cooperate, Deprel: xcomp, Head: agreed\n",
      "Word: with, Deprel: case, Head: prosecutors\n",
      "Word: prosecutors, Deprel: obl, Head: cooperate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Last week former chief financial officer Franklyn Bergonzi pleaded guilty to one count of conspiracy and agreed to cooperate with the government s investigation'\n",
      "Word: Last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: pleaded\n",
      "Word: former, Deprel: amod, Head: Franklyn\n",
      "Word: chief, Deprel: amod, Head: officer\n",
      "Word: financial, Deprel: amod, Head: officer\n",
      "Word: officer, Deprel: compound, Head: Franklyn\n",
      "Word: Franklyn, Deprel: nsubj, Head: pleaded\n",
      "Word: Bergonzi, Deprel: flat, Head: Franklyn\n",
      "Word: pleaded, Deprel: root, Head: ROOT\n",
      "Word: guilty, Deprel: obj, Head: pleaded\n",
      "Word: to, Deprel: case, Head: count\n",
      "Word: one, Deprel: nummod, Head: count\n",
      "Word: count, Deprel: obl, Head: pleaded\n",
      "Word: of, Deprel: case, Head: conspiracy\n",
      "Word: conspiracy, Deprel: nmod, Head: count\n",
      "Word: and, Deprel: cc, Head: agreed\n",
      "Word: agreed, Deprel: conj, Head: pleaded\n",
      "Word: to, Deprel: mark, Head: cooperate\n",
      "Word: cooperate, Deprel: xcomp, Head: agreed\n",
      "Word: with, Deprel: case, Head: investigation\n",
      "Word: the, Deprel: det, Head: government\n",
      "Word: government, Deprel: nmod:poss, Head: investigation\n",
      "Word: s, Deprel: case, Head: government\n",
      "Word: investigation, Deprel: obl, Head: cooperate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The company did n't detail the costs of the replacement and repairs'\n",
      "Word: The, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: detail\n",
      "Word: did, Deprel: aux, Head: detail\n",
      "Word: n't, Deprel: advmod, Head: detail\n",
      "Word: detail, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: costs\n",
      "Word: costs, Deprel: obj, Head: detail\n",
      "Word: of, Deprel: case, Head: replacement\n",
      "Word: the, Deprel: det, Head: replacement\n",
      "Word: replacement, Deprel: nmod, Head: costs\n",
      "Word: and, Deprel: cc, Head: repairs\n",
      "Word: repairs, Deprel: conj, Head: replacement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But company officials expect the costs of the replacement work to run into the millions of dollars'\n",
      "Word: But, Deprel: cc, Head: expect\n",
      "Word: company, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: expect\n",
      "Word: expect, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: costs\n",
      "Word: costs, Deprel: obj, Head: expect\n",
      "Word: of, Deprel: case, Head: work\n",
      "Word: the, Deprel: det, Head: work\n",
      "Word: replacement, Deprel: compound, Head: work\n",
      "Word: work, Deprel: nmod, Head: costs\n",
      "Word: to, Deprel: mark, Head: run\n",
      "Word: run, Deprel: acl, Head: costs\n",
      "Word: into, Deprel: case, Head: millions\n",
      "Word: the, Deprel: det, Head: millions\n",
      "Word: millions, Deprel: obl, Head: run\n",
      "Word: of, Deprel: case, Head: dollars\n",
      "Word: dollars, Deprel: nmod, Head: millions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dean told reporters traveling on his 10-city Sleepless Summer tour that he considered campaigning in Texas a challenge'\n",
      "Word: Dean, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: reporters, Deprel: iobj, Head: told\n",
      "Word: traveling, Deprel: xcomp, Head: told\n",
      "Word: on, Deprel: case, Head: tour\n",
      "Word: his, Deprel: nmod:poss, Head: tour\n",
      "Word: 10-city, Deprel: amod, Head: tour\n",
      "Word: Sleepless, Deprel: compound, Head: tour\n",
      "Word: Summer, Deprel: compound, Head: tour\n",
      "Word: tour, Deprel: obl, Head: traveling\n",
      "Word: that, Deprel: mark, Head: considered\n",
      "Word: he, Deprel: nsubj, Head: considered\n",
      "Word: considered, Deprel: ccomp, Head: traveling\n",
      "Word: campaigning, Deprel: xcomp, Head: considered\n",
      "Word: in, Deprel: case, Head: Texas\n",
      "Word: Texas, Deprel: obl, Head: campaigning\n",
      "Word: a, Deprel: det, Head: challenge\n",
      "Word: challenge, Deprel: obj, Head: campaigning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Today Dean ends his four-day 10-city Sleepless Summer tour in Chicago and New York'\n",
      "Word: Today, Deprel: obl:tmod, Head: ends\n",
      "Word: Dean, Deprel: nsubj, Head: ends\n",
      "Word: ends, Deprel: root, Head: ROOT\n",
      "Word: his, Deprel: nmod:poss, Head: tour\n",
      "Word: four-day, Deprel: amod, Head: tour\n",
      "Word: 10-city, Deprel: compound, Head: tour\n",
      "Word: Sleepless, Deprel: compound, Head: tour\n",
      "Word: Summer, Deprel: compound, Head: tour\n",
      "Word: tour, Deprel: obj, Head: ends\n",
      "Word: in, Deprel: case, Head: Chicago\n",
      "Word: Chicago, Deprel: nmod, Head: tour\n",
      "Word: and, Deprel: cc, Head: York\n",
      "Word: New, Deprel: amod, Head: York\n",
      "Word: York, Deprel: conj, Head: Chicago\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I felt that if I disagreed with Rosie too much I would lose my job she said'\n",
      "Word: I, Deprel: nsubj, Head: felt\n",
      "Word: felt, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: lose\n",
      "Word: if, Deprel: mark, Head: disagreed\n",
      "Word: I, Deprel: nsubj, Head: disagreed\n",
      "Word: disagreed, Deprel: advcl, Head: lose\n",
      "Word: with, Deprel: case, Head: Rosie\n",
      "Word: Rosie, Deprel: obl, Head: disagreed\n",
      "Word: too, Deprel: advmod, Head: much\n",
      "Word: much, Deprel: advmod, Head: disagreed\n",
      "Word: I, Deprel: nsubj, Head: lose\n",
      "Word: would, Deprel: aux, Head: lose\n",
      "Word: lose, Deprel: ccomp, Head: felt\n",
      "Word: my, Deprel: nmod:poss, Head: job\n",
      "Word: job, Deprel: obj, Head: lose\n",
      "Word: she, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: felt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Cavender did say I felt that if I disagreed with Rosie too much I would lose my job'\n",
      "Word: Cavender, Deprel: nsubj, Head: say\n",
      "Word: did, Deprel: aux, Head: say\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: I, Deprel: nsubj, Head: felt\n",
      "Word: felt, Deprel: ccomp, Head: say\n",
      "Word: that, Deprel: mark, Head: lose\n",
      "Word: if, Deprel: mark, Head: disagreed\n",
      "Word: I, Deprel: nsubj, Head: disagreed\n",
      "Word: disagreed, Deprel: advcl, Head: lose\n",
      "Word: with, Deprel: case, Head: Rosie\n",
      "Word: Rosie, Deprel: obl, Head: disagreed\n",
      "Word: too, Deprel: advmod, Head: much\n",
      "Word: much, Deprel: advmod, Head: disagreed\n",
      "Word: I, Deprel: nsubj, Head: lose\n",
      "Word: would, Deprel: aux, Head: lose\n",
      "Word: lose, Deprel: ccomp, Head: felt\n",
      "Word: my, Deprel: nmod:poss, Head: job\n",
      "Word: job, Deprel: obj, Head: lose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The device plays Internet radio streams and comes with a 30-day trial of RealNetworks Rhapsody music service'\n",
      "Word: The, Deprel: det, Head: device\n",
      "Word: device, Deprel: nsubj, Head: plays\n",
      "Word: plays, Deprel: root, Head: ROOT\n",
      "Word: Internet, Deprel: compound, Head: streams\n",
      "Word: radio, Deprel: compound, Head: streams\n",
      "Word: streams, Deprel: obj, Head: plays\n",
      "Word: and, Deprel: cc, Head: comes\n",
      "Word: comes, Deprel: conj, Head: plays\n",
      "Word: with, Deprel: case, Head: trial\n",
      "Word: a, Deprel: det, Head: trial\n",
      "Word: 30-day, Deprel: amod, Head: trial\n",
      "Word: trial, Deprel: obl, Head: comes\n",
      "Word: of, Deprel: case, Head: service\n",
      "Word: RealNetworks, Deprel: compound, Head: Rhapsody\n",
      "Word: Rhapsody, Deprel: compound, Head: service\n",
      "Word: music, Deprel: compound, Head: service\n",
      "Word: service, Deprel: nmod, Head: trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The product also streams Internet radio and comes with a 30-day free trial for RealNetworks Rhapsody digital music subscription service'\n",
      "Word: The, Deprel: det, Head: product\n",
      "Word: product, Deprel: nsubj, Head: streams\n",
      "Word: also, Deprel: advmod, Head: streams\n",
      "Word: streams, Deprel: root, Head: ROOT\n",
      "Word: Internet, Deprel: compound, Head: radio\n",
      "Word: radio, Deprel: obj, Head: streams\n",
      "Word: and, Deprel: cc, Head: comes\n",
      "Word: comes, Deprel: conj, Head: streams\n",
      "Word: with, Deprel: case, Head: trial\n",
      "Word: a, Deprel: det, Head: trial\n",
      "Word: 30-day, Deprel: compound, Head: trial\n",
      "Word: free, Deprel: amod, Head: trial\n",
      "Word: trial, Deprel: obl, Head: comes\n",
      "Word: for, Deprel: case, Head: service\n",
      "Word: RealNetworks, Deprel: compound, Head: Rhapsody\n",
      "Word: Rhapsody, Deprel: compound, Head: service\n",
      "Word: digital, Deprel: amod, Head: music\n",
      "Word: music, Deprel: compound, Head: service\n",
      "Word: subscription, Deprel: compound, Head: service\n",
      "Word: service, Deprel: nmod, Head: trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The dollar fell as low as 1.1624 per euro from 1.1486 on Friday and traded at 1.1594 at 10:15 a.m in London'\n",
      "Word: The, Deprel: det, Head: dollar\n",
      "Word: dollar, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: advmod, Head: low\n",
      "Word: low, Deprel: advmod, Head: fell\n",
      "Word: as, Deprel: case, Head: 1.1624\n",
      "Word: 1.1624, Deprel: obl, Head: low\n",
      "Word: per, Deprel: case, Head: euro\n",
      "Word: euro, Deprel: nmod, Head: 1.1624\n",
      "Word: from, Deprel: case, Head: 1.1486\n",
      "Word: 1.1486, Deprel: obl, Head: fell\n",
      "Word: on, Deprel: case, Head: Friday\n",
      "Word: Friday, Deprel: obl, Head: fell\n",
      "Word: and, Deprel: cc, Head: traded\n",
      "Word: traded, Deprel: conj, Head: fell\n",
      "Word: at, Deprel: case, Head: 1.1594\n",
      "Word: 1.1594, Deprel: obl, Head: traded\n",
      "Word: at, Deprel: case, Head: a.m\n",
      "Word: 10:15, Deprel: nummod, Head: a.m\n",
      "Word: a.m, Deprel: obl, Head: traded\n",
      "Word: in, Deprel: case, Head: London\n",
      "Word: London, Deprel: nmod, Head: a.m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The dollar dropped to 1.1564 per euro at 7:30 a.m in London from 1.1486 on Friday'\n",
      "Word: The, Deprel: det, Head: dollar\n",
      "Word: dollar, Deprel: nsubj, Head: dropped\n",
      "Word: dropped, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: 1.1564\n",
      "Word: 1.1564, Deprel: obl, Head: dropped\n",
      "Word: per, Deprel: case, Head: euro\n",
      "Word: euro, Deprel: nmod, Head: 1.1564\n",
      "Word: at, Deprel: case, Head: a.m\n",
      "Word: 7:30, Deprel: nummod, Head: a.m\n",
      "Word: a.m, Deprel: obl, Head: dropped\n",
      "Word: in, Deprel: case, Head: London\n",
      "Word: London, Deprel: obl, Head: dropped\n",
      "Word: from, Deprel: case, Head: 1.1486\n",
      "Word: 1.1486, Deprel: obl, Head: dropped\n",
      "Word: on, Deprel: case, Head: Friday\n",
      "Word: Friday, Deprel: obl, Head: dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The American decision provoked an angry reaction from the European Commission which described the move as legally unwarranted economically unfounded and politically unhelpful'\n",
      "Word: The, Deprel: det, Head: decision\n",
      "Word: American, Deprel: amod, Head: decision\n",
      "Word: decision, Deprel: nsubj, Head: provoked\n",
      "Word: provoked, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: reaction\n",
      "Word: angry, Deprel: amod, Head: reaction\n",
      "Word: reaction, Deprel: obj, Head: provoked\n",
      "Word: from, Deprel: case, Head: Commission\n",
      "Word: the, Deprel: det, Head: Commission\n",
      "Word: European, Deprel: amod, Head: Commission\n",
      "Word: Commission, Deprel: nmod, Head: reaction\n",
      "Word: which, Deprel: nsubj, Head: described\n",
      "Word: described, Deprel: acl:relcl, Head: reaction\n",
      "Word: the, Deprel: det, Head: move\n",
      "Word: move, Deprel: obj, Head: described\n",
      "Word: as, Deprel: case, Head: unwarranted\n",
      "Word: legally, Deprel: advmod, Head: unwarranted\n",
      "Word: unwarranted, Deprel: obl, Head: described\n",
      "Word: economically, Deprel: advmod, Head: unfounded\n",
      "Word: unfounded, Deprel: amod, Head: unwarranted\n",
      "Word: and, Deprel: cc, Head: unhelpful\n",
      "Word: politically, Deprel: advmod, Head: unhelpful\n",
      "Word: unhelpful, Deprel: conj, Head: unfounded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The European Commission the EU s powerful executive body described the move as legally unwarranted economically unfounded and politically unhelpful'\n",
      "Word: The, Deprel: det, Head: Commission\n",
      "Word: European, Deprel: amod, Head: Commission\n",
      "Word: Commission, Deprel: nsubj, Head: described\n",
      "Word: the, Deprel: det, Head: EU\n",
      "Word: EU, Deprel: nmod:poss, Head: body\n",
      "Word: s, Deprel: case, Head: EU\n",
      "Word: powerful, Deprel: amod, Head: body\n",
      "Word: executive, Deprel: amod, Head: body\n",
      "Word: body, Deprel: appos, Head: Commission\n",
      "Word: described, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: move\n",
      "Word: move, Deprel: obj, Head: described\n",
      "Word: as, Deprel: case, Head: unwarranted\n",
      "Word: legally, Deprel: advmod, Head: unwarranted\n",
      "Word: unwarranted, Deprel: obl, Head: described\n",
      "Word: economically, Deprel: advmod, Head: unfounded\n",
      "Word: unfounded, Deprel: amod, Head: unwarranted\n",
      "Word: and, Deprel: cc, Head: unhelpful\n",
      "Word: politically, Deprel: advmod, Head: unhelpful\n",
      "Word: unhelpful, Deprel: conj, Head: unfounded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Ms Cripps-Prawak left last Friday two days after the department introduced a plan to distribute medical marijuana through doctors offices'\n",
      "Word: Ms, Deprel: nsubj, Head: left\n",
      "Word: Cripps-Prawak, Deprel: flat, Head: Ms\n",
      "Word: left, Deprel: root, Head: ROOT\n",
      "Word: last, Deprel: amod, Head: Friday\n",
      "Word: Friday, Deprel: obl:tmod, Head: left\n",
      "Word: two, Deprel: nummod, Head: days\n",
      "Word: days, Deprel: obl:tmod, Head: left\n",
      "Word: after, Deprel: mark, Head: introduced\n",
      "Word: the, Deprel: det, Head: department\n",
      "Word: department, Deprel: nsubj, Head: introduced\n",
      "Word: introduced, Deprel: advcl, Head: left\n",
      "Word: a, Deprel: det, Head: plan\n",
      "Word: plan, Deprel: obj, Head: introduced\n",
      "Word: to, Deprel: mark, Head: distribute\n",
      "Word: distribute, Deprel: acl, Head: plan\n",
      "Word: medical, Deprel: amod, Head: marijuana\n",
      "Word: marijuana, Deprel: obj, Head: distribute\n",
      "Word: through, Deprel: case, Head: offices\n",
      "Word: doctors, Deprel: compound, Head: offices\n",
      "Word: offices, Deprel: obl, Head: distribute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The director of the Office of Medical Access Cindy Cripps-Prawak left her job after the department introduced a plan to distribute marijuana through doctors offices'\n",
      "Word: The, Deprel: det, Head: director\n",
      "Word: director, Deprel: nsubj, Head: left\n",
      "Word: of, Deprel: case, Head: Office\n",
      "Word: the, Deprel: det, Head: Office\n",
      "Word: Office, Deprel: nmod, Head: director\n",
      "Word: of, Deprel: case, Head: Access\n",
      "Word: Medical, Deprel: amod, Head: Access\n",
      "Word: Access, Deprel: nmod, Head: Office\n",
      "Word: Cindy, Deprel: appos, Head: Office\n",
      "Word: Cripps-Prawak, Deprel: flat, Head: Cindy\n",
      "Word: left, Deprel: root, Head: ROOT\n",
      "Word: her, Deprel: nmod:poss, Head: job\n",
      "Word: job, Deprel: obj, Head: left\n",
      "Word: after, Deprel: mark, Head: introduced\n",
      "Word: the, Deprel: det, Head: department\n",
      "Word: department, Deprel: nsubj, Head: introduced\n",
      "Word: introduced, Deprel: advcl, Head: left\n",
      "Word: a, Deprel: det, Head: plan\n",
      "Word: plan, Deprel: obj, Head: introduced\n",
      "Word: to, Deprel: mark, Head: distribute\n",
      "Word: distribute, Deprel: acl, Head: plan\n",
      "Word: marijuana, Deprel: obj, Head: distribute\n",
      "Word: through, Deprel: case, Head: offices\n",
      "Word: doctors, Deprel: compound, Head: offices\n",
      "Word: offices, Deprel: obl, Head: distribute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'During 2001 and 2002 Morgenthau said wire transfers from just four of Beacon Hill s 40 accounts totaled more than 3.2 billion'\n",
      "Word: During, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: said\n",
      "Word: and, Deprel: cc, Head: 2002\n",
      "Word: 2002, Deprel: conj, Head: 2001\n",
      "Word: Morgenthau, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: wire, Deprel: compound, Head: transfers\n",
      "Word: transfers, Deprel: nsubj, Head: totaled\n",
      "Word: from, Deprel: case, Head: four\n",
      "Word: just, Deprel: advmod, Head: four\n",
      "Word: four, Deprel: nmod, Head: transfers\n",
      "Word: of, Deprel: case, Head: accounts\n",
      "Word: Beacon, Deprel: compound, Head: Hill\n",
      "Word: Hill, Deprel: nmod:poss, Head: accounts\n",
      "Word: s, Deprel: case, Head: Hill\n",
      "Word: 40, Deprel: nummod, Head: accounts\n",
      "Word: accounts, Deprel: nmod, Head: four\n",
      "Word: totaled, Deprel: ccomp, Head: said\n",
      "Word: more, Deprel: advmod, Head: billion\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 3.2, Deprel: nummod, Head: billion\n",
      "Word: billion, Deprel: obj, Head: totaled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Wire transfers from four of the 40 accounts open at Beacon Hill totaled more than 3.2 billion from 2001 to 2002 Morgenthau said'\n",
      "Word: Wire, Deprel: compound, Head: transfers\n",
      "Word: transfers, Deprel: nsubj, Head: totaled\n",
      "Word: from, Deprel: case, Head: four\n",
      "Word: four, Deprel: nmod, Head: transfers\n",
      "Word: of, Deprel: case, Head: accounts\n",
      "Word: the, Deprel: det, Head: accounts\n",
      "Word: 40, Deprel: nummod, Head: accounts\n",
      "Word: accounts, Deprel: nmod, Head: four\n",
      "Word: open, Deprel: amod, Head: accounts\n",
      "Word: at, Deprel: case, Head: Hill\n",
      "Word: Beacon, Deprel: compound, Head: Hill\n",
      "Word: Hill, Deprel: obl, Head: open\n",
      "Word: totaled, Deprel: root, Head: ROOT\n",
      "Word: more, Deprel: advmod, Head: billion\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 3.2, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obj, Head: totaled\n",
      "Word: from, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: totaled\n",
      "Word: to, Deprel: case, Head: 2002\n",
      "Word: 2002, Deprel: obl, Head: totaled\n",
      "Word: Morgenthau, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: totaled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Last year he made an unsuccessful bid for the Democratic nomination for governor'\n",
      "Word: Last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: made\n",
      "Word: he, Deprel: nsubj, Head: made\n",
      "Word: made, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: bid\n",
      "Word: unsuccessful, Deprel: amod, Head: bid\n",
      "Word: bid, Deprel: obj, Head: made\n",
      "Word: for, Deprel: case, Head: nomination\n",
      "Word: the, Deprel: det, Head: nomination\n",
      "Word: Democratic, Deprel: amod, Head: nomination\n",
      "Word: nomination, Deprel: nmod, Head: bid\n",
      "Word: for, Deprel: case, Head: governor\n",
      "Word: governor, Deprel: nmod, Head: nomination\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He ran last year for the Democratic nomination for Texas governor but lost the primary to multimillionaire Tony Sanchez'\n",
      "Word: He, Deprel: nsubj, Head: ran\n",
      "Word: ran, Deprel: root, Head: ROOT\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: ran\n",
      "Word: for, Deprel: case, Head: nomination\n",
      "Word: the, Deprel: det, Head: nomination\n",
      "Word: Democratic, Deprel: amod, Head: nomination\n",
      "Word: nomination, Deprel: obl, Head: ran\n",
      "Word: for, Deprel: case, Head: governor\n",
      "Word: Texas, Deprel: compound, Head: governor\n",
      "Word: governor, Deprel: nmod, Head: nomination\n",
      "Word: but, Deprel: cc, Head: lost\n",
      "Word: lost, Deprel: conj, Head: ran\n",
      "Word: the, Deprel: det, Head: primary\n",
      "Word: primary, Deprel: obj, Head: lost\n",
      "Word: to, Deprel: case, Head: multimillionaire\n",
      "Word: multimillionaire, Deprel: obl, Head: lost\n",
      "Word: Tony, Deprel: flat, Head: multimillionaire\n",
      "Word: Sanchez, Deprel: flat, Head: Tony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The nation s largest retailer has told its 100 top suppliers they have to start using electronic tags on all pallets of goods by Jan 25 2005'\n",
      "Word: The, Deprel: det, Head: nation\n",
      "Word: nation, Deprel: nmod:poss, Head: retailer\n",
      "Word: s, Deprel: case, Head: nation\n",
      "Word: largest, Deprel: amod, Head: retailer\n",
      "Word: retailer, Deprel: nsubj, Head: told\n",
      "Word: has, Deprel: aux, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: suppliers\n",
      "Word: 100, Deprel: nummod, Head: suppliers\n",
      "Word: top, Deprel: amod, Head: suppliers\n",
      "Word: suppliers, Deprel: iobj, Head: told\n",
      "Word: they, Deprel: nsubj, Head: have\n",
      "Word: have, Deprel: ccomp, Head: told\n",
      "Word: to, Deprel: mark, Head: start\n",
      "Word: start, Deprel: xcomp, Head: have\n",
      "Word: using, Deprel: xcomp, Head: start\n",
      "Word: electronic, Deprel: amod, Head: tags\n",
      "Word: tags, Deprel: obj, Head: using\n",
      "Word: on, Deprel: case, Head: pallets\n",
      "Word: all, Deprel: det, Head: pallets\n",
      "Word: pallets, Deprel: obl, Head: using\n",
      "Word: of, Deprel: case, Head: goods\n",
      "Word: goods, Deprel: nmod, Head: pallets\n",
      "Word: by, Deprel: case, Head: Jan\n",
      "Word: Jan, Deprel: obl, Head: using\n",
      "Word: 25, Deprel: nummod, Head: Jan\n",
      "Word: 2005, Deprel: nummod, Head: Jan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Wal-Mart has told its top 100 suppliers that they ll need to have radio-frequency ID systems in place for tracking pallets of goods through the supply chain by Jan 25 2005'\n",
      "Word: Wal-Mart, Deprel: nsubj, Head: told\n",
      "Word: has, Deprel: aux, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: suppliers\n",
      "Word: top, Deprel: amod, Head: suppliers\n",
      "Word: 100, Deprel: nummod, Head: suppliers\n",
      "Word: suppliers, Deprel: iobj, Head: told\n",
      "Word: that, Deprel: mark, Head: need\n",
      "Word: they, Deprel: nsubj, Head: need\n",
      "Word: ll, Deprel: aux, Head: need\n",
      "Word: need, Deprel: ccomp, Head: told\n",
      "Word: to, Deprel: mark, Head: have\n",
      "Word: have, Deprel: xcomp, Head: need\n",
      "Word: radio-frequency, Deprel: compound, Head: systems\n",
      "Word: ID, Deprel: compound, Head: systems\n",
      "Word: systems, Deprel: obj, Head: have\n",
      "Word: in, Deprel: case, Head: place\n",
      "Word: place, Deprel: obl, Head: have\n",
      "Word: for, Deprel: mark, Head: tracking\n",
      "Word: tracking, Deprel: advcl, Head: have\n",
      "Word: pallets, Deprel: obj, Head: tracking\n",
      "Word: of, Deprel: case, Head: goods\n",
      "Word: goods, Deprel: nmod, Head: pallets\n",
      "Word: through, Deprel: case, Head: chain\n",
      "Word: the, Deprel: det, Head: chain\n",
      "Word: supply, Deprel: compound, Head: chain\n",
      "Word: chain, Deprel: obl, Head: tracking\n",
      "Word: by, Deprel: case, Head: Jan\n",
      "Word: Jan, Deprel: obl, Head: tracking\n",
      "Word: 25, Deprel: nummod, Head: Jan\n",
      "Word: 2005, Deprel: nummod, Head: Jan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He was taken to a hospital for precautionary X-rays on his neck'\n",
      "Word: He, Deprel: nsubj:pass, Head: taken\n",
      "Word: was, Deprel: aux:pass, Head: taken\n",
      "Word: taken, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: hospital\n",
      "Word: a, Deprel: det, Head: hospital\n",
      "Word: hospital, Deprel: obl, Head: taken\n",
      "Word: for, Deprel: case, Head: X-rays\n",
      "Word: precautionary, Deprel: amod, Head: X-rays\n",
      "Word: X-rays, Deprel: obl, Head: taken\n",
      "Word: on, Deprel: case, Head: neck\n",
      "Word: his, Deprel: nmod:poss, Head: neck\n",
      "Word: neck, Deprel: nmod, Head: X-rays\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Harvey was taken to St Luke s Hospital for precautionary neck X-rays which came back negative'\n",
      "Word: Harvey, Deprel: nsubj:pass, Head: taken\n",
      "Word: was, Deprel: aux:pass, Head: taken\n",
      "Word: taken, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Hospital\n",
      "Word: St, Deprel: nmod:poss, Head: Hospital\n",
      "Word: Luke, Deprel: flat, Head: St\n",
      "Word: s, Deprel: case, Head: St\n",
      "Word: Hospital, Deprel: obl, Head: taken\n",
      "Word: for, Deprel: case, Head: X-rays\n",
      "Word: precautionary, Deprel: amod, Head: X-rays\n",
      "Word: neck, Deprel: compound, Head: X-rays\n",
      "Word: X-rays, Deprel: obl, Head: taken\n",
      "Word: which, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: acl:relcl, Head: X-rays\n",
      "Word: back, Deprel: advmod, Head: negative\n",
      "Word: negative, Deprel: obj, Head: came\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'During the hearing Morales expressed sincere regrets and remorse for his actions'\n",
      "Word: During, Deprel: case, Head: hearing\n",
      "Word: the, Deprel: det, Head: hearing\n",
      "Word: hearing, Deprel: obl, Head: expressed\n",
      "Word: Morales, Deprel: nsubj, Head: expressed\n",
      "Word: expressed, Deprel: root, Head: ROOT\n",
      "Word: sincere, Deprel: amod, Head: regrets\n",
      "Word: regrets, Deprel: obj, Head: expressed\n",
      "Word: and, Deprel: cc, Head: remorse\n",
      "Word: remorse, Deprel: conj, Head: regrets\n",
      "Word: for, Deprel: case, Head: actions\n",
      "Word: his, Deprel: nmod:poss, Head: actions\n",
      "Word: actions, Deprel: nmod, Head: regrets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Morales who pleaded guilty in July expressed sincere regret and remorse for his crimes'\n",
      "Word: Morales, Deprel: nsubj, Head: expressed\n",
      "Word: who, Deprel: nsubj, Head: pleaded\n",
      "Word: pleaded, Deprel: acl:relcl, Head: Morales\n",
      "Word: guilty, Deprel: obj, Head: pleaded\n",
      "Word: in, Deprel: case, Head: July\n",
      "Word: July, Deprel: obl, Head: pleaded\n",
      "Word: expressed, Deprel: root, Head: ROOT\n",
      "Word: sincere, Deprel: amod, Head: regret\n",
      "Word: regret, Deprel: obj, Head: expressed\n",
      "Word: and, Deprel: cc, Head: remorse\n",
      "Word: remorse, Deprel: conj, Head: regret\n",
      "Word: for, Deprel: case, Head: crimes\n",
      "Word: his, Deprel: nmod:poss, Head: crimes\n",
      "Word: crimes, Deprel: nmod, Head: regret\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The bill says that a woman who undergoes such an abortion could n't be prosecuted'\n",
      "Word: The, Deprel: det, Head: bill\n",
      "Word: bill, Deprel: nsubj, Head: says\n",
      "Word: says, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: prosecuted\n",
      "Word: a, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj:pass, Head: prosecuted\n",
      "Word: who, Deprel: nsubj, Head: undergoes\n",
      "Word: undergoes, Deprel: acl:relcl, Head: woman\n",
      "Word: such, Deprel: det:predet, Head: abortion\n",
      "Word: an, Deprel: det, Head: abortion\n",
      "Word: abortion, Deprel: obj, Head: undergoes\n",
      "Word: could, Deprel: aux, Head: prosecuted\n",
      "Word: n't, Deprel: advmod, Head: prosecuted\n",
      "Word: be, Deprel: aux:pass, Head: prosecuted\n",
      "Word: prosecuted, Deprel: ccomp, Head: says\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman who underwent such an abortion could not be prosecuted under the bill'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj:pass, Head: prosecuted\n",
      "Word: who, Deprel: nsubj, Head: underwent\n",
      "Word: underwent, Deprel: acl:relcl, Head: woman\n",
      "Word: such, Deprel: det:predet, Head: abortion\n",
      "Word: an, Deprel: det, Head: abortion\n",
      "Word: abortion, Deprel: obj, Head: underwent\n",
      "Word: could, Deprel: aux, Head: prosecuted\n",
      "Word: not, Deprel: advmod, Head: prosecuted\n",
      "Word: be, Deprel: aux:pass, Head: prosecuted\n",
      "Word: prosecuted, Deprel: root, Head: ROOT\n",
      "Word: under, Deprel: case, Head: bill\n",
      "Word: the, Deprel: det, Head: bill\n",
      "Word: bill, Deprel: obl, Head: prosecuted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'U.S District Judge Edmund Sargus ruled that the Akron-based company should have determined that changes at one of its plants would increase overall pollution emissions'\n",
      "Word: U.S, Deprel: compound, Head: District\n",
      "Word: District, Deprel: compound, Head: Judge\n",
      "Word: Judge, Deprel: nsubj, Head: ruled\n",
      "Word: Edmund, Deprel: flat, Head: Judge\n",
      "Word: Sargus, Deprel: flat, Head: Judge\n",
      "Word: ruled, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: determined\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: Akron-based, Deprel: amod, Head: company\n",
      "Word: company, Deprel: nsubj, Head: determined\n",
      "Word: should, Deprel: aux, Head: determined\n",
      "Word: have, Deprel: aux, Head: determined\n",
      "Word: determined, Deprel: ccomp, Head: ruled\n",
      "Word: that, Deprel: mark, Head: increase\n",
      "Word: changes, Deprel: nsubj, Head: increase\n",
      "Word: at, Deprel: case, Head: one\n",
      "Word: one, Deprel: nmod, Head: changes\n",
      "Word: of, Deprel: case, Head: plants\n",
      "Word: its, Deprel: nmod:poss, Head: plants\n",
      "Word: plants, Deprel: nmod, Head: one\n",
      "Word: would, Deprel: aux, Head: increase\n",
      "Word: increase, Deprel: ccomp, Head: determined\n",
      "Word: overall, Deprel: amod, Head: emissions\n",
      "Word: pollution, Deprel: compound, Head: emissions\n",
      "Word: emissions, Deprel: obj, Head: increase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'FirstEnergy Corp should have determined that modernizing one of its plants would increase overall pollution emissions U.S District Judge Edmund Sargus ruled Thursday'\n",
      "Word: FirstEnergy, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: nsubj, Head: determined\n",
      "Word: should, Deprel: aux, Head: determined\n",
      "Word: have, Deprel: aux, Head: determined\n",
      "Word: determined, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: increase\n",
      "Word: modernizing, Deprel: csubj, Head: increase\n",
      "Word: one, Deprel: obj, Head: modernizing\n",
      "Word: of, Deprel: case, Head: plants\n",
      "Word: its, Deprel: nmod:poss, Head: plants\n",
      "Word: plants, Deprel: nmod, Head: one\n",
      "Word: would, Deprel: aux, Head: increase\n",
      "Word: increase, Deprel: ccomp, Head: determined\n",
      "Word: overall, Deprel: amod, Head: emissions\n",
      "Word: pollution, Deprel: compound, Head: emissions\n",
      "Word: emissions, Deprel: obj, Head: increase\n",
      "Word: U.S, Deprel: compound, Head: District\n",
      "Word: District, Deprel: compound, Head: Judge\n",
      "Word: Judge, Deprel: nsubj, Head: ruled\n",
      "Word: Edmund, Deprel: flat, Head: Judge\n",
      "Word: Sargus, Deprel: flat, Head: Judge\n",
      "Word: ruled, Deprel: acl:relcl, Head: emissions\n",
      "Word: Thursday, Deprel: obl:tmod, Head: ruled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Site Finder has been visited 65 million times since its introduction Galvin said'\n",
      "Word: Site, Deprel: compound, Head: Finder\n",
      "Word: Finder, Deprel: nsubj:pass, Head: visited\n",
      "Word: has, Deprel: aux, Head: visited\n",
      "Word: been, Deprel: aux:pass, Head: visited\n",
      "Word: visited, Deprel: root, Head: ROOT\n",
      "Word: 65, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: times\n",
      "Word: times, Deprel: obl:tmod, Head: visited\n",
      "Word: since, Deprel: case, Head: introduction\n",
      "Word: its, Deprel: nmod:poss, Head: introduction\n",
      "Word: introduction, Deprel: obl, Head: visited\n",
      "Word: Galvin, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: introduction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Through Sunday Sept 21 Site Finder has been visited over 65 million times by Internet users'\n",
      "Word: Through, Deprel: case, Head: Sept\n",
      "Word: Sunday, Deprel: compound, Head: Sept\n",
      "Word: Sept, Deprel: compound, Head: Finder\n",
      "Word: 21, Deprel: nummod, Head: Sept\n",
      "Word: Site, Deprel: compound, Head: Finder\n",
      "Word: Finder, Deprel: nsubj:pass, Head: visited\n",
      "Word: has, Deprel: aux, Head: visited\n",
      "Word: been, Deprel: aux:pass, Head: visited\n",
      "Word: visited, Deprel: root, Head: ROOT\n",
      "Word: over, Deprel: advmod, Head: million\n",
      "Word: 65, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: times\n",
      "Word: times, Deprel: obl:tmod, Head: visited\n",
      "Word: by, Deprel: case, Head: users\n",
      "Word: Internet, Deprel: compound, Head: users\n",
      "Word: users, Deprel: obl, Head: visited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'There are 103 Democrats in the Assembly and 47 Republicans'\n",
      "Word: There, Deprel: expl, Head: are\n",
      "Word: are, Deprel: root, Head: ROOT\n",
      "Word: 103, Deprel: nummod, Head: Democrats\n",
      "Word: Democrats, Deprel: nsubj, Head: are\n",
      "Word: in, Deprel: case, Head: Assembly\n",
      "Word: the, Deprel: det, Head: Assembly\n",
      "Word: Assembly, Deprel: nmod, Head: Democrats\n",
      "Word: and, Deprel: cc, Head: Republicans\n",
      "Word: 47, Deprel: nummod, Head: Republicans\n",
      "Word: Republicans, Deprel: conj, Head: Democrats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Democrats dominate the Assembly while Republicans control the Senate'\n",
      "Word: Democrats, Deprel: nsubj, Head: dominate\n",
      "Word: dominate, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: Assembly\n",
      "Word: Assembly, Deprel: obj, Head: dominate\n",
      "Word: while, Deprel: mark, Head: control\n",
      "Word: Republicans, Deprel: nsubj, Head: control\n",
      "Word: control, Deprel: advcl, Head: dominate\n",
      "Word: the, Deprel: det, Head: Senate\n",
      "Word: Senate, Deprel: obj, Head: control\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Pollard said This is a terrible personal tragedy and a shocking blow for James s family'\n",
      "Word: Mr, Deprel: nsubj, Head: said\n",
      "Word: Pollard, Deprel: flat, Head: Mr\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: This, Deprel: nsubj, Head: tragedy\n",
      "Word: is, Deprel: cop, Head: tragedy\n",
      "Word: a, Deprel: det, Head: tragedy\n",
      "Word: terrible, Deprel: amod, Head: tragedy\n",
      "Word: personal, Deprel: amod, Head: tragedy\n",
      "Word: tragedy, Deprel: ccomp, Head: said\n",
      "Word: and, Deprel: cc, Head: blow\n",
      "Word: a, Deprel: det, Head: blow\n",
      "Word: shocking, Deprel: amod, Head: blow\n",
      "Word: blow, Deprel: conj, Head: tragedy\n",
      "Word: for, Deprel: case, Head: family\n",
      "Word: James, Deprel: nmod:poss, Head: family\n",
      "Word: s, Deprel: case, Head: James\n",
      "Word: family, Deprel: nmod, Head: blow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Nick Pollard the head of Sky News said This is a shocking blow for James s family'\n",
      "Word: Nick, Deprel: nsubj, Head: said\n",
      "Word: Pollard, Deprel: flat, Head: Nick\n",
      "Word: the, Deprel: det, Head: head\n",
      "Word: head, Deprel: appos, Head: Nick\n",
      "Word: of, Deprel: case, Head: News\n",
      "Word: Sky, Deprel: compound, Head: News\n",
      "Word: News, Deprel: nmod, Head: head\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: This, Deprel: nsubj, Head: blow\n",
      "Word: is, Deprel: cop, Head: blow\n",
      "Word: a, Deprel: det, Head: blow\n",
      "Word: shocking, Deprel: amod, Head: blow\n",
      "Word: blow, Deprel: ccomp, Head: said\n",
      "Word: for, Deprel: case, Head: family\n",
      "Word: James, Deprel: nmod:poss, Head: family\n",
      "Word: s, Deprel: case, Head: James\n",
      "Word: family, Deprel: nmod, Head: blow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I came basically to Washington to establish relationships and to make sure that we are getting more federal money to California Schwarzenegger said after meeting with congressional Republicans'\n",
      "Word: I, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: root, Head: ROOT\n",
      "Word: basically, Deprel: advmod, Head: came\n",
      "Word: to, Deprel: case, Head: Washington\n",
      "Word: Washington, Deprel: obl, Head: came\n",
      "Word: to, Deprel: mark, Head: establish\n",
      "Word: establish, Deprel: advcl, Head: came\n",
      "Word: relationships, Deprel: obj, Head: establish\n",
      "Word: and, Deprel: cc, Head: make\n",
      "Word: to, Deprel: mark, Head: make\n",
      "Word: make, Deprel: conj, Head: establish\n",
      "Word: sure, Deprel: xcomp, Head: make\n",
      "Word: that, Deprel: mark, Head: getting\n",
      "Word: we, Deprel: nsubj, Head: getting\n",
      "Word: are, Deprel: aux, Head: getting\n",
      "Word: getting, Deprel: ccomp, Head: sure\n",
      "Word: more, Deprel: amod, Head: money\n",
      "Word: federal, Deprel: amod, Head: money\n",
      "Word: money, Deprel: obj, Head: getting\n",
      "Word: to, Deprel: case, Head: California\n",
      "Word: California, Deprel: obl, Head: getting\n",
      "Word: Schwarzenegger, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: ccomp, Head: sure\n",
      "Word: after, Deprel: case, Head: meeting\n",
      "Word: meeting, Deprel: advcl, Head: said\n",
      "Word: with, Deprel: case, Head: Republicans\n",
      "Word: congressional, Deprel: amod, Head: Republicans\n",
      "Word: Republicans, Deprel: nmod, Head: meeting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I came to Washington basically to establish relationships and make sure we are getting more federal money Schwarzenegger said after one meeting'\n",
      "Word: I, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Washington\n",
      "Word: Washington, Deprel: obl, Head: came\n",
      "Word: basically, Deprel: advmod, Head: came\n",
      "Word: to, Deprel: mark, Head: establish\n",
      "Word: establish, Deprel: advcl, Head: came\n",
      "Word: relationships, Deprel: obj, Head: establish\n",
      "Word: and, Deprel: cc, Head: make\n",
      "Word: make, Deprel: conj, Head: establish\n",
      "Word: sure, Deprel: xcomp, Head: make\n",
      "Word: we, Deprel: nsubj, Head: getting\n",
      "Word: are, Deprel: aux, Head: getting\n",
      "Word: getting, Deprel: ccomp, Head: sure\n",
      "Word: more, Deprel: amod, Head: money\n",
      "Word: federal, Deprel: amod, Head: money\n",
      "Word: money, Deprel: obj, Head: getting\n",
      "Word: Schwarzenegger, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: money\n",
      "Word: after, Deprel: case, Head: meeting\n",
      "Word: one, Deprel: nummod, Head: meeting\n",
      "Word: meeting, Deprel: obl, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The latest snapshot of the labor markets was slightly better than economists were expecting they were forecasting claims to fall no lower than 410,000 for last week'\n",
      "Word: The, Deprel: det, Head: snapshot\n",
      "Word: latest, Deprel: amod, Head: snapshot\n",
      "Word: snapshot, Deprel: nsubj, Head: better\n",
      "Word: of, Deprel: case, Head: markets\n",
      "Word: the, Deprel: det, Head: markets\n",
      "Word: labor, Deprel: compound, Head: markets\n",
      "Word: markets, Deprel: nmod, Head: snapshot\n",
      "Word: was, Deprel: cop, Head: better\n",
      "Word: slightly, Deprel: advmod, Head: better\n",
      "Word: better, Deprel: root, Head: ROOT\n",
      "Word: than, Deprel: case, Head: economists\n",
      "Word: economists, Deprel: obl, Head: better\n",
      "Word: were, Deprel: aux, Head: expecting\n",
      "Word: expecting, Deprel: acl:relcl, Head: economists\n",
      "Word: they, Deprel: nsubj, Head: claims\n",
      "Word: were, Deprel: cop, Head: claims\n",
      "Word: forecasting, Deprel: amod, Head: claims\n",
      "Word: claims, Deprel: ccomp, Head: expecting\n",
      "Word: to, Deprel: mark, Head: fall\n",
      "Word: fall, Deprel: acl, Head: claims\n",
      "Word: no, Deprel: advmod, Head: lower\n",
      "Word: lower, Deprel: advmod, Head: fall\n",
      "Word: than, Deprel: case, Head: 410,000\n",
      "Word: 410,000, Deprel: obl, Head: lower\n",
      "Word: for, Deprel: case, Head: week\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl, Head: lower\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Despite problems in the job market the latest snapshot of the labor markets was slightly better than economists were expecting'\n",
      "Word: Despite, Deprel: case, Head: problems\n",
      "Word: problems, Deprel: obl, Head: better\n",
      "Word: in, Deprel: case, Head: market\n",
      "Word: the, Deprel: det, Head: market\n",
      "Word: job, Deprel: compound, Head: market\n",
      "Word: market, Deprel: nmod, Head: problems\n",
      "Word: the, Deprel: det, Head: snapshot\n",
      "Word: latest, Deprel: amod, Head: snapshot\n",
      "Word: snapshot, Deprel: nsubj, Head: better\n",
      "Word: of, Deprel: case, Head: markets\n",
      "Word: the, Deprel: det, Head: markets\n",
      "Word: labor, Deprel: compound, Head: markets\n",
      "Word: markets, Deprel: nmod, Head: snapshot\n",
      "Word: was, Deprel: cop, Head: better\n",
      "Word: slightly, Deprel: advmod, Head: better\n",
      "Word: better, Deprel: root, Head: ROOT\n",
      "Word: than, Deprel: mark, Head: expecting\n",
      "Word: economists, Deprel: nsubj, Head: expecting\n",
      "Word: were, Deprel: aux, Head: expecting\n",
      "Word: expecting, Deprel: advcl, Head: better\n",
      "\n",
      "Dependencies for Sentence: 'They were tossed around like feathers Gordon said'\n",
      "Word: They, Deprel: nsubj:pass, Head: tossed\n",
      "Word: were, Deprel: aux:pass, Head: tossed\n",
      "Word: tossed, Deprel: root, Head: ROOT\n",
      "Word: around, Deprel: advmod, Head: tossed\n",
      "Word: like, Deprel: case, Head: feathers\n",
      "Word: feathers, Deprel: obl, Head: tossed\n",
      "Word: Gordon, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: feathers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The concrete barriers between lanes were being tossed around like feathers'\n",
      "Word: The, Deprel: det, Head: barriers\n",
      "Word: concrete, Deprel: compound, Head: barriers\n",
      "Word: barriers, Deprel: nsubj:pass, Head: tossed\n",
      "Word: between, Deprel: case, Head: lanes\n",
      "Word: lanes, Deprel: nmod, Head: barriers\n",
      "Word: were, Deprel: aux, Head: tossed\n",
      "Word: being, Deprel: aux:pass, Head: tossed\n",
      "Word: tossed, Deprel: root, Head: ROOT\n",
      "Word: around, Deprel: advmod, Head: tossed\n",
      "Word: like, Deprel: case, Head: feathers\n",
      "Word: feathers, Deprel: obl, Head: tossed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Chante Jawan Mallard 27 went on trial Monday charged with first-degree murder'\n",
      "Word: Chante, Deprel: nsubj, Head: went\n",
      "Word: Jawan, Deprel: flat, Head: Chante\n",
      "Word: Mallard, Deprel: flat, Head: Chante\n",
      "Word: 27, Deprel: nummod, Head: Chante\n",
      "Word: went, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: trial\n",
      "Word: trial, Deprel: obl, Head: went\n",
      "Word: Monday, Deprel: obl:tmod, Head: went\n",
      "Word: charged, Deprel: advcl, Head: went\n",
      "Word: with, Deprel: case, Head: murder\n",
      "Word: first-degree, Deprel: amod, Head: murder\n",
      "Word: murder, Deprel: obl, Head: charged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Chante Jawaon Mallard 27 is charged with murder and tampering with evidence'\n",
      "Word: Chante, Deprel: nsubj:pass, Head: charged\n",
      "Word: Jawaon, Deprel: flat, Head: Chante\n",
      "Word: Mallard, Deprel: flat, Head: Chante\n",
      "Word: 27, Deprel: nummod, Head: Chante\n",
      "Word: is, Deprel: aux:pass, Head: charged\n",
      "Word: charged, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: murder\n",
      "Word: murder, Deprel: obl, Head: charged\n",
      "Word: and, Deprel: cc, Head: tampering\n",
      "Word: tampering, Deprel: conj, Head: murder\n",
      "Word: with, Deprel: case, Head: evidence\n",
      "Word: evidence, Deprel: obl, Head: tampering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'IT is the only vehicle on which established economies will be able to compete Barrett said'\n",
      "Word: IT, Deprel: nsubj, Head: vehicle\n",
      "Word: is, Deprel: cop, Head: vehicle\n",
      "Word: the, Deprel: det, Head: vehicle\n",
      "Word: only, Deprel: amod, Head: vehicle\n",
      "Word: vehicle, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: which\n",
      "Word: which, Deprel: obl, Head: able\n",
      "Word: established, Deprel: amod, Head: economies\n",
      "Word: economies, Deprel: nsubj, Head: able\n",
      "Word: will, Deprel: aux, Head: able\n",
      "Word: be, Deprel: cop, Head: able\n",
      "Word: able, Deprel: acl:relcl, Head: vehicle\n",
      "Word: to, Deprel: mark, Head: compete\n",
      "Word: compete, Deprel: xcomp, Head: able\n",
      "Word: Barrett, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: xcomp, Head: compete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'IT is the only vehicle on which established economies will be able to compete with fast-growing economies such as China and India Barrett said'\n",
      "Word: IT, Deprel: nsubj, Head: vehicle\n",
      "Word: is, Deprel: cop, Head: vehicle\n",
      "Word: the, Deprel: det, Head: vehicle\n",
      "Word: only, Deprel: amod, Head: vehicle\n",
      "Word: vehicle, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: which\n",
      "Word: which, Deprel: obl, Head: able\n",
      "Word: established, Deprel: amod, Head: economies\n",
      "Word: economies, Deprel: nsubj, Head: able\n",
      "Word: will, Deprel: aux, Head: able\n",
      "Word: be, Deprel: cop, Head: able\n",
      "Word: able, Deprel: acl:relcl, Head: vehicle\n",
      "Word: to, Deprel: mark, Head: compete\n",
      "Word: compete, Deprel: xcomp, Head: able\n",
      "Word: with, Deprel: case, Head: economies\n",
      "Word: fast-growing, Deprel: amod, Head: economies\n",
      "Word: economies, Deprel: obl, Head: compete\n",
      "Word: such, Deprel: case, Head: China\n",
      "Word: as, Deprel: fixed, Head: such\n",
      "Word: China, Deprel: nmod, Head: economies\n",
      "Word: and, Deprel: cc, Head: Barrett\n",
      "Word: India, Deprel: compound, Head: Barrett\n",
      "Word: Barrett, Deprel: conj, Head: China\n",
      "Word: said, Deprel: acl:relcl, Head: China\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Linda Saunders pleaded guilty in federal court to six charges including extortion money laundering and conspiracy'\n",
      "Word: Linda, Deprel: nsubj, Head: pleaded\n",
      "Word: Saunders, Deprel: flat, Head: Linda\n",
      "Word: pleaded, Deprel: root, Head: ROOT\n",
      "Word: guilty, Deprel: obj, Head: pleaded\n",
      "Word: in, Deprel: case, Head: court\n",
      "Word: federal, Deprel: amod, Head: court\n",
      "Word: court, Deprel: obl, Head: pleaded\n",
      "Word: to, Deprel: case, Head: charges\n",
      "Word: six, Deprel: nummod, Head: charges\n",
      "Word: charges, Deprel: obl, Head: pleaded\n",
      "Word: including, Deprel: case, Head: laundering\n",
      "Word: extortion, Deprel: compound, Head: money\n",
      "Word: money, Deprel: compound, Head: laundering\n",
      "Word: laundering, Deprel: nmod, Head: charges\n",
      "Word: and, Deprel: cc, Head: conspiracy\n",
      "Word: conspiracy, Deprel: conj, Head: laundering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Former Phipps aides Linda Saunders and Bobby McLamb have both pleaded guilty to federal charges including extortion'\n",
      "Word: Former, Deprel: amod, Head: aides\n",
      "Word: Phipps, Deprel: compound, Head: aides\n",
      "Word: aides, Deprel: nmod:desc, Head: Linda\n",
      "Word: Linda, Deprel: nsubj, Head: pleaded\n",
      "Word: Saunders, Deprel: flat, Head: Linda\n",
      "Word: and, Deprel: cc, Head: Bobby\n",
      "Word: Bobby, Deprel: conj, Head: Linda\n",
      "Word: McLamb, Deprel: flat, Head: Bobby\n",
      "Word: have, Deprel: aux, Head: pleaded\n",
      "Word: both, Deprel: advmod, Head: pleaded\n",
      "Word: pleaded, Deprel: root, Head: ROOT\n",
      "Word: guilty, Deprel: xcomp, Head: pleaded\n",
      "Word: to, Deprel: case, Head: charges\n",
      "Word: federal, Deprel: amod, Head: charges\n",
      "Word: charges, Deprel: obl, Head: pleaded\n",
      "Word: including, Deprel: case, Head: extortion\n",
      "Word: extortion, Deprel: nmod, Head: charges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Vivendi shares closed 3.8 percent up in Paris at 15.78 euros'\n",
      "Word: Vivendi, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: closed\n",
      "Word: closed, Deprel: root, Head: ROOT\n",
      "Word: 3.8, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:npmod, Head: up\n",
      "Word: up, Deprel: advmod, Head: closed\n",
      "Word: in, Deprel: case, Head: Paris\n",
      "Word: Paris, Deprel: obl, Head: closed\n",
      "Word: at, Deprel: case, Head: euros\n",
      "Word: 15.78, Deprel: nummod, Head: euros\n",
      "Word: euros, Deprel: obl, Head: closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Vivendi shares were 0.3 percent up at 15.62 euros in Paris at 0841 GMT'\n",
      "Word: Vivendi, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: up\n",
      "Word: were, Deprel: cop, Head: up\n",
      "Word: 0.3, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:npmod, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: euros\n",
      "Word: 15.62, Deprel: nummod, Head: euros\n",
      "Word: euros, Deprel: obl, Head: up\n",
      "Word: in, Deprel: case, Head: Paris\n",
      "Word: Paris, Deprel: nmod, Head: euros\n",
      "Word: at, Deprel: case, Head: GMT\n",
      "Word: 0841, Deprel: nummod, Head: GMT\n",
      "Word: GMT, Deprel: obl, Head: up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Microsoft has identified the freely distributed Linux software as one of the biggest threats to its sales'\n",
      "Word: Microsoft, Deprel: nsubj, Head: identified\n",
      "Word: has, Deprel: aux, Head: identified\n",
      "Word: identified, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: software\n",
      "Word: freely, Deprel: advmod, Head: distributed\n",
      "Word: distributed, Deprel: amod, Head: software\n",
      "Word: Linux, Deprel: compound, Head: software\n",
      "Word: software, Deprel: obj, Head: identified\n",
      "Word: as, Deprel: case, Head: one\n",
      "Word: one, Deprel: obl, Head: identified\n",
      "Word: of, Deprel: case, Head: threats\n",
      "Word: the, Deprel: det, Head: threats\n",
      "Word: biggest, Deprel: amod, Head: threats\n",
      "Word: threats, Deprel: nmod, Head: one\n",
      "Word: to, Deprel: case, Head: sales\n",
      "Word: its, Deprel: nmod:poss, Head: sales\n",
      "Word: sales, Deprel: nmod, Head: threats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The company has publicly identified Linux as one of its biggest competitive threats'\n",
      "Word: The, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: identified\n",
      "Word: has, Deprel: aux, Head: identified\n",
      "Word: publicly, Deprel: advmod, Head: identified\n",
      "Word: identified, Deprel: root, Head: ROOT\n",
      "Word: Linux, Deprel: obj, Head: identified\n",
      "Word: as, Deprel: case, Head: one\n",
      "Word: one, Deprel: obl, Head: identified\n",
      "Word: of, Deprel: case, Head: threats\n",
      "Word: its, Deprel: nmod:poss, Head: threats\n",
      "Word: biggest, Deprel: amod, Head: threats\n",
      "Word: competitive, Deprel: amod, Head: threats\n",
      "Word: threats, Deprel: nmod, Head: one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Antonio Monteiro de Castro 58 currently director of the group ’ s Latin America Caribbean operations will become chief operating officer from the same date'\n",
      "Word: Antonio, Deprel: nsubj, Head: become\n",
      "Word: Monteiro, Deprel: flat, Head: Antonio\n",
      "Word: de, Deprel: flat, Head: Antonio\n",
      "Word: Castro, Deprel: flat, Head: Antonio\n",
      "Word: 58, Deprel: nmod:npmod, Head: Antonio\n",
      "Word: currently, Deprel: advmod, Head: director\n",
      "Word: director, Deprel: appos, Head: Antonio\n",
      "Word: of, Deprel: case, Head: operations\n",
      "Word: the, Deprel: det, Head: group\n",
      "Word: group, Deprel: nmod:poss, Head: operations\n",
      "Word: ’, Deprel: case, Head: group\n",
      "Word: s, Deprel: case, Head: group\n",
      "Word: Latin, Deprel: amod, Head: America\n",
      "Word: America, Deprel: compound, Head: operations\n",
      "Word: Caribbean, Deprel: compound, Head: operations\n",
      "Word: operations, Deprel: nmod, Head: director\n",
      "Word: will, Deprel: aux, Head: become\n",
      "Word: become, Deprel: root, Head: ROOT\n",
      "Word: chief, Deprel: amod, Head: officer\n",
      "Word: operating, Deprel: compound, Head: officer\n",
      "Word: officer, Deprel: xcomp, Head: become\n",
      "Word: from, Deprel: case, Head: date\n",
      "Word: the, Deprel: det, Head: date\n",
      "Word: same, Deprel: amod, Head: date\n",
      "Word: date, Deprel: nmod, Head: officer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'BAT also said Antonio Monteiro de Castro director for Latin America and the Caribbean would become chief operating officer on January 1 2004'\n",
      "Word: BAT, Deprel: nsubj, Head: said\n",
      "Word: also, Deprel: advmod, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Antonio, Deprel: nsubj, Head: become\n",
      "Word: Monteiro, Deprel: flat, Head: Antonio\n",
      "Word: de, Deprel: flat, Head: Antonio\n",
      "Word: Castro, Deprel: flat, Head: Antonio\n",
      "Word: director, Deprel: flat, Head: Antonio\n",
      "Word: for, Deprel: case, Head: America\n",
      "Word: Latin, Deprel: compound, Head: America\n",
      "Word: America, Deprel: nmod, Head: director\n",
      "Word: and, Deprel: cc, Head: Caribbean\n",
      "Word: the, Deprel: det, Head: Caribbean\n",
      "Word: Caribbean, Deprel: conj, Head: America\n",
      "Word: would, Deprel: aux, Head: become\n",
      "Word: become, Deprel: ccomp, Head: said\n",
      "Word: chief, Deprel: amod, Head: officer\n",
      "Word: operating, Deprel: compound, Head: officer\n",
      "Word: officer, Deprel: xcomp, Head: become\n",
      "Word: on, Deprel: case, Head: 1\n",
      "Word: January, Deprel: compound, Head: 1\n",
      "Word: 1, Deprel: nmod, Head: officer\n",
      "Word: 2004, Deprel: nmod:tmod, Head: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Spin and manipulative public relations and propaganda are not the answer it said'\n",
      "Word: Spin, Deprel: nsubj, Head: answer\n",
      "Word: and, Deprel: cc, Head: relations\n",
      "Word: manipulative, Deprel: amod, Head: relations\n",
      "Word: public, Deprel: amod, Head: relations\n",
      "Word: relations, Deprel: conj, Head: Spin\n",
      "Word: and, Deprel: cc, Head: propaganda\n",
      "Word: propaganda, Deprel: conj, Head: relations\n",
      "Word: are, Deprel: cop, Head: answer\n",
      "Word: not, Deprel: advmod, Head: answer\n",
      "Word: the, Deprel: det, Head: answer\n",
      "Word: answer, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: answer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The report added that spin and manipulative public relations are not the answer but that neither is avoiding the debate'\n",
      "Word: The, Deprel: det, Head: report\n",
      "Word: report, Deprel: nsubj, Head: added\n",
      "Word: added, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: answer\n",
      "Word: spin, Deprel: nsubj, Head: answer\n",
      "Word: and, Deprel: cc, Head: relations\n",
      "Word: manipulative, Deprel: amod, Head: relations\n",
      "Word: public, Deprel: amod, Head: relations\n",
      "Word: relations, Deprel: conj, Head: spin\n",
      "Word: are, Deprel: cop, Head: answer\n",
      "Word: not, Deprel: advmod, Head: answer\n",
      "Word: the, Deprel: det, Head: answer\n",
      "Word: answer, Deprel: ccomp, Head: added\n",
      "Word: but, Deprel: cc, Head: avoiding\n",
      "Word: that, Deprel: mark, Head: avoiding\n",
      "Word: neither, Deprel: nsubj, Head: avoiding\n",
      "Word: is, Deprel: aux, Head: avoiding\n",
      "Word: avoiding, Deprel: conj, Head: answer\n",
      "Word: the, Deprel: det, Head: debate\n",
      "Word: debate, Deprel: obj, Head: avoiding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Another shooting linked to the spree occurred Nov 11 at Hamilton Central Elementary in Obetz about two miles from the freeway'\n",
      "Word: Another, Deprel: det, Head: shooting\n",
      "Word: shooting, Deprel: nsubj, Head: occurred\n",
      "Word: linked, Deprel: acl, Head: shooting\n",
      "Word: to, Deprel: case, Head: spree\n",
      "Word: the, Deprel: det, Head: spree\n",
      "Word: spree, Deprel: obl, Head: linked\n",
      "Word: occurred, Deprel: root, Head: ROOT\n",
      "Word: Nov, Deprel: obl:tmod, Head: occurred\n",
      "Word: 11, Deprel: nummod, Head: Nov\n",
      "Word: at, Deprel: case, Head: Elementary\n",
      "Word: Hamilton, Deprel: compound, Head: Elementary\n",
      "Word: Central, Deprel: amod, Head: Elementary\n",
      "Word: Elementary, Deprel: obl, Head: occurred\n",
      "Word: in, Deprel: case, Head: Obetz\n",
      "Word: Obetz, Deprel: nmod, Head: Elementary\n",
      "Word: about, Deprel: advmod, Head: two\n",
      "Word: two, Deprel: nummod, Head: miles\n",
      "Word: miles, Deprel: nmod:npmod, Head: freeway\n",
      "Word: from, Deprel: case, Head: freeway\n",
      "Word: the, Deprel: det, Head: freeway\n",
      "Word: freeway, Deprel: obl, Head: occurred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The latest shooting linked to the spree was a Nov 11 shooting at Hamilton Township Elementary School in Obetz about two miles from the freeway'\n",
      "Word: The, Deprel: det, Head: shooting\n",
      "Word: latest, Deprel: amod, Head: shooting\n",
      "Word: shooting, Deprel: nsubj, Head: shooting\n",
      "Word: linked, Deprel: acl, Head: shooting\n",
      "Word: to, Deprel: case, Head: spree\n",
      "Word: the, Deprel: det, Head: spree\n",
      "Word: spree, Deprel: obl, Head: linked\n",
      "Word: was, Deprel: cop, Head: shooting\n",
      "Word: a, Deprel: det, Head: shooting\n",
      "Word: Nov, Deprel: compound, Head: shooting\n",
      "Word: 11, Deprel: nummod, Head: Nov\n",
      "Word: shooting, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: School\n",
      "Word: Hamilton, Deprel: compound, Head: School\n",
      "Word: Township, Deprel: compound, Head: School\n",
      "Word: Elementary, Deprel: amod, Head: School\n",
      "Word: School, Deprel: nmod, Head: shooting\n",
      "Word: in, Deprel: case, Head: Obetz\n",
      "Word: Obetz, Deprel: nmod, Head: School\n",
      "Word: about, Deprel: advmod, Head: two\n",
      "Word: two, Deprel: nummod, Head: miles\n",
      "Word: miles, Deprel: nmod:npmod, Head: freeway\n",
      "Word: from, Deprel: case, Head: freeway\n",
      "Word: the, Deprel: det, Head: freeway\n",
      "Word: freeway, Deprel: nmod, Head: shooting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Tuesday the central bank left interest rates steady as expected but also declared that overall risks were weighted toward weakness and warned of deflation risks'\n",
      "Word: On, Deprel: case, Head: Tuesday\n",
      "Word: Tuesday, Deprel: obl, Head: left\n",
      "Word: the, Deprel: det, Head: bank\n",
      "Word: central, Deprel: amod, Head: bank\n",
      "Word: bank, Deprel: nsubj, Head: left\n",
      "Word: left, Deprel: root, Head: ROOT\n",
      "Word: interest, Deprel: compound, Head: rates\n",
      "Word: rates, Deprel: obj, Head: left\n",
      "Word: steady, Deprel: xcomp, Head: left\n",
      "Word: as, Deprel: mark, Head: expected\n",
      "Word: expected, Deprel: advcl, Head: left\n",
      "Word: but, Deprel: cc, Head: declared\n",
      "Word: also, Deprel: advmod, Head: declared\n",
      "Word: declared, Deprel: conj, Head: left\n",
      "Word: that, Deprel: mark, Head: weighted\n",
      "Word: overall, Deprel: amod, Head: risks\n",
      "Word: risks, Deprel: nsubj:pass, Head: weighted\n",
      "Word: were, Deprel: aux:pass, Head: weighted\n",
      "Word: weighted, Deprel: ccomp, Head: declared\n",
      "Word: toward, Deprel: case, Head: weakness\n",
      "Word: weakness, Deprel: obl, Head: weighted\n",
      "Word: and, Deprel: cc, Head: warned\n",
      "Word: warned, Deprel: conj, Head: weighted\n",
      "Word: of, Deprel: case, Head: risks\n",
      "Word: deflation, Deprel: compound, Head: risks\n",
      "Word: risks, Deprel: obl, Head: warned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The central bank s policy board left rates steady for now as widely expected but surprised the market by declaring that overall risks were weighted toward weakness'\n",
      "Word: The, Deprel: det, Head: bank\n",
      "Word: central, Deprel: amod, Head: bank\n",
      "Word: bank, Deprel: nmod:poss, Head: board\n",
      "Word: s, Deprel: case, Head: bank\n",
      "Word: policy, Deprel: compound, Head: board\n",
      "Word: board, Deprel: nsubj, Head: left\n",
      "Word: left, Deprel: root, Head: ROOT\n",
      "Word: rates, Deprel: obj, Head: left\n",
      "Word: steady, Deprel: advmod, Head: left\n",
      "Word: for, Deprel: case, Head: now\n",
      "Word: now, Deprel: obl, Head: left\n",
      "Word: as, Deprel: mark, Head: expected\n",
      "Word: widely, Deprel: advmod, Head: expected\n",
      "Word: expected, Deprel: advcl, Head: left\n",
      "Word: but, Deprel: cc, Head: surprised\n",
      "Word: surprised, Deprel: conj, Head: left\n",
      "Word: the, Deprel: det, Head: market\n",
      "Word: market, Deprel: obj, Head: surprised\n",
      "Word: by, Deprel: mark, Head: declaring\n",
      "Word: declaring, Deprel: advcl, Head: surprised\n",
      "Word: that, Deprel: mark, Head: weighted\n",
      "Word: overall, Deprel: amod, Head: risks\n",
      "Word: risks, Deprel: nsubj, Head: weighted\n",
      "Word: were, Deprel: cop, Head: weighted\n",
      "Word: weighted, Deprel: ccomp, Head: declaring\n",
      "Word: toward, Deprel: case, Head: weakness\n",
      "Word: weakness, Deprel: obl, Head: weighted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new system costs between 1.1 million and 22 million depending on configuration'\n",
      "Word: The, Deprel: det, Head: system\n",
      "Word: new, Deprel: amod, Head: system\n",
      "Word: system, Deprel: nsubj, Head: costs\n",
      "Word: costs, Deprel: root, Head: ROOT\n",
      "Word: between, Deprel: advmod, Head: million\n",
      "Word: 1.1, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: costs\n",
      "Word: and, Deprel: cc, Head: million\n",
      "Word: 22, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: conj, Head: million\n",
      "Word: depending, Deprel: case, Head: configuration\n",
      "Word: on, Deprel: fixed, Head: depending\n",
      "Word: configuration, Deprel: obl, Head: costs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The system is priced from US 1.1 million to 22.4 million depending on configuration'\n",
      "Word: The, Deprel: det, Head: system\n",
      "Word: system, Deprel: nsubj:pass, Head: priced\n",
      "Word: is, Deprel: aux:pass, Head: priced\n",
      "Word: priced, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: US\n",
      "Word: US, Deprel: obl, Head: priced\n",
      "Word: 1.1, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: US\n",
      "Word: to, Deprel: case, Head: million\n",
      "Word: 22.4, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obl, Head: priced\n",
      "Word: depending, Deprel: case, Head: configuration\n",
      "Word: on, Deprel: fixed, Head: depending\n",
      "Word: configuration, Deprel: obl, Head: priced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Fighting erupted after four North Korean journalists confronted a dozen South Korean activists protesting human rights abuses in the North outside the main media centre'\n",
      "Word: Fighting, Deprel: nsubj, Head: erupted\n",
      "Word: erupted, Deprel: root, Head: ROOT\n",
      "Word: after, Deprel: mark, Head: confronted\n",
      "Word: four, Deprel: nummod, Head: journalists\n",
      "Word: North, Deprel: compound, Head: Korean\n",
      "Word: Korean, Deprel: amod, Head: journalists\n",
      "Word: journalists, Deprel: nsubj, Head: confronted\n",
      "Word: confronted, Deprel: advcl, Head: erupted\n",
      "Word: a, Deprel: det, Head: dozen\n",
      "Word: dozen, Deprel: nummod, Head: activists\n",
      "Word: South, Deprel: compound, Head: Korean\n",
      "Word: Korean, Deprel: amod, Head: activists\n",
      "Word: activists, Deprel: obj, Head: confronted\n",
      "Word: protesting, Deprel: acl, Head: activists\n",
      "Word: human, Deprel: amod, Head: rights\n",
      "Word: rights, Deprel: compound, Head: abuses\n",
      "Word: abuses, Deprel: obj, Head: protesting\n",
      "Word: in, Deprel: case, Head: North\n",
      "Word: the, Deprel: det, Head: North\n",
      "Word: North, Deprel: obl, Head: protesting\n",
      "Word: outside, Deprel: case, Head: centre\n",
      "Word: the, Deprel: det, Head: centre\n",
      "Word: main, Deprel: amod, Head: centre\n",
      "Word: media, Deprel: compound, Head: centre\n",
      "Word: centre, Deprel: nmod, Head: North\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Trouble flared when at least four North Korean reporters rushed from the Taegu media centre to confront a dozen activists protesting against human rights abuses in the North'\n",
      "Word: Trouble, Deprel: nsubj, Head: flared\n",
      "Word: flared, Deprel: root, Head: ROOT\n",
      "Word: when, Deprel: advmod, Head: rushed\n",
      "Word: at, Deprel: advmod, Head: four\n",
      "Word: least, Deprel: nmod, Head: four\n",
      "Word: four, Deprel: nummod, Head: reporters\n",
      "Word: North, Deprel: compound, Head: Korean\n",
      "Word: Korean, Deprel: amod, Head: reporters\n",
      "Word: reporters, Deprel: nsubj, Head: rushed\n",
      "Word: rushed, Deprel: advcl, Head: flared\n",
      "Word: from, Deprel: case, Head: centre\n",
      "Word: the, Deprel: det, Head: centre\n",
      "Word: Taegu, Deprel: compound, Head: centre\n",
      "Word: media, Deprel: compound, Head: centre\n",
      "Word: centre, Deprel: obl, Head: rushed\n",
      "Word: to, Deprel: mark, Head: confront\n",
      "Word: confront, Deprel: advcl, Head: rushed\n",
      "Word: a, Deprel: det, Head: dozen\n",
      "Word: dozen, Deprel: nummod, Head: activists\n",
      "Word: activists, Deprel: obj, Head: confront\n",
      "Word: protesting, Deprel: acl, Head: activists\n",
      "Word: against, Deprel: case, Head: abuses\n",
      "Word: human, Deprel: amod, Head: rights\n",
      "Word: rights, Deprel: compound, Head: abuses\n",
      "Word: abuses, Deprel: obl, Head: protesting\n",
      "Word: in, Deprel: case, Head: North\n",
      "Word: the, Deprel: det, Head: North\n",
      "Word: North, Deprel: nmod, Head: abuses\n",
      "\n",
      "Dependencies for Sentence: 'Dusty had battled kidney cancer for more than a year'\n",
      "Word: Dusty, Deprel: nsubj, Head: battled\n",
      "Word: had, Deprel: aux, Head: battled\n",
      "Word: battled, Deprel: root, Head: ROOT\n",
      "Word: kidney, Deprel: compound, Head: cancer\n",
      "Word: cancer, Deprel: obj, Head: battled\n",
      "Word: for, Deprel: case, Head: year\n",
      "Word: more, Deprel: advmod, Head: year\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: a, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl, Head: battled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dusty had surgery for cancer in 2001 and had a kidney removed'\n",
      "Word: Dusty, Deprel: nsubj, Head: had\n",
      "Word: had, Deprel: root, Head: ROOT\n",
      "Word: surgery, Deprel: obj, Head: had\n",
      "Word: for, Deprel: case, Head: cancer\n",
      "Word: cancer, Deprel: nmod, Head: surgery\n",
      "Word: in, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: had\n",
      "Word: and, Deprel: cc, Head: had\n",
      "Word: had, Deprel: conj, Head: had\n",
      "Word: a, Deprel: det, Head: kidney\n",
      "Word: kidney, Deprel: obj, Head: had\n",
      "Word: removed, Deprel: xcomp, Head: had\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'According to SunnComm s Peter Jacobs MediaMax performs exactly as advertised to the companies who purchased it'\n",
      "Word: According, Deprel: case, Head: Peter\n",
      "Word: to, Deprel: fixed, Head: According\n",
      "Word: SunnComm, Deprel: nmod:poss, Head: Peter\n",
      "Word: s, Deprel: case, Head: SunnComm\n",
      "Word: Peter, Deprel: obl, Head: performs\n",
      "Word: Jacobs, Deprel: flat, Head: Peter\n",
      "Word: MediaMax, Deprel: nsubj, Head: performs\n",
      "Word: performs, Deprel: root, Head: ROOT\n",
      "Word: exactly, Deprel: advmod, Head: advertised\n",
      "Word: as, Deprel: mark, Head: advertised\n",
      "Word: advertised, Deprel: advcl, Head: performs\n",
      "Word: to, Deprel: case, Head: companies\n",
      "Word: the, Deprel: det, Head: companies\n",
      "Word: companies, Deprel: obl, Head: advertised\n",
      "Word: who, Deprel: nsubj, Head: purchased\n",
      "Word: purchased, Deprel: acl:relcl, Head: companies\n",
      "Word: it, Deprel: obj, Head: purchased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'MediaMax performs EXACTLY as advertised to the companies who purchased it Jacobs said in the statement'\n",
      "Word: MediaMax, Deprel: nsubj, Head: performs\n",
      "Word: performs, Deprel: root, Head: ROOT\n",
      "Word: EXACTLY, Deprel: advmod, Head: performs\n",
      "Word: as, Deprel: mark, Head: advertised\n",
      "Word: advertised, Deprel: advcl, Head: performs\n",
      "Word: to, Deprel: case, Head: companies\n",
      "Word: the, Deprel: det, Head: companies\n",
      "Word: companies, Deprel: obl, Head: advertised\n",
      "Word: who, Deprel: nsubj, Head: purchased\n",
      "Word: purchased, Deprel: acl:relcl, Head: companies\n",
      "Word: it, Deprel: obj, Head: purchased\n",
      "Word: Jacobs, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: performs\n",
      "Word: in, Deprel: case, Head: statement\n",
      "Word: the, Deprel: det, Head: statement\n",
      "Word: statement, Deprel: obl, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Kadyrov was not injured but four of his bodyguards were among those killed'\n",
      "Word: Kadyrov, Deprel: nsubj, Head: injured\n",
      "Word: was, Deprel: cop, Head: injured\n",
      "Word: not, Deprel: advmod, Head: injured\n",
      "Word: injured, Deprel: root, Head: ROOT\n",
      "Word: but, Deprel: cc, Head: those\n",
      "Word: four, Deprel: nsubj, Head: those\n",
      "Word: of, Deprel: case, Head: bodyguards\n",
      "Word: his, Deprel: nmod:poss, Head: bodyguards\n",
      "Word: bodyguards, Deprel: nmod, Head: four\n",
      "Word: were, Deprel: cop, Head: those\n",
      "Word: among, Deprel: case, Head: those\n",
      "Word: those, Deprel: conj, Head: injured\n",
      "Word: killed, Deprel: acl, Head: those\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But Itar-Tass news agency said four of his bodyguards were among those killed by the bomb'\n",
      "Word: But, Deprel: cc, Head: said\n",
      "Word: Itar-Tass, Deprel: compound, Head: agency\n",
      "Word: news, Deprel: compound, Head: agency\n",
      "Word: agency, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: four, Deprel: nsubj, Head: those\n",
      "Word: of, Deprel: case, Head: bodyguards\n",
      "Word: his, Deprel: nmod:poss, Head: bodyguards\n",
      "Word: bodyguards, Deprel: nmod, Head: four\n",
      "Word: were, Deprel: cop, Head: those\n",
      "Word: among, Deprel: case, Head: those\n",
      "Word: those, Deprel: ccomp, Head: said\n",
      "Word: killed, Deprel: acl, Head: those\n",
      "Word: by, Deprel: case, Head: bomb\n",
      "Word: the, Deprel: det, Head: bomb\n",
      "Word: bomb, Deprel: obl:agent, Head: killed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The router will be available in the first quarter of 2004 and will cost around 200 the company said'\n",
      "Word: The, Deprel: det, Head: router\n",
      "Word: router, Deprel: nsubj, Head: available\n",
      "Word: will, Deprel: aux, Head: available\n",
      "Word: be, Deprel: cop, Head: available\n",
      "Word: available, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: first, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: available\n",
      "Word: of, Deprel: case, Head: 2004\n",
      "Word: 2004, Deprel: nmod, Head: quarter\n",
      "Word: and, Deprel: cc, Head: cost\n",
      "Word: will, Deprel: aux, Head: cost\n",
      "Word: cost, Deprel: conj, Head: available\n",
      "Word: around, Deprel: advmod, Head: 200\n",
      "Word: 200, Deprel: obj, Head: cost\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: advcl, Head: cost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Netgear prices the WGT634U Super Wireless Media Router which will be available in the first quarter of 2004 at under 200'\n",
      "Word: Netgear, Deprel: compound, Head: prices\n",
      "Word: prices, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: Router\n",
      "Word: WGT634U, Deprel: compound, Head: Router\n",
      "Word: Super, Deprel: amod, Head: Wireless\n",
      "Word: Wireless, Deprel: compound, Head: Router\n",
      "Word: Media, Deprel: compound, Head: Router\n",
      "Word: Router, Deprel: appos, Head: prices\n",
      "Word: which, Deprel: nsubj, Head: available\n",
      "Word: will, Deprel: aux, Head: available\n",
      "Word: be, Deprel: cop, Head: available\n",
      "Word: available, Deprel: acl:relcl, Head: Router\n",
      "Word: in, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: first, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: available\n",
      "Word: of, Deprel: case, Head: 2004\n",
      "Word: 2004, Deprel: nmod, Head: quarter\n",
      "Word: at, Deprel: case, Head: 200\n",
      "Word: under, Deprel: case, Head: 200\n",
      "Word: 200, Deprel: obl, Head: available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The commission estimates California lost 1.34 billion the most of any state to tax shelters in 2001'\n",
      "Word: The, Deprel: det, Head: commission\n",
      "Word: commission, Deprel: nsubj, Head: estimates\n",
      "Word: estimates, Deprel: root, Head: ROOT\n",
      "Word: California, Deprel: nsubj, Head: lost\n",
      "Word: lost, Deprel: ccomp, Head: estimates\n",
      "Word: 1.34, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obj, Head: lost\n",
      "Word: the, Deprel: det, Head: most\n",
      "Word: most, Deprel: obj, Head: lost\n",
      "Word: of, Deprel: case, Head: state\n",
      "Word: any, Deprel: det, Head: state\n",
      "Word: state, Deprel: nmod, Head: most\n",
      "Word: to, Deprel: case, Head: shelters\n",
      "Word: tax, Deprel: compound, Head: shelters\n",
      "Word: shelters, Deprel: obl, Head: lost\n",
      "Word: in, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: lost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The commission estimated California lost 937 million to corporate tax shelters in 2001'\n",
      "Word: The, Deprel: det, Head: commission\n",
      "Word: commission, Deprel: nsubj, Head: estimated\n",
      "Word: estimated, Deprel: root, Head: ROOT\n",
      "Word: California, Deprel: nsubj, Head: lost\n",
      "Word: lost, Deprel: ccomp, Head: estimated\n",
      "Word: 937, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: lost\n",
      "Word: to, Deprel: case, Head: shelters\n",
      "Word: corporate, Deprel: amod, Head: shelters\n",
      "Word: tax, Deprel: compound, Head: shelters\n",
      "Word: shelters, Deprel: obl, Head: lost\n",
      "Word: in, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: lost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The officials did not say whether U.S forces crossed into Syrian territory and were vague about how the Syrian border guards became involved'\n",
      "Word: The, Deprel: det, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: say\n",
      "Word: did, Deprel: aux, Head: say\n",
      "Word: not, Deprel: advmod, Head: say\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: whether, Deprel: mark, Head: crossed\n",
      "Word: U.S, Deprel: compound, Head: forces\n",
      "Word: forces, Deprel: nsubj, Head: crossed\n",
      "Word: crossed, Deprel: ccomp, Head: say\n",
      "Word: into, Deprel: case, Head: territory\n",
      "Word: Syrian, Deprel: amod, Head: territory\n",
      "Word: territory, Deprel: obl, Head: crossed\n",
      "Word: and, Deprel: cc, Head: vague\n",
      "Word: were, Deprel: cop, Head: vague\n",
      "Word: vague, Deprel: conj, Head: crossed\n",
      "Word: about, Deprel: mark, Head: became\n",
      "Word: how, Deprel: advmod, Head: became\n",
      "Word: the, Deprel: det, Head: guards\n",
      "Word: Syrian, Deprel: amod, Head: guards\n",
      "Word: border, Deprel: compound, Head: guards\n",
      "Word: guards, Deprel: nsubj, Head: became\n",
      "Word: became, Deprel: advcl, Head: vague\n",
      "Word: involved, Deprel: xcomp, Head: became\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'U.S officials did not say whether American forces who were acting on intelligence crossed into Syrian territory and were vague about how the Syrian guards were involved'\n",
      "Word: U.S, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: say\n",
      "Word: did, Deprel: aux, Head: say\n",
      "Word: not, Deprel: advmod, Head: say\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: whether, Deprel: mark, Head: crossed\n",
      "Word: American, Deprel: amod, Head: forces\n",
      "Word: forces, Deprel: nsubj, Head: crossed\n",
      "Word: who, Deprel: nsubj, Head: acting\n",
      "Word: were, Deprel: aux, Head: acting\n",
      "Word: acting, Deprel: acl:relcl, Head: forces\n",
      "Word: on, Deprel: case, Head: intelligence\n",
      "Word: intelligence, Deprel: obl, Head: acting\n",
      "Word: crossed, Deprel: ccomp, Head: say\n",
      "Word: into, Deprel: case, Head: territory\n",
      "Word: Syrian, Deprel: amod, Head: territory\n",
      "Word: territory, Deprel: obl, Head: crossed\n",
      "Word: and, Deprel: cc, Head: vague\n",
      "Word: were, Deprel: cop, Head: vague\n",
      "Word: vague, Deprel: conj, Head: crossed\n",
      "Word: about, Deprel: mark, Head: involved\n",
      "Word: how, Deprel: advmod, Head: involved\n",
      "Word: the, Deprel: det, Head: guards\n",
      "Word: Syrian, Deprel: amod, Head: guards\n",
      "Word: guards, Deprel: nsubj, Head: involved\n",
      "Word: were, Deprel: cop, Head: involved\n",
      "Word: involved, Deprel: advcl, Head: vague\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'VeriSign introduced its Site Finder service on Sept 15'\n",
      "Word: VeriSign, Deprel: nsubj, Head: introduced\n",
      "Word: introduced, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: service\n",
      "Word: Site, Deprel: compound, Head: Finder\n",
      "Word: Finder, Deprel: compound, Head: service\n",
      "Word: service, Deprel: obj, Head: introduced\n",
      "Word: on, Deprel: case, Head: Sept\n",
      "Word: Sept, Deprel: obl, Head: introduced\n",
      "Word: 15, Deprel: nummod, Head: Sept\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The battle around VeriSign s three-week-old Site Finder service rages on'\n",
      "Word: The, Deprel: det, Head: battle\n",
      "Word: battle, Deprel: nsubj, Head: rages\n",
      "Word: around, Deprel: case, Head: service\n",
      "Word: VeriSign, Deprel: nmod:poss, Head: service\n",
      "Word: s, Deprel: case, Head: VeriSign\n",
      "Word: three-week-old, Deprel: amod, Head: service\n",
      "Word: Site, Deprel: compound, Head: service\n",
      "Word: Finder, Deprel: compound, Head: service\n",
      "Word: service, Deprel: nmod, Head: battle\n",
      "Word: rages, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: advmod, Head: rages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Monday as first reported by CNET News.com the RIAA withdrew a DMCA notice to Penn State University s astronomy and astrophysics department'\n",
      "Word: On, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: withdrew\n",
      "Word: as, Deprel: mark, Head: reported\n",
      "Word: first, Deprel: advmod, Head: reported\n",
      "Word: reported, Deprel: advcl, Head: withdrew\n",
      "Word: by, Deprel: case, Head: News.com\n",
      "Word: CNET, Deprel: compound, Head: News.com\n",
      "Word: News.com, Deprel: obl, Head: reported\n",
      "Word: the, Deprel: det, Head: RIAA\n",
      "Word: RIAA, Deprel: nsubj, Head: withdrew\n",
      "Word: withdrew, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: notice\n",
      "Word: DMCA, Deprel: compound, Head: notice\n",
      "Word: notice, Deprel: obj, Head: withdrew\n",
      "Word: to, Deprel: case, Head: department\n",
      "Word: Penn, Deprel: compound, Head: University\n",
      "Word: State, Deprel: compound, Head: University\n",
      "Word: University, Deprel: nmod:poss, Head: department\n",
      "Word: s, Deprel: case, Head: University\n",
      "Word: astronomy, Deprel: compound, Head: department\n",
      "Word: and, Deprel: cc, Head: astrophysics\n",
      "Word: astrophysics, Deprel: conj, Head: astronomy\n",
      "Word: department, Deprel: obl, Head: withdrew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Last Thursday the RIAA sent a stiff copyright warning to Penn State s department of astronomy and astrophysics'\n",
      "Word: Last, Deprel: amod, Head: Thursday\n",
      "Word: Thursday, Deprel: obl:tmod, Head: sent\n",
      "Word: the, Deprel: det, Head: RIAA\n",
      "Word: RIAA, Deprel: nsubj, Head: sent\n",
      "Word: sent, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: warning\n",
      "Word: stiff, Deprel: amod, Head: warning\n",
      "Word: copyright, Deprel: compound, Head: warning\n",
      "Word: warning, Deprel: obj, Head: sent\n",
      "Word: to, Deprel: case, Head: department\n",
      "Word: Penn, Deprel: compound, Head: State\n",
      "Word: State, Deprel: nmod:poss, Head: department\n",
      "Word: s, Deprel: case, Head: State\n",
      "Word: department, Deprel: nmod, Head: warning\n",
      "Word: of, Deprel: case, Head: astronomy\n",
      "Word: astronomy, Deprel: nmod, Head: department\n",
      "Word: and, Deprel: cc, Head: astrophysics\n",
      "Word: astrophysics, Deprel: conj, Head: astronomy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Druce is still being held at the prison and is now in isolation she said'\n",
      "Word: Druce, Deprel: nsubj:pass, Head: held\n",
      "Word: is, Deprel: aux, Head: held\n",
      "Word: still, Deprel: advmod, Head: held\n",
      "Word: being, Deprel: aux:pass, Head: held\n",
      "Word: held, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: prison\n",
      "Word: the, Deprel: det, Head: prison\n",
      "Word: prison, Deprel: obl, Head: held\n",
      "Word: and, Deprel: cc, Head: isolation\n",
      "Word: is, Deprel: cop, Head: isolation\n",
      "Word: now, Deprel: advmod, Head: isolation\n",
      "Word: in, Deprel: case, Head: isolation\n",
      "Word: isolation, Deprel: conj, Head: held\n",
      "Word: she, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: held\n",
      "\n",
      "Dependencies for Sentence: 'Druce last night was held in isolation at the same prison'\n",
      "Word: Druce, Deprel: nsubj:pass, Head: held\n",
      "Word: last, Deprel: amod, Head: night\n",
      "Word: night, Deprel: nmod:tmod, Head: Druce\n",
      "Word: was, Deprel: aux:pass, Head: held\n",
      "Word: held, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: isolation\n",
      "Word: isolation, Deprel: obl, Head: held\n",
      "Word: at, Deprel: case, Head: prison\n",
      "Word: the, Deprel: det, Head: prison\n",
      "Word: same, Deprel: amod, Head: prison\n",
      "Word: prison, Deprel: nmod, Head: isolation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The first health-care worker in the country to die of SARS was a Filipina-Canadian who contracted the disease at North York General Hospital the site of the second outbreak'\n",
      "Word: The, Deprel: det, Head: worker\n",
      "Word: first, Deprel: amod, Head: worker\n",
      "Word: health-care, Deprel: compound, Head: worker\n",
      "Word: worker, Deprel: nsubj, Head: Filipina-Canadian\n",
      "Word: in, Deprel: case, Head: country\n",
      "Word: the, Deprel: det, Head: country\n",
      "Word: country, Deprel: nmod, Head: worker\n",
      "Word: to, Deprel: mark, Head: die\n",
      "Word: die, Deprel: acl, Head: worker\n",
      "Word: of, Deprel: case, Head: SARS\n",
      "Word: SARS, Deprel: obl, Head: die\n",
      "Word: was, Deprel: cop, Head: Filipina-Canadian\n",
      "Word: a, Deprel: det, Head: Filipina-Canadian\n",
      "Word: Filipina-Canadian, Deprel: root, Head: ROOT\n",
      "Word: who, Deprel: nsubj, Head: contracted\n",
      "Word: contracted, Deprel: acl:relcl, Head: Filipina-Canadian\n",
      "Word: the, Deprel: det, Head: disease\n",
      "Word: disease, Deprel: obj, Head: contracted\n",
      "Word: at, Deprel: case, Head: Hospital\n",
      "Word: North, Deprel: compound, Head: York\n",
      "Word: York, Deprel: compound, Head: Hospital\n",
      "Word: General, Deprel: amod, Head: Hospital\n",
      "Word: Hospital, Deprel: obl, Head: contracted\n",
      "Word: the, Deprel: det, Head: site\n",
      "Word: site, Deprel: obl:tmod, Head: contracted\n",
      "Word: of, Deprel: case, Head: outbreak\n",
      "Word: the, Deprel: det, Head: outbreak\n",
      "Word: second, Deprel: amod, Head: outbreak\n",
      "Word: outbreak, Deprel: nmod, Head: site\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Emile Laroza 51 contracted SARS while working as a nurse at North York General Hospital the epicentre of the second SARS outbreak'\n",
      "Word: Emile, Deprel: nsubj, Head: contracted\n",
      "Word: Laroza, Deprel: flat, Head: Emile\n",
      "Word: 51, Deprel: nmod:npmod, Head: Emile\n",
      "Word: contracted, Deprel: root, Head: ROOT\n",
      "Word: SARS, Deprel: obj, Head: contracted\n",
      "Word: while, Deprel: mark, Head: working\n",
      "Word: working, Deprel: advcl, Head: contracted\n",
      "Word: as, Deprel: case, Head: nurse\n",
      "Word: a, Deprel: det, Head: nurse\n",
      "Word: nurse, Deprel: obl, Head: working\n",
      "Word: at, Deprel: case, Head: Hospital\n",
      "Word: North, Deprel: compound, Head: York\n",
      "Word: York, Deprel: compound, Head: Hospital\n",
      "Word: General, Deprel: amod, Head: Hospital\n",
      "Word: Hospital, Deprel: nmod, Head: nurse\n",
      "Word: the, Deprel: det, Head: epicentre\n",
      "Word: epicentre, Deprel: obj, Head: working\n",
      "Word: of, Deprel: case, Head: outbreak\n",
      "Word: the, Deprel: det, Head: outbreak\n",
      "Word: second, Deprel: amod, Head: outbreak\n",
      "Word: SARS, Deprel: compound, Head: outbreak\n",
      "Word: outbreak, Deprel: nmod, Head: epicentre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Their leader Abu Bakr al-Azdi turned himself in in June his deputy was killed in a recent shootout with Saudi forces'\n",
      "Word: Their, Deprel: nmod:poss, Head: leader\n",
      "Word: leader, Deprel: compound, Head: Abu\n",
      "Word: Abu, Deprel: nsubj, Head: turned\n",
      "Word: Bakr, Deprel: flat, Head: Abu\n",
      "Word: al-Azdi, Deprel: flat, Head: Abu\n",
      "Word: turned, Deprel: root, Head: ROOT\n",
      "Word: himself, Deprel: obj, Head: turned\n",
      "Word: in, Deprel: compound:prt, Head: turned\n",
      "Word: in, Deprel: case, Head: June\n",
      "Word: June, Deprel: obl, Head: turned\n",
      "Word: his, Deprel: nmod:poss, Head: deputy\n",
      "Word: deputy, Deprel: nsubj:pass, Head: killed\n",
      "Word: was, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: parataxis, Head: turned\n",
      "Word: in, Deprel: case, Head: shootout\n",
      "Word: a, Deprel: det, Head: shootout\n",
      "Word: recent, Deprel: amod, Head: shootout\n",
      "Word: shootout, Deprel: obl, Head: killed\n",
      "Word: with, Deprel: case, Head: forces\n",
      "Word: Saudi, Deprel: amod, Head: forces\n",
      "Word: forces, Deprel: nmod, Head: shootout\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Their leader Abu Bakr al-Azdi surrendered in June his deputy was killed in a shoot-out with Saudi forces recently'\n",
      "Word: Their, Deprel: nmod:poss, Head: leader\n",
      "Word: leader, Deprel: compound, Head: Abu\n",
      "Word: Abu, Deprel: nsubj, Head: surrendered\n",
      "Word: Bakr, Deprel: flat, Head: Abu\n",
      "Word: al-Azdi, Deprel: flat, Head: Abu\n",
      "Word: surrendered, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: June\n",
      "Word: June, Deprel: obl, Head: surrendered\n",
      "Word: his, Deprel: nmod:poss, Head: deputy\n",
      "Word: deputy, Deprel: nsubj:pass, Head: killed\n",
      "Word: was, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: ccomp, Head: surrendered\n",
      "Word: in, Deprel: case, Head: shoot-out\n",
      "Word: a, Deprel: det, Head: shoot-out\n",
      "Word: shoot-out, Deprel: obl, Head: killed\n",
      "Word: with, Deprel: case, Head: forces\n",
      "Word: Saudi, Deprel: amod, Head: forces\n",
      "Word: forces, Deprel: nmod, Head: shoot-out\n",
      "Word: recently, Deprel: advmod, Head: forces\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'After Freitas opening statement King County Superior Court Judge Charles Mertel recessed trial until after the Thanksgiving weekend'\n",
      "Word: After, Deprel: case, Head: statement\n",
      "Word: Freitas, Deprel: compound, Head: statement\n",
      "Word: opening, Deprel: amod, Head: statement\n",
      "Word: statement, Deprel: obl, Head: recessed\n",
      "Word: King, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: Court\n",
      "Word: Superior, Deprel: amod, Head: Court\n",
      "Word: Court, Deprel: compound, Head: Judge\n",
      "Word: Judge, Deprel: nsubj, Head: recessed\n",
      "Word: Charles, Deprel: flat, Head: Judge\n",
      "Word: Mertel, Deprel: flat, Head: Judge\n",
      "Word: recessed, Deprel: root, Head: ROOT\n",
      "Word: trial, Deprel: obj, Head: recessed\n",
      "Word: until, Deprel: case, Head: weekend\n",
      "Word: after, Deprel: case, Head: weekend\n",
      "Word: the, Deprel: det, Head: weekend\n",
      "Word: Thanksgiving, Deprel: compound, Head: weekend\n",
      "Word: weekend, Deprel: obl, Head: recessed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'King County Superior Court Judge Charles Mertel will then recess the trial until Monday'\n",
      "Word: King, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: Judge\n",
      "Word: Superior, Deprel: amod, Head: Court\n",
      "Word: Court, Deprel: compound, Head: Judge\n",
      "Word: Judge, Deprel: nsubj, Head: recess\n",
      "Word: Charles, Deprel: flat, Head: Judge\n",
      "Word: Mertel, Deprel: flat, Head: Judge\n",
      "Word: will, Deprel: aux, Head: recess\n",
      "Word: then, Deprel: advmod, Head: recess\n",
      "Word: recess, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: trial\n",
      "Word: trial, Deprel: obj, Head: recess\n",
      "Word: until, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: recess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Google s investors include prominent VC firms Kleiner Perkins Caufield Byers and Sequoia Capital the paper noted'\n",
      "Word: Google, Deprel: nmod:poss, Head: investors\n",
      "Word: s, Deprel: case, Head: Google\n",
      "Word: investors, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: prominent, Deprel: amod, Head: firms\n",
      "Word: VC, Deprel: compound, Head: firms\n",
      "Word: firms, Deprel: obj, Head: include\n",
      "Word: Kleiner, Deprel: appos, Head: firms\n",
      "Word: Perkins, Deprel: flat, Head: Kleiner\n",
      "Word: Caufield, Deprel: flat, Head: Kleiner\n",
      "Word: Byers, Deprel: flat, Head: Kleiner\n",
      "Word: and, Deprel: cc, Head: Capital\n",
      "Word: Sequoia, Deprel: compound, Head: Capital\n",
      "Word: Capital, Deprel: conj, Head: Kleiner\n",
      "Word: the, Deprel: det, Head: paper\n",
      "Word: paper, Deprel: nsubj, Head: noted\n",
      "Word: noted, Deprel: parataxis, Head: include\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Google s early stage backers in include California-based Stanford University and VC firms Kleiner Perkins and Sequoia Capital'\n",
      "Word: Google, Deprel: nmod:poss, Head: backers\n",
      "Word: s, Deprel: case, Head: Google\n",
      "Word: early, Deprel: amod, Head: stage\n",
      "Word: stage, Deprel: compound, Head: backers\n",
      "Word: backers, Deprel: nsubj, Head: include\n",
      "Word: in, Deprel: nmod, Head: backers\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: California-based, Deprel: amod, Head: University\n",
      "Word: Stanford, Deprel: compound, Head: University\n",
      "Word: University, Deprel: obj, Head: include\n",
      "Word: and, Deprel: cc, Head: firms\n",
      "Word: VC, Deprel: compound, Head: firms\n",
      "Word: firms, Deprel: conj, Head: University\n",
      "Word: Kleiner, Deprel: conj, Head: University\n",
      "Word: Perkins, Deprel: flat, Head: Kleiner\n",
      "Word: and, Deprel: cc, Head: Capital\n",
      "Word: Sequoia, Deprel: compound, Head: Capital\n",
      "Word: Capital, Deprel: conj, Head: Kleiner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'July 1st is the sixth anniversary of Hong Kong s return to Chinese rule'\n",
      "Word: July, Deprel: nsubj, Head: anniversary\n",
      "Word: 1st, Deprel: nummod, Head: July\n",
      "Word: is, Deprel: cop, Head: anniversary\n",
      "Word: the, Deprel: det, Head: anniversary\n",
      "Word: sixth, Deprel: amod, Head: anniversary\n",
      "Word: anniversary, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: return\n",
      "Word: Hong, Deprel: compound, Head: Kong\n",
      "Word: Kong, Deprel: nmod:poss, Head: return\n",
      "Word: s, Deprel: case, Head: Kong\n",
      "Word: return, Deprel: nmod, Head: anniversary\n",
      "Word: to, Deprel: case, Head: rule\n",
      "Word: Chinese, Deprel: amod, Head: rule\n",
      "Word: rule, Deprel: nmod, Head: return\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The rally overshadowed ceremonies marking the sixth anniversary of Hong Kong s return to China on 1 July 1997'\n",
      "Word: The, Deprel: det, Head: rally\n",
      "Word: rally, Deprel: nsubj, Head: overshadowed\n",
      "Word: overshadowed, Deprel: root, Head: ROOT\n",
      "Word: ceremonies, Deprel: obj, Head: overshadowed\n",
      "Word: marking, Deprel: acl, Head: ceremonies\n",
      "Word: the, Deprel: det, Head: anniversary\n",
      "Word: sixth, Deprel: amod, Head: anniversary\n",
      "Word: anniversary, Deprel: obj, Head: marking\n",
      "Word: of, Deprel: case, Head: return\n",
      "Word: Hong, Deprel: nmod:poss, Head: return\n",
      "Word: Kong, Deprel: flat, Head: Hong\n",
      "Word: s, Deprel: case, Head: Hong\n",
      "Word: return, Deprel: nmod, Head: anniversary\n",
      "Word: to, Deprel: case, Head: China\n",
      "Word: China, Deprel: nmod, Head: return\n",
      "Word: on, Deprel: case, Head: July\n",
      "Word: 1, Deprel: nummod, Head: July\n",
      "Word: July, Deprel: nmod, Head: anniversary\n",
      "Word: 1997, Deprel: nummod, Head: July\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Palm Wednesday announced plans to acquire Handspring a company started by Jeff Hawkins regarded by many as the father of the Palm handheld'\n",
      "Word: Palm, Deprel: compound, Head: Wednesday\n",
      "Word: Wednesday, Deprel: nsubj, Head: announced\n",
      "Word: announced, Deprel: root, Head: ROOT\n",
      "Word: plans, Deprel: obj, Head: announced\n",
      "Word: to, Deprel: mark, Head: acquire\n",
      "Word: acquire, Deprel: acl, Head: plans\n",
      "Word: Handspring, Deprel: obj, Head: acquire\n",
      "Word: a, Deprel: det, Head: company\n",
      "Word: company, Deprel: obj, Head: acquire\n",
      "Word: started, Deprel: acl, Head: company\n",
      "Word: by, Deprel: case, Head: Jeff\n",
      "Word: Jeff, Deprel: obl, Head: started\n",
      "Word: Hawkins, Deprel: flat, Head: Jeff\n",
      "Word: regarded, Deprel: acl, Head: company\n",
      "Word: by, Deprel: case, Head: many\n",
      "Word: many, Deprel: obl:agent, Head: regarded\n",
      "Word: as, Deprel: case, Head: father\n",
      "Word: the, Deprel: det, Head: father\n",
      "Word: father, Deprel: obl, Head: regarded\n",
      "Word: of, Deprel: case, Head: handheld\n",
      "Word: the, Deprel: det, Head: handheld\n",
      "Word: Palm, Deprel: compound, Head: handheld\n",
      "Word: handheld, Deprel: nmod, Head: father\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Palm said on Wednesday it plans to buy Handspring a company created by renegade Palm co-founder Jeff Hawkins'\n",
      "Word: Palm, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: said\n",
      "Word: it, Deprel: nsubj, Head: plans\n",
      "Word: plans, Deprel: ccomp, Head: said\n",
      "Word: to, Deprel: mark, Head: buy\n",
      "Word: buy, Deprel: xcomp, Head: plans\n",
      "Word: Handspring, Deprel: obj, Head: buy\n",
      "Word: a, Deprel: det, Head: company\n",
      "Word: company, Deprel: obj, Head: buy\n",
      "Word: created, Deprel: acl, Head: company\n",
      "Word: by, Deprel: case, Head: Jeff\n",
      "Word: renegade, Deprel: amod, Head: Jeff\n",
      "Word: Palm, Deprel: compound, Head: co-founder\n",
      "Word: co-founder, Deprel: compound, Head: Jeff\n",
      "Word: Jeff, Deprel: obl, Head: created\n",
      "Word: Hawkins, Deprel: flat, Head: Jeff\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I m not going to be sponsoring it because it is not our proposal but I m not going to be negative about it'\n",
      "Word: I, Deprel: nsubj, Head: going\n",
      "Word: m, Deprel: aux, Head: going\n",
      "Word: not, Deprel: advmod, Head: going\n",
      "Word: going, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: sponsoring\n",
      "Word: be, Deprel: aux, Head: sponsoring\n",
      "Word: sponsoring, Deprel: xcomp, Head: going\n",
      "Word: it, Deprel: obj, Head: sponsoring\n",
      "Word: because, Deprel: mark, Head: proposal\n",
      "Word: it, Deprel: nsubj, Head: proposal\n",
      "Word: is, Deprel: cop, Head: proposal\n",
      "Word: not, Deprel: advmod, Head: proposal\n",
      "Word: our, Deprel: nmod:poss, Head: proposal\n",
      "Word: proposal, Deprel: advcl, Head: going\n",
      "Word: but, Deprel: cc, Head: going\n",
      "Word: I, Deprel: nsubj, Head: going\n",
      "Word: m, Deprel: aux, Head: going\n",
      "Word: not, Deprel: advmod, Head: going\n",
      "Word: going, Deprel: conj, Head: going\n",
      "Word: to, Deprel: mark, Head: negative\n",
      "Word: be, Deprel: cop, Head: negative\n",
      "Word: negative, Deprel: xcomp, Head: going\n",
      "Word: about, Deprel: case, Head: it\n",
      "Word: it, Deprel: obl, Head: negative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I m not going to be sponsoring it because it s not our proposal but I m not responding to it in a negative way he said'\n",
      "Word: I, Deprel: nsubj, Head: going\n",
      "Word: m, Deprel: aux, Head: going\n",
      "Word: not, Deprel: advmod, Head: going\n",
      "Word: going, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: sponsoring\n",
      "Word: be, Deprel: aux, Head: sponsoring\n",
      "Word: sponsoring, Deprel: xcomp, Head: going\n",
      "Word: it, Deprel: obj, Head: sponsoring\n",
      "Word: because, Deprel: mark, Head: proposal\n",
      "Word: it, Deprel: nsubj, Head: proposal\n",
      "Word: s, Deprel: cop, Head: proposal\n",
      "Word: not, Deprel: advmod, Head: proposal\n",
      "Word: our, Deprel: nmod:poss, Head: proposal\n",
      "Word: proposal, Deprel: advcl, Head: going\n",
      "Word: but, Deprel: cc, Head: responding\n",
      "Word: I, Deprel: nsubj, Head: responding\n",
      "Word: m, Deprel: aux, Head: responding\n",
      "Word: not, Deprel: advmod, Head: responding\n",
      "Word: responding, Deprel: conj, Head: going\n",
      "Word: to, Deprel: case, Head: it\n",
      "Word: it, Deprel: obl, Head: responding\n",
      "Word: in, Deprel: case, Head: way\n",
      "Word: a, Deprel: det, Head: way\n",
      "Word: negative, Deprel: amod, Head: way\n",
      "Word: way, Deprel: obl, Head: responding\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: way\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The government recently shelved peace talks with the MILF being brokered by Malaysia after a string of attacks including three bombings on Mindanao'\n",
      "Word: The, Deprel: det, Head: government\n",
      "Word: government, Deprel: nsubj, Head: shelved\n",
      "Word: recently, Deprel: advmod, Head: shelved\n",
      "Word: shelved, Deprel: root, Head: ROOT\n",
      "Word: peace, Deprel: compound, Head: talks\n",
      "Word: talks, Deprel: obj, Head: shelved\n",
      "Word: with, Deprel: case, Head: MILF\n",
      "Word: the, Deprel: det, Head: MILF\n",
      "Word: MILF, Deprel: nmod, Head: talks\n",
      "Word: being, Deprel: aux:pass, Head: brokered\n",
      "Word: brokered, Deprel: acl, Head: MILF\n",
      "Word: by, Deprel: case, Head: Malaysia\n",
      "Word: Malaysia, Deprel: obl, Head: brokered\n",
      "Word: after, Deprel: case, Head: string\n",
      "Word: a, Deprel: det, Head: string\n",
      "Word: string, Deprel: obl, Head: brokered\n",
      "Word: of, Deprel: case, Head: attacks\n",
      "Word: attacks, Deprel: nmod, Head: string\n",
      "Word: including, Deprel: case, Head: bombings\n",
      "Word: three, Deprel: nummod, Head: bombings\n",
      "Word: bombings, Deprel: nmod, Head: attacks\n",
      "Word: on, Deprel: case, Head: Mindanao\n",
      "Word: Mindanao, Deprel: nmod, Head: bombings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The government recently shelved peace talks being brokered by neighbouring Malaysia after a spate of attacks on Mindanao including three deadly bombings that it blamed on the MILF'\n",
      "Word: The, Deprel: det, Head: government\n",
      "Word: government, Deprel: nsubj, Head: shelved\n",
      "Word: recently, Deprel: advmod, Head: shelved\n",
      "Word: shelved, Deprel: root, Head: ROOT\n",
      "Word: peace, Deprel: compound, Head: talks\n",
      "Word: talks, Deprel: obj, Head: shelved\n",
      "Word: being, Deprel: aux:pass, Head: brokered\n",
      "Word: brokered, Deprel: acl, Head: talks\n",
      "Word: by, Deprel: case, Head: Malaysia\n",
      "Word: neighbouring, Deprel: amod, Head: Malaysia\n",
      "Word: Malaysia, Deprel: obl, Head: brokered\n",
      "Word: after, Deprel: case, Head: spate\n",
      "Word: a, Deprel: det, Head: spate\n",
      "Word: spate, Deprel: obl, Head: brokered\n",
      "Word: of, Deprel: case, Head: attacks\n",
      "Word: attacks, Deprel: nmod, Head: spate\n",
      "Word: on, Deprel: case, Head: Mindanao\n",
      "Word: Mindanao, Deprel: nmod, Head: attacks\n",
      "Word: including, Deprel: case, Head: bombings\n",
      "Word: three, Deprel: nummod, Head: bombings\n",
      "Word: deadly, Deprel: amod, Head: bombings\n",
      "Word: bombings, Deprel: nmod, Head: spate\n",
      "Word: that, Deprel: obj, Head: blamed\n",
      "Word: it, Deprel: nsubj, Head: blamed\n",
      "Word: blamed, Deprel: acl:relcl, Head: bombings\n",
      "Word: on, Deprel: case, Head: MILF\n",
      "Word: the, Deprel: det, Head: MILF\n",
      "Word: MILF, Deprel: obl, Head: blamed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The company posted a profit of 54.3 million or 22 cents per share in the year-ago period'\n",
      "Word: The, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: posted\n",
      "Word: posted, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: profit\n",
      "Word: profit, Deprel: obj, Head: posted\n",
      "Word: of, Deprel: case, Head: million\n",
      "Word: 54.3, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nmod, Head: profit\n",
      "Word: or, Deprel: cc, Head: cents\n",
      "Word: 22, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: conj, Head: million\n",
      "Word: per, Deprel: case, Head: share\n",
      "Word: share, Deprel: nmod, Head: cents\n",
      "Word: in, Deprel: case, Head: period\n",
      "Word: the, Deprel: det, Head: period\n",
      "Word: year-ago, Deprel: compound, Head: period\n",
      "Word: period, Deprel: obl, Head: posted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'That was up from the year-ago quarter when the company earned 54.3 million or 22 cents a share'\n",
      "Word: That, Deprel: nsubj, Head: up\n",
      "Word: was, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: year-ago, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: up\n",
      "Word: when, Deprel: advmod, Head: earned\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: earned\n",
      "Word: earned, Deprel: advcl, Head: up\n",
      "Word: 54.3, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: earned\n",
      "Word: or, Deprel: cc, Head: cents\n",
      "Word: 22, Deprel: conj, Head: million\n",
      "Word: cents, Deprel: obj, Head: earned\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: obl:tmod, Head: earned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Joining Boston on Monday were the Massachusetts communities of Watertown Saugus and Framingham'\n",
      "Word: Joining, Deprel: root, Head: ROOT\n",
      "Word: Boston, Deprel: obj, Head: Joining\n",
      "Word: on, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: Joining\n",
      "Word: were, Deprel: aux, Head: Joining\n",
      "Word: the, Deprel: det, Head: communities\n",
      "Word: Massachusetts, Deprel: compound, Head: communities\n",
      "Word: communities, Deprel: nsubj, Head: Joining\n",
      "Word: of, Deprel: case, Head: Saugus\n",
      "Word: Watertown, Deprel: compound, Head: Saugus\n",
      "Word: Saugus, Deprel: nmod, Head: communities\n",
      "Word: and, Deprel: cc, Head: Framingham\n",
      "Word: Framingham, Deprel: conj, Head: Saugus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Along with Boston Watertown Saugus and Framingham also are going smoke-free Monday'\n",
      "Word: Along, Deprel: case, Head: Watertown\n",
      "Word: with, Deprel: case, Head: Watertown\n",
      "Word: Boston, Deprel: compound, Head: Watertown\n",
      "Word: Watertown, Deprel: obl, Head: going\n",
      "Word: Saugus, Deprel: nsubj, Head: going\n",
      "Word: and, Deprel: cc, Head: Framingham\n",
      "Word: Framingham, Deprel: conj, Head: Saugus\n",
      "Word: also, Deprel: advmod, Head: going\n",
      "Word: are, Deprel: aux, Head: going\n",
      "Word: going, Deprel: root, Head: ROOT\n",
      "Word: smoke-free, Deprel: xcomp, Head: going\n",
      "Word: Monday, Deprel: obl:tmod, Head: going\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He was tracked to Atlanta where he was arrested on Tuesday night'\n",
      "Word: He, Deprel: nsubj:pass, Head: tracked\n",
      "Word: was, Deprel: aux:pass, Head: tracked\n",
      "Word: tracked, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Atlanta\n",
      "Word: Atlanta, Deprel: obl, Head: tracked\n",
      "Word: where, Deprel: advmod, Head: arrested\n",
      "Word: he, Deprel: nsubj:pass, Head: arrested\n",
      "Word: was, Deprel: aux:pass, Head: arrested\n",
      "Word: arrested, Deprel: acl:relcl, Head: Atlanta\n",
      "Word: on, Deprel: case, Head: night\n",
      "Word: Tuesday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl, Head: arrested\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He was arrested in Atlanta Georgia on Monday night by police acting on a tip-off'\n",
      "Word: He, Deprel: nsubj:pass, Head: arrested\n",
      "Word: was, Deprel: aux:pass, Head: arrested\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: Georgia\n",
      "Word: Atlanta, Deprel: obl, Head: arrested\n",
      "Word: Georgia, Deprel: obl, Head: arrested\n",
      "Word: on, Deprel: case, Head: night\n",
      "Word: Monday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl, Head: arrested\n",
      "Word: by, Deprel: case, Head: police\n",
      "Word: police, Deprel: obl, Head: arrested\n",
      "Word: acting, Deprel: advcl, Head: arrested\n",
      "Word: on, Deprel: case, Head: tip-off\n",
      "Word: a, Deprel: det, Head: tip-off\n",
      "Word: tip-off, Deprel: obl, Head: acting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'ISRAELI soldiers knocked down empty mobile homes and water towers in 10 tiny West Bank settlement outposts overnight as part of a US-backed Mideast peace plan'\n",
      "Word: ISRAELI, Deprel: amod, Head: soldiers\n",
      "Word: soldiers, Deprel: nsubj, Head: knocked\n",
      "Word: knocked, Deprel: root, Head: ROOT\n",
      "Word: down, Deprel: compound:prt, Head: knocked\n",
      "Word: empty, Deprel: amod, Head: homes\n",
      "Word: mobile, Deprel: amod, Head: homes\n",
      "Word: homes, Deprel: obj, Head: knocked\n",
      "Word: and, Deprel: cc, Head: towers\n",
      "Word: water, Deprel: compound, Head: towers\n",
      "Word: towers, Deprel: conj, Head: homes\n",
      "Word: in, Deprel: case, Head: outposts\n",
      "Word: 10, Deprel: nummod, Head: outposts\n",
      "Word: tiny, Deprel: amod, Head: outposts\n",
      "Word: West, Deprel: compound, Head: Bank\n",
      "Word: Bank, Deprel: compound, Head: outposts\n",
      "Word: settlement, Deprel: compound, Head: outposts\n",
      "Word: outposts, Deprel: obl, Head: knocked\n",
      "Word: overnight, Deprel: advmod, Head: knocked\n",
      "Word: as, Deprel: case, Head: part\n",
      "Word: part, Deprel: obl, Head: knocked\n",
      "Word: of, Deprel: case, Head: plan\n",
      "Word: a, Deprel: det, Head: plan\n",
      "Word: US-backed, Deprel: amod, Head: plan\n",
      "Word: Mideast, Deprel: compound, Head: plan\n",
      "Word: peace, Deprel: compound, Head: plan\n",
      "Word: plan, Deprel: nmod, Head: part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Israeli soldiers began tearing down settlement outposts in the West Bank yesterday an Israeli obligation under a new Mideast peace plan'\n",
      "Word: Israeli, Deprel: amod, Head: soldiers\n",
      "Word: soldiers, Deprel: nsubj, Head: began\n",
      "Word: began, Deprel: root, Head: ROOT\n",
      "Word: tearing, Deprel: xcomp, Head: began\n",
      "Word: down, Deprel: compound:prt, Head: tearing\n",
      "Word: settlement, Deprel: compound, Head: outposts\n",
      "Word: outposts, Deprel: obj, Head: tearing\n",
      "Word: in, Deprel: case, Head: Bank\n",
      "Word: the, Deprel: det, Head: Bank\n",
      "Word: West, Deprel: compound, Head: Bank\n",
      "Word: Bank, Deprel: nmod, Head: outposts\n",
      "Word: yesterday, Deprel: obl:tmod, Head: tearing\n",
      "Word: an, Deprel: det, Head: obligation\n",
      "Word: Israeli, Deprel: amod, Head: obligation\n",
      "Word: obligation, Deprel: obj, Head: tearing\n",
      "Word: under, Deprel: case, Head: plan\n",
      "Word: a, Deprel: det, Head: plan\n",
      "Word: new, Deprel: amod, Head: plan\n",
      "Word: Mideast, Deprel: compound, Head: plan\n",
      "Word: peace, Deprel: compound, Head: plan\n",
      "Word: plan, Deprel: nmod, Head: obligation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The union had not yet revealed which chain would be targeted'\n",
      "Word: The, Deprel: det, Head: union\n",
      "Word: union, Deprel: nsubj, Head: revealed\n",
      "Word: had, Deprel: aux, Head: revealed\n",
      "Word: not, Deprel: advmod, Head: revealed\n",
      "Word: yet, Deprel: advmod, Head: revealed\n",
      "Word: revealed, Deprel: root, Head: ROOT\n",
      "Word: which, Deprel: det, Head: chain\n",
      "Word: chain, Deprel: nsubj:pass, Head: targeted\n",
      "Word: would, Deprel: aux, Head: targeted\n",
      "Word: be, Deprel: aux:pass, Head: targeted\n",
      "Word: targeted, Deprel: ccomp, Head: revealed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The union said it would reveal later which chain would be targeted'\n",
      "Word: The, Deprel: det, Head: union\n",
      "Word: union, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: reveal\n",
      "Word: would, Deprel: aux, Head: reveal\n",
      "Word: reveal, Deprel: ccomp, Head: said\n",
      "Word: later, Deprel: advmod, Head: reveal\n",
      "Word: which, Deprel: det, Head: chain\n",
      "Word: chain, Deprel: nsubj:pass, Head: targeted\n",
      "Word: would, Deprel: aux, Head: targeted\n",
      "Word: be, Deprel: aux:pass, Head: targeted\n",
      "Word: targeted, Deprel: ccomp, Head: reveal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Get it all out says Howard Davidowitz chairman of Davidowitz Associates a national retail consulting firm based in New York City'\n",
      "Word: Get, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: obj, Head: Get\n",
      "Word: all, Deprel: det, Head: it\n",
      "Word: out, Deprel: compound:prt, Head: Get\n",
      "Word: says, Deprel: parataxis, Head: Get\n",
      "Word: Howard, Deprel: nsubj, Head: says\n",
      "Word: Davidowitz, Deprel: flat, Head: Howard\n",
      "Word: chairman, Deprel: appos, Head: Howard\n",
      "Word: of, Deprel: case, Head: Associates\n",
      "Word: Davidowitz, Deprel: compound, Head: Associates\n",
      "Word: Associates, Deprel: nmod, Head: chairman\n",
      "Word: a, Deprel: det, Head: firm\n",
      "Word: national, Deprel: amod, Head: firm\n",
      "Word: retail, Deprel: compound, Head: firm\n",
      "Word: consulting, Deprel: compound, Head: firm\n",
      "Word: firm, Deprel: appos, Head: Howard\n",
      "Word: based, Deprel: acl, Head: firm\n",
      "Word: in, Deprel: case, Head: City\n",
      "Word: New, Deprel: amod, Head: City\n",
      "Word: York, Deprel: compound, Head: City\n",
      "Word: City, Deprel: obl, Head: based\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Innocent or not she s damaged goods said Howard Davidowitz chairman of Davidowitz Associates a national retail consulting firm in New York'\n",
      "Word: Innocent, Deprel: advmod, Head: goods\n",
      "Word: or, Deprel: cc, Head: not\n",
      "Word: not, Deprel: conj, Head: Innocent\n",
      "Word: she, Deprel: nsubj, Head: goods\n",
      "Word: s, Deprel: cop, Head: goods\n",
      "Word: damaged, Deprel: amod, Head: goods\n",
      "Word: goods, Deprel: root, Head: ROOT\n",
      "Word: said, Deprel: parataxis, Head: goods\n",
      "Word: Howard, Deprel: obj, Head: said\n",
      "Word: Davidowitz, Deprel: flat, Head: Howard\n",
      "Word: chairman, Deprel: flat, Head: Howard\n",
      "Word: of, Deprel: case, Head: Associates\n",
      "Word: Davidowitz, Deprel: compound, Head: Associates\n",
      "Word: Associates, Deprel: nmod, Head: chairman\n",
      "Word: a, Deprel: det, Head: firm\n",
      "Word: national, Deprel: amod, Head: firm\n",
      "Word: retail, Deprel: compound, Head: firm\n",
      "Word: consulting, Deprel: compound, Head: firm\n",
      "Word: firm, Deprel: appos, Head: Associates\n",
      "Word: in, Deprel: case, Head: York\n",
      "Word: New, Deprel: amod, Head: York\n",
      "Word: York, Deprel: nmod, Head: firm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The updated products include Pylon Pro Pylon Conduit Pylon Anywhere and Pylon Application Server'\n",
      "Word: The, Deprel: det, Head: products\n",
      "Word: updated, Deprel: amod, Head: products\n",
      "Word: products, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: Pylon, Deprel: compound, Head: Pylon\n",
      "Word: Pro, Deprel: compound, Head: Pylon\n",
      "Word: Pylon, Deprel: compound, Head: Conduit\n",
      "Word: Conduit, Deprel: compound, Head: Pylon\n",
      "Word: Pylon, Deprel: obj, Head: include\n",
      "Word: Anywhere, Deprel: appos, Head: Pylon\n",
      "Word: and, Deprel: cc, Head: Server\n",
      "Word: Pylon, Deprel: compound, Head: Application\n",
      "Word: Application, Deprel: compound, Head: Server\n",
      "Word: Server, Deprel: conj, Head: Anywhere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new products on the desktop side include the latest versions of Pylon Conduit and Pylon Pro'\n",
      "Word: The, Deprel: det, Head: products\n",
      "Word: new, Deprel: amod, Head: products\n",
      "Word: products, Deprel: nsubj, Head: include\n",
      "Word: on, Deprel: case, Head: side\n",
      "Word: the, Deprel: det, Head: side\n",
      "Word: desktop, Deprel: compound, Head: side\n",
      "Word: side, Deprel: nmod, Head: products\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: versions\n",
      "Word: latest, Deprel: amod, Head: versions\n",
      "Word: versions, Deprel: obj, Head: include\n",
      "Word: of, Deprel: case, Head: Conduit\n",
      "Word: Pylon, Deprel: compound, Head: Conduit\n",
      "Word: Conduit, Deprel: nmod, Head: versions\n",
      "Word: and, Deprel: cc, Head: Pro\n",
      "Word: Pylon, Deprel: compound, Head: Pro\n",
      "Word: Pro, Deprel: conj, Head: Conduit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dixon was otherwise the class of the field at Pikes Peak International Raceway'\n",
      "Word: Dixon, Deprel: nsubj, Head: class\n",
      "Word: was, Deprel: cop, Head: class\n",
      "Word: otherwise, Deprel: advmod, Head: class\n",
      "Word: the, Deprel: det, Head: class\n",
      "Word: class, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: field\n",
      "Word: the, Deprel: det, Head: field\n",
      "Word: field, Deprel: nmod, Head: class\n",
      "Word: at, Deprel: case, Head: Raceway\n",
      "Word: Pikes, Deprel: compound, Head: Peak\n",
      "Word: Peak, Deprel: compound, Head: Raceway\n",
      "Word: International, Deprel: amod, Head: Raceway\n",
      "Word: Raceway, Deprel: nmod, Head: class\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Scott Dixon eventually made winning the Honda Indy 225 look easy Sunday at Pikes Peak International Raceway'\n",
      "Word: Scott, Deprel: nsubj, Head: made\n",
      "Word: Dixon, Deprel: flat, Head: Scott\n",
      "Word: eventually, Deprel: advmod, Head: made\n",
      "Word: made, Deprel: root, Head: ROOT\n",
      "Word: winning, Deprel: xcomp, Head: made\n",
      "Word: the, Deprel: det, Head: 225\n",
      "Word: Honda, Deprel: compound, Head: 225\n",
      "Word: Indy, Deprel: compound, Head: 225\n",
      "Word: 225, Deprel: nsubj, Head: look\n",
      "Word: look, Deprel: xcomp, Head: winning\n",
      "Word: easy, Deprel: xcomp, Head: look\n",
      "Word: Sunday, Deprel: obl:tmod, Head: look\n",
      "Word: at, Deprel: case, Head: Raceway\n",
      "Word: Pikes, Deprel: compound, Head: Peak\n",
      "Word: Peak, Deprel: compound, Head: Raceway\n",
      "Word: International, Deprel: amod, Head: Raceway\n",
      "Word: Raceway, Deprel: obl, Head: look\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Turkish authorities have said all the suicide bombers were Turks'\n",
      "Word: Turkish, Deprel: amod, Head: authorities\n",
      "Word: authorities, Deprel: nsubj, Head: said\n",
      "Word: have, Deprel: aux, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: all, Deprel: det:predet, Head: bombers\n",
      "Word: the, Deprel: det, Head: bombers\n",
      "Word: suicide, Deprel: compound, Head: bombers\n",
      "Word: bombers, Deprel: nsubj, Head: Turks\n",
      "Word: were, Deprel: cop, Head: Turks\n",
      "Word: Turks, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Ankara says all four suicide bombers were Turkish'\n",
      "Word: Ankara, Deprel: nsubj, Head: says\n",
      "Word: says, Deprel: root, Head: ROOT\n",
      "Word: all, Deprel: det, Head: bombers\n",
      "Word: four, Deprel: nummod, Head: bombers\n",
      "Word: suicide, Deprel: compound, Head: bombers\n",
      "Word: bombers, Deprel: nsubj, Head: Turkish\n",
      "Word: were, Deprel: cop, Head: Turkish\n",
      "Word: Turkish, Deprel: ccomp, Head: says\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In April it had forecast operating earnings in the range of 60 to 80 cents a share'\n",
      "Word: In, Deprel: case, Head: April\n",
      "Word: April, Deprel: obl, Head: forecast\n",
      "Word: it, Deprel: nsubj, Head: forecast\n",
      "Word: had, Deprel: aux, Head: forecast\n",
      "Word: forecast, Deprel: root, Head: ROOT\n",
      "Word: operating, Deprel: compound, Head: earnings\n",
      "Word: earnings, Deprel: obj, Head: forecast\n",
      "Word: in, Deprel: case, Head: range\n",
      "Word: the, Deprel: det, Head: range\n",
      "Word: range, Deprel: obl, Head: forecast\n",
      "Word: of, Deprel: case, Head: cents\n",
      "Word: 60, Deprel: nummod, Head: cents\n",
      "Word: to, Deprel: case, Head: 80\n",
      "Word: 80, Deprel: nmod, Head: 60\n",
      "Word: cents, Deprel: nmod, Head: range\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:npmod, Head: cents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Kodak expects earnings of 5 cents to 25 cents a share in the quarter'\n",
      "Word: Kodak, Deprel: nsubj, Head: expects\n",
      "Word: expects, Deprel: root, Head: ROOT\n",
      "Word: earnings, Deprel: obj, Head: expects\n",
      "Word: of, Deprel: case, Head: cents\n",
      "Word: 5, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: nmod, Head: earnings\n",
      "Word: to, Deprel: case, Head: cents\n",
      "Word: 25, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl, Head: expects\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:tmod, Head: cents\n",
      "Word: in, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: expects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'From Florida to Alaska thousands of revelers vowed to push for more legal rights including same-sex marriages'\n",
      "Word: From, Deprel: case, Head: Florida\n",
      "Word: Florida, Deprel: obl, Head: vowed\n",
      "Word: to, Deprel: case, Head: Alaska\n",
      "Word: Alaska, Deprel: nmod, Head: Florida\n",
      "Word: thousands, Deprel: nsubj, Head: vowed\n",
      "Word: of, Deprel: case, Head: revelers\n",
      "Word: revelers, Deprel: nmod, Head: thousands\n",
      "Word: vowed, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: push\n",
      "Word: push, Deprel: xcomp, Head: vowed\n",
      "Word: for, Deprel: case, Head: rights\n",
      "Word: more, Deprel: amod, Head: rights\n",
      "Word: legal, Deprel: amod, Head: rights\n",
      "Word: rights, Deprel: obl, Head: push\n",
      "Word: including, Deprel: case, Head: marriages\n",
      "Word: same-sex, Deprel: amod, Head: marriages\n",
      "Word: marriages, Deprel: nmod, Head: rights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Thousands of revellers celebrating the decision vowed to push for more legal rights including same-sex marriages'\n",
      "Word: Thousands, Deprel: nsubj, Head: vowed\n",
      "Word: of, Deprel: case, Head: revellers\n",
      "Word: revellers, Deprel: nmod, Head: Thousands\n",
      "Word: celebrating, Deprel: acl, Head: revellers\n",
      "Word: the, Deprel: det, Head: decision\n",
      "Word: decision, Deprel: obj, Head: celebrating\n",
      "Word: vowed, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: push\n",
      "Word: push, Deprel: xcomp, Head: vowed\n",
      "Word: for, Deprel: case, Head: rights\n",
      "Word: more, Deprel: amod, Head: rights\n",
      "Word: legal, Deprel: amod, Head: rights\n",
      "Word: rights, Deprel: obl, Head: push\n",
      "Word: including, Deprel: case, Head: marriages\n",
      "Word: same-sex, Deprel: amod, Head: marriages\n",
      "Word: marriages, Deprel: nmod, Head: rights\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'By Sunday night the fires had blackened 277,000 acres hundreds of miles apart'\n",
      "Word: By, Deprel: case, Head: night\n",
      "Word: Sunday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl, Head: blackened\n",
      "Word: the, Deprel: det, Head: fires\n",
      "Word: fires, Deprel: nsubj, Head: blackened\n",
      "Word: had, Deprel: aux, Head: blackened\n",
      "Word: blackened, Deprel: root, Head: ROOT\n",
      "Word: 277,000, Deprel: nummod, Head: acres\n",
      "Word: acres, Deprel: obj, Head: blackened\n",
      "Word: hundreds, Deprel: obl:npmod, Head: apart\n",
      "Word: of, Deprel: case, Head: miles\n",
      "Word: miles, Deprel: nmod, Head: hundreds\n",
      "Word: apart, Deprel: advmod, Head: blackened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Major fires had burned 264,000 acres by early last night'\n",
      "Word: Major, Deprel: amod, Head: fires\n",
      "Word: fires, Deprel: nsubj, Head: burned\n",
      "Word: had, Deprel: aux, Head: burned\n",
      "Word: burned, Deprel: root, Head: ROOT\n",
      "Word: 264,000, Deprel: nummod, Head: acres\n",
      "Word: acres, Deprel: obj, Head: burned\n",
      "Word: by, Deprel: case, Head: night\n",
      "Word: early, Deprel: advmod, Head: night\n",
      "Word: last, Deprel: amod, Head: night\n",
      "Word: night, Deprel: obl, Head: burned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Others with such a status are Egypt Israel and Australia'\n",
      "Word: Others, Deprel: nsubj, Head: Egypt\n",
      "Word: with, Deprel: case, Head: status\n",
      "Word: such, Deprel: det:predet, Head: status\n",
      "Word: a, Deprel: det, Head: status\n",
      "Word: status, Deprel: nmod, Head: Others\n",
      "Word: are, Deprel: cop, Head: Egypt\n",
      "Word: Egypt, Deprel: root, Head: ROOT\n",
      "Word: Israel, Deprel: flat, Head: Egypt\n",
      "Word: and, Deprel: cc, Head: Australia\n",
      "Word: Australia, Deprel: conj, Head: Israel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Nations like Israel and Australia already have such status'\n",
      "Word: Nations, Deprel: nsubj, Head: have\n",
      "Word: like, Deprel: case, Head: Israel\n",
      "Word: Israel, Deprel: nmod, Head: Nations\n",
      "Word: and, Deprel: cc, Head: Australia\n",
      "Word: Australia, Deprel: conj, Head: Israel\n",
      "Word: already, Deprel: advmod, Head: have\n",
      "Word: have, Deprel: root, Head: ROOT\n",
      "Word: such, Deprel: amod, Head: status\n",
      "Word: status, Deprel: obj, Head: have\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The findings appear in Wednesday s Journal of the American Medical Association news web sites'\n",
      "Word: The, Deprel: det, Head: findings\n",
      "Word: findings, Deprel: nsubj, Head: appear\n",
      "Word: appear, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: Journal\n",
      "Word: Wednesday, Deprel: nmod:poss, Head: Journal\n",
      "Word: s, Deprel: case, Head: Wednesday\n",
      "Word: Journal, Deprel: obl, Head: appear\n",
      "Word: of, Deprel: case, Head: sites\n",
      "Word: the, Deprel: det, Head: sites\n",
      "Word: American, Deprel: amod, Head: sites\n",
      "Word: Medical, Deprel: amod, Head: Association\n",
      "Word: Association, Deprel: compound, Head: sites\n",
      "Word: news, Deprel: compound, Head: sites\n",
      "Word: web, Deprel: compound, Head: sites\n",
      "Word: sites, Deprel: nmod, Head: Journal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The results are to be published in Wednesday s issue of The Journal of the American Medical Association'\n",
      "Word: The, Deprel: det, Head: results\n",
      "Word: results, Deprel: nsubj, Head: are\n",
      "Word: are, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: published\n",
      "Word: be, Deprel: aux:pass, Head: published\n",
      "Word: published, Deprel: xcomp, Head: are\n",
      "Word: in, Deprel: case, Head: issue\n",
      "Word: Wednesday, Deprel: nmod:poss, Head: issue\n",
      "Word: s, Deprel: case, Head: Wednesday\n",
      "Word: issue, Deprel: obl, Head: published\n",
      "Word: of, Deprel: case, Head: Journal\n",
      "Word: The, Deprel: det, Head: Journal\n",
      "Word: Journal, Deprel: nmod, Head: issue\n",
      "Word: of, Deprel: case, Head: Association\n",
      "Word: the, Deprel: det, Head: Association\n",
      "Word: American, Deprel: amod, Head: Association\n",
      "Word: Medical, Deprel: amod, Head: Association\n",
      "Word: Association, Deprel: nmod, Head: Journal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Additionally the h2210 ’ s cradle has room to charge a second battery'\n",
      "Word: Additionally, Deprel: advmod, Head: has\n",
      "Word: the, Deprel: det, Head: h2210\n",
      "Word: h2210, Deprel: nmod:poss, Head: cradle\n",
      "Word: ’, Deprel: case, Head: h2210\n",
      "Word: s, Deprel: case, Head: h2210\n",
      "Word: cradle, Deprel: nsubj, Head: has\n",
      "Word: has, Deprel: root, Head: ROOT\n",
      "Word: room, Deprel: obj, Head: has\n",
      "Word: to, Deprel: mark, Head: charge\n",
      "Word: charge, Deprel: acl, Head: room\n",
      "Word: a, Deprel: det, Head: battery\n",
      "Word: second, Deprel: amod, Head: battery\n",
      "Word: battery, Deprel: obj, Head: charge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The cradle for the h2200 has space for recharging a second battery'\n",
      "Word: The, Deprel: det, Head: cradle\n",
      "Word: cradle, Deprel: nsubj, Head: has\n",
      "Word: for, Deprel: case, Head: h2200\n",
      "Word: the, Deprel: det, Head: h2200\n",
      "Word: h2200, Deprel: nmod, Head: cradle\n",
      "Word: has, Deprel: root, Head: ROOT\n",
      "Word: space, Deprel: obj, Head: has\n",
      "Word: for, Deprel: mark, Head: recharging\n",
      "Word: recharging, Deprel: acl, Head: space\n",
      "Word: a, Deprel: det, Head: battery\n",
      "Word: second, Deprel: amod, Head: battery\n",
      "Word: battery, Deprel: obj, Head: recharging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'U.S forces struck dozens of targets on Monday killing six guerrillas and arresting 21 others the military said'\n",
      "Word: U.S, Deprel: compound, Head: forces\n",
      "Word: forces, Deprel: nsubj, Head: struck\n",
      "Word: struck, Deprel: root, Head: ROOT\n",
      "Word: dozens, Deprel: obj, Head: struck\n",
      "Word: of, Deprel: case, Head: targets\n",
      "Word: targets, Deprel: nmod, Head: dozens\n",
      "Word: on, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: struck\n",
      "Word: killing, Deprel: advcl, Head: struck\n",
      "Word: six, Deprel: nummod, Head: guerrillas\n",
      "Word: guerrillas, Deprel: obj, Head: killing\n",
      "Word: and, Deprel: cc, Head: arresting\n",
      "Word: arresting, Deprel: conj, Head: killing\n",
      "Word: 21, Deprel: nummod, Head: others\n",
      "Word: others, Deprel: obj, Head: arresting\n",
      "Word: the, Deprel: det, Head: military\n",
      "Word: military, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: others\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'U.S forces struck dozens of targets on Monday killing six guerrillas and arresting 99 others during 1,729 patrols and 25 raids conducted over 24 hours'\n",
      "Word: U.S, Deprel: compound, Head: forces\n",
      "Word: forces, Deprel: nsubj, Head: struck\n",
      "Word: struck, Deprel: root, Head: ROOT\n",
      "Word: dozens, Deprel: obj, Head: struck\n",
      "Word: of, Deprel: case, Head: targets\n",
      "Word: targets, Deprel: nmod, Head: dozens\n",
      "Word: on, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: struck\n",
      "Word: killing, Deprel: advcl, Head: struck\n",
      "Word: six, Deprel: nummod, Head: guerrillas\n",
      "Word: guerrillas, Deprel: obj, Head: killing\n",
      "Word: and, Deprel: cc, Head: arresting\n",
      "Word: arresting, Deprel: conj, Head: killing\n",
      "Word: 99, Deprel: nummod, Head: others\n",
      "Word: others, Deprel: obj, Head: arresting\n",
      "Word: during, Deprel: case, Head: patrols\n",
      "Word: 1,729, Deprel: nummod, Head: patrols\n",
      "Word: patrols, Deprel: obl, Head: arresting\n",
      "Word: and, Deprel: cc, Head: raids\n",
      "Word: 25, Deprel: nummod, Head: raids\n",
      "Word: raids, Deprel: conj, Head: patrols\n",
      "Word: conducted, Deprel: acl, Head: raids\n",
      "Word: over, Deprel: case, Head: hours\n",
      "Word: 24, Deprel: nummod, Head: hours\n",
      "Word: hours, Deprel: obl, Head: conducted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'One of the 14 Kurds pointed at the word refugee in an English/Turkish dictionary'\n",
      "Word: One, Deprel: nsubj, Head: pointed\n",
      "Word: of, Deprel: case, Head: Kurds\n",
      "Word: the, Deprel: det, Head: Kurds\n",
      "Word: 14, Deprel: nummod, Head: Kurds\n",
      "Word: Kurds, Deprel: nmod, Head: One\n",
      "Word: pointed, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: word\n",
      "Word: the, Deprel: det, Head: word\n",
      "Word: word, Deprel: obl, Head: pointed\n",
      "Word: refugee, Deprel: appos, Head: word\n",
      "Word: in, Deprel: case, Head: dictionary\n",
      "Word: an, Deprel: det, Head: dictionary\n",
      "Word: English/Turkish, Deprel: amod, Head: dictionary\n",
      "Word: dictionary, Deprel: nmod, Head: word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'One man had brandished an English-Turkish dictionary and pointed to the word refugee'\n",
      "Word: One, Deprel: nummod, Head: man\n",
      "Word: man, Deprel: nsubj, Head: brandished\n",
      "Word: had, Deprel: aux, Head: brandished\n",
      "Word: brandished, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: dictionary\n",
      "Word: English-Turkish, Deprel: amod, Head: dictionary\n",
      "Word: dictionary, Deprel: obj, Head: brandished\n",
      "Word: and, Deprel: cc, Head: pointed\n",
      "Word: pointed, Deprel: conj, Head: brandished\n",
      "Word: to, Deprel: case, Head: word\n",
      "Word: the, Deprel: det, Head: word\n",
      "Word: word, Deprel: obl, Head: pointed\n",
      "Word: refugee, Deprel: appos, Head: word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Close co-operation between law-enforcement agencies and intelligence services lie at the heart of the ongoing fight against terrorism Mr Howard said'\n",
      "Word: Close, Deprel: amod, Head: co-operation\n",
      "Word: co-operation, Deprel: nsubj, Head: lie\n",
      "Word: between, Deprel: case, Head: agencies\n",
      "Word: law-enforcement, Deprel: compound, Head: agencies\n",
      "Word: agencies, Deprel: nmod, Head: co-operation\n",
      "Word: and, Deprel: cc, Head: services\n",
      "Word: intelligence, Deprel: compound, Head: services\n",
      "Word: services, Deprel: conj, Head: agencies\n",
      "Word: lie, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: heart\n",
      "Word: the, Deprel: det, Head: heart\n",
      "Word: heart, Deprel: obl, Head: lie\n",
      "Word: of, Deprel: case, Head: fight\n",
      "Word: the, Deprel: det, Head: fight\n",
      "Word: ongoing, Deprel: amod, Head: fight\n",
      "Word: fight, Deprel: nmod, Head: heart\n",
      "Word: against, Deprel: case, Head: terrorism\n",
      "Word: terrorism, Deprel: nmod, Head: fight\n",
      "Word: Mr, Deprel: nsubj, Head: said\n",
      "Word: Howard, Deprel: flat, Head: Mr\n",
      "Word: said, Deprel: acl:relcl, Head: fight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Close cooperation between regional law enforcement agencies and intelligence services was at the heart of the fight against terrorism he said'\n",
      "Word: Close, Deprel: amod, Head: cooperation\n",
      "Word: cooperation, Deprel: nsubj, Head: heart\n",
      "Word: between, Deprel: case, Head: agencies\n",
      "Word: regional, Deprel: amod, Head: agencies\n",
      "Word: law, Deprel: compound, Head: enforcement\n",
      "Word: enforcement, Deprel: compound, Head: agencies\n",
      "Word: agencies, Deprel: nmod, Head: cooperation\n",
      "Word: and, Deprel: cc, Head: services\n",
      "Word: intelligence, Deprel: compound, Head: services\n",
      "Word: services, Deprel: conj, Head: agencies\n",
      "Word: was, Deprel: cop, Head: heart\n",
      "Word: at, Deprel: case, Head: heart\n",
      "Word: the, Deprel: det, Head: heart\n",
      "Word: heart, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: fight\n",
      "Word: the, Deprel: det, Head: fight\n",
      "Word: fight, Deprel: nmod, Head: heart\n",
      "Word: against, Deprel: case, Head: terrorism\n",
      "Word: terrorism, Deprel: nmod, Head: fight\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: fight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In 2006 the group says the market will rebound 29.6 percent to 21.3 billion in sales'\n",
      "Word: In, Deprel: case, Head: 2006\n",
      "Word: 2006, Deprel: obl, Head: says\n",
      "Word: the, Deprel: det, Head: group\n",
      "Word: group, Deprel: nsubj, Head: says\n",
      "Word: says, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: market\n",
      "Word: market, Deprel: nsubj, Head: rebound\n",
      "Word: will, Deprel: aux, Head: rebound\n",
      "Word: rebound, Deprel: ccomp, Head: says\n",
      "Word: 29.6, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: rebound\n",
      "Word: to, Deprel: case, Head: billion\n",
      "Word: 21.3, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obl, Head: rebound\n",
      "Word: in, Deprel: case, Head: sales\n",
      "Word: sales, Deprel: nmod, Head: billion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In 2006 Asia Pacific will report growth of 7.9 percent to 81.8 billion'\n",
      "Word: In, Deprel: case, Head: 2006\n",
      "Word: 2006, Deprel: obl, Head: report\n",
      "Word: Asia, Deprel: compound, Head: Pacific\n",
      "Word: Pacific, Deprel: nsubj, Head: report\n",
      "Word: will, Deprel: aux, Head: report\n",
      "Word: report, Deprel: root, Head: ROOT\n",
      "Word: growth, Deprel: obj, Head: report\n",
      "Word: of, Deprel: case, Head: percent\n",
      "Word: 7.9, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: nmod, Head: growth\n",
      "Word: to, Deprel: case, Head: billion\n",
      "Word: 81.8, Deprel: nummod, Head: billion\n",
      "Word: billion, Deprel: nmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Captain Robert Ramsey of the US 1st Armoured Division said a truck had exploded outside the building about 11am and that one of the compound s outer walls had collapsed'\n",
      "Word: Captain, Deprel: nsubj, Head: said\n",
      "Word: Robert, Deprel: flat, Head: Captain\n",
      "Word: Ramsey, Deprel: flat, Head: Captain\n",
      "Word: of, Deprel: case, Head: Division\n",
      "Word: the, Deprel: det, Head: Division\n",
      "Word: US, Deprel: compound, Head: Division\n",
      "Word: 1st, Deprel: amod, Head: Division\n",
      "Word: Armoured, Deprel: amod, Head: Division\n",
      "Word: Division, Deprel: nmod, Head: Captain\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: truck\n",
      "Word: truck, Deprel: nsubj, Head: exploded\n",
      "Word: had, Deprel: aux, Head: exploded\n",
      "Word: exploded, Deprel: ccomp, Head: said\n",
      "Word: outside, Deprel: case, Head: building\n",
      "Word: the, Deprel: det, Head: building\n",
      "Word: building, Deprel: obl, Head: exploded\n",
      "Word: about, Deprel: advmod, Head: 11am\n",
      "Word: 11am, Deprel: obl:tmod, Head: exploded\n",
      "Word: and, Deprel: cc, Head: collapsed\n",
      "Word: that, Deprel: mark, Head: collapsed\n",
      "Word: one, Deprel: nsubj, Head: collapsed\n",
      "Word: of, Deprel: case, Head: walls\n",
      "Word: the, Deprel: det, Head: compound\n",
      "Word: compound, Deprel: nmod:poss, Head: walls\n",
      "Word: s, Deprel: case, Head: compound\n",
      "Word: outer, Deprel: amod, Head: walls\n",
      "Word: walls, Deprel: nmod, Head: one\n",
      "Word: had, Deprel: aux, Head: collapsed\n",
      "Word: collapsed, Deprel: conj, Head: exploded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Captain Robert Ramsey of US 1St Armored Division said a truck had exploded outside the building at around 11 am'\n",
      "Word: Captain, Deprel: nsubj, Head: said\n",
      "Word: Robert, Deprel: flat, Head: Captain\n",
      "Word: Ramsey, Deprel: flat, Head: Captain\n",
      "Word: of, Deprel: case, Head: Division\n",
      "Word: US, Deprel: compound, Head: Division\n",
      "Word: 1St, Deprel: amod, Head: Division\n",
      "Word: Armored, Deprel: amod, Head: Division\n",
      "Word: Division, Deprel: nmod, Head: Captain\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: truck\n",
      "Word: truck, Deprel: nsubj, Head: exploded\n",
      "Word: had, Deprel: aux, Head: exploded\n",
      "Word: exploded, Deprel: ccomp, Head: said\n",
      "Word: outside, Deprel: case, Head: building\n",
      "Word: the, Deprel: det, Head: building\n",
      "Word: building, Deprel: obl, Head: exploded\n",
      "Word: at, Deprel: case, Head: am\n",
      "Word: around, Deprel: case, Head: am\n",
      "Word: 11, Deprel: nummod, Head: am\n",
      "Word: am, Deprel: obl, Head: exploded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'They came despite what BA called a difficult quarter which it said included unofficial industrial action at Heathrow'\n",
      "Word: They, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: root, Head: ROOT\n",
      "Word: despite, Deprel: case, Head: what\n",
      "Word: what, Deprel: obl, Head: came\n",
      "Word: BA, Deprel: nsubj, Head: called\n",
      "Word: called, Deprel: acl:relcl, Head: what\n",
      "Word: a, Deprel: det, Head: quarter\n",
      "Word: difficult, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obj, Head: called\n",
      "Word: which, Deprel: nsubj, Head: included\n",
      "Word: it, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: quarter\n",
      "Word: included, Deprel: ccomp, Head: said\n",
      "Word: unofficial, Deprel: amod, Head: action\n",
      "Word: industrial, Deprel: amod, Head: action\n",
      "Word: action, Deprel: obj, Head: included\n",
      "Word: at, Deprel: case, Head: Heathrow\n",
      "Word: Heathrow, Deprel: nmod, Head: action\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'BA said the second quarter which included unofficial industrial action at Heathrow had been difficult'\n",
      "Word: BA, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: second, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: nsubj, Head: difficult\n",
      "Word: which, Deprel: nsubj, Head: included\n",
      "Word: included, Deprel: acl:relcl, Head: quarter\n",
      "Word: unofficial, Deprel: amod, Head: action\n",
      "Word: industrial, Deprel: amod, Head: action\n",
      "Word: action, Deprel: obj, Head: included\n",
      "Word: at, Deprel: case, Head: Heathrow\n",
      "Word: Heathrow, Deprel: obl, Head: included\n",
      "Word: had, Deprel: aux, Head: difficult\n",
      "Word: been, Deprel: cop, Head: difficult\n",
      "Word: difficult, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This northern autumn US trainers will work with soldiers from four North African countries on patrolling and gathering intelligence'\n",
      "Word: This, Deprel: det, Head: trainers\n",
      "Word: northern, Deprel: amod, Head: autumn\n",
      "Word: autumn, Deprel: compound, Head: trainers\n",
      "Word: US, Deprel: compound, Head: trainers\n",
      "Word: trainers, Deprel: nsubj, Head: work\n",
      "Word: will, Deprel: aux, Head: work\n",
      "Word: work, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: soldiers\n",
      "Word: soldiers, Deprel: obl, Head: work\n",
      "Word: from, Deprel: case, Head: countries\n",
      "Word: four, Deprel: nummod, Head: countries\n",
      "Word: North, Deprel: compound, Head: African\n",
      "Word: African, Deprel: amod, Head: countries\n",
      "Word: countries, Deprel: nmod, Head: soldiers\n",
      "Word: on, Deprel: mark, Head: patrolling\n",
      "Word: patrolling, Deprel: advcl, Head: work\n",
      "Word: and, Deprel: cc, Head: gathering\n",
      "Word: gathering, Deprel: conj, Head: patrolling\n",
      "Word: intelligence, Deprel: obj, Head: patrolling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Later this year the command will send trainers with soldiers from four North African nations on patrolling and intelligence gathering missions'\n",
      "Word: Later, Deprel: advmod, Head: year\n",
      "Word: this, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: send\n",
      "Word: the, Deprel: det, Head: command\n",
      "Word: command, Deprel: nsubj, Head: send\n",
      "Word: will, Deprel: aux, Head: send\n",
      "Word: send, Deprel: root, Head: ROOT\n",
      "Word: trainers, Deprel: obj, Head: send\n",
      "Word: with, Deprel: case, Head: soldiers\n",
      "Word: soldiers, Deprel: obl, Head: send\n",
      "Word: from, Deprel: case, Head: nations\n",
      "Word: four, Deprel: nummod, Head: nations\n",
      "Word: North, Deprel: compound, Head: African\n",
      "Word: African, Deprel: amod, Head: nations\n",
      "Word: nations, Deprel: obl, Head: send\n",
      "Word: on, Deprel: case, Head: missions\n",
      "Word: patrolling, Deprel: amod, Head: missions\n",
      "Word: and, Deprel: cc, Head: gathering\n",
      "Word: intelligence, Deprel: compound, Head: gathering\n",
      "Word: gathering, Deprel: conj, Head: patrolling\n",
      "Word: missions, Deprel: nmod, Head: nations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Bush administration blames Hussein loyalists and foreign Muslim militants who have entered Iraq to fight U.S troops for the wave of bombings and guerrilla attacks'\n",
      "Word: The, Deprel: det, Head: Bush\n",
      "Word: Bush, Deprel: nsubj, Head: blames\n",
      "Word: administration, Deprel: flat, Head: Bush\n",
      "Word: blames, Deprel: root, Head: ROOT\n",
      "Word: Hussein, Deprel: compound, Head: loyalists\n",
      "Word: loyalists, Deprel: obj, Head: blames\n",
      "Word: and, Deprel: cc, Head: militants\n",
      "Word: foreign, Deprel: amod, Head: militants\n",
      "Word: Muslim, Deprel: amod, Head: militants\n",
      "Word: militants, Deprel: conj, Head: loyalists\n",
      "Word: who, Deprel: nsubj, Head: entered\n",
      "Word: have, Deprel: aux, Head: entered\n",
      "Word: entered, Deprel: acl:relcl, Head: loyalists\n",
      "Word: Iraq, Deprel: obj, Head: entered\n",
      "Word: to, Deprel: mark, Head: fight\n",
      "Word: fight, Deprel: xcomp, Head: entered\n",
      "Word: U.S, Deprel: compound, Head: troops\n",
      "Word: troops, Deprel: obj, Head: fight\n",
      "Word: for, Deprel: case, Head: wave\n",
      "Word: the, Deprel: det, Head: wave\n",
      "Word: wave, Deprel: obl, Head: fight\n",
      "Word: of, Deprel: case, Head: bombings\n",
      "Word: bombings, Deprel: nmod, Head: wave\n",
      "Word: and, Deprel: cc, Head: attacks\n",
      "Word: guerrilla, Deprel: compound, Head: attacks\n",
      "Word: attacks, Deprel: conj, Head: bombings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Bush administration blames the wave of bombings and guerrilla attacks on Saddam loyalists and foreign Muslim militants who have entered Iraq to fight U.S troops'\n",
      "Word: The, Deprel: det, Head: Bush\n",
      "Word: Bush, Deprel: nsubj, Head: blames\n",
      "Word: administration, Deprel: flat, Head: Bush\n",
      "Word: blames, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: wave\n",
      "Word: wave, Deprel: obj, Head: blames\n",
      "Word: of, Deprel: case, Head: bombings\n",
      "Word: bombings, Deprel: nmod, Head: wave\n",
      "Word: and, Deprel: cc, Head: attacks\n",
      "Word: guerrilla, Deprel: compound, Head: attacks\n",
      "Word: attacks, Deprel: conj, Head: bombings\n",
      "Word: on, Deprel: case, Head: loyalists\n",
      "Word: Saddam, Deprel: compound, Head: loyalists\n",
      "Word: loyalists, Deprel: nmod, Head: bombings\n",
      "Word: and, Deprel: cc, Head: militants\n",
      "Word: foreign, Deprel: amod, Head: militants\n",
      "Word: Muslim, Deprel: amod, Head: militants\n",
      "Word: militants, Deprel: conj, Head: loyalists\n",
      "Word: who, Deprel: nsubj, Head: entered\n",
      "Word: have, Deprel: aux, Head: entered\n",
      "Word: entered, Deprel: acl:relcl, Head: loyalists\n",
      "Word: Iraq, Deprel: obj, Head: entered\n",
      "Word: to, Deprel: mark, Head: fight\n",
      "Word: fight, Deprel: advcl, Head: entered\n",
      "Word: U.S, Deprel: compound, Head: troops\n",
      "Word: troops, Deprel: obj, Head: fight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It later emerged that he had broken his right thigh and bones in his right wrist and elbow'\n",
      "Word: It, Deprel: nsubj, Head: emerged\n",
      "Word: later, Deprel: advmod, Head: emerged\n",
      "Word: emerged, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: broken\n",
      "Word: he, Deprel: nsubj, Head: broken\n",
      "Word: had, Deprel: aux, Head: broken\n",
      "Word: broken, Deprel: ccomp, Head: emerged\n",
      "Word: his, Deprel: nmod:poss, Head: thigh\n",
      "Word: right, Deprel: amod, Head: thigh\n",
      "Word: thigh, Deprel: obj, Head: broken\n",
      "Word: and, Deprel: cc, Head: bones\n",
      "Word: bones, Deprel: conj, Head: thigh\n",
      "Word: in, Deprel: case, Head: wrist\n",
      "Word: his, Deprel: nmod:poss, Head: wrist\n",
      "Word: right, Deprel: amod, Head: wrist\n",
      "Word: wrist, Deprel: obl, Head: broken\n",
      "Word: and, Deprel: cc, Head: elbow\n",
      "Word: elbow, Deprel: conj, Head: wrist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Tour doctors later confirmed that he had broken his right leg near the hip and also sustained wrist and elbow fractures'\n",
      "Word: Tour, Deprel: compound, Head: doctors\n",
      "Word: doctors, Deprel: nsubj, Head: confirmed\n",
      "Word: later, Deprel: advmod, Head: confirmed\n",
      "Word: confirmed, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: broken\n",
      "Word: he, Deprel: nsubj, Head: broken\n",
      "Word: had, Deprel: aux, Head: broken\n",
      "Word: broken, Deprel: ccomp, Head: confirmed\n",
      "Word: his, Deprel: nmod:poss, Head: leg\n",
      "Word: right, Deprel: amod, Head: leg\n",
      "Word: leg, Deprel: obj, Head: broken\n",
      "Word: near, Deprel: case, Head: hip\n",
      "Word: the, Deprel: det, Head: hip\n",
      "Word: hip, Deprel: obl, Head: broken\n",
      "Word: and, Deprel: cc, Head: sustained\n",
      "Word: also, Deprel: advmod, Head: sustained\n",
      "Word: sustained, Deprel: conj, Head: broken\n",
      "Word: wrist, Deprel: compound, Head: fractures\n",
      "Word: and, Deprel: cc, Head: elbow\n",
      "Word: elbow, Deprel: conj, Head: wrist\n",
      "Word: fractures, Deprel: obj, Head: sustained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The author is one of several defense experts expected to testify'\n",
      "Word: The, Deprel: det, Head: author\n",
      "Word: author, Deprel: nsubj, Head: one\n",
      "Word: is, Deprel: cop, Head: one\n",
      "Word: one, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: experts\n",
      "Word: several, Deprel: amod, Head: experts\n",
      "Word: defense, Deprel: compound, Head: experts\n",
      "Word: experts, Deprel: nmod, Head: one\n",
      "Word: expected, Deprel: acl, Head: experts\n",
      "Word: to, Deprel: mark, Head: testify\n",
      "Word: testify, Deprel: xcomp, Head: expected\n",
      "\n",
      "Dependencies for Sentence: 'Spitz is expected to testify later for the defense'\n",
      "Word: Spitz, Deprel: nsubj:pass, Head: expected\n",
      "Word: is, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: testify\n",
      "Word: testify, Deprel: xcomp, Head: expected\n",
      "Word: later, Deprel: advmod, Head: testify\n",
      "Word: for, Deprel: case, Head: defense\n",
      "Word: the, Deprel: det, Head: defense\n",
      "Word: defense, Deprel: obl, Head: testify\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The figures are becoming catastrophic said Dr Patrick Pelloux the president of the association of emergency room physicians'\n",
      "Word: The, Deprel: det, Head: figures\n",
      "Word: figures, Deprel: nsubj, Head: becoming\n",
      "Word: are, Deprel: aux, Head: becoming\n",
      "Word: becoming, Deprel: root, Head: ROOT\n",
      "Word: catastrophic, Deprel: xcomp, Head: becoming\n",
      "Word: said, Deprel: xcomp, Head: becoming\n",
      "Word: Dr, Deprel: obj, Head: said\n",
      "Word: Patrick, Deprel: flat, Head: Dr\n",
      "Word: Pelloux, Deprel: flat, Head: Dr\n",
      "Word: the, Deprel: det, Head: president\n",
      "Word: president, Deprel: appos, Head: Dr\n",
      "Word: of, Deprel: case, Head: association\n",
      "Word: the, Deprel: det, Head: association\n",
      "Word: association, Deprel: nmod, Head: president\n",
      "Word: of, Deprel: case, Head: physicians\n",
      "Word: emergency, Deprel: compound, Head: room\n",
      "Word: room, Deprel: compound, Head: physicians\n",
      "Word: physicians, Deprel: nmod, Head: association\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This is unacceptable said Patrick Pelloux the president of France s Association of Emergency Doctors'\n",
      "Word: This, Deprel: nsubj, Head: unacceptable\n",
      "Word: is, Deprel: cop, Head: unacceptable\n",
      "Word: unacceptable, Deprel: ccomp, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Patrick, Deprel: obj, Head: said\n",
      "Word: Pelloux, Deprel: flat, Head: Patrick\n",
      "Word: the, Deprel: det, Head: president\n",
      "Word: president, Deprel: appos, Head: Patrick\n",
      "Word: of, Deprel: case, Head: Association\n",
      "Word: France, Deprel: nmod:poss, Head: Association\n",
      "Word: s, Deprel: case, Head: France\n",
      "Word: Association, Deprel: nmod, Head: president\n",
      "Word: of, Deprel: case, Head: Doctors\n",
      "Word: Emergency, Deprel: compound, Head: Doctors\n",
      "Word: Doctors, Deprel: nmod, Head: Association\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Whatever has happened to you by way of punishment is certainly more than enough Covello told the 49-year-old whose family friends and supporters filled half the courtroom'\n",
      "Word: Whatever, Deprel: nsubj, Head: more\n",
      "Word: has, Deprel: aux, Head: happened\n",
      "Word: happened, Deprel: acl:relcl, Head: Whatever\n",
      "Word: to, Deprel: case, Head: you\n",
      "Word: you, Deprel: obl, Head: happened\n",
      "Word: by, Deprel: case, Head: way\n",
      "Word: way, Deprel: obl, Head: happened\n",
      "Word: of, Deprel: case, Head: punishment\n",
      "Word: punishment, Deprel: nmod, Head: way\n",
      "Word: is, Deprel: cop, Head: more\n",
      "Word: certainly, Deprel: advmod, Head: more\n",
      "Word: more, Deprel: ccomp, Head: told\n",
      "Word: than, Deprel: case, Head: enough\n",
      "Word: enough, Deprel: obl, Head: more\n",
      "Word: Covello, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: 49-year-old\n",
      "Word: 49-year-old, Deprel: iobj, Head: told\n",
      "Word: whose, Deprel: nmod:poss, Head: friends\n",
      "Word: family, Deprel: compound, Head: friends\n",
      "Word: friends, Deprel: nsubj, Head: filled\n",
      "Word: and, Deprel: cc, Head: supporters\n",
      "Word: supporters, Deprel: conj, Head: friends\n",
      "Word: filled, Deprel: acl:relcl, Head: 49-year-old\n",
      "Word: half, Deprel: det:predet, Head: courtroom\n",
      "Word: the, Deprel: det, Head: courtroom\n",
      "Word: courtroom, Deprel: obj, Head: filled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'What has happened to you sir by way of punishment is certainly more than enough Covello said'\n",
      "Word: What, Deprel: nsubj, Head: more\n",
      "Word: has, Deprel: aux, Head: happened\n",
      "Word: happened, Deprel: acl:relcl, Head: What\n",
      "Word: to, Deprel: case, Head: you\n",
      "Word: you, Deprel: obl, Head: happened\n",
      "Word: sir, Deprel: flat, Head: you\n",
      "Word: by, Deprel: case, Head: way\n",
      "Word: way, Deprel: obl, Head: happened\n",
      "Word: of, Deprel: case, Head: punishment\n",
      "Word: punishment, Deprel: nmod, Head: way\n",
      "Word: is, Deprel: cop, Head: more\n",
      "Word: certainly, Deprel: advmod, Head: more\n",
      "Word: more, Deprel: root, Head: ROOT\n",
      "Word: than, Deprel: case, Head: enough\n",
      "Word: enough, Deprel: obl, Head: more\n",
      "Word: Covello, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: advcl, Head: more\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The mother also alleged in the lawsuit that she was sexually assaulted by one of the guards'\n",
      "Word: The, Deprel: det, Head: mother\n",
      "Word: mother, Deprel: nsubj, Head: alleged\n",
      "Word: also, Deprel: advmod, Head: alleged\n",
      "Word: alleged, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: lawsuit\n",
      "Word: the, Deprel: det, Head: lawsuit\n",
      "Word: lawsuit, Deprel: obl, Head: alleged\n",
      "Word: that, Deprel: mark, Head: assaulted\n",
      "Word: she, Deprel: nsubj:pass, Head: assaulted\n",
      "Word: was, Deprel: aux:pass, Head: assaulted\n",
      "Word: sexually, Deprel: advmod, Head: assaulted\n",
      "Word: assaulted, Deprel: ccomp, Head: alleged\n",
      "Word: by, Deprel: case, Head: one\n",
      "Word: one, Deprel: obl, Head: assaulted\n",
      "Word: of, Deprel: case, Head: guards\n",
      "Word: the, Deprel: det, Head: guards\n",
      "Word: guards, Deprel: nmod, Head: one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The mother also contended that she was sexually assaulted by one of the guards during the 1998 confrontation'\n",
      "Word: The, Deprel: det, Head: mother\n",
      "Word: mother, Deprel: nsubj, Head: contended\n",
      "Word: also, Deprel: advmod, Head: contended\n",
      "Word: contended, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: assaulted\n",
      "Word: she, Deprel: nsubj:pass, Head: assaulted\n",
      "Word: was, Deprel: aux:pass, Head: assaulted\n",
      "Word: sexually, Deprel: advmod, Head: assaulted\n",
      "Word: assaulted, Deprel: ccomp, Head: contended\n",
      "Word: by, Deprel: case, Head: one\n",
      "Word: one, Deprel: obl, Head: assaulted\n",
      "Word: of, Deprel: case, Head: guards\n",
      "Word: the, Deprel: det, Head: guards\n",
      "Word: guards, Deprel: nmod, Head: one\n",
      "Word: during, Deprel: case, Head: confrontation\n",
      "Word: the, Deprel: det, Head: confrontation\n",
      "Word: 1998, Deprel: nummod, Head: confrontation\n",
      "Word: confrontation, Deprel: obl, Head: assaulted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The two-year note US2YT=RR fell 5/32 in price taking its yield to 1.23 percent from 1.16 percent late on Monday'\n",
      "Word: The, Deprel: det, Head: note\n",
      "Word: two-year, Deprel: amod, Head: note\n",
      "Word: note, Deprel: nsubj, Head: fell\n",
      "Word: US2YT=RR, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 5/32, Deprel: obj, Head: fell\n",
      "Word: in, Deprel: case, Head: price\n",
      "Word: price, Deprel: nmod, Head: 5/32\n",
      "Word: taking, Deprel: advcl, Head: fell\n",
      "Word: its, Deprel: nmod:poss, Head: yield\n",
      "Word: yield, Deprel: obj, Head: taking\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 1.23, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n",
      "Word: from, Deprel: case, Head: percent\n",
      "Word: 1.16, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n",
      "Word: late, Deprel: advmod, Head: Monday\n",
      "Word: on, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: taking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The benchmark 10-year note US10YT=RR lost 11/32 in price taking its yield to 3.21 percent from 3.17 percent late on Monday'\n",
      "Word: The, Deprel: det, Head: note\n",
      "Word: benchmark, Deprel: compound, Head: note\n",
      "Word: 10-year, Deprel: compound, Head: note\n",
      "Word: note, Deprel: compound, Head: US10YT=RR\n",
      "Word: US10YT=RR, Deprel: nsubj, Head: lost\n",
      "Word: lost, Deprel: root, Head: ROOT\n",
      "Word: 11/32, Deprel: obj, Head: lost\n",
      "Word: in, Deprel: case, Head: price\n",
      "Word: price, Deprel: nmod, Head: 11/32\n",
      "Word: taking, Deprel: advcl, Head: lost\n",
      "Word: its, Deprel: nmod:poss, Head: yield\n",
      "Word: yield, Deprel: obj, Head: taking\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 3.21, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n",
      "Word: from, Deprel: case, Head: percent\n",
      "Word: 3.17, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n",
      "Word: late, Deprel: advmod, Head: Monday\n",
      "Word: on, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: taking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'As part of a restructuring Peregrine sold its Remedy help desk software unit last year to BMC Software Inc'\n",
      "Word: As, Deprel: case, Head: part\n",
      "Word: part, Deprel: obl, Head: sold\n",
      "Word: of, Deprel: case, Head: restructuring\n",
      "Word: a, Deprel: det, Head: restructuring\n",
      "Word: restructuring, Deprel: nmod, Head: part\n",
      "Word: Peregrine, Deprel: nsubj, Head: sold\n",
      "Word: sold, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: unit\n",
      "Word: Remedy, Deprel: compound, Head: help\n",
      "Word: help, Deprel: compound, Head: desk\n",
      "Word: desk, Deprel: compound, Head: unit\n",
      "Word: software, Deprel: compound, Head: unit\n",
      "Word: unit, Deprel: obj, Head: sold\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: sold\n",
      "Word: to, Deprel: case, Head: Inc\n",
      "Word: BMC, Deprel: compound, Head: Inc\n",
      "Word: Software, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: obl, Head: sold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Peregrine sold its Remedy business unit to BMC Software in November for 355 million'\n",
      "Word: Peregrine, Deprel: nsubj, Head: sold\n",
      "Word: sold, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: unit\n",
      "Word: Remedy, Deprel: compound, Head: unit\n",
      "Word: business, Deprel: compound, Head: unit\n",
      "Word: unit, Deprel: obj, Head: sold\n",
      "Word: to, Deprel: case, Head: Software\n",
      "Word: BMC, Deprel: compound, Head: Software\n",
      "Word: Software, Deprel: obl, Head: sold\n",
      "Word: in, Deprel: case, Head: November\n",
      "Word: November, Deprel: obl, Head: sold\n",
      "Word: for, Deprel: case, Head: million\n",
      "Word: 355, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: obl, Head: sold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Yes from today Flash memory purchased from AMD or Fujitsu will be branded Spansion'\n",
      "Word: Yes, Deprel: discourse, Head: branded\n",
      "Word: from, Deprel: case, Head: today\n",
      "Word: today, Deprel: obl, Head: branded\n",
      "Word: Flash, Deprel: compound, Head: memory\n",
      "Word: memory, Deprel: nsubj:pass, Head: branded\n",
      "Word: purchased, Deprel: acl, Head: memory\n",
      "Word: from, Deprel: case, Head: AMD\n",
      "Word: AMD, Deprel: obl, Head: purchased\n",
      "Word: or, Deprel: cc, Head: Fujitsu\n",
      "Word: Fujitsu, Deprel: conj, Head: AMD\n",
      "Word: will, Deprel: aux, Head: branded\n",
      "Word: be, Deprel: aux:pass, Head: branded\n",
      "Word: branded, Deprel: root, Head: ROOT\n",
      "Word: Spansion, Deprel: obj, Head: branded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Spansion Flash memory solutions are available worldwide from AMD and Fujitsu'\n",
      "Word: Spansion, Deprel: compound, Head: solutions\n",
      "Word: Flash, Deprel: compound, Head: solutions\n",
      "Word: memory, Deprel: compound, Head: solutions\n",
      "Word: solutions, Deprel: nsubj, Head: available\n",
      "Word: are, Deprel: cop, Head: available\n",
      "Word: available, Deprel: root, Head: ROOT\n",
      "Word: worldwide, Deprel: advmod, Head: available\n",
      "Word: from, Deprel: case, Head: AMD\n",
      "Word: AMD, Deprel: obl, Head: available\n",
      "Word: and, Deprel: cc, Head: Fujitsu\n",
      "Word: Fujitsu, Deprel: conj, Head: AMD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The world s two largest automakers said their U.S sales declined more than predicted last month as a late summer sales frenzy caused more of an industry backlash than expected'\n",
      "Word: The, Deprel: det, Head: world\n",
      "Word: world, Deprel: nmod:poss, Head: automakers\n",
      "Word: s, Deprel: case, Head: world\n",
      "Word: two, Deprel: nummod, Head: automakers\n",
      "Word: largest, Deprel: amod, Head: automakers\n",
      "Word: automakers, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: their, Deprel: nmod:poss, Head: sales\n",
      "Word: U.S, Deprel: compound, Head: sales\n",
      "Word: sales, Deprel: nsubj, Head: declined\n",
      "Word: declined, Deprel: ccomp, Head: said\n",
      "Word: more, Deprel: advmod, Head: declined\n",
      "Word: than, Deprel: mark, Head: predicted\n",
      "Word: predicted, Deprel: advcl, Head: more\n",
      "Word: last, Deprel: amod, Head: month\n",
      "Word: month, Deprel: obl:tmod, Head: declined\n",
      "Word: as, Deprel: mark, Head: caused\n",
      "Word: a, Deprel: det, Head: frenzy\n",
      "Word: late, Deprel: amod, Head: frenzy\n",
      "Word: summer, Deprel: compound, Head: frenzy\n",
      "Word: sales, Deprel: compound, Head: frenzy\n",
      "Word: frenzy, Deprel: nsubj, Head: caused\n",
      "Word: caused, Deprel: advcl, Head: declined\n",
      "Word: more, Deprel: obj, Head: caused\n",
      "Word: of, Deprel: case, Head: backlash\n",
      "Word: an, Deprel: det, Head: backlash\n",
      "Word: industry, Deprel: compound, Head: backlash\n",
      "Word: backlash, Deprel: obl, Head: more\n",
      "Word: than, Deprel: mark, Head: expected\n",
      "Word: expected, Deprel: acl, Head: backlash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Domestic sales at both GM and No 2 Ford Motor Co declined more than predicted as a late summer sales frenzy prompted a larger-than-expected industry backlash'\n",
      "Word: Domestic, Deprel: amod, Head: sales\n",
      "Word: sales, Deprel: nsubj, Head: declined\n",
      "Word: at, Deprel: case, Head: GM\n",
      "Word: both, Deprel: det, Head: GM\n",
      "Word: GM, Deprel: nmod, Head: sales\n",
      "Word: and, Deprel: cc, Head: Co\n",
      "Word: No, Deprel: det, Head: 2\n",
      "Word: 2, Deprel: conj, Head: GM\n",
      "Word: Ford, Deprel: compound, Head: Co\n",
      "Word: Motor, Deprel: compound, Head: Co\n",
      "Word: Co, Deprel: conj, Head: GM\n",
      "Word: declined, Deprel: root, Head: ROOT\n",
      "Word: more, Deprel: advmod, Head: predicted\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: predicted, Deprel: advcl, Head: declined\n",
      "Word: as, Deprel: mark, Head: prompted\n",
      "Word: a, Deprel: det, Head: frenzy\n",
      "Word: late, Deprel: amod, Head: frenzy\n",
      "Word: summer, Deprel: compound, Head: frenzy\n",
      "Word: sales, Deprel: compound, Head: frenzy\n",
      "Word: frenzy, Deprel: nsubj, Head: prompted\n",
      "Word: prompted, Deprel: advcl, Head: declined\n",
      "Word: a, Deprel: det, Head: backlash\n",
      "Word: larger-than-expected, Deprel: amod, Head: backlash\n",
      "Word: industry, Deprel: compound, Head: backlash\n",
      "Word: backlash, Deprel: obj, Head: prompted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A tropical storm rapidly developed in the Gulf of Mexico Sunday and was expected to hit somewhere along the Texas or Louisiana coasts by Monday night'\n",
      "Word: A, Deprel: det, Head: storm\n",
      "Word: tropical, Deprel: amod, Head: storm\n",
      "Word: storm, Deprel: nsubj, Head: developed\n",
      "Word: rapidly, Deprel: advmod, Head: developed\n",
      "Word: developed, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: Gulf\n",
      "Word: the, Deprel: det, Head: Gulf\n",
      "Word: Gulf, Deprel: obl, Head: developed\n",
      "Word: of, Deprel: case, Head: Mexico\n",
      "Word: Mexico, Deprel: nmod, Head: Gulf\n",
      "Word: Sunday, Deprel: obl:tmod, Head: developed\n",
      "Word: and, Deprel: cc, Head: expected\n",
      "Word: was, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: conj, Head: developed\n",
      "Word: to, Deprel: mark, Head: hit\n",
      "Word: hit, Deprel: xcomp, Head: expected\n",
      "Word: somewhere, Deprel: advmod, Head: hit\n",
      "Word: along, Deprel: case, Head: coasts\n",
      "Word: the, Deprel: det, Head: coasts\n",
      "Word: Texas, Deprel: compound, Head: coasts\n",
      "Word: or, Deprel: cc, Head: Louisiana\n",
      "Word: Louisiana, Deprel: conj, Head: Texas\n",
      "Word: coasts, Deprel: obl, Head: hit\n",
      "Word: by, Deprel: case, Head: night\n",
      "Word: Monday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl, Head: hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A tropical storm rapidly developed in the Gulf of Mexico on Sunday and could have hurricane-force winds when it hits land somewhere along the Louisiana coast Monday night'\n",
      "Word: A, Deprel: det, Head: storm\n",
      "Word: tropical, Deprel: amod, Head: storm\n",
      "Word: storm, Deprel: nsubj, Head: developed\n",
      "Word: rapidly, Deprel: advmod, Head: developed\n",
      "Word: developed, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: Gulf\n",
      "Word: the, Deprel: det, Head: Gulf\n",
      "Word: Gulf, Deprel: obl, Head: developed\n",
      "Word: of, Deprel: case, Head: Mexico\n",
      "Word: Mexico, Deprel: nmod, Head: Gulf\n",
      "Word: on, Deprel: case, Head: Sunday\n",
      "Word: Sunday, Deprel: obl, Head: developed\n",
      "Word: and, Deprel: cc, Head: have\n",
      "Word: could, Deprel: aux, Head: have\n",
      "Word: have, Deprel: conj, Head: developed\n",
      "Word: hurricane-force, Deprel: compound, Head: winds\n",
      "Word: winds, Deprel: obj, Head: have\n",
      "Word: when, Deprel: advmod, Head: hits\n",
      "Word: it, Deprel: nsubj, Head: hits\n",
      "Word: hits, Deprel: advcl, Head: have\n",
      "Word: land, Deprel: obj, Head: hits\n",
      "Word: somewhere, Deprel: advmod, Head: hits\n",
      "Word: along, Deprel: case, Head: coast\n",
      "Word: the, Deprel: det, Head: coast\n",
      "Word: Louisiana, Deprel: compound, Head: coast\n",
      "Word: coast, Deprel: obl, Head: somewhere\n",
      "Word: Monday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: hits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The pressure may well rise on Thursday with national coverage of the final round planned by ESPN the cable sports network'\n",
      "Word: The, Deprel: det, Head: pressure\n",
      "Word: pressure, Deprel: nsubj, Head: rise\n",
      "Word: may, Deprel: aux, Head: rise\n",
      "Word: well, Deprel: advmod, Head: rise\n",
      "Word: rise, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: rise\n",
      "Word: with, Deprel: case, Head: coverage\n",
      "Word: national, Deprel: amod, Head: coverage\n",
      "Word: coverage, Deprel: obl, Head: rise\n",
      "Word: of, Deprel: case, Head: round\n",
      "Word: the, Deprel: det, Head: round\n",
      "Word: final, Deprel: amod, Head: round\n",
      "Word: round, Deprel: nmod, Head: coverage\n",
      "Word: planned, Deprel: acl, Head: round\n",
      "Word: by, Deprel: case, Head: ESPN\n",
      "Word: ESPN, Deprel: obl, Head: planned\n",
      "Word: the, Deprel: det, Head: network\n",
      "Word: cable, Deprel: compound, Head: network\n",
      "Word: sports, Deprel: compound, Head: network\n",
      "Word: network, Deprel: obj, Head: planned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The pressure will intensify today with national coverage of the final round planned by ESPN and words that are even more difficult'\n",
      "Word: The, Deprel: det, Head: pressure\n",
      "Word: pressure, Deprel: nsubj, Head: intensify\n",
      "Word: will, Deprel: aux, Head: intensify\n",
      "Word: intensify, Deprel: root, Head: ROOT\n",
      "Word: today, Deprel: obl:tmod, Head: intensify\n",
      "Word: with, Deprel: case, Head: coverage\n",
      "Word: national, Deprel: amod, Head: coverage\n",
      "Word: coverage, Deprel: obl, Head: intensify\n",
      "Word: of, Deprel: case, Head: round\n",
      "Word: the, Deprel: det, Head: round\n",
      "Word: final, Deprel: amod, Head: round\n",
      "Word: round, Deprel: nmod, Head: coverage\n",
      "Word: planned, Deprel: acl, Head: round\n",
      "Word: by, Deprel: case, Head: ESPN\n",
      "Word: ESPN, Deprel: obl:agent, Head: planned\n",
      "Word: and, Deprel: cc, Head: words\n",
      "Word: words, Deprel: conj, Head: ESPN\n",
      "Word: that, Deprel: nsubj, Head: difficult\n",
      "Word: are, Deprel: cop, Head: difficult\n",
      "Word: even, Deprel: advmod, Head: more\n",
      "Word: more, Deprel: advmod, Head: difficult\n",
      "Word: difficult, Deprel: acl:relcl, Head: words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Pataki praised Abraham s decision and LIPA Chairman Richard Kessel said the cable should be kept in operation permanently'\n",
      "Word: Pataki, Deprel: nsubj, Head: praised\n",
      "Word: praised, Deprel: root, Head: ROOT\n",
      "Word: Abraham, Deprel: nmod:poss, Head: decision\n",
      "Word: s, Deprel: case, Head: Abraham\n",
      "Word: decision, Deprel: obj, Head: praised\n",
      "Word: and, Deprel: cc, Head: said\n",
      "Word: LIPA, Deprel: compound, Head: Chairman\n",
      "Word: Chairman, Deprel: nsubj, Head: said\n",
      "Word: Richard, Deprel: flat, Head: Chairman\n",
      "Word: Kessel, Deprel: flat, Head: Richard\n",
      "Word: said, Deprel: conj, Head: praised\n",
      "Word: the, Deprel: det, Head: cable\n",
      "Word: cable, Deprel: nsubj:pass, Head: kept\n",
      "Word: should, Deprel: aux, Head: kept\n",
      "Word: be, Deprel: aux:pass, Head: kept\n",
      "Word: kept, Deprel: ccomp, Head: said\n",
      "Word: in, Deprel: case, Head: operation\n",
      "Word: operation, Deprel: obl, Head: kept\n",
      "Word: permanently, Deprel: advmod, Head: kept\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'LIPA Chairman Richard Kessel said that meant the cable could be used as we see fit'\n",
      "Word: LIPA, Deprel: compound, Head: Chairman\n",
      "Word: Chairman, Deprel: compound, Head: Richard\n",
      "Word: Richard, Deprel: nsubj, Head: said\n",
      "Word: Kessel, Deprel: flat, Head: Richard\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: meant\n",
      "Word: meant, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: cable\n",
      "Word: cable, Deprel: nsubj:pass, Head: used\n",
      "Word: could, Deprel: aux, Head: used\n",
      "Word: be, Deprel: aux:pass, Head: used\n",
      "Word: used, Deprel: ccomp, Head: meant\n",
      "Word: as, Deprel: mark, Head: see\n",
      "Word: we, Deprel: nsubj, Head: see\n",
      "Word: see, Deprel: advcl, Head: used\n",
      "Word: fit, Deprel: obj, Head: see\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Part of the accord was the implementation of a special health council that would monitor health spending and progress in reforming the health system'\n",
      "Word: Part, Deprel: nsubj, Head: implementation\n",
      "Word: of, Deprel: case, Head: accord\n",
      "Word: the, Deprel: det, Head: accord\n",
      "Word: accord, Deprel: nmod, Head: Part\n",
      "Word: was, Deprel: cop, Head: implementation\n",
      "Word: the, Deprel: det, Head: implementation\n",
      "Word: implementation, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: council\n",
      "Word: a, Deprel: det, Head: council\n",
      "Word: special, Deprel: amod, Head: council\n",
      "Word: health, Deprel: compound, Head: council\n",
      "Word: council, Deprel: nmod, Head: implementation\n",
      "Word: that, Deprel: nsubj, Head: monitor\n",
      "Word: would, Deprel: aux, Head: monitor\n",
      "Word: monitor, Deprel: acl:relcl, Head: council\n",
      "Word: health, Deprel: compound, Head: spending\n",
      "Word: spending, Deprel: obj, Head: monitor\n",
      "Word: and, Deprel: cc, Head: progress\n",
      "Word: progress, Deprel: conj, Head: spending\n",
      "Word: in, Deprel: mark, Head: reforming\n",
      "Word: reforming, Deprel: acl, Head: progress\n",
      "Word: the, Deprel: det, Head: system\n",
      "Word: health, Deprel: compound, Head: system\n",
      "Word: system, Deprel: obj, Head: reforming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A key portion of the accord was the implementation of a special council to monitor health spending set goals for the system and measure progress in reforming health care'\n",
      "Word: A, Deprel: det, Head: portion\n",
      "Word: key, Deprel: amod, Head: portion\n",
      "Word: portion, Deprel: nsubj, Head: implementation\n",
      "Word: of, Deprel: case, Head: accord\n",
      "Word: the, Deprel: det, Head: accord\n",
      "Word: accord, Deprel: nmod, Head: portion\n",
      "Word: was, Deprel: cop, Head: implementation\n",
      "Word: the, Deprel: det, Head: implementation\n",
      "Word: implementation, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: council\n",
      "Word: a, Deprel: det, Head: council\n",
      "Word: special, Deprel: amod, Head: council\n",
      "Word: council, Deprel: nmod, Head: implementation\n",
      "Word: to, Deprel: mark, Head: monitor\n",
      "Word: monitor, Deprel: acl, Head: council\n",
      "Word: health, Deprel: compound, Head: spending\n",
      "Word: spending, Deprel: obj, Head: monitor\n",
      "Word: set, Deprel: amod, Head: goals\n",
      "Word: goals, Deprel: obj, Head: monitor\n",
      "Word: for, Deprel: case, Head: system\n",
      "Word: the, Deprel: det, Head: system\n",
      "Word: system, Deprel: nmod, Head: goals\n",
      "Word: and, Deprel: cc, Head: measure\n",
      "Word: measure, Deprel: conj, Head: monitor\n",
      "Word: progress, Deprel: obj, Head: measure\n",
      "Word: in, Deprel: mark, Head: reforming\n",
      "Word: reforming, Deprel: acl, Head: progress\n",
      "Word: health, Deprel: compound, Head: care\n",
      "Word: care, Deprel: obj, Head: reforming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dynes came to UC San Diego in 1991 after 22 years as a physicist with AT T Bell Labs'\n",
      "Word: Dynes, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: UC\n",
      "Word: UC, Deprel: obl, Head: came\n",
      "Word: San, Deprel: flat, Head: UC\n",
      "Word: Diego, Deprel: flat, Head: San\n",
      "Word: in, Deprel: case, Head: 1991\n",
      "Word: 1991, Deprel: obl, Head: came\n",
      "Word: after, Deprel: case, Head: years\n",
      "Word: 22, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl, Head: came\n",
      "Word: as, Deprel: case, Head: physicist\n",
      "Word: a, Deprel: det, Head: physicist\n",
      "Word: physicist, Deprel: nmod, Head: years\n",
      "Word: with, Deprel: case, Head: Labs\n",
      "Word: AT, Deprel: compound, Head: Labs\n",
      "Word: T, Deprel: flat, Head: AT\n",
      "Word: Bell, Deprel: flat, Head: AT\n",
      "Word: Labs, Deprel: nmod, Head: physicist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dynes has been at UC San Diego since 1991 after spending 22 years with AT T Bell Labs where he worked on superconductors and other materials'\n",
      "Word: Dynes, Deprel: nsubj, Head: UC\n",
      "Word: has, Deprel: aux, Head: UC\n",
      "Word: been, Deprel: cop, Head: UC\n",
      "Word: at, Deprel: case, Head: UC\n",
      "Word: UC, Deprel: root, Head: ROOT\n",
      "Word: San, Deprel: flat, Head: UC\n",
      "Word: Diego, Deprel: flat, Head: San\n",
      "Word: since, Deprel: case, Head: 1991\n",
      "Word: 1991, Deprel: obl, Head: UC\n",
      "Word: after, Deprel: mark, Head: spending\n",
      "Word: spending, Deprel: advcl, Head: UC\n",
      "Word: 22, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obj, Head: spending\n",
      "Word: with, Deprel: case, Head: Labs\n",
      "Word: AT, Deprel: compound, Head: Labs\n",
      "Word: T, Deprel: compound, Head: Labs\n",
      "Word: Bell, Deprel: flat, Head: AT\n",
      "Word: Labs, Deprel: nmod, Head: years\n",
      "Word: where, Deprel: advmod, Head: worked\n",
      "Word: he, Deprel: nsubj, Head: worked\n",
      "Word: worked, Deprel: acl:relcl, Head: Labs\n",
      "Word: on, Deprel: case, Head: superconductors\n",
      "Word: superconductors, Deprel: obl, Head: worked\n",
      "Word: and, Deprel: cc, Head: materials\n",
      "Word: other, Deprel: amod, Head: materials\n",
      "Word: materials, Deprel: conj, Head: superconductors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares in BA were down 1.5 percent at 168 pence by 1420 GMT off a low of 164p in a slightly stronger overall London market'\n",
      "Word: Shares, Deprel: nsubj, Head: down\n",
      "Word: in, Deprel: case, Head: BA\n",
      "Word: BA, Deprel: nmod, Head: Shares\n",
      "Word: were, Deprel: cop, Head: down\n",
      "Word: down, Deprel: root, Head: ROOT\n",
      "Word: 1.5, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: down\n",
      "Word: at, Deprel: case, Head: pence\n",
      "Word: 168, Deprel: nummod, Head: pence\n",
      "Word: pence, Deprel: obl, Head: down\n",
      "Word: by, Deprel: case, Head: GMT\n",
      "Word: 1420, Deprel: nummod, Head: GMT\n",
      "Word: GMT, Deprel: obl, Head: down\n",
      "Word: off, Deprel: case, Head: low\n",
      "Word: a, Deprel: det, Head: low\n",
      "Word: low, Deprel: obl, Head: down\n",
      "Word: of, Deprel: case, Head: 164p\n",
      "Word: 164p, Deprel: nmod, Head: low\n",
      "Word: in, Deprel: case, Head: market\n",
      "Word: a, Deprel: det, Head: market\n",
      "Word: slightly, Deprel: advmod, Head: stronger\n",
      "Word: stronger, Deprel: amod, Head: market\n",
      "Word: overall, Deprel: amod, Head: market\n",
      "Word: London, Deprel: compound, Head: market\n",
      "Word: market, Deprel: obl, Head: down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares in BA were down three percent at 165-1/4 pence by 0933 GMT off a low of 164 pence in a stronger market'\n",
      "Word: Shares, Deprel: nsubj, Head: down\n",
      "Word: in, Deprel: case, Head: BA\n",
      "Word: BA, Deprel: nmod, Head: Shares\n",
      "Word: were, Deprel: cop, Head: down\n",
      "Word: down, Deprel: root, Head: ROOT\n",
      "Word: three, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: down\n",
      "Word: at, Deprel: case, Head: pence\n",
      "Word: 165-1/4, Deprel: nummod, Head: pence\n",
      "Word: pence, Deprel: obl, Head: down\n",
      "Word: by, Deprel: case, Head: GMT\n",
      "Word: 0933, Deprel: nummod, Head: GMT\n",
      "Word: GMT, Deprel: obl, Head: down\n",
      "Word: off, Deprel: case, Head: low\n",
      "Word: a, Deprel: det, Head: low\n",
      "Word: low, Deprel: obl, Head: down\n",
      "Word: of, Deprel: case, Head: pence\n",
      "Word: 164, Deprel: nummod, Head: pence\n",
      "Word: pence, Deprel: nmod, Head: low\n",
      "Word: in, Deprel: case, Head: market\n",
      "Word: a, Deprel: det, Head: market\n",
      "Word: stronger, Deprel: amod, Head: market\n",
      "Word: market, Deprel: nmod, Head: low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Senate agreed Tuesday to lift a 10-year-old ban on the research and development of low-yield nuclear weapons'\n",
      "Word: The, Deprel: det, Head: Senate\n",
      "Word: Senate, Deprel: nsubj, Head: agreed\n",
      "Word: agreed, Deprel: root, Head: ROOT\n",
      "Word: Tuesday, Deprel: obl:tmod, Head: agreed\n",
      "Word: to, Deprel: mark, Head: lift\n",
      "Word: lift, Deprel: xcomp, Head: agreed\n",
      "Word: a, Deprel: det, Head: ban\n",
      "Word: 10-year-old, Deprel: amod, Head: ban\n",
      "Word: ban, Deprel: obj, Head: lift\n",
      "Word: on, Deprel: case, Head: research\n",
      "Word: the, Deprel: det, Head: research\n",
      "Word: research, Deprel: nmod, Head: ban\n",
      "Word: and, Deprel: cc, Head: development\n",
      "Word: development, Deprel: conj, Head: research\n",
      "Word: of, Deprel: case, Head: weapons\n",
      "Word: low-yield, Deprel: amod, Head: weapons\n",
      "Word: nuclear, Deprel: amod, Head: weapons\n",
      "Word: weapons, Deprel: nmod, Head: research\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Both the House and Senate bills would end the ban on research and development of low-yield nuclear weapons'\n",
      "Word: Both, Deprel: det:predet, Head: bills\n",
      "Word: the, Deprel: det, Head: bills\n",
      "Word: House, Deprel: compound, Head: bills\n",
      "Word: and, Deprel: cc, Head: Senate\n",
      "Word: Senate, Deprel: conj, Head: House\n",
      "Word: bills, Deprel: nsubj, Head: end\n",
      "Word: would, Deprel: aux, Head: end\n",
      "Word: end, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: ban\n",
      "Word: ban, Deprel: obj, Head: end\n",
      "Word: on, Deprel: case, Head: research\n",
      "Word: research, Deprel: nmod, Head: ban\n",
      "Word: and, Deprel: cc, Head: development\n",
      "Word: development, Deprel: conj, Head: research\n",
      "Word: of, Deprel: case, Head: weapons\n",
      "Word: low-yield, Deprel: amod, Head: weapons\n",
      "Word: nuclear, Deprel: amod, Head: weapons\n",
      "Word: weapons, Deprel: nmod, Head: research\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Meningitis is an infection of the spinal cord fluid and the tissue around the brain'\n",
      "Word: Meningitis, Deprel: nsubj, Head: infection\n",
      "Word: is, Deprel: cop, Head: infection\n",
      "Word: an, Deprel: det, Head: infection\n",
      "Word: infection, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: fluid\n",
      "Word: the, Deprel: det, Head: fluid\n",
      "Word: spinal, Deprel: amod, Head: cord\n",
      "Word: cord, Deprel: compound, Head: fluid\n",
      "Word: fluid, Deprel: nmod, Head: infection\n",
      "Word: and, Deprel: cc, Head: tissue\n",
      "Word: the, Deprel: det, Head: tissue\n",
      "Word: tissue, Deprel: conj, Head: fluid\n",
      "Word: around, Deprel: case, Head: brain\n",
      "Word: the, Deprel: det, Head: brain\n",
      "Word: brain, Deprel: nmod, Head: tissue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Meningitis is an infection of the fluid in a person s spinal cord and around the brain'\n",
      "Word: Meningitis, Deprel: nsubj, Head: infection\n",
      "Word: is, Deprel: cop, Head: infection\n",
      "Word: an, Deprel: det, Head: infection\n",
      "Word: infection, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: fluid\n",
      "Word: the, Deprel: det, Head: fluid\n",
      "Word: fluid, Deprel: nmod, Head: infection\n",
      "Word: in, Deprel: case, Head: cord\n",
      "Word: a, Deprel: det, Head: person\n",
      "Word: person, Deprel: nmod:poss, Head: cord\n",
      "Word: s, Deprel: case, Head: person\n",
      "Word: spinal, Deprel: amod, Head: cord\n",
      "Word: cord, Deprel: nmod, Head: fluid\n",
      "Word: and, Deprel: cc, Head: brain\n",
      "Word: around, Deprel: case, Head: brain\n",
      "Word: the, Deprel: det, Head: brain\n",
      "Word: brain, Deprel: conj, Head: cord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The companies Chiron and Aventis Pasteur together made about 80 million doses of the injected vaccine which ordinarily would have been enough to meet U.S demand'\n",
      "Word: The, Deprel: det, Head: companies\n",
      "Word: companies, Deprel: nsubj, Head: made\n",
      "Word: Chiron, Deprel: appos, Head: companies\n",
      "Word: and, Deprel: cc, Head: Pasteur\n",
      "Word: Aventis, Deprel: compound, Head: Pasteur\n",
      "Word: Pasteur, Deprel: conj, Head: Chiron\n",
      "Word: together, Deprel: advmod, Head: made\n",
      "Word: made, Deprel: root, Head: ROOT\n",
      "Word: about, Deprel: advmod, Head: million\n",
      "Word: 80, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: nummod, Head: doses\n",
      "Word: doses, Deprel: obj, Head: made\n",
      "Word: of, Deprel: case, Head: vaccine\n",
      "Word: the, Deprel: det, Head: vaccine\n",
      "Word: injected, Deprel: amod, Head: vaccine\n",
      "Word: vaccine, Deprel: nmod, Head: doses\n",
      "Word: which, Deprel: nsubj, Head: enough\n",
      "Word: ordinarily, Deprel: advmod, Head: enough\n",
      "Word: would, Deprel: aux, Head: enough\n",
      "Word: have, Deprel: aux, Head: enough\n",
      "Word: been, Deprel: cop, Head: enough\n",
      "Word: enough, Deprel: acl:relcl, Head: doses\n",
      "Word: to, Deprel: mark, Head: meet\n",
      "Word: meet, Deprel: advcl, Head: enough\n",
      "Word: U.S, Deprel: compound, Head: demand\n",
      "Word: demand, Deprel: obj, Head: meet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Chiron and Aventis Pasteur together made about 80 million doses ordinarily enough for U.S demand The Associated Press reported'\n",
      "Word: Chiron, Deprel: nsubj, Head: made\n",
      "Word: and, Deprel: cc, Head: Pasteur\n",
      "Word: Aventis, Deprel: compound, Head: Pasteur\n",
      "Word: Pasteur, Deprel: conj, Head: Chiron\n",
      "Word: together, Deprel: advmod, Head: made\n",
      "Word: made, Deprel: root, Head: ROOT\n",
      "Word: about, Deprel: advmod, Head: million\n",
      "Word: 80, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: nummod, Head: doses\n",
      "Word: doses, Deprel: obj, Head: made\n",
      "Word: ordinarily, Deprel: advmod, Head: made\n",
      "Word: enough, Deprel: advmod, Head: ordinarily\n",
      "Word: for, Deprel: case, Head: demand\n",
      "Word: U.S, Deprel: compound, Head: demand\n",
      "Word: demand, Deprel: obl, Head: enough\n",
      "Word: The, Deprel: det, Head: Press\n",
      "Word: Associated, Deprel: amod, Head: Press\n",
      "Word: Press, Deprel: nsubj, Head: reported\n",
      "Word: reported, Deprel: parataxis, Head: made\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mayor Joe T Parker said late Thursday that the three workers were two men and a woman who were inside the building when the first blast occurred'\n",
      "Word: Mayor, Deprel: nsubj, Head: said\n",
      "Word: Joe, Deprel: flat, Head: Mayor\n",
      "Word: T, Deprel: flat, Head: Mayor\n",
      "Word: Parker, Deprel: flat, Head: Mayor\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: late, Deprel: amod, Head: Thursday\n",
      "Word: Thursday, Deprel: obl:tmod, Head: said\n",
      "Word: that, Deprel: mark, Head: men\n",
      "Word: the, Deprel: det, Head: workers\n",
      "Word: three, Deprel: nummod, Head: workers\n",
      "Word: workers, Deprel: nsubj, Head: men\n",
      "Word: were, Deprel: cop, Head: men\n",
      "Word: two, Deprel: nummod, Head: men\n",
      "Word: men, Deprel: ccomp, Head: said\n",
      "Word: and, Deprel: cc, Head: woman\n",
      "Word: a, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: conj, Head: men\n",
      "Word: who, Deprel: nsubj, Head: building\n",
      "Word: were, Deprel: cop, Head: building\n",
      "Word: inside, Deprel: case, Head: building\n",
      "Word: the, Deprel: det, Head: building\n",
      "Word: building, Deprel: acl:relcl, Head: woman\n",
      "Word: when, Deprel: advmod, Head: occurred\n",
      "Word: the, Deprel: det, Head: blast\n",
      "Word: first, Deprel: amod, Head: blast\n",
      "Word: blast, Deprel: nsubj, Head: occurred\n",
      "Word: occurred, Deprel: advcl, Head: building\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The missing workers two men and a woman were inside the building when the first blast occurred Mayor Joe T Parker said'\n",
      "Word: The, Deprel: det, Head: workers\n",
      "Word: missing, Deprel: amod, Head: workers\n",
      "Word: workers, Deprel: nsubj, Head: building\n",
      "Word: two, Deprel: nummod, Head: men\n",
      "Word: men, Deprel: appos, Head: workers\n",
      "Word: and, Deprel: cc, Head: woman\n",
      "Word: a, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: conj, Head: men\n",
      "Word: were, Deprel: cop, Head: building\n",
      "Word: inside, Deprel: case, Head: building\n",
      "Word: the, Deprel: det, Head: building\n",
      "Word: building, Deprel: root, Head: ROOT\n",
      "Word: when, Deprel: advmod, Head: occurred\n",
      "Word: the, Deprel: det, Head: blast\n",
      "Word: first, Deprel: amod, Head: blast\n",
      "Word: blast, Deprel: nsubj, Head: occurred\n",
      "Word: occurred, Deprel: advcl, Head: building\n",
      "Word: Mayor, Deprel: obj, Head: occurred\n",
      "Word: Joe, Deprel: flat, Head: Mayor\n",
      "Word: T, Deprel: flat, Head: Mayor\n",
      "Word: Parker, Deprel: flat, Head: Mayor\n",
      "Word: said, Deprel: ccomp, Head: occurred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'London-based NCRI official Ali Safavi told Reuters We condemn this raid which is in our view illegal and morally and politically unjustifiable'\n",
      "Word: London-based, Deprel: amod, Head: official\n",
      "Word: NCRI, Deprel: compound, Head: official\n",
      "Word: official, Deprel: compound, Head: Ali\n",
      "Word: Ali, Deprel: nsubj, Head: told\n",
      "Word: Safavi, Deprel: flat, Head: Ali\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: Reuters, Deprel: iobj, Head: told\n",
      "Word: We, Deprel: nsubj, Head: condemn\n",
      "Word: condemn, Deprel: ccomp, Head: told\n",
      "Word: this, Deprel: det, Head: raid\n",
      "Word: raid, Deprel: obj, Head: condemn\n",
      "Word: which, Deprel: nsubj, Head: view\n",
      "Word: is, Deprel: cop, Head: view\n",
      "Word: in, Deprel: case, Head: view\n",
      "Word: our, Deprel: nmod:poss, Head: view\n",
      "Word: view, Deprel: acl:relcl, Head: raid\n",
      "Word: illegal, Deprel: amod, Head: view\n",
      "Word: and, Deprel: cc, Head: morally\n",
      "Word: morally, Deprel: conj, Head: illegal\n",
      "Word: and, Deprel: cc, Head: politically\n",
      "Word: politically, Deprel: conj, Head: morally\n",
      "Word: unjustifiable, Deprel: conj, Head: illegal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We condemn this raid which is in our view illegal and morally and politically unjustifiable London-based NCRI official Ali Safavi told Reuters by telephone'\n",
      "Word: We, Deprel: nsubj, Head: condemn\n",
      "Word: condemn, Deprel: root, Head: ROOT\n",
      "Word: this, Deprel: det, Head: raid\n",
      "Word: raid, Deprel: obj, Head: condemn\n",
      "Word: which, Deprel: nsubj, Head: view\n",
      "Word: is, Deprel: cop, Head: view\n",
      "Word: in, Deprel: case, Head: view\n",
      "Word: our, Deprel: nmod:poss, Head: view\n",
      "Word: view, Deprel: acl:relcl, Head: raid\n",
      "Word: illegal, Deprel: amod, Head: view\n",
      "Word: and, Deprel: cc, Head: told\n",
      "Word: morally, Deprel: advmod, Head: unjustifiable\n",
      "Word: and, Deprel: cc, Head: unjustifiable\n",
      "Word: politically, Deprel: advmod, Head: unjustifiable\n",
      "Word: unjustifiable, Deprel: amod, Head: official\n",
      "Word: London-based, Deprel: amod, Head: official\n",
      "Word: NCRI, Deprel: compound, Head: official\n",
      "Word: official, Deprel: compound, Head: Ali\n",
      "Word: Ali, Deprel: nsubj, Head: told\n",
      "Word: Safavi, Deprel: flat, Head: Ali\n",
      "Word: told, Deprel: acl:relcl, Head: raid\n",
      "Word: Reuters, Deprel: iobj, Head: told\n",
      "Word: by, Deprel: case, Head: telephone\n",
      "Word: telephone, Deprel: obl, Head: told\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Investigators uncovered a 4-inch bone fragment from beneath the concrete slab Thursday but it turned out to be an animal bone authorities said'\n",
      "Word: Investigators, Deprel: nsubj, Head: uncovered\n",
      "Word: uncovered, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: fragment\n",
      "Word: 4-inch, Deprel: amod, Head: fragment\n",
      "Word: bone, Deprel: compound, Head: fragment\n",
      "Word: fragment, Deprel: obj, Head: uncovered\n",
      "Word: from, Deprel: case, Head: slab\n",
      "Word: beneath, Deprel: case, Head: slab\n",
      "Word: the, Deprel: det, Head: slab\n",
      "Word: concrete, Deprel: compound, Head: slab\n",
      "Word: slab, Deprel: obl, Head: uncovered\n",
      "Word: Thursday, Deprel: obl:tmod, Head: uncovered\n",
      "Word: but, Deprel: cc, Head: turned\n",
      "Word: it, Deprel: nsubj, Head: turned\n",
      "Word: turned, Deprel: conj, Head: uncovered\n",
      "Word: out, Deprel: compound:prt, Head: turned\n",
      "Word: to, Deprel: mark, Head: authorities\n",
      "Word: be, Deprel: cop, Head: authorities\n",
      "Word: an, Deprel: det, Head: authorities\n",
      "Word: animal, Deprel: compound, Head: authorities\n",
      "Word: bone, Deprel: compound, Head: authorities\n",
      "Word: authorities, Deprel: xcomp, Head: turned\n",
      "Word: said, Deprel: acl, Head: authorities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Investigators uncovered a 4-inch bone fragment Thursday night but authorities said it was from an animal'\n",
      "Word: Investigators, Deprel: nsubj, Head: uncovered\n",
      "Word: uncovered, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: fragment\n",
      "Word: 4-inch, Deprel: amod, Head: fragment\n",
      "Word: bone, Deprel: compound, Head: fragment\n",
      "Word: fragment, Deprel: obj, Head: uncovered\n",
      "Word: Thursday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: uncovered\n",
      "Word: but, Deprel: cc, Head: said\n",
      "Word: authorities, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: conj, Head: uncovered\n",
      "Word: it, Deprel: nsubj, Head: animal\n",
      "Word: was, Deprel: cop, Head: animal\n",
      "Word: from, Deprel: case, Head: animal\n",
      "Word: an, Deprel: det, Head: animal\n",
      "Word: animal, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Joining Stern and McEntee on stage was International Union of Painters and Allied Trades President James Williams'\n",
      "Word: Joining, Deprel: csubj, Head: Union\n",
      "Word: Stern, Deprel: obj, Head: Joining\n",
      "Word: and, Deprel: cc, Head: McEntee\n",
      "Word: McEntee, Deprel: conj, Head: Stern\n",
      "Word: on, Deprel: case, Head: stage\n",
      "Word: stage, Deprel: obl, Head: Joining\n",
      "Word: was, Deprel: cop, Head: Union\n",
      "Word: International, Deprel: amod, Head: Union\n",
      "Word: Union, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: Painters\n",
      "Word: Painters, Deprel: nmod, Head: Union\n",
      "Word: and, Deprel: cc, Head: President\n",
      "Word: Allied, Deprel: amod, Head: President\n",
      "Word: Trades, Deprel: compound, Head: President\n",
      "Word: President, Deprel: conj, Head: Union\n",
      "Word: James, Deprel: flat, Head: President\n",
      "Word: Williams, Deprel: flat, Head: President\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The International Union of Painters and Allied Trades endorsed Mr Dean several weeks ago'\n",
      "Word: The, Deprel: det, Head: Union\n",
      "Word: International, Deprel: amod, Head: Union\n",
      "Word: Union, Deprel: nsubj, Head: endorsed\n",
      "Word: of, Deprel: case, Head: Painters\n",
      "Word: Painters, Deprel: nmod, Head: Union\n",
      "Word: and, Deprel: cc, Head: Trades\n",
      "Word: Allied, Deprel: amod, Head: Trades\n",
      "Word: Trades, Deprel: conj, Head: Union\n",
      "Word: endorsed, Deprel: root, Head: ROOT\n",
      "Word: Mr, Deprel: obj, Head: endorsed\n",
      "Word: Dean, Deprel: flat, Head: Mr\n",
      "Word: several, Deprel: amod, Head: weeks\n",
      "Word: weeks, Deprel: obl:npmod, Head: ago\n",
      "Word: ago, Deprel: advmod, Head: endorsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It exploded in his hands but the former Italian prime minister was unhurt'\n",
      "Word: It, Deprel: nsubj, Head: exploded\n",
      "Word: exploded, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: hands\n",
      "Word: his, Deprel: nmod:poss, Head: hands\n",
      "Word: hands, Deprel: obl, Head: exploded\n",
      "Word: but, Deprel: cc, Head: unhurt\n",
      "Word: the, Deprel: det, Head: minister\n",
      "Word: former, Deprel: amod, Head: minister\n",
      "Word: Italian, Deprel: amod, Head: minister\n",
      "Word: prime, Deprel: amod, Head: minister\n",
      "Word: minister, Deprel: nsubj, Head: unhurt\n",
      "Word: was, Deprel: cop, Head: unhurt\n",
      "Word: unhurt, Deprel: conj, Head: exploded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The letter bomb sent to Prodi exploded in his hands but he was unhurt'\n",
      "Word: The, Deprel: det, Head: bomb\n",
      "Word: letter, Deprel: compound, Head: bomb\n",
      "Word: bomb, Deprel: nsubj, Head: exploded\n",
      "Word: sent, Deprel: acl, Head: bomb\n",
      "Word: to, Deprel: case, Head: Prodi\n",
      "Word: Prodi, Deprel: obl, Head: sent\n",
      "Word: exploded, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: hands\n",
      "Word: his, Deprel: nmod:poss, Head: hands\n",
      "Word: hands, Deprel: obl, Head: exploded\n",
      "Word: but, Deprel: cc, Head: unhurt\n",
      "Word: he, Deprel: nsubj, Head: unhurt\n",
      "Word: was, Deprel: cop, Head: unhurt\n",
      "Word: unhurt, Deprel: conj, Head: exploded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Some 95 million Americans half of all households invest in mutual funds'\n",
      "Word: Some, Deprel: det, Head: Americans\n",
      "Word: 95, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: Americans\n",
      "Word: Americans, Deprel: nsubj, Head: invest\n",
      "Word: half, Deprel: nsubj, Head: invest\n",
      "Word: of, Deprel: case, Head: households\n",
      "Word: all, Deprel: det, Head: households\n",
      "Word: households, Deprel: nmod, Head: half\n",
      "Word: invest, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: funds\n",
      "Word: mutual, Deprel: amod, Head: funds\n",
      "Word: funds, Deprel: obl, Head: invest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'About half of all U.S households have money in mutual funds'\n",
      "Word: About, Deprel: advmod, Head: half\n",
      "Word: half, Deprel: nsubj, Head: have\n",
      "Word: of, Deprel: case, Head: households\n",
      "Word: all, Deprel: det, Head: households\n",
      "Word: U.S, Deprel: compound, Head: households\n",
      "Word: households, Deprel: nmod, Head: half\n",
      "Word: have, Deprel: root, Head: ROOT\n",
      "Word: money, Deprel: obj, Head: have\n",
      "Word: in, Deprel: case, Head: funds\n",
      "Word: mutual, Deprel: amod, Head: funds\n",
      "Word: funds, Deprel: obl, Head: have\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Halabi s military attorney Air Force Maj James Key denied the charges which could carry a death penalty'\n",
      "Word: Halabi, Deprel: nmod:poss, Head: Maj\n",
      "Word: s, Deprel: case, Head: Halabi\n",
      "Word: military, Deprel: amod, Head: attorney\n",
      "Word: attorney, Deprel: compound, Head: Maj\n",
      "Word: Air, Deprel: compound, Head: Force\n",
      "Word: Force, Deprel: compound, Head: Maj\n",
      "Word: Maj, Deprel: nsubj, Head: denied\n",
      "Word: James, Deprel: flat, Head: Maj\n",
      "Word: Key, Deprel: flat, Head: Maj\n",
      "Word: denied, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: charges\n",
      "Word: charges, Deprel: obj, Head: denied\n",
      "Word: which, Deprel: nsubj, Head: carry\n",
      "Word: could, Deprel: aux, Head: carry\n",
      "Word: carry, Deprel: acl:relcl, Head: charges\n",
      "Word: a, Deprel: det, Head: penalty\n",
      "Word: death, Deprel: compound, Head: penalty\n",
      "Word: penalty, Deprel: obj, Head: carry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The attorney representing al-Halabi Air Force Maj James Key III denied the charges according to The Associated Press'\n",
      "Word: The, Deprel: det, Head: attorney\n",
      "Word: attorney, Deprel: nsubj, Head: denied\n",
      "Word: representing, Deprel: acl, Head: attorney\n",
      "Word: al-Halabi, Deprel: compound, Head: Maj\n",
      "Word: Air, Deprel: compound, Head: Force\n",
      "Word: Force, Deprel: compound, Head: Maj\n",
      "Word: Maj, Deprel: obj, Head: representing\n",
      "Word: James, Deprel: flat, Head: Maj\n",
      "Word: Key, Deprel: flat, Head: Maj\n",
      "Word: III, Deprel: flat, Head: Maj\n",
      "Word: denied, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: charges\n",
      "Word: charges, Deprel: obj, Head: denied\n",
      "Word: according, Deprel: case, Head: Press\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: The, Deprel: det, Head: Press\n",
      "Word: Associated, Deprel: amod, Head: Press\n",
      "Word: Press, Deprel: obl, Head: denied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Waksal in a letter to the court said I tore my family apart'\n",
      "Word: Waksal, Deprel: nsubj, Head: said\n",
      "Word: in, Deprel: case, Head: letter\n",
      "Word: a, Deprel: det, Head: letter\n",
      "Word: letter, Deprel: nmod, Head: Waksal\n",
      "Word: to, Deprel: case, Head: court\n",
      "Word: the, Deprel: det, Head: court\n",
      "Word: court, Deprel: nmod, Head: letter\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: I, Deprel: nsubj, Head: tore\n",
      "Word: tore, Deprel: ccomp, Head: said\n",
      "Word: my, Deprel: nmod:poss, Head: family\n",
      "Word: family, Deprel: obj, Head: tore\n",
      "Word: apart, Deprel: advmod, Head: tore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In seeking leniency Waksal apologized to the court his employees and his family'\n",
      "Word: In, Deprel: mark, Head: seeking\n",
      "Word: seeking, Deprel: advcl, Head: apologized\n",
      "Word: leniency, Deprel: obj, Head: seeking\n",
      "Word: Waksal, Deprel: nsubj, Head: apologized\n",
      "Word: apologized, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: court\n",
      "Word: the, Deprel: det, Head: court\n",
      "Word: court, Deprel: obl, Head: apologized\n",
      "Word: his, Deprel: nmod:poss, Head: employees\n",
      "Word: employees, Deprel: obj, Head: apologized\n",
      "Word: and, Deprel: cc, Head: family\n",
      "Word: his, Deprel: nmod:poss, Head: family\n",
      "Word: family, Deprel: conj, Head: employees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Since early May the city has received 1,400 reports of dead blue jays and crows Jayroe said'\n",
      "Word: Since, Deprel: case, Head: May\n",
      "Word: early, Deprel: amod, Head: May\n",
      "Word: May, Deprel: obl, Head: received\n",
      "Word: the, Deprel: det, Head: city\n",
      "Word: city, Deprel: nsubj, Head: received\n",
      "Word: has, Deprel: aux, Head: received\n",
      "Word: received, Deprel: root, Head: ROOT\n",
      "Word: 1,400, Deprel: nummod, Head: reports\n",
      "Word: reports, Deprel: obj, Head: received\n",
      "Word: of, Deprel: case, Head: jays\n",
      "Word: dead, Deprel: amod, Head: jays\n",
      "Word: blue, Deprel: amod, Head: jays\n",
      "Word: jays, Deprel: nmod, Head: reports\n",
      "Word: and, Deprel: cc, Head: crows\n",
      "Word: crows, Deprel: conj, Head: reports\n",
      "Word: Jayroe, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: received\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Since early May the city has received 1,400 reports he said'\n",
      "Word: Since, Deprel: case, Head: May\n",
      "Word: early, Deprel: amod, Head: May\n",
      "Word: May, Deprel: obl, Head: received\n",
      "Word: the, Deprel: det, Head: city\n",
      "Word: city, Deprel: nsubj, Head: received\n",
      "Word: has, Deprel: aux, Head: received\n",
      "Word: received, Deprel: root, Head: ROOT\n",
      "Word: 1,400, Deprel: nummod, Head: reports\n",
      "Word: reports, Deprel: obj, Head: received\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: reports\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But Forest the Freedom Organisation for the Right to Enjoy Smoking Tobacco said Mention the word prohibition and everyone knows what happened there'\n",
      "Word: But, Deprel: cc, Head: said\n",
      "Word: Forest, Deprel: nsubj, Head: said\n",
      "Word: the, Deprel: det, Head: Organisation\n",
      "Word: Freedom, Deprel: compound, Head: Organisation\n",
      "Word: Organisation, Deprel: nsubj, Head: said\n",
      "Word: for, Deprel: case, Head: Right\n",
      "Word: the, Deprel: det, Head: Right\n",
      "Word: Right, Deprel: nmod, Head: Organisation\n",
      "Word: to, Deprel: mark, Head: Enjoy\n",
      "Word: Enjoy, Deprel: acl, Head: Right\n",
      "Word: Smoking, Deprel: compound, Head: Tobacco\n",
      "Word: Tobacco, Deprel: obj, Head: Enjoy\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Mention, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: word\n",
      "Word: word, Deprel: compound, Head: prohibition\n",
      "Word: prohibition, Deprel: obj, Head: Mention\n",
      "Word: and, Deprel: cc, Head: knows\n",
      "Word: everyone, Deprel: nsubj, Head: knows\n",
      "Word: knows, Deprel: conj, Head: said\n",
      "Word: what, Deprel: nsubj, Head: happened\n",
      "Word: happened, Deprel: ccomp, Head: knows\n",
      "Word: there, Deprel: advmod, Head: happened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Forest the Freedom Organisation for the Right to Enjoy Smoking Tobacco said it had greeted The Lancet s call with amusement and disbelief'\n",
      "Word: Forest, Deprel: nsubj, Head: said\n",
      "Word: the, Deprel: det, Head: Organisation\n",
      "Word: Freedom, Deprel: compound, Head: Organisation\n",
      "Word: Organisation, Deprel: appos, Head: Forest\n",
      "Word: for, Deprel: case, Head: Right\n",
      "Word: the, Deprel: det, Head: Right\n",
      "Word: Right, Deprel: nmod, Head: Organisation\n",
      "Word: to, Deprel: mark, Head: Enjoy\n",
      "Word: Enjoy, Deprel: acl, Head: Right\n",
      "Word: Smoking, Deprel: compound, Head: Tobacco\n",
      "Word: Tobacco, Deprel: obj, Head: Enjoy\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: greeted\n",
      "Word: had, Deprel: aux, Head: greeted\n",
      "Word: greeted, Deprel: ccomp, Head: said\n",
      "Word: The, Deprel: det, Head: Lancet\n",
      "Word: Lancet, Deprel: nmod:poss, Head: call\n",
      "Word: s, Deprel: case, Head: Lancet\n",
      "Word: call, Deprel: obj, Head: greeted\n",
      "Word: with, Deprel: case, Head: amusement\n",
      "Word: amusement, Deprel: obl, Head: greeted\n",
      "Word: and, Deprel: cc, Head: disbelief\n",
      "Word: disbelief, Deprel: conj, Head: amusement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The House has passed prescription-drug legislation in the last two sessions but the Senate has failed to do so'\n",
      "Word: The, Deprel: det, Head: House\n",
      "Word: House, Deprel: nsubj, Head: passed\n",
      "Word: has, Deprel: aux, Head: passed\n",
      "Word: passed, Deprel: root, Head: ROOT\n",
      "Word: prescription-drug, Deprel: compound, Head: legislation\n",
      "Word: legislation, Deprel: obj, Head: passed\n",
      "Word: in, Deprel: case, Head: sessions\n",
      "Word: the, Deprel: det, Head: sessions\n",
      "Word: last, Deprel: amod, Head: sessions\n",
      "Word: two, Deprel: nummod, Head: sessions\n",
      "Word: sessions, Deprel: obl, Head: passed\n",
      "Word: but, Deprel: cc, Head: failed\n",
      "Word: the, Deprel: det, Head: Senate\n",
      "Word: Senate, Deprel: nsubj, Head: failed\n",
      "Word: has, Deprel: aux, Head: failed\n",
      "Word: failed, Deprel: conj, Head: passed\n",
      "Word: to, Deprel: mark, Head: do\n",
      "Word: do, Deprel: xcomp, Head: failed\n",
      "Word: so, Deprel: advmod, Head: do\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The House has passed bills the past two Congresses but the Senate has not'\n",
      "Word: The, Deprel: det, Head: House\n",
      "Word: House, Deprel: nsubj, Head: passed\n",
      "Word: has, Deprel: aux, Head: passed\n",
      "Word: passed, Deprel: root, Head: ROOT\n",
      "Word: bills, Deprel: obj, Head: passed\n",
      "Word: the, Deprel: det, Head: Congresses\n",
      "Word: past, Deprel: amod, Head: Congresses\n",
      "Word: two, Deprel: nummod, Head: Congresses\n",
      "Word: Congresses, Deprel: obl:tmod, Head: passed\n",
      "Word: but, Deprel: cc, Head: has\n",
      "Word: the, Deprel: det, Head: Senate\n",
      "Word: Senate, Deprel: nsubj, Head: has\n",
      "Word: has, Deprel: conj, Head: passed\n",
      "Word: not, Deprel: advmod, Head: has\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Once converted BayStar will own an aggregate of approximately 2.95 million shares of SCO common stock or 17.5 percent of the company s outstanding shares'\n",
      "Word: Once, Deprel: advmod, Head: converted\n",
      "Word: converted, Deprel: advcl, Head: own\n",
      "Word: BayStar, Deprel: nsubj, Head: own\n",
      "Word: will, Deprel: aux, Head: own\n",
      "Word: own, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: aggregate\n",
      "Word: aggregate, Deprel: obj, Head: own\n",
      "Word: of, Deprel: case, Head: shares\n",
      "Word: approximately, Deprel: advmod, Head: million\n",
      "Word: 2.95, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: shares\n",
      "Word: shares, Deprel: nmod, Head: aggregate\n",
      "Word: of, Deprel: case, Head: stock\n",
      "Word: SCO, Deprel: compound, Head: stock\n",
      "Word: common, Deprel: amod, Head: stock\n",
      "Word: stock, Deprel: nmod, Head: shares\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 17.5, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: aggregate\n",
      "Word: of, Deprel: case, Head: shares\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nmod:poss, Head: shares\n",
      "Word: s, Deprel: case, Head: company\n",
      "Word: outstanding, Deprel: amod, Head: shares\n",
      "Word: shares, Deprel: nmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The investment gives Larkspur Calif.-based BayStar more than 2.9 million shares of SCO common stock or 17.5 percent of the company s outstanding shares'\n",
      "Word: The, Deprel: det, Head: investment\n",
      "Word: investment, Deprel: nsubj, Head: gives\n",
      "Word: gives, Deprel: root, Head: ROOT\n",
      "Word: Larkspur, Deprel: iobj, Head: gives\n",
      "Word: Calif.-based, Deprel: compound, Head: BayStar\n",
      "Word: BayStar, Deprel: flat, Head: Larkspur\n",
      "Word: more, Deprel: advmod, Head: million\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 2.9, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: shares\n",
      "Word: shares, Deprel: obj, Head: gives\n",
      "Word: of, Deprel: case, Head: stock\n",
      "Word: SCO, Deprel: compound, Head: stock\n",
      "Word: common, Deprel: amod, Head: stock\n",
      "Word: stock, Deprel: nmod, Head: shares\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 17.5, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: shares\n",
      "Word: of, Deprel: case, Head: shares\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nmod:poss, Head: shares\n",
      "Word: s, Deprel: case, Head: company\n",
      "Word: outstanding, Deprel: amod, Head: shares\n",
      "Word: shares, Deprel: nmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The elderly and those with weakened immune systems are also urged to protect against mosquito bites'\n",
      "Word: The, Deprel: det, Head: elderly\n",
      "Word: elderly, Deprel: nsubj:pass, Head: urged\n",
      "Word: and, Deprel: cc, Head: those\n",
      "Word: those, Deprel: conj, Head: elderly\n",
      "Word: with, Deprel: case, Head: systems\n",
      "Word: weakened, Deprel: amod, Head: systems\n",
      "Word: immune, Deprel: amod, Head: systems\n",
      "Word: systems, Deprel: nmod, Head: those\n",
      "Word: are, Deprel: aux:pass, Head: urged\n",
      "Word: also, Deprel: advmod, Head: urged\n",
      "Word: urged, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: protect\n",
      "Word: protect, Deprel: xcomp, Head: urged\n",
      "Word: against, Deprel: case, Head: bites\n",
      "Word: mosquito, Deprel: compound, Head: bites\n",
      "Word: bites, Deprel: obl, Head: protect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But for the elderly and those with weakened immune systems it can be fatal'\n",
      "Word: But, Deprel: cc, Head: fatal\n",
      "Word: for, Deprel: case, Head: elderly\n",
      "Word: the, Deprel: det, Head: elderly\n",
      "Word: elderly, Deprel: obl, Head: fatal\n",
      "Word: and, Deprel: cc, Head: those\n",
      "Word: those, Deprel: conj, Head: elderly\n",
      "Word: with, Deprel: case, Head: systems\n",
      "Word: weakened, Deprel: amod, Head: systems\n",
      "Word: immune, Deprel: amod, Head: systems\n",
      "Word: systems, Deprel: nmod, Head: those\n",
      "Word: it, Deprel: nsubj, Head: fatal\n",
      "Word: can, Deprel: aux, Head: fatal\n",
      "Word: be, Deprel: cop, Head: fatal\n",
      "Word: fatal, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'OPEC producers at a meeting on Wednesday are set to pressure independent oil exporters to contribute to the cartel s next supply cut to allow for the return of Iraqi oil'\n",
      "Word: OPEC, Deprel: compound, Head: producers\n",
      "Word: producers, Deprel: nsubj, Head: set\n",
      "Word: at, Deprel: case, Head: meeting\n",
      "Word: a, Deprel: det, Head: meeting\n",
      "Word: meeting, Deprel: nmod, Head: producers\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: nmod, Head: meeting\n",
      "Word: are, Deprel: cop, Head: set\n",
      "Word: set, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: pressure\n",
      "Word: pressure, Deprel: xcomp, Head: set\n",
      "Word: independent, Deprel: amod, Head: exporters\n",
      "Word: oil, Deprel: compound, Head: exporters\n",
      "Word: exporters, Deprel: obj, Head: pressure\n",
      "Word: to, Deprel: mark, Head: contribute\n",
      "Word: contribute, Deprel: xcomp, Head: pressure\n",
      "Word: to, Deprel: case, Head: cut\n",
      "Word: the, Deprel: det, Head: cartel\n",
      "Word: cartel, Deprel: nmod:poss, Head: cut\n",
      "Word: s, Deprel: case, Head: cartel\n",
      "Word: next, Deprel: amod, Head: supply\n",
      "Word: supply, Deprel: compound, Head: cut\n",
      "Word: cut, Deprel: obl, Head: contribute\n",
      "Word: to, Deprel: mark, Head: allow\n",
      "Word: allow, Deprel: advcl, Head: contribute\n",
      "Word: for, Deprel: case, Head: return\n",
      "Word: the, Deprel: det, Head: return\n",
      "Word: return, Deprel: obl, Head: allow\n",
      "Word: of, Deprel: case, Head: oil\n",
      "Word: Iraqi, Deprel: amod, Head: oil\n",
      "Word: oil, Deprel: nmod, Head: return\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'OPEC this week is set to pressure independent exporters to back the cartel s next supply cut to prevent the resumption of Iraqi exports undercutting oil prices'\n",
      "Word: OPEC, Deprel: nsubj, Head: set\n",
      "Word: this, Deprel: det, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: set\n",
      "Word: is, Deprel: cop, Head: set\n",
      "Word: set, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: pressure\n",
      "Word: pressure, Deprel: xcomp, Head: set\n",
      "Word: independent, Deprel: amod, Head: exporters\n",
      "Word: exporters, Deprel: obj, Head: pressure\n",
      "Word: to, Deprel: mark, Head: back\n",
      "Word: back, Deprel: advcl, Head: pressure\n",
      "Word: the, Deprel: det, Head: cartel\n",
      "Word: cartel, Deprel: nmod:poss, Head: cut\n",
      "Word: s, Deprel: case, Head: cartel\n",
      "Word: next, Deprel: amod, Head: supply\n",
      "Word: supply, Deprel: compound, Head: cut\n",
      "Word: cut, Deprel: obj, Head: back\n",
      "Word: to, Deprel: mark, Head: prevent\n",
      "Word: prevent, Deprel: advcl, Head: back\n",
      "Word: the, Deprel: det, Head: resumption\n",
      "Word: resumption, Deprel: obj, Head: prevent\n",
      "Word: of, Deprel: case, Head: exports\n",
      "Word: Iraqi, Deprel: amod, Head: exports\n",
      "Word: exports, Deprel: nmod, Head: resumption\n",
      "Word: undercutting, Deprel: acl, Head: resumption\n",
      "Word: oil, Deprel: compound, Head: prices\n",
      "Word: prices, Deprel: obj, Head: undercutting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Winston-Salem North Carolina company opened six stores during the quarter bringing the total to 282'\n",
      "Word: The, Deprel: det, Head: company\n",
      "Word: Winston-Salem, Deprel: compound, Head: company\n",
      "Word: North, Deprel: compound, Head: Carolina\n",
      "Word: Carolina, Deprel: compound, Head: company\n",
      "Word: company, Deprel: nsubj, Head: opened\n",
      "Word: opened, Deprel: root, Head: ROOT\n",
      "Word: six, Deprel: nummod, Head: stores\n",
      "Word: stores, Deprel: obj, Head: opened\n",
      "Word: during, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: opened\n",
      "Word: bringing, Deprel: advcl, Head: opened\n",
      "Word: the, Deprel: det, Head: total\n",
      "Word: total, Deprel: obj, Head: bringing\n",
      "Word: to, Deprel: case, Head: 282\n",
      "Word: 282, Deprel: obl, Head: bringing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Six new Krispy Kreme stores were opened in the first quarter bringing the total number of stores to 282'\n",
      "Word: Six, Deprel: nummod, Head: stores\n",
      "Word: new, Deprel: amod, Head: stores\n",
      "Word: Krispy, Deprel: compound, Head: stores\n",
      "Word: Kreme, Deprel: compound, Head: stores\n",
      "Word: stores, Deprel: nsubj:pass, Head: opened\n",
      "Word: were, Deprel: aux:pass, Head: opened\n",
      "Word: opened, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: first, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: opened\n",
      "Word: bringing, Deprel: advcl, Head: opened\n",
      "Word: the, Deprel: det, Head: number\n",
      "Word: total, Deprel: amod, Head: number\n",
      "Word: number, Deprel: obj, Head: bringing\n",
      "Word: of, Deprel: case, Head: stores\n",
      "Word: stores, Deprel: nmod, Head: number\n",
      "Word: to, Deprel: case, Head: 282\n",
      "Word: 282, Deprel: obl, Head: bringing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Ms Lafferty s lawyer Thomas Ezzell told a Kentucky newspaper My understanding of this is that there is a lower percentage of successful impregnations with frozen'\n",
      "Word: Ms, Deprel: nmod:poss, Head: lawyer\n",
      "Word: Lafferty, Deprel: flat, Head: Ms\n",
      "Word: s, Deprel: case, Head: Ms\n",
      "Word: lawyer, Deprel: nsubj, Head: told\n",
      "Word: Thomas, Deprel: appos, Head: lawyer\n",
      "Word: Ezzell, Deprel: flat, Head: Thomas\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: newspaper\n",
      "Word: Kentucky, Deprel: compound, Head: newspaper\n",
      "Word: newspaper, Deprel: iobj, Head: told\n",
      "Word: My, Deprel: nmod:poss, Head: understanding\n",
      "Word: understanding, Deprel: nsubj:outer, Head: is\n",
      "Word: of, Deprel: case, Head: this\n",
      "Word: this, Deprel: nmod, Head: understanding\n",
      "Word: is, Deprel: cop, Head: is\n",
      "Word: that, Deprel: mark, Head: is\n",
      "Word: there, Deprel: expl, Head: is\n",
      "Word: is, Deprel: ccomp, Head: told\n",
      "Word: a, Deprel: det, Head: percentage\n",
      "Word: lower, Deprel: amod, Head: percentage\n",
      "Word: percentage, Deprel: nsubj, Head: is\n",
      "Word: of, Deprel: case, Head: impregnations\n",
      "Word: successful, Deprel: amod, Head: impregnations\n",
      "Word: impregnations, Deprel: nmod, Head: percentage\n",
      "Word: with, Deprel: case, Head: frozen\n",
      "Word: frozen, Deprel: nmod, Head: impregnations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'My understanding of this is that there is a lower percentage of successful impregnations with frozen Ezzell said'\n",
      "Word: My, Deprel: nmod:poss, Head: understanding\n",
      "Word: understanding, Deprel: nsubj:outer, Head: is\n",
      "Word: of, Deprel: case, Head: this\n",
      "Word: this, Deprel: nmod, Head: understanding\n",
      "Word: is, Deprel: cop, Head: is\n",
      "Word: that, Deprel: mark, Head: is\n",
      "Word: there, Deprel: expl, Head: is\n",
      "Word: is, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: percentage\n",
      "Word: lower, Deprel: amod, Head: percentage\n",
      "Word: percentage, Deprel: nsubj, Head: is\n",
      "Word: of, Deprel: case, Head: impregnations\n",
      "Word: successful, Deprel: amod, Head: impregnations\n",
      "Word: impregnations, Deprel: nmod, Head: percentage\n",
      "Word: with, Deprel: mark, Head: said\n",
      "Word: frozen, Deprel: amod, Head: Ezzell\n",
      "Word: Ezzell, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: advcl, Head: is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Federal Trade Commission FTC asked Congress today for additional authority to fight unwanted Internet spam which now accounts for up to half of all e-mail traffic'\n",
      "Word: The, Deprel: det, Head: FTC\n",
      "Word: Federal, Deprel: amod, Head: Commission\n",
      "Word: Trade, Deprel: compound, Head: Commission\n",
      "Word: Commission, Deprel: compound, Head: FTC\n",
      "Word: FTC, Deprel: nsubj, Head: asked\n",
      "Word: asked, Deprel: root, Head: ROOT\n",
      "Word: Congress, Deprel: iobj, Head: asked\n",
      "Word: today, Deprel: obl:tmod, Head: asked\n",
      "Word: for, Deprel: case, Head: authority\n",
      "Word: additional, Deprel: amod, Head: authority\n",
      "Word: authority, Deprel: obl, Head: asked\n",
      "Word: to, Deprel: mark, Head: fight\n",
      "Word: fight, Deprel: acl, Head: authority\n",
      "Word: unwanted, Deprel: amod, Head: spam\n",
      "Word: Internet, Deprel: compound, Head: spam\n",
      "Word: spam, Deprel: obj, Head: fight\n",
      "Word: which, Deprel: nsubj, Head: accounts\n",
      "Word: now, Deprel: advmod, Head: accounts\n",
      "Word: accounts, Deprel: acl:relcl, Head: spam\n",
      "Word: for, Deprel: case, Head: half\n",
      "Word: up, Deprel: advmod, Head: half\n",
      "Word: to, Deprel: fixed, Head: up\n",
      "Word: half, Deprel: obl, Head: accounts\n",
      "Word: of, Deprel: case, Head: traffic\n",
      "Word: all, Deprel: det, Head: traffic\n",
      "Word: e-mail, Deprel: compound, Head: traffic\n",
      "Word: traffic, Deprel: nmod, Head: half\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Federal Trade Commission asked Congress yesterday for broader powers to attack the rapidly growing problem of spam which new studies show accounts for half of all e-mail traffic'\n",
      "Word: The, Deprel: det, Head: Commission\n",
      "Word: Federal, Deprel: amod, Head: Commission\n",
      "Word: Trade, Deprel: compound, Head: Commission\n",
      "Word: Commission, Deprel: nsubj, Head: asked\n",
      "Word: asked, Deprel: root, Head: ROOT\n",
      "Word: Congress, Deprel: iobj, Head: asked\n",
      "Word: yesterday, Deprel: obl:tmod, Head: asked\n",
      "Word: for, Deprel: case, Head: powers\n",
      "Word: broader, Deprel: amod, Head: powers\n",
      "Word: powers, Deprel: obl, Head: asked\n",
      "Word: to, Deprel: mark, Head: attack\n",
      "Word: attack, Deprel: acl, Head: powers\n",
      "Word: the, Deprel: det, Head: problem\n",
      "Word: rapidly, Deprel: advmod, Head: growing\n",
      "Word: growing, Deprel: amod, Head: problem\n",
      "Word: problem, Deprel: obj, Head: attack\n",
      "Word: of, Deprel: case, Head: spam\n",
      "Word: spam, Deprel: nmod, Head: problem\n",
      "Word: which, Deprel: obj, Head: show\n",
      "Word: new, Deprel: amod, Head: studies\n",
      "Word: studies, Deprel: nsubj, Head: show\n",
      "Word: show, Deprel: acl:relcl, Head: problem\n",
      "Word: accounts, Deprel: obj, Head: show\n",
      "Word: for, Deprel: case, Head: half\n",
      "Word: half, Deprel: obl, Head: show\n",
      "Word: of, Deprel: case, Head: traffic\n",
      "Word: all, Deprel: det, Head: traffic\n",
      "Word: e-mail, Deprel: compound, Head: traffic\n",
      "Word: traffic, Deprel: nmod, Head: half\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A federal grand jury indicted them on Tuesday the document was sealed until yesterday to allow authorities to make arrests'\n",
      "Word: A, Deprel: det, Head: jury\n",
      "Word: federal, Deprel: amod, Head: jury\n",
      "Word: grand, Deprel: amod, Head: jury\n",
      "Word: jury, Deprel: nsubj, Head: indicted\n",
      "Word: indicted, Deprel: root, Head: ROOT\n",
      "Word: them, Deprel: obj, Head: indicted\n",
      "Word: on, Deprel: case, Head: Tuesday\n",
      "Word: Tuesday, Deprel: obl, Head: indicted\n",
      "Word: the, Deprel: det, Head: document\n",
      "Word: document, Deprel: nsubj:pass, Head: sealed\n",
      "Word: was, Deprel: aux:pass, Head: sealed\n",
      "Word: sealed, Deprel: ccomp, Head: indicted\n",
      "Word: until, Deprel: case, Head: yesterday\n",
      "Word: yesterday, Deprel: obl, Head: sealed\n",
      "Word: to, Deprel: mark, Head: allow\n",
      "Word: allow, Deprel: advcl, Head: sealed\n",
      "Word: authorities, Deprel: iobj, Head: allow\n",
      "Word: to, Deprel: mark, Head: make\n",
      "Word: make, Deprel: xcomp, Head: allow\n",
      "Word: arrests, Deprel: obj, Head: make\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Federal officials said the document remained sealed until Thursday morning to allow authorities to make arrests in five Western states'\n",
      "Word: Federal, Deprel: amod, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: document\n",
      "Word: document, Deprel: nsubj, Head: remained\n",
      "Word: remained, Deprel: ccomp, Head: said\n",
      "Word: sealed, Deprel: xcomp, Head: remained\n",
      "Word: until, Deprel: case, Head: morning\n",
      "Word: Thursday, Deprel: compound, Head: morning\n",
      "Word: morning, Deprel: obl, Head: sealed\n",
      "Word: to, Deprel: mark, Head: allow\n",
      "Word: allow, Deprel: advcl, Head: sealed\n",
      "Word: authorities, Deprel: iobj, Head: allow\n",
      "Word: to, Deprel: mark, Head: make\n",
      "Word: make, Deprel: xcomp, Head: allow\n",
      "Word: arrests, Deprel: obj, Head: make\n",
      "Word: in, Deprel: case, Head: states\n",
      "Word: five, Deprel: nummod, Head: states\n",
      "Word: Western, Deprel: amod, Head: states\n",
      "Word: states, Deprel: obl, Head: make\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'People who have opposed these actions throughout are now trying to find fresh reasons to say this was n't the right thing to do'\n",
      "Word: People, Deprel: nsubj, Head: trying\n",
      "Word: who, Deprel: nsubj, Head: opposed\n",
      "Word: have, Deprel: aux, Head: opposed\n",
      "Word: opposed, Deprel: acl:relcl, Head: People\n",
      "Word: these, Deprel: det, Head: actions\n",
      "Word: actions, Deprel: obj, Head: opposed\n",
      "Word: throughout, Deprel: mark, Head: trying\n",
      "Word: are, Deprel: aux, Head: trying\n",
      "Word: now, Deprel: advmod, Head: trying\n",
      "Word: trying, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: find\n",
      "Word: find, Deprel: xcomp, Head: trying\n",
      "Word: fresh, Deprel: amod, Head: reasons\n",
      "Word: reasons, Deprel: obj, Head: find\n",
      "Word: to, Deprel: mark, Head: say\n",
      "Word: say, Deprel: acl, Head: reasons\n",
      "Word: this, Deprel: nsubj, Head: thing\n",
      "Word: was, Deprel: cop, Head: thing\n",
      "Word: n't, Deprel: advmod, Head: thing\n",
      "Word: the, Deprel: det, Head: thing\n",
      "Word: right, Deprel: amod, Head: thing\n",
      "Word: thing, Deprel: ccomp, Head: say\n",
      "Word: to, Deprel: mark, Head: do\n",
      "Word: do, Deprel: acl, Head: thing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'What is happening here is that people who have opposed this action throughout are trying to find fresh reasons why it was not the right thing to do'\n",
      "Word: What, Deprel: nsubj, Head: happening\n",
      "Word: is, Deprel: aux, Head: happening\n",
      "Word: happening, Deprel: csubj:outer, Head: trying\n",
      "Word: here, Deprel: advmod, Head: happening\n",
      "Word: is, Deprel: cop, Head: trying\n",
      "Word: that, Deprel: mark, Head: trying\n",
      "Word: people, Deprel: nsubj, Head: trying\n",
      "Word: who, Deprel: nsubj, Head: opposed\n",
      "Word: have, Deprel: aux, Head: opposed\n",
      "Word: opposed, Deprel: acl:relcl, Head: people\n",
      "Word: this, Deprel: det, Head: action\n",
      "Word: action, Deprel: obj, Head: opposed\n",
      "Word: throughout, Deprel: case, Head: trying\n",
      "Word: are, Deprel: aux, Head: trying\n",
      "Word: trying, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: find\n",
      "Word: find, Deprel: xcomp, Head: trying\n",
      "Word: fresh, Deprel: amod, Head: reasons\n",
      "Word: reasons, Deprel: obj, Head: find\n",
      "Word: why, Deprel: advmod, Head: thing\n",
      "Word: it, Deprel: nsubj, Head: thing\n",
      "Word: was, Deprel: cop, Head: thing\n",
      "Word: not, Deprel: advmod, Head: thing\n",
      "Word: the, Deprel: det, Head: thing\n",
      "Word: right, Deprel: amod, Head: thing\n",
      "Word: thing, Deprel: acl:relcl, Head: reasons\n",
      "Word: to, Deprel: mark, Head: do\n",
      "Word: do, Deprel: acl, Head: thing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Klarman was arrested by FBI agents in the Hamptons an exclusive summer resort enclave east of New York City'\n",
      "Word: Klarman, Deprel: nsubj:pass, Head: arrested\n",
      "Word: was, Deprel: aux:pass, Head: arrested\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: agents\n",
      "Word: FBI, Deprel: compound, Head: agents\n",
      "Word: agents, Deprel: obl, Head: arrested\n",
      "Word: in, Deprel: case, Head: Hamptons\n",
      "Word: the, Deprel: det, Head: Hamptons\n",
      "Word: Hamptons, Deprel: nmod, Head: agents\n",
      "Word: an, Deprel: det, Head: enclave\n",
      "Word: exclusive, Deprel: amod, Head: enclave\n",
      "Word: summer, Deprel: compound, Head: enclave\n",
      "Word: resort, Deprel: compound, Head: enclave\n",
      "Word: enclave, Deprel: xcomp, Head: arrested\n",
      "Word: east, Deprel: advmod, Head: enclave\n",
      "Word: of, Deprel: case, Head: City\n",
      "Word: New, Deprel: compound, Head: City\n",
      "Word: York, Deprel: compound, Head: City\n",
      "Word: City, Deprel: obl, Head: east\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Klarman was arrested by FBI agents Monday morning at his home in New York'\n",
      "Word: Klarman, Deprel: nsubj:pass, Head: arrested\n",
      "Word: was, Deprel: aux:pass, Head: arrested\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: agents\n",
      "Word: FBI, Deprel: compound, Head: agents\n",
      "Word: agents, Deprel: obl, Head: arrested\n",
      "Word: Monday, Deprel: compound, Head: morning\n",
      "Word: morning, Deprel: obl:tmod, Head: arrested\n",
      "Word: at, Deprel: case, Head: home\n",
      "Word: his, Deprel: nmod:poss, Head: home\n",
      "Word: home, Deprel: obl, Head: arrested\n",
      "Word: in, Deprel: case, Head: York\n",
      "Word: New, Deprel: amod, Head: York\n",
      "Word: York, Deprel: nmod, Head: home\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The bishop told police he thought he had hit a dog or a cat or that someone had thrown a rock at his vehicle'\n",
      "Word: The, Deprel: det, Head: bishop\n",
      "Word: bishop, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: police, Deprel: iobj, Head: told\n",
      "Word: he, Deprel: nsubj, Head: thought\n",
      "Word: thought, Deprel: ccomp, Head: told\n",
      "Word: he, Deprel: nsubj, Head: hit\n",
      "Word: had, Deprel: aux, Head: hit\n",
      "Word: hit, Deprel: ccomp, Head: thought\n",
      "Word: a, Deprel: det, Head: dog\n",
      "Word: dog, Deprel: obj, Head: hit\n",
      "Word: or, Deprel: cc, Head: cat\n",
      "Word: a, Deprel: det, Head: cat\n",
      "Word: cat, Deprel: conj, Head: dog\n",
      "Word: or, Deprel: cc, Head: thrown\n",
      "Word: that, Deprel: mark, Head: thrown\n",
      "Word: someone, Deprel: nsubj, Head: thrown\n",
      "Word: had, Deprel: aux, Head: thrown\n",
      "Word: thrown, Deprel: conj, Head: hit\n",
      "Word: a, Deprel: det, Head: rock\n",
      "Word: rock, Deprel: obj, Head: thrown\n",
      "Word: at, Deprel: case, Head: vehicle\n",
      "Word: his, Deprel: nmod:poss, Head: vehicle\n",
      "Word: vehicle, Deprel: obl, Head: thrown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bishop O'Brien aged 67 had told police he thought he had hit a dog or cat'\n",
      "Word: Bishop, Deprel: nsubj, Head: told\n",
      "Word: O'Brien, Deprel: flat, Head: Bishop\n",
      "Word: aged, Deprel: acl, Head: Bishop\n",
      "Word: 67, Deprel: obj, Head: aged\n",
      "Word: had, Deprel: aux, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: police, Deprel: iobj, Head: told\n",
      "Word: he, Deprel: nsubj, Head: thought\n",
      "Word: thought, Deprel: ccomp, Head: told\n",
      "Word: he, Deprel: nsubj, Head: hit\n",
      "Word: had, Deprel: aux, Head: hit\n",
      "Word: hit, Deprel: ccomp, Head: thought\n",
      "Word: a, Deprel: det, Head: dog\n",
      "Word: dog, Deprel: obj, Head: hit\n",
      "Word: or, Deprel: cc, Head: cat\n",
      "Word: cat, Deprel: conj, Head: dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The report also claims that there will be up to 9.3 million visitors to hot spots this year up again from the meagre 2.5 million in 2002'\n",
      "Word: The, Deprel: det, Head: report\n",
      "Word: report, Deprel: nsubj, Head: claims\n",
      "Word: also, Deprel: advmod, Head: claims\n",
      "Word: claims, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: be\n",
      "Word: there, Deprel: expl, Head: be\n",
      "Word: will, Deprel: aux, Head: be\n",
      "Word: be, Deprel: ccomp, Head: claims\n",
      "Word: up, Deprel: advmod, Head: million\n",
      "Word: to, Deprel: fixed, Head: up\n",
      "Word: 9.3, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: visitors\n",
      "Word: visitors, Deprel: nsubj, Head: be\n",
      "Word: to, Deprel: case, Head: spots\n",
      "Word: hot, Deprel: amod, Head: spots\n",
      "Word: spots, Deprel: obl, Head: be\n",
      "Word: this, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: be\n",
      "Word: up, Deprel: advmod, Head: be\n",
      "Word: again, Deprel: advmod, Head: be\n",
      "Word: from, Deprel: case, Head: million\n",
      "Word: the, Deprel: det, Head: million\n",
      "Word: meagre, Deprel: amod, Head: million\n",
      "Word: 2.5, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obl, Head: be\n",
      "Word: in, Deprel: case, Head: 2002\n",
      "Word: 2002, Deprel: nmod, Head: million\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'There will be 9.3 million visitors to hot spots in 2003 up from 2.5 million in 2002 Gartner said'\n",
      "Word: There, Deprel: expl, Head: be\n",
      "Word: will, Deprel: aux, Head: be\n",
      "Word: be, Deprel: root, Head: ROOT\n",
      "Word: 9.3, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: visitors\n",
      "Word: visitors, Deprel: nsubj, Head: be\n",
      "Word: to, Deprel: case, Head: spots\n",
      "Word: hot, Deprel: amod, Head: spots\n",
      "Word: spots, Deprel: nmod, Head: visitors\n",
      "Word: in, Deprel: case, Head: 2003\n",
      "Word: 2003, Deprel: obl, Head: be\n",
      "Word: up, Deprel: advmod, Head: million\n",
      "Word: from, Deprel: case, Head: million\n",
      "Word: 2.5, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obl, Head: be\n",
      "Word: in, Deprel: case, Head: 2002\n",
      "Word: 2002, Deprel: nmod, Head: million\n",
      "Word: Gartner, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: be\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Richard Miller remained hospitalized after undergoing a liver transplant but his wife has recovered'\n",
      "Word: Richard, Deprel: nsubj, Head: remained\n",
      "Word: Miller, Deprel: flat, Head: Richard\n",
      "Word: remained, Deprel: root, Head: ROOT\n",
      "Word: hospitalized, Deprel: xcomp, Head: remained\n",
      "Word: after, Deprel: mark, Head: undergoing\n",
      "Word: undergoing, Deprel: advcl, Head: hospitalized\n",
      "Word: a, Deprel: det, Head: transplant\n",
      "Word: liver, Deprel: compound, Head: transplant\n",
      "Word: transplant, Deprel: obj, Head: undergoing\n",
      "Word: but, Deprel: cc, Head: recovered\n",
      "Word: his, Deprel: nmod:poss, Head: wife\n",
      "Word: wife, Deprel: nsubj, Head: recovered\n",
      "Word: has, Deprel: aux, Head: recovered\n",
      "Word: recovered, Deprel: conj, Head: remained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Richard Miller 57 survived a lifesaving liver transplant but remains hospitalized'\n",
      "Word: Richard, Deprel: nsubj, Head: survived\n",
      "Word: Miller, Deprel: flat, Head: Richard\n",
      "Word: 57, Deprel: nmod:npmod, Head: Richard\n",
      "Word: survived, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: transplant\n",
      "Word: lifesaving, Deprel: amod, Head: transplant\n",
      "Word: liver, Deprel: compound, Head: transplant\n",
      "Word: transplant, Deprel: obj, Head: survived\n",
      "Word: but, Deprel: cc, Head: remains\n",
      "Word: remains, Deprel: conj, Head: survived\n",
      "Word: hospitalized, Deprel: xcomp, Head: remains\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Sequent representatives could not immediately be reached for comment on the SCO announcement'\n",
      "Word: Sequent, Deprel: amod, Head: representatives\n",
      "Word: representatives, Deprel: nsubj:pass, Head: reached\n",
      "Word: could, Deprel: aux, Head: reached\n",
      "Word: not, Deprel: advmod, Head: reached\n",
      "Word: immediately, Deprel: advmod, Head: reached\n",
      "Word: be, Deprel: aux:pass, Head: reached\n",
      "Word: reached, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: comment\n",
      "Word: comment, Deprel: obl, Head: reached\n",
      "Word: on, Deprel: case, Head: announcement\n",
      "Word: the, Deprel: det, Head: announcement\n",
      "Word: SCO, Deprel: compound, Head: announcement\n",
      "Word: announcement, Deprel: nmod, Head: comment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A spokesman for SCO could not be reached for comment this afternoon'\n",
      "Word: A, Deprel: det, Head: spokesman\n",
      "Word: spokesman, Deprel: nsubj:pass, Head: reached\n",
      "Word: for, Deprel: case, Head: SCO\n",
      "Word: SCO, Deprel: nmod, Head: spokesman\n",
      "Word: could, Deprel: aux, Head: reached\n",
      "Word: not, Deprel: advmod, Head: reached\n",
      "Word: be, Deprel: aux:pass, Head: reached\n",
      "Word: reached, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: comment\n",
      "Word: comment, Deprel: obl, Head: reached\n",
      "Word: this, Deprel: det, Head: afternoon\n",
      "Word: afternoon, Deprel: nmod:tmod, Head: comment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The proportion of people covered by employers dropped from 62.3 percent in 2001 to 61.3 percent last year'\n",
      "Word: The, Deprel: det, Head: proportion\n",
      "Word: proportion, Deprel: nsubj, Head: dropped\n",
      "Word: of, Deprel: case, Head: people\n",
      "Word: people, Deprel: nmod, Head: proportion\n",
      "Word: covered, Deprel: acl, Head: people\n",
      "Word: by, Deprel: case, Head: employers\n",
      "Word: employers, Deprel: obl, Head: covered\n",
      "Word: dropped, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: percent\n",
      "Word: 62.3, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: dropped\n",
      "Word: in, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: dropped\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 61.3, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: dropped\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: nmod:tmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The proportion of Americans with insurance from employers declined to 61.3 percent from 62.6 percent in 2001 and 63.6 percent in 2000'\n",
      "Word: The, Deprel: det, Head: proportion\n",
      "Word: proportion, Deprel: nsubj, Head: declined\n",
      "Word: of, Deprel: case, Head: Americans\n",
      "Word: Americans, Deprel: nmod, Head: proportion\n",
      "Word: with, Deprel: case, Head: insurance\n",
      "Word: insurance, Deprel: nmod, Head: Americans\n",
      "Word: from, Deprel: case, Head: employers\n",
      "Word: employers, Deprel: nmod, Head: insurance\n",
      "Word: declined, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 61.3, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: declined\n",
      "Word: from, Deprel: case, Head: percent\n",
      "Word: 62.6, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: declined\n",
      "Word: in, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: declined\n",
      "Word: and, Deprel: cc, Head: percent\n",
      "Word: 63.6, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: declined\n",
      "Word: in, Deprel: case, Head: 2000\n",
      "Word: 2000, Deprel: nmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'WORLD No 2 Lleyton Hewitt has accused the Association of Tennis Professionals of malice including an alleged attempt last year to dupe him into refusing a drug test'\n",
      "Word: WORLD, Deprel: root, Head: ROOT\n",
      "Word: No, Deprel: det, Head: 2\n",
      "Word: 2, Deprel: nummod, Head: WORLD\n",
      "Word: Lleyton, Deprel: nsubj, Head: accused\n",
      "Word: Hewitt, Deprel: flat, Head: Lleyton\n",
      "Word: has, Deprel: aux, Head: accused\n",
      "Word: accused, Deprel: appos, Head: WORLD\n",
      "Word: the, Deprel: det, Head: Association\n",
      "Word: Association, Deprel: obj, Head: accused\n",
      "Word: of, Deprel: case, Head: Professionals\n",
      "Word: Tennis, Deprel: compound, Head: Professionals\n",
      "Word: Professionals, Deprel: nmod, Head: Association\n",
      "Word: of, Deprel: case, Head: malice\n",
      "Word: malice, Deprel: nmod, Head: Professionals\n",
      "Word: including, Deprel: case, Head: attempt\n",
      "Word: an, Deprel: det, Head: attempt\n",
      "Word: alleged, Deprel: amod, Head: attempt\n",
      "Word: attempt, Deprel: obl, Head: accused\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: nmod:tmod, Head: attempt\n",
      "Word: to, Deprel: mark, Head: dupe\n",
      "Word: dupe, Deprel: acl, Head: attempt\n",
      "Word: him, Deprel: obj, Head: dupe\n",
      "Word: into, Deprel: mark, Head: refusing\n",
      "Word: refusing, Deprel: advcl, Head: dupe\n",
      "Word: a, Deprel: det, Head: test\n",
      "Word: drug, Deprel: compound, Head: test\n",
      "Word: test, Deprel: obj, Head: refusing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'World No.2 Lleyton Hewitt has accused his professional peers of long-standing malice including an attempt last year to dupe him into refusing a drug test'\n",
      "Word: World, Deprel: compound, Head: No.2\n",
      "Word: No.2, Deprel: compound, Head: Lleyton\n",
      "Word: Lleyton, Deprel: nsubj, Head: accused\n",
      "Word: Hewitt, Deprel: flat, Head: Lleyton\n",
      "Word: has, Deprel: aux, Head: accused\n",
      "Word: accused, Deprel: root, Head: ROOT\n",
      "Word: his, Deprel: nmod:poss, Head: peers\n",
      "Word: professional, Deprel: amod, Head: peers\n",
      "Word: peers, Deprel: obj, Head: accused\n",
      "Word: of, Deprel: case, Head: malice\n",
      "Word: long-standing, Deprel: amod, Head: malice\n",
      "Word: malice, Deprel: obl, Head: accused\n",
      "Word: including, Deprel: case, Head: attempt\n",
      "Word: an, Deprel: det, Head: attempt\n",
      "Word: attempt, Deprel: nmod, Head: malice\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: nmod:tmod, Head: attempt\n",
      "Word: to, Deprel: mark, Head: dupe\n",
      "Word: dupe, Deprel: advcl, Head: accused\n",
      "Word: him, Deprel: obj, Head: dupe\n",
      "Word: into, Deprel: mark, Head: refusing\n",
      "Word: refusing, Deprel: advcl, Head: dupe\n",
      "Word: a, Deprel: det, Head: test\n",
      "Word: drug, Deprel: compound, Head: test\n",
      "Word: test, Deprel: obj, Head: refusing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'MSN Messenger 6 will be available for download starting at 6 p.m GMT on Wednesday from http messenger.msn.com/download/v6preview.asp'\n",
      "Word: MSN, Deprel: compound, Head: Messenger\n",
      "Word: Messenger, Deprel: nsubj, Head: available\n",
      "Word: 6, Deprel: nummod, Head: Messenger\n",
      "Word: will, Deprel: aux, Head: available\n",
      "Word: be, Deprel: cop, Head: available\n",
      "Word: available, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: download\n",
      "Word: download, Deprel: obl, Head: available\n",
      "Word: starting, Deprel: acl, Head: download\n",
      "Word: at, Deprel: case, Head: p.m\n",
      "Word: 6, Deprel: nummod, Head: p.m\n",
      "Word: p.m, Deprel: obl, Head: starting\n",
      "Word: GMT, Deprel: nmod:npmod, Head: p.m\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: starting\n",
      "Word: from, Deprel: case, Head: http\n",
      "Word: http, Deprel: nmod, Head: Wednesday\n",
      "Word: messenger.msn.com/download/v6preview.asp, Deprel: parataxis, Head: available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The MSN Messenger 6 software will be available from 11 a.m PST on Wednesday according to Microsoft'\n",
      "Word: The, Deprel: det, Head: software\n",
      "Word: MSN, Deprel: compound, Head: Messenger\n",
      "Word: Messenger, Deprel: compound, Head: software\n",
      "Word: 6, Deprel: nummod, Head: Messenger\n",
      "Word: software, Deprel: nsubj, Head: available\n",
      "Word: will, Deprel: aux, Head: available\n",
      "Word: be, Deprel: cop, Head: available\n",
      "Word: available, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: a.m\n",
      "Word: 11, Deprel: nummod, Head: a.m\n",
      "Word: a.m, Deprel: obl, Head: available\n",
      "Word: PST, Deprel: nmod:npmod, Head: a.m\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: available\n",
      "Word: according, Deprel: case, Head: Microsoft\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: Microsoft, Deprel: obl, Head: available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Families stuck on the highway remained in their cars and used their cell phones to call home'\n",
      "Word: Families, Deprel: nsubj, Head: remained\n",
      "Word: stuck, Deprel: acl, Head: Families\n",
      "Word: on, Deprel: case, Head: highway\n",
      "Word: the, Deprel: det, Head: highway\n",
      "Word: highway, Deprel: obl, Head: stuck\n",
      "Word: remained, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: cars\n",
      "Word: their, Deprel: nmod:poss, Head: cars\n",
      "Word: cars, Deprel: obl, Head: remained\n",
      "Word: and, Deprel: cc, Head: used\n",
      "Word: used, Deprel: conj, Head: remained\n",
      "Word: their, Deprel: nmod:poss, Head: phones\n",
      "Word: cell, Deprel: compound, Head: phones\n",
      "Word: phones, Deprel: obj, Head: used\n",
      "Word: to, Deprel: mark, Head: call\n",
      "Word: call, Deprel: advcl, Head: used\n",
      "Word: home, Deprel: advmod, Head: call\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Families stuck on the highway were being urged to remain in their cars and to use their cell phones only in case of emergency'\n",
      "Word: Families, Deprel: nsubj:pass, Head: urged\n",
      "Word: stuck, Deprel: acl, Head: Families\n",
      "Word: on, Deprel: case, Head: highway\n",
      "Word: the, Deprel: det, Head: highway\n",
      "Word: highway, Deprel: obl, Head: stuck\n",
      "Word: were, Deprel: aux, Head: urged\n",
      "Word: being, Deprel: aux:pass, Head: urged\n",
      "Word: urged, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: remain\n",
      "Word: remain, Deprel: xcomp, Head: urged\n",
      "Word: in, Deprel: case, Head: cars\n",
      "Word: their, Deprel: nmod:poss, Head: cars\n",
      "Word: cars, Deprel: obl, Head: remain\n",
      "Word: and, Deprel: cc, Head: use\n",
      "Word: to, Deprel: mark, Head: use\n",
      "Word: use, Deprel: conj, Head: remain\n",
      "Word: their, Deprel: nmod:poss, Head: phones\n",
      "Word: cell, Deprel: compound, Head: phones\n",
      "Word: phones, Deprel: obj, Head: use\n",
      "Word: only, Deprel: advmod, Head: emergency\n",
      "Word: in, Deprel: case, Head: emergency\n",
      "Word: case, Deprel: fixed, Head: in\n",
      "Word: of, Deprel: fixed, Head: in\n",
      "Word: emergency, Deprel: obl, Head: use\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In connection with the incident I have acknowledged that I behaved inappropriately'\n",
      "Word: In, Deprel: case, Head: connection\n",
      "Word: connection, Deprel: obl, Head: acknowledged\n",
      "Word: with, Deprel: case, Head: incident\n",
      "Word: the, Deprel: det, Head: incident\n",
      "Word: incident, Deprel: nmod, Head: connection\n",
      "Word: I, Deprel: nsubj, Head: acknowledged\n",
      "Word: have, Deprel: aux, Head: acknowledged\n",
      "Word: acknowledged, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: behaved\n",
      "Word: I, Deprel: nsubj, Head: behaved\n",
      "Word: behaved, Deprel: ccomp, Head: acknowledged\n",
      "Word: inappropriately, Deprel: advmod, Head: behaved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I have acknowledged that I behaved inappropriately he said'\n",
      "Word: I, Deprel: nsubj, Head: acknowledged\n",
      "Word: have, Deprel: aux, Head: acknowledged\n",
      "Word: acknowledged, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: behaved\n",
      "Word: I, Deprel: nsubj, Head: behaved\n",
      "Word: behaved, Deprel: ccomp, Head: acknowledged\n",
      "Word: inappropriately, Deprel: advmod, Head: behaved\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: acknowledged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A promotional poster complete with countdown dial reminds readers of the upcoming release of Harry Potter and the Order of the Phoenix'\n",
      "Word: A, Deprel: det, Head: poster\n",
      "Word: promotional, Deprel: amod, Head: poster\n",
      "Word: poster, Deprel: nsubj, Head: reminds\n",
      "Word: complete, Deprel: amod, Head: poster\n",
      "Word: with, Deprel: case, Head: dial\n",
      "Word: countdown, Deprel: compound, Head: dial\n",
      "Word: dial, Deprel: obl, Head: complete\n",
      "Word: reminds, Deprel: root, Head: ROOT\n",
      "Word: readers, Deprel: iobj, Head: reminds\n",
      "Word: of, Deprel: case, Head: release\n",
      "Word: the, Deprel: det, Head: release\n",
      "Word: upcoming, Deprel: amod, Head: release\n",
      "Word: release, Deprel: nmod, Head: readers\n",
      "Word: of, Deprel: case, Head: Harry\n",
      "Word: Harry, Deprel: nmod, Head: release\n",
      "Word: Potter, Deprel: flat, Head: Harry\n",
      "Word: and, Deprel: cc, Head: Order\n",
      "Word: the, Deprel: det, Head: Order\n",
      "Word: Order, Deprel: conj, Head: Harry\n",
      "Word: of, Deprel: case, Head: Phoenix\n",
      "Word: the, Deprel: det, Head: Phoenix\n",
      "Word: Phoenix, Deprel: nmod, Head: Order\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The crates are full of hardback copies of Harry Potter and the Order of the Phoenix'\n",
      "Word: The, Deprel: det, Head: crates\n",
      "Word: crates, Deprel: nsubj, Head: full\n",
      "Word: are, Deprel: cop, Head: full\n",
      "Word: full, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: copies\n",
      "Word: hardback, Deprel: compound, Head: copies\n",
      "Word: copies, Deprel: obl, Head: full\n",
      "Word: of, Deprel: case, Head: Harry\n",
      "Word: Harry, Deprel: nmod, Head: copies\n",
      "Word: Potter, Deprel: flat, Head: Harry\n",
      "Word: and, Deprel: cc, Head: Order\n",
      "Word: the, Deprel: det, Head: Order\n",
      "Word: Order, Deprel: conj, Head: Harry\n",
      "Word: of, Deprel: case, Head: Phoenix\n",
      "Word: the, Deprel: det, Head: Phoenix\n",
      "Word: Phoenix, Deprel: nmod, Head: Order\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A spokesman said Since November we have co-operated fully with the police'\n",
      "Word: A, Deprel: det, Head: spokesman\n",
      "Word: spokesman, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Since, Deprel: case, Head: November\n",
      "Word: November, Deprel: obl, Head: co-operated\n",
      "Word: we, Deprel: nsubj, Head: co-operated\n",
      "Word: have, Deprel: aux, Head: co-operated\n",
      "Word: co-operated, Deprel: ccomp, Head: said\n",
      "Word: fully, Deprel: advmod, Head: co-operated\n",
      "Word: with, Deprel: case, Head: police\n",
      "Word: the, Deprel: det, Head: police\n",
      "Word: police, Deprel: obl, Head: co-operated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It added it had co-operated fully with police since November'\n",
      "Word: It, Deprel: nsubj, Head: added\n",
      "Word: added, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: co-operated\n",
      "Word: had, Deprel: aux, Head: co-operated\n",
      "Word: co-operated, Deprel: ccomp, Head: added\n",
      "Word: fully, Deprel: advmod, Head: co-operated\n",
      "Word: with, Deprel: case, Head: police\n",
      "Word: police, Deprel: obl, Head: co-operated\n",
      "Word: since, Deprel: case, Head: November\n",
      "Word: November, Deprel: obl, Head: co-operated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Women who eat potatoes and other tuberous vegetables during pregnancy may be at risk of triggering type 1 diabetes in their children Melbourne researchers believe'\n",
      "Word: Women, Deprel: nsubj, Head: risk\n",
      "Word: who, Deprel: nsubj, Head: eat\n",
      "Word: eat, Deprel: acl:relcl, Head: Women\n",
      "Word: potatoes, Deprel: obj, Head: eat\n",
      "Word: and, Deprel: cc, Head: vegetables\n",
      "Word: other, Deprel: amod, Head: vegetables\n",
      "Word: tuberous, Deprel: amod, Head: vegetables\n",
      "Word: vegetables, Deprel: conj, Head: potatoes\n",
      "Word: during, Deprel: case, Head: pregnancy\n",
      "Word: pregnancy, Deprel: obl, Head: eat\n",
      "Word: may, Deprel: aux, Head: risk\n",
      "Word: be, Deprel: cop, Head: risk\n",
      "Word: at, Deprel: case, Head: risk\n",
      "Word: risk, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: mark, Head: triggering\n",
      "Word: triggering, Deprel: acl, Head: risk\n",
      "Word: type, Deprel: compound, Head: diabetes\n",
      "Word: 1, Deprel: nummod, Head: type\n",
      "Word: diabetes, Deprel: obj, Head: triggering\n",
      "Word: in, Deprel: case, Head: children\n",
      "Word: their, Deprel: nmod:poss, Head: children\n",
      "Word: children, Deprel: nmod, Head: diabetes\n",
      "Word: Melbourne, Deprel: compound, Head: researchers\n",
      "Word: researchers, Deprel: nsubj, Head: believe\n",
      "Word: believe, Deprel: acl:relcl, Head: children\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Australian researchers believe they have found a trigger of type 1 diabetes in children their mothers eating potatoes and other tuberous vegetables during pregnancy'\n",
      "Word: Australian, Deprel: amod, Head: researchers\n",
      "Word: researchers, Deprel: nsubj, Head: believe\n",
      "Word: believe, Deprel: root, Head: ROOT\n",
      "Word: they, Deprel: nsubj, Head: found\n",
      "Word: have, Deprel: aux, Head: found\n",
      "Word: found, Deprel: ccomp, Head: believe\n",
      "Word: a, Deprel: det, Head: trigger\n",
      "Word: trigger, Deprel: obj, Head: found\n",
      "Word: of, Deprel: case, Head: diabetes\n",
      "Word: type, Deprel: compound, Head: diabetes\n",
      "Word: 1, Deprel: nummod, Head: type\n",
      "Word: diabetes, Deprel: nmod, Head: trigger\n",
      "Word: in, Deprel: case, Head: children\n",
      "Word: children, Deprel: nmod, Head: diabetes\n",
      "Word: their, Deprel: nmod:poss, Head: mothers\n",
      "Word: mothers, Deprel: nsubj, Head: eating\n",
      "Word: eating, Deprel: acl, Head: diabetes\n",
      "Word: potatoes, Deprel: obj, Head: eating\n",
      "Word: and, Deprel: cc, Head: vegetables\n",
      "Word: other, Deprel: amod, Head: vegetables\n",
      "Word: tuberous, Deprel: amod, Head: vegetables\n",
      "Word: vegetables, Deprel: conj, Head: potatoes\n",
      "Word: during, Deprel: case, Head: pregnancy\n",
      "Word: pregnancy, Deprel: obl, Head: eating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broad Standard Poor s 500 Index SPX inched up 3 points or 0.32 percent to 970'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broad, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: s\n",
      "Word: Poor, Deprel: amod, Head: s\n",
      "Word: s, Deprel: compound, Head: SPX\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: inched\n",
      "Word: inched, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: advmod, Head: inched\n",
      "Word: 3, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:tmod, Head: inched\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.32, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 970\n",
      "Word: 970, Deprel: obl, Head: inched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index IXIC lost 2 points or 0.18 percent to 1,649'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-laced, Deprel: amod, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: lost\n",
      "Word: lost, Deprel: root, Head: ROOT\n",
      "Word: 2, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: lost\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.18, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,649\n",
      "Word: 1,649, Deprel: obl, Head: lost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'People who once thought their blood pressure was fine actually may be well on their way to hypertension under new U.S guidelines published on Wednesday'\n",
      "Word: People, Deprel: nsubj, Head: well\n",
      "Word: who, Deprel: nsubj, Head: thought\n",
      "Word: once, Deprel: advmod, Head: thought\n",
      "Word: thought, Deprel: acl:relcl, Head: People\n",
      "Word: their, Deprel: nmod:poss, Head: pressure\n",
      "Word: blood, Deprel: compound, Head: pressure\n",
      "Word: pressure, Deprel: nsubj, Head: fine\n",
      "Word: was, Deprel: cop, Head: fine\n",
      "Word: fine, Deprel: ccomp, Head: thought\n",
      "Word: actually, Deprel: advmod, Head: fine\n",
      "Word: may, Deprel: aux, Head: well\n",
      "Word: be, Deprel: cop, Head: well\n",
      "Word: well, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: way\n",
      "Word: their, Deprel: nmod:poss, Head: way\n",
      "Word: way, Deprel: obl, Head: well\n",
      "Word: to, Deprel: case, Head: hypertension\n",
      "Word: hypertension, Deprel: obl, Head: well\n",
      "Word: under, Deprel: case, Head: guidelines\n",
      "Word: new, Deprel: amod, Head: guidelines\n",
      "Word: U.S, Deprel: compound, Head: guidelines\n",
      "Word: guidelines, Deprel: obl, Head: well\n",
      "Word: published, Deprel: acl, Head: guidelines\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: published\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'People who once thought their blood pressure was fine actually need to start exercising and eating better according to new U.S guidelines published on Wednesday'\n",
      "Word: People, Deprel: nsubj, Head: need\n",
      "Word: who, Deprel: nsubj, Head: thought\n",
      "Word: once, Deprel: advmod, Head: thought\n",
      "Word: thought, Deprel: acl:relcl, Head: People\n",
      "Word: their, Deprel: nmod:poss, Head: pressure\n",
      "Word: blood, Deprel: compound, Head: pressure\n",
      "Word: pressure, Deprel: nsubj, Head: fine\n",
      "Word: was, Deprel: cop, Head: fine\n",
      "Word: fine, Deprel: ccomp, Head: thought\n",
      "Word: actually, Deprel: advmod, Head: need\n",
      "Word: need, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: start\n",
      "Word: start, Deprel: xcomp, Head: need\n",
      "Word: exercising, Deprel: xcomp, Head: start\n",
      "Word: and, Deprel: cc, Head: eating\n",
      "Word: eating, Deprel: conj, Head: exercising\n",
      "Word: better, Deprel: advmod, Head: eating\n",
      "Word: according, Deprel: case, Head: guidelines\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: new, Deprel: amod, Head: guidelines\n",
      "Word: U.S, Deprel: compound, Head: guidelines\n",
      "Word: guidelines, Deprel: obl, Head: exercising\n",
      "Word: published, Deprel: acl, Head: guidelines\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: published\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Further testing is still under way but at this stage given the early detection the outlook in such instances would be positive the specialist said yesterday'\n",
      "Word: Further, Deprel: amod, Head: testing\n",
      "Word: testing, Deprel: nsubj, Head: way\n",
      "Word: is, Deprel: cop, Head: way\n",
      "Word: still, Deprel: advmod, Head: way\n",
      "Word: under, Deprel: case, Head: way\n",
      "Word: way, Deprel: root, Head: ROOT\n",
      "Word: but, Deprel: cc, Head: positive\n",
      "Word: at, Deprel: case, Head: stage\n",
      "Word: this, Deprel: det, Head: stage\n",
      "Word: stage, Deprel: obl, Head: positive\n",
      "Word: given, Deprel: acl, Head: stage\n",
      "Word: the, Deprel: det, Head: detection\n",
      "Word: early, Deprel: amod, Head: detection\n",
      "Word: detection, Deprel: obj, Head: given\n",
      "Word: the, Deprel: det, Head: outlook\n",
      "Word: outlook, Deprel: nsubj, Head: positive\n",
      "Word: in, Deprel: case, Head: instances\n",
      "Word: such, Deprel: amod, Head: instances\n",
      "Word: instances, Deprel: nmod, Head: outlook\n",
      "Word: would, Deprel: aux, Head: positive\n",
      "Word: be, Deprel: cop, Head: positive\n",
      "Word: positive, Deprel: conj, Head: way\n",
      "Word: the, Deprel: det, Head: specialist\n",
      "Word: specialist, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: ccomp, Head: positive\n",
      "Word: yesterday, Deprel: obl:tmod, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But at this stage given the early detection the outlook in such instances would be positive he said'\n",
      "Word: But, Deprel: cc, Head: positive\n",
      "Word: at, Deprel: case, Head: stage\n",
      "Word: this, Deprel: det, Head: stage\n",
      "Word: stage, Deprel: obl, Head: positive\n",
      "Word: given, Deprel: acl, Head: stage\n",
      "Word: the, Deprel: det, Head: detection\n",
      "Word: early, Deprel: amod, Head: detection\n",
      "Word: detection, Deprel: obj, Head: given\n",
      "Word: the, Deprel: det, Head: outlook\n",
      "Word: outlook, Deprel: nsubj, Head: positive\n",
      "Word: in, Deprel: case, Head: instances\n",
      "Word: such, Deprel: amod, Head: instances\n",
      "Word: instances, Deprel: nmod, Head: outlook\n",
      "Word: would, Deprel: aux, Head: positive\n",
      "Word: be, Deprel: cop, Head: positive\n",
      "Word: positive, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: ccomp, Head: positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Amazon also reported that the New York Attorney General s office had settled civil fraud charges with one of the spoofers it identified'\n",
      "Word: Amazon, Deprel: nsubj, Head: reported\n",
      "Word: also, Deprel: advmod, Head: reported\n",
      "Word: reported, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: settled\n",
      "Word: the, Deprel: det, Head: General\n",
      "Word: New, Deprel: compound, Head: Attorney\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Attorney, Deprel: compound, Head: General\n",
      "Word: General, Deprel: nmod:poss, Head: office\n",
      "Word: s, Deprel: case, Head: General\n",
      "Word: office, Deprel: nsubj, Head: settled\n",
      "Word: had, Deprel: aux, Head: settled\n",
      "Word: settled, Deprel: ccomp, Head: reported\n",
      "Word: civil, Deprel: amod, Head: fraud\n",
      "Word: fraud, Deprel: compound, Head: charges\n",
      "Word: charges, Deprel: obj, Head: settled\n",
      "Word: with, Deprel: case, Head: one\n",
      "Word: one, Deprel: obl, Head: settled\n",
      "Word: of, Deprel: case, Head: spoofers\n",
      "Word: the, Deprel: det, Head: spoofers\n",
      "Word: spoofers, Deprel: nmod, Head: one\n",
      "Word: it, Deprel: nsubj, Head: identified\n",
      "Word: identified, Deprel: acl:relcl, Head: spoofers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Amazon and the New York attorney general s office have already settled with one of the alleged e-mail forgers'\n",
      "Word: Amazon, Deprel: nsubj, Head: settled\n",
      "Word: and, Deprel: cc, Head: office\n",
      "Word: the, Deprel: det, Head: office\n",
      "Word: New, Deprel: compound, Head: attorney\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: attorney, Deprel: compound, Head: general\n",
      "Word: general, Deprel: nmod:poss, Head: office\n",
      "Word: s, Deprel: case, Head: general\n",
      "Word: office, Deprel: conj, Head: Amazon\n",
      "Word: have, Deprel: aux, Head: settled\n",
      "Word: already, Deprel: advmod, Head: settled\n",
      "Word: settled, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: one\n",
      "Word: one, Deprel: obl, Head: settled\n",
      "Word: of, Deprel: case, Head: forgers\n",
      "Word: the, Deprel: det, Head: forgers\n",
      "Word: alleged, Deprel: amod, Head: forgers\n",
      "Word: e-mail, Deprel: compound, Head: forgers\n",
      "Word: forgers, Deprel: nmod, Head: one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The leading actress nod went to energetic newcomer Marissa Jaret Winokur as Edna s daughter Tracy'\n",
      "Word: The, Deprel: det, Head: actress\n",
      "Word: leading, Deprel: amod, Head: actress\n",
      "Word: actress, Deprel: compound, Head: nod\n",
      "Word: nod, Deprel: nsubj, Head: went\n",
      "Word: went, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: newcomer\n",
      "Word: energetic, Deprel: amod, Head: newcomer\n",
      "Word: newcomer, Deprel: obl, Head: went\n",
      "Word: Marissa, Deprel: appos, Head: newcomer\n",
      "Word: Jaret, Deprel: flat, Head: newcomer\n",
      "Word: Winokur, Deprel: flat, Head: newcomer\n",
      "Word: as, Deprel: case, Head: daughter\n",
      "Word: Edna, Deprel: nmod:poss, Head: daughter\n",
      "Word: s, Deprel: case, Head: Edna\n",
      "Word: daughter, Deprel: obl, Head: went\n",
      "Word: Tracy, Deprel: appos, Head: daughter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Marissa Jaret Winokur as Tracy won for best actress in a musical'\n",
      "Word: Marissa, Deprel: root, Head: ROOT\n",
      "Word: Jaret, Deprel: flat, Head: Marissa\n",
      "Word: Winokur, Deprel: flat, Head: Marissa\n",
      "Word: as, Deprel: mark, Head: won\n",
      "Word: Tracy, Deprel: nsubj, Head: won\n",
      "Word: won, Deprel: advcl, Head: Marissa\n",
      "Word: for, Deprel: case, Head: actress\n",
      "Word: best, Deprel: amod, Head: actress\n",
      "Word: actress, Deprel: obl, Head: won\n",
      "Word: in, Deprel: case, Head: musical\n",
      "Word: a, Deprel: det, Head: musical\n",
      "Word: musical, Deprel: obl, Head: won\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In morning trading the Dow Jones industrial average was up 40.12 or 0.5 percent at 8,571.69 having fallen 51 points Monday'\n",
      "Word: In, Deprel: case, Head: trading\n",
      "Word: morning, Deprel: compound, Head: trading\n",
      "Word: trading, Deprel: obl, Head: up\n",
      "Word: the, Deprel: det, Head: average\n",
      "Word: Dow, Deprel: compound, Head: Jones\n",
      "Word: Jones, Deprel: compound, Head: average\n",
      "Word: industrial, Deprel: compound, Head: average\n",
      "Word: average, Deprel: nsubj, Head: up\n",
      "Word: was, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: 40.12, Deprel: obl:npmod, Head: up\n",
      "Word: or, Deprel: cc, Head: 0.5\n",
      "Word: 0.5, Deprel: conj, Head: 40.12\n",
      "Word: percent, Deprel: conj, Head: up\n",
      "Word: at, Deprel: case, Head: 8,571.69\n",
      "Word: 8,571.69, Deprel: nmod, Head: percent\n",
      "Word: having, Deprel: aux, Head: fallen\n",
      "Word: fallen, Deprel: advcl, Head: up\n",
      "Word: 51, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: fallen\n",
      "Word: Monday, Deprel: obl:tmod, Head: fallen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In New York the Dow Jones industrial average a gauge of 30 blue chip stocks was up 3.29 points or 0.04 per cent to 8,585.97'\n",
      "Word: In, Deprel: case, Head: York\n",
      "Word: New, Deprel: amod, Head: York\n",
      "Word: York, Deprel: obl, Head: up\n",
      "Word: the, Deprel: det, Head: average\n",
      "Word: Dow, Deprel: compound, Head: average\n",
      "Word: Jones, Deprel: flat, Head: Dow\n",
      "Word: industrial, Deprel: amod, Head: average\n",
      "Word: average, Deprel: nsubj, Head: up\n",
      "Word: a, Deprel: det, Head: gauge\n",
      "Word: gauge, Deprel: appos, Head: average\n",
      "Word: of, Deprel: case, Head: stocks\n",
      "Word: 30, Deprel: nummod, Head: stocks\n",
      "Word: blue, Deprel: amod, Head: stocks\n",
      "Word: chip, Deprel: compound, Head: stocks\n",
      "Word: stocks, Deprel: nmod, Head: gauge\n",
      "Word: was, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: 3.29, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: up\n",
      "Word: or, Deprel: cc, Head: cent\n",
      "Word: 0.04, Deprel: nummod, Head: cent\n",
      "Word: per, Deprel: compound, Head: cent\n",
      "Word: cent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 8,585.97\n",
      "Word: 8,585.97, Deprel: obl, Head: up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'For the entire season the average five-day forecast track error was 259 miles Franklin said'\n",
      "Word: For, Deprel: case, Head: season\n",
      "Word: the, Deprel: det, Head: season\n",
      "Word: entire, Deprel: amod, Head: season\n",
      "Word: season, Deprel: obl, Head: miles\n",
      "Word: the, Deprel: det, Head: error\n",
      "Word: average, Deprel: amod, Head: error\n",
      "Word: five-day, Deprel: amod, Head: track\n",
      "Word: forecast, Deprel: compound, Head: track\n",
      "Word: track, Deprel: compound, Head: error\n",
      "Word: error, Deprel: nsubj, Head: miles\n",
      "Word: was, Deprel: cop, Head: miles\n",
      "Word: 259, Deprel: nummod, Head: miles\n",
      "Word: miles, Deprel: root, Head: ROOT\n",
      "Word: Franklin, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: miles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The average track error for the five-day forecast is 323 nautical miles'\n",
      "Word: The, Deprel: det, Head: error\n",
      "Word: average, Deprel: amod, Head: error\n",
      "Word: track, Deprel: compound, Head: error\n",
      "Word: error, Deprel: nsubj, Head: miles\n",
      "Word: for, Deprel: case, Head: forecast\n",
      "Word: the, Deprel: det, Head: forecast\n",
      "Word: five-day, Deprel: amod, Head: forecast\n",
      "Word: forecast, Deprel: nmod, Head: error\n",
      "Word: is, Deprel: cop, Head: miles\n",
      "Word: 323, Deprel: nummod, Head: miles\n",
      "Word: nautical, Deprel: amod, Head: miles\n",
      "Word: miles, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Rich media doubled its share increasing from 3 in Q2 2002 to 6 in Q2 2003'\n",
      "Word: Rich, Deprel: amod, Head: media\n",
      "Word: media, Deprel: nsubj, Head: doubled\n",
      "Word: doubled, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: share\n",
      "Word: share, Deprel: obj, Head: doubled\n",
      "Word: increasing, Deprel: advcl, Head: doubled\n",
      "Word: from, Deprel: case, Head: 3\n",
      "Word: 3, Deprel: obl, Head: increasing\n",
      "Word: in, Deprel: case, Head: Q2\n",
      "Word: Q2, Deprel: nmod, Head: 3\n",
      "Word: 2002, Deprel: nummod, Head: Q2\n",
      "Word: to, Deprel: case, Head: 6\n",
      "Word: 6, Deprel: obl, Head: increasing\n",
      "Word: in, Deprel: case, Head: Q2\n",
      "Word: Q2, Deprel: obl, Head: increasing\n",
      "Word: 2003, Deprel: nummod, Head: Q2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Rich Media interactive ad formats doubled their share from 3 in second quarter of 2002 to 6 in the second quarter of 2003'\n",
      "Word: Rich, Deprel: amod, Head: Media\n",
      "Word: Media, Deprel: compound, Head: formats\n",
      "Word: interactive, Deprel: amod, Head: formats\n",
      "Word: ad, Deprel: compound, Head: formats\n",
      "Word: formats, Deprel: nsubj, Head: doubled\n",
      "Word: doubled, Deprel: root, Head: ROOT\n",
      "Word: their, Deprel: nmod:poss, Head: share\n",
      "Word: share, Deprel: obj, Head: doubled\n",
      "Word: from, Deprel: case, Head: 3\n",
      "Word: 3, Deprel: obl, Head: doubled\n",
      "Word: in, Deprel: case, Head: quarter\n",
      "Word: second, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: nmod, Head: 3\n",
      "Word: of, Deprel: case, Head: 2002\n",
      "Word: 2002, Deprel: nmod, Head: quarter\n",
      "Word: to, Deprel: case, Head: 6\n",
      "Word: 6, Deprel: obl, Head: doubled\n",
      "Word: in, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: second, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: doubled\n",
      "Word: of, Deprel: case, Head: 2003\n",
      "Word: 2003, Deprel: nmod, Head: quarter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It appears from our initial report that this was a textbook landing considering the circumstances Burke said'\n",
      "Word: It, Deprel: expl, Head: appears\n",
      "Word: appears, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: report\n",
      "Word: our, Deprel: nmod:poss, Head: report\n",
      "Word: initial, Deprel: amod, Head: report\n",
      "Word: report, Deprel: obl, Head: appears\n",
      "Word: that, Deprel: mark, Head: landing\n",
      "Word: this, Deprel: nsubj, Head: landing\n",
      "Word: was, Deprel: cop, Head: landing\n",
      "Word: a, Deprel: det, Head: landing\n",
      "Word: textbook, Deprel: compound, Head: landing\n",
      "Word: landing, Deprel: csubj, Head: appears\n",
      "Word: considering, Deprel: acl, Head: landing\n",
      "Word: the, Deprel: det, Head: circumstances\n",
      "Word: circumstances, Deprel: obj, Head: considering\n",
      "Word: Burke, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: circumstances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Said Mr Burke It was a textbook landing considering the circumstances'\n",
      "Word: Said, Deprel: root, Head: ROOT\n",
      "Word: Mr, Deprel: obj, Head: Said\n",
      "Word: Burke, Deprel: flat, Head: Mr\n",
      "Word: It, Deprel: nsubj, Head: landing\n",
      "Word: was, Deprel: cop, Head: landing\n",
      "Word: a, Deprel: det, Head: landing\n",
      "Word: textbook, Deprel: compound, Head: landing\n",
      "Word: landing, Deprel: parataxis, Head: Said\n",
      "Word: considering, Deprel: acl, Head: landing\n",
      "Word: the, Deprel: det, Head: circumstances\n",
      "Word: circumstances, Deprel: obj, Head: considering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Allegiant shares rose 4 or 17.2 percent to 27.43 in Thursday morning trading on the Nasdaq Stock Market'\n",
      "Word: Allegiant, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 4, Deprel: nummod, Head: percent\n",
      "Word: or, Deprel: cc, Head: 17.2\n",
      "Word: 17.2, Deprel: conj, Head: 4\n",
      "Word: percent, Deprel: obl:tmod, Head: rose\n",
      "Word: to, Deprel: case, Head: 27.43\n",
      "Word: 27.43, Deprel: obl, Head: rose\n",
      "Word: in, Deprel: case, Head: morning\n",
      "Word: Thursday, Deprel: compound, Head: morning\n",
      "Word: morning, Deprel: obl, Head: rose\n",
      "Word: trading, Deprel: nmod:npmod, Head: morning\n",
      "Word: on, Deprel: case, Head: Market\n",
      "Word: the, Deprel: det, Head: Market\n",
      "Word: Nasdaq, Deprel: compound, Head: Market\n",
      "Word: Stock, Deprel: compound, Head: Market\n",
      "Word: Market, Deprel: obl, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Allegiant s stock closed Wednesday at 23.40 up 64 cents in trading on the Nasdaq market'\n",
      "Word: Allegiant, Deprel: nmod:poss, Head: stock\n",
      "Word: s, Deprel: case, Head: Allegiant\n",
      "Word: stock, Deprel: nsubj, Head: closed\n",
      "Word: closed, Deprel: root, Head: ROOT\n",
      "Word: Wednesday, Deprel: obl:tmod, Head: closed\n",
      "Word: at, Deprel: case, Head: 23.40\n",
      "Word: 23.40, Deprel: obl, Head: closed\n",
      "Word: up, Deprel: advmod, Head: closed\n",
      "Word: 64, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:npmod, Head: up\n",
      "Word: in, Deprel: case, Head: trading\n",
      "Word: trading, Deprel: obl, Head: up\n",
      "Word: on, Deprel: case, Head: market\n",
      "Word: the, Deprel: det, Head: market\n",
      "Word: Nasdaq, Deprel: compound, Head: market\n",
      "Word: market, Deprel: obl, Head: closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'By state law 911 calls are not public information and were not released'\n",
      "Word: By, Deprel: case, Head: calls\n",
      "Word: state, Deprel: compound, Head: law\n",
      "Word: law, Deprel: compound, Head: calls\n",
      "Word: 911, Deprel: compound, Head: calls\n",
      "Word: calls, Deprel: nsubj, Head: information\n",
      "Word: are, Deprel: cop, Head: information\n",
      "Word: not, Deprel: advmod, Head: information\n",
      "Word: public, Deprel: amod, Head: information\n",
      "Word: information, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: released\n",
      "Word: were, Deprel: aux:pass, Head: released\n",
      "Word: not, Deprel: advmod, Head: released\n",
      "Word: released, Deprel: conj, Head: information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'By law 911 calls are not public information in Rhode Island'\n",
      "Word: By, Deprel: case, Head: calls\n",
      "Word: law, Deprel: compound, Head: 911\n",
      "Word: 911, Deprel: compound, Head: calls\n",
      "Word: calls, Deprel: nsubj, Head: information\n",
      "Word: are, Deprel: cop, Head: information\n",
      "Word: not, Deprel: advmod, Head: information\n",
      "Word: public, Deprel: amod, Head: information\n",
      "Word: information, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: Island\n",
      "Word: Rhode, Deprel: compound, Head: Island\n",
      "Word: Island, Deprel: nmod, Head: information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The ADRs fell 10 cents to 28.95 at 10:06 a.m in New York Stock Exchange composite trading today'\n",
      "Word: The, Deprel: det, Head: ADRs\n",
      "Word: ADRs, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 10, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: fell\n",
      "Word: to, Deprel: case, Head: 28.95\n",
      "Word: 28.95, Deprel: obl, Head: fell\n",
      "Word: at, Deprel: case, Head: a.m\n",
      "Word: 10:06, Deprel: nummod, Head: a.m\n",
      "Word: a.m, Deprel: obl, Head: fell\n",
      "Word: in, Deprel: case, Head: trading\n",
      "Word: New, Deprel: amod, Head: York\n",
      "Word: York, Deprel: compound, Head: Exchange\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: compound, Head: composite\n",
      "Word: composite, Deprel: compound, Head: trading\n",
      "Word: trading, Deprel: obl, Head: fell\n",
      "Word: today, Deprel: obl:tmod, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of Fox Entertainment Group Inc News Corp s U.S media and entertainment arm fell 45 cents to 26.85 in New York Stock Exchange composite trading'\n",
      "Word: Shares, Deprel: nsubj, Head: fell\n",
      "Word: of, Deprel: case, Head: arm\n",
      "Word: Fox, Deprel: compound, Head: Group\n",
      "Word: Entertainment, Deprel: compound, Head: Group\n",
      "Word: Group, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: compound, Head: Corp\n",
      "Word: News, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: nmod:poss, Head: arm\n",
      "Word: s, Deprel: case, Head: Corp\n",
      "Word: U.S, Deprel: compound, Head: arm\n",
      "Word: media, Deprel: compound, Head: arm\n",
      "Word: and, Deprel: cc, Head: entertainment\n",
      "Word: entertainment, Deprel: conj, Head: media\n",
      "Word: arm, Deprel: nmod, Head: Shares\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 45, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obj, Head: fell\n",
      "Word: to, Deprel: case, Head: 26.85\n",
      "Word: 26.85, Deprel: obl, Head: fell\n",
      "Word: in, Deprel: case, Head: trading\n",
      "Word: New, Deprel: amod, Head: York\n",
      "Word: York, Deprel: compound, Head: Exchange\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: compound, Head: trading\n",
      "Word: composite, Deprel: compound, Head: trading\n",
      "Word: trading, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It will take time to oust die-hard remnants of Saddam Hussein s deposed regime in Iraq Defense Secretary Donald H Rumsfeld said Tuesday'\n",
      "Word: It, Deprel: expl, Head: take\n",
      "Word: will, Deprel: aux, Head: take\n",
      "Word: take, Deprel: root, Head: ROOT\n",
      "Word: time, Deprel: obj, Head: take\n",
      "Word: to, Deprel: mark, Head: oust\n",
      "Word: oust, Deprel: acl, Head: time\n",
      "Word: die-hard, Deprel: amod, Head: remnants\n",
      "Word: remnants, Deprel: obj, Head: oust\n",
      "Word: of, Deprel: case, Head: regime\n",
      "Word: Saddam, Deprel: nmod:poss, Head: regime\n",
      "Word: Hussein, Deprel: flat, Head: Saddam\n",
      "Word: s, Deprel: case, Head: Saddam\n",
      "Word: deposed, Deprel: amod, Head: regime\n",
      "Word: regime, Deprel: nmod, Head: remnants\n",
      "Word: in, Deprel: case, Head: Secretary\n",
      "Word: Iraq, Deprel: compound, Head: Secretary\n",
      "Word: Defense, Deprel: compound, Head: Secretary\n",
      "Word: Secretary, Deprel: nmod, Head: regime\n",
      "Word: Donald, Deprel: flat, Head: Secretary\n",
      "Word: H, Deprel: flat, Head: Secretary\n",
      "Word: Rumsfeld, Deprel: flat, Head: Secretary\n",
      "Word: said, Deprel: parataxis, Head: take\n",
      "Word: Tuesday, Deprel: obl:tmod, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Defense Secretary Donald H Rumsfeld said Tuesday it will take time to locate die-hard remnants of Saddam Hussein s deposed regime in Iraq'\n",
      "Word: Defense, Deprel: compound, Head: Secretary\n",
      "Word: Secretary, Deprel: nsubj, Head: said\n",
      "Word: Donald, Deprel: flat, Head: Secretary\n",
      "Word: H, Deprel: flat, Head: Secretary\n",
      "Word: Rumsfeld, Deprel: flat, Head: Secretary\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Tuesday, Deprel: obl:tmod, Head: said\n",
      "Word: it, Deprel: expl, Head: take\n",
      "Word: will, Deprel: aux, Head: take\n",
      "Word: take, Deprel: ccomp, Head: said\n",
      "Word: time, Deprel: obj, Head: take\n",
      "Word: to, Deprel: mark, Head: locate\n",
      "Word: locate, Deprel: acl, Head: time\n",
      "Word: die-hard, Deprel: amod, Head: remnants\n",
      "Word: remnants, Deprel: obj, Head: locate\n",
      "Word: of, Deprel: case, Head: regime\n",
      "Word: Saddam, Deprel: nmod:poss, Head: regime\n",
      "Word: Hussein, Deprel: flat, Head: Saddam\n",
      "Word: s, Deprel: case, Head: Saddam\n",
      "Word: deposed, Deprel: amod, Head: regime\n",
      "Word: regime, Deprel: nmod, Head: remnants\n",
      "Word: in, Deprel: case, Head: Iraq\n",
      "Word: Iraq, Deprel: nmod, Head: regime\n",
      "\n",
      "Dependencies for Sentence: 'Orange shares jumped as much as 15 percent'\n",
      "Word: Orange, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: jumped\n",
      "Word: jumped, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: advmod, Head: 15\n",
      "Word: much, Deprel: fixed, Head: as\n",
      "Word: as, Deprel: fixed, Head: as\n",
      "Word: 15, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: jumped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'France Telecom shares dropped 3.6 percent while Orange surged 13 percent'\n",
      "Word: France, Deprel: compound, Head: Telecom\n",
      "Word: Telecom, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: dropped\n",
      "Word: dropped, Deprel: root, Head: ROOT\n",
      "Word: 3.6, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: dropped\n",
      "Word: while, Deprel: mark, Head: surged\n",
      "Word: Orange, Deprel: nsubj, Head: surged\n",
      "Word: surged, Deprel: advcl, Head: dropped\n",
      "Word: 13, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: surged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bremer said one initiative is to launch a 70 million nationwide program in the next two weeks to clean up neighborhoods and build community projects'\n",
      "Word: Bremer, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: one, Deprel: nummod, Head: initiative\n",
      "Word: initiative, Deprel: nsubj:outer, Head: launch\n",
      "Word: is, Deprel: cop, Head: launch\n",
      "Word: to, Deprel: mark, Head: launch\n",
      "Word: launch, Deprel: ccomp, Head: said\n",
      "Word: a, Deprel: det, Head: program\n",
      "Word: 70, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: nummod, Head: program\n",
      "Word: nationwide, Deprel: amod, Head: program\n",
      "Word: program, Deprel: obj, Head: launch\n",
      "Word: in, Deprel: case, Head: weeks\n",
      "Word: the, Deprel: det, Head: weeks\n",
      "Word: next, Deprel: amod, Head: weeks\n",
      "Word: two, Deprel: nummod, Head: weeks\n",
      "Word: weeks, Deprel: obl, Head: launch\n",
      "Word: to, Deprel: mark, Head: clean\n",
      "Word: clean, Deprel: advcl, Head: launch\n",
      "Word: up, Deprel: compound:prt, Head: clean\n",
      "Word: neighborhoods, Deprel: obj, Head: clean\n",
      "Word: and, Deprel: cc, Head: build\n",
      "Word: build, Deprel: conj, Head: clean\n",
      "Word: community, Deprel: compound, Head: projects\n",
      "Word: projects, Deprel: obj, Head: build\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bremer said he would launch a 70-million program in the next two weeks to clean up neighborhoods across Iraq and build community projects but gave no details'\n",
      "Word: Bremer, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: launch\n",
      "Word: would, Deprel: aux, Head: launch\n",
      "Word: launch, Deprel: ccomp, Head: said\n",
      "Word: a, Deprel: det, Head: program\n",
      "Word: 70-million, Deprel: nummod, Head: program\n",
      "Word: program, Deprel: obj, Head: launch\n",
      "Word: in, Deprel: case, Head: weeks\n",
      "Word: the, Deprel: det, Head: weeks\n",
      "Word: next, Deprel: amod, Head: weeks\n",
      "Word: two, Deprel: nummod, Head: weeks\n",
      "Word: weeks, Deprel: obl, Head: launch\n",
      "Word: to, Deprel: mark, Head: clean\n",
      "Word: clean, Deprel: advcl, Head: launch\n",
      "Word: up, Deprel: compound:prt, Head: clean\n",
      "Word: neighborhoods, Deprel: obj, Head: clean\n",
      "Word: across, Deprel: case, Head: Iraq\n",
      "Word: Iraq, Deprel: obl, Head: clean\n",
      "Word: and, Deprel: cc, Head: build\n",
      "Word: build, Deprel: conj, Head: clean\n",
      "Word: community, Deprel: compound, Head: projects\n",
      "Word: projects, Deprel: obj, Head: build\n",
      "Word: but, Deprel: cc, Head: gave\n",
      "Word: gave, Deprel: conj, Head: launch\n",
      "Word: no, Deprel: det, Head: details\n",
      "Word: details, Deprel: obj, Head: gave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A search for three missing teenagers uncovered at least two bodies buried beneath freshly poured concrete in the basement of a house authorities said Wednesday'\n",
      "Word: A, Deprel: det, Head: search\n",
      "Word: search, Deprel: nsubj, Head: uncovered\n",
      "Word: for, Deprel: case, Head: teenagers\n",
      "Word: three, Deprel: nummod, Head: teenagers\n",
      "Word: missing, Deprel: amod, Head: teenagers\n",
      "Word: teenagers, Deprel: nmod, Head: search\n",
      "Word: uncovered, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: least\n",
      "Word: least, Deprel: nmod, Head: two\n",
      "Word: two, Deprel: nummod, Head: bodies\n",
      "Word: bodies, Deprel: obj, Head: uncovered\n",
      "Word: buried, Deprel: acl, Head: bodies\n",
      "Word: beneath, Deprel: case, Head: concrete\n",
      "Word: freshly, Deprel: advmod, Head: poured\n",
      "Word: poured, Deprel: amod, Head: concrete\n",
      "Word: concrete, Deprel: obl, Head: buried\n",
      "Word: in, Deprel: case, Head: basement\n",
      "Word: the, Deprel: det, Head: basement\n",
      "Word: basement, Deprel: obl, Head: buried\n",
      "Word: of, Deprel: case, Head: house\n",
      "Word: a, Deprel: det, Head: authorities\n",
      "Word: house, Deprel: compound, Head: authorities\n",
      "Word: authorities, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: uncovered\n",
      "Word: Wednesday, Deprel: obj, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Authorities performed an autopsy Thursday on one of three bodies recovered from beneath a layer of freshly poured concrete in the basement of a northwest Indiana home'\n",
      "Word: Authorities, Deprel: nsubj, Head: performed\n",
      "Word: performed, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: autopsy\n",
      "Word: autopsy, Deprel: obj, Head: performed\n",
      "Word: Thursday, Deprel: obl:tmod, Head: performed\n",
      "Word: on, Deprel: case, Head: one\n",
      "Word: one, Deprel: obl, Head: performed\n",
      "Word: of, Deprel: case, Head: bodies\n",
      "Word: three, Deprel: nummod, Head: bodies\n",
      "Word: bodies, Deprel: nmod, Head: one\n",
      "Word: recovered, Deprel: acl, Head: bodies\n",
      "Word: from, Deprel: obl, Head: recovered\n",
      "Word: beneath, Deprel: case, Head: layer\n",
      "Word: a, Deprel: det, Head: layer\n",
      "Word: layer, Deprel: obl, Head: recovered\n",
      "Word: of, Deprel: case, Head: concrete\n",
      "Word: freshly, Deprel: advmod, Head: poured\n",
      "Word: poured, Deprel: amod, Head: concrete\n",
      "Word: concrete, Deprel: nmod, Head: layer\n",
      "Word: in, Deprel: case, Head: basement\n",
      "Word: the, Deprel: det, Head: basement\n",
      "Word: basement, Deprel: nmod, Head: layer\n",
      "Word: of, Deprel: case, Head: home\n",
      "Word: a, Deprel: det, Head: home\n",
      "Word: northwest, Deprel: amod, Head: home\n",
      "Word: Indiana, Deprel: compound, Head: home\n",
      "Word: home, Deprel: nmod, Head: basement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Sayliyah was the command base for the Iraq war but Central Command sent hundreds who ran the war back home to Tampa Florida'\n",
      "Word: Sayliyah, Deprel: nsubj, Head: base\n",
      "Word: was, Deprel: cop, Head: base\n",
      "Word: the, Deprel: det, Head: base\n",
      "Word: command, Deprel: compound, Head: base\n",
      "Word: base, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: war\n",
      "Word: the, Deprel: det, Head: war\n",
      "Word: Iraq, Deprel: compound, Head: war\n",
      "Word: war, Deprel: nmod, Head: base\n",
      "Word: but, Deprel: cc, Head: sent\n",
      "Word: Central, Deprel: amod, Head: Command\n",
      "Word: Command, Deprel: nsubj, Head: sent\n",
      "Word: sent, Deprel: conj, Head: base\n",
      "Word: hundreds, Deprel: obj, Head: sent\n",
      "Word: who, Deprel: nsubj, Head: ran\n",
      "Word: ran, Deprel: acl:relcl, Head: hundreds\n",
      "Word: the, Deprel: det, Head: war\n",
      "Word: war, Deprel: obj, Head: ran\n",
      "Word: back, Deprel: advmod, Head: home\n",
      "Word: home, Deprel: advmod, Head: ran\n",
      "Word: to, Deprel: case, Head: Florida\n",
      "Word: Tampa, Deprel: compound, Head: Florida\n",
      "Word: Florida, Deprel: obl, Head: ran\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'As Sayliyah was the command base for the Iraq war but hundreds who ran the war have returned to the United States'\n",
      "Word: As, Deprel: mark, Head: base\n",
      "Word: Sayliyah, Deprel: nsubj, Head: base\n",
      "Word: was, Deprel: cop, Head: base\n",
      "Word: the, Deprel: det, Head: base\n",
      "Word: command, Deprel: compound, Head: base\n",
      "Word: base, Deprel: advcl, Head: returned\n",
      "Word: for, Deprel: case, Head: war\n",
      "Word: the, Deprel: det, Head: war\n",
      "Word: Iraq, Deprel: compound, Head: war\n",
      "Word: war, Deprel: nmod, Head: base\n",
      "Word: but, Deprel: cc, Head: returned\n",
      "Word: hundreds, Deprel: nsubj, Head: returned\n",
      "Word: who, Deprel: nsubj, Head: ran\n",
      "Word: ran, Deprel: acl:relcl, Head: hundreds\n",
      "Word: the, Deprel: det, Head: war\n",
      "Word: war, Deprel: obj, Head: ran\n",
      "Word: have, Deprel: aux, Head: returned\n",
      "Word: returned, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: States\n",
      "Word: the, Deprel: det, Head: States\n",
      "Word: United, Deprel: amod, Head: States\n",
      "Word: States, Deprel: obl, Head: returned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Beleaguered telecommunications gear maker Lucent Technologies is being investigated by two federal agencies for possible violations of U.S bribery laws in its operations in Saudi Arabia'\n",
      "Word: Beleaguered, Deprel: amod, Head: Technologies\n",
      "Word: telecommunications, Deprel: compound, Head: maker\n",
      "Word: gear, Deprel: compound, Head: maker\n",
      "Word: maker, Deprel: compound, Head: Technologies\n",
      "Word: Lucent, Deprel: compound, Head: Technologies\n",
      "Word: Technologies, Deprel: nsubj:pass, Head: investigated\n",
      "Word: is, Deprel: aux, Head: investigated\n",
      "Word: being, Deprel: aux:pass, Head: investigated\n",
      "Word: investigated, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: agencies\n",
      "Word: two, Deprel: nummod, Head: agencies\n",
      "Word: federal, Deprel: amod, Head: agencies\n",
      "Word: agencies, Deprel: obl, Head: investigated\n",
      "Word: for, Deprel: case, Head: violations\n",
      "Word: possible, Deprel: amod, Head: violations\n",
      "Word: violations, Deprel: obl, Head: investigated\n",
      "Word: of, Deprel: case, Head: laws\n",
      "Word: U.S, Deprel: compound, Head: laws\n",
      "Word: bribery, Deprel: compound, Head: laws\n",
      "Word: laws, Deprel: nmod, Head: violations\n",
      "Word: in, Deprel: case, Head: operations\n",
      "Word: its, Deprel: nmod:poss, Head: operations\n",
      "Word: operations, Deprel: nmod, Head: laws\n",
      "Word: in, Deprel: case, Head: Arabia\n",
      "Word: Saudi, Deprel: amod, Head: Arabia\n",
      "Word: Arabia, Deprel: nmod, Head: operations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Two federal agencies are investigating telecommunications gear maker Lucent Technologies for possible violations of U.S bribery laws in its operations in Saudi Arabia'\n",
      "Word: Two, Deprel: nummod, Head: agencies\n",
      "Word: federal, Deprel: amod, Head: agencies\n",
      "Word: agencies, Deprel: nsubj, Head: investigating\n",
      "Word: are, Deprel: aux, Head: investigating\n",
      "Word: investigating, Deprel: root, Head: ROOT\n",
      "Word: telecommunications, Deprel: compound, Head: maker\n",
      "Word: gear, Deprel: compound, Head: maker\n",
      "Word: maker, Deprel: compound, Head: Technologies\n",
      "Word: Lucent, Deprel: compound, Head: Technologies\n",
      "Word: Technologies, Deprel: obj, Head: investigating\n",
      "Word: for, Deprel: case, Head: violations\n",
      "Word: possible, Deprel: amod, Head: violations\n",
      "Word: violations, Deprel: obl, Head: investigating\n",
      "Word: of, Deprel: case, Head: laws\n",
      "Word: U.S, Deprel: compound, Head: laws\n",
      "Word: bribery, Deprel: compound, Head: laws\n",
      "Word: laws, Deprel: nmod, Head: violations\n",
      "Word: in, Deprel: case, Head: operations\n",
      "Word: its, Deprel: nmod:poss, Head: operations\n",
      "Word: operations, Deprel: nmod, Head: laws\n",
      "Word: in, Deprel: case, Head: Arabia\n",
      "Word: Saudi, Deprel: amod, Head: Arabia\n",
      "Word: Arabia, Deprel: nmod, Head: operations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'SCO says the pricing terms for a license will not be announced for weeks'\n",
      "Word: SCO, Deprel: nsubj, Head: says\n",
      "Word: says, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: terms\n",
      "Word: pricing, Deprel: compound, Head: terms\n",
      "Word: terms, Deprel: nsubj:pass, Head: announced\n",
      "Word: for, Deprel: case, Head: license\n",
      "Word: a, Deprel: det, Head: license\n",
      "Word: license, Deprel: nmod, Head: terms\n",
      "Word: will, Deprel: aux, Head: announced\n",
      "Word: not, Deprel: advmod, Head: announced\n",
      "Word: be, Deprel: aux:pass, Head: announced\n",
      "Word: announced, Deprel: ccomp, Head: says\n",
      "Word: for, Deprel: case, Head: weeks\n",
      "Word: weeks, Deprel: obl, Head: announced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Details on pricing will be announced within a few weeks McBride said'\n",
      "Word: Details, Deprel: nsubj:pass, Head: announced\n",
      "Word: on, Deprel: case, Head: pricing\n",
      "Word: pricing, Deprel: nmod, Head: Details\n",
      "Word: will, Deprel: aux, Head: announced\n",
      "Word: be, Deprel: aux:pass, Head: announced\n",
      "Word: announced, Deprel: root, Head: ROOT\n",
      "Word: within, Deprel: case, Head: weeks\n",
      "Word: a, Deprel: det, Head: weeks\n",
      "Word: few, Deprel: amod, Head: weeks\n",
      "Word: weeks, Deprel: obl, Head: announced\n",
      "Word: McBride, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: announced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Nasdaq composite index added 30.46 points or 2 percent to 1,520.15'\n",
      "Word: The, Deprel: det, Head: index\n",
      "Word: Nasdaq, Deprel: compound, Head: composite\n",
      "Word: composite, Deprel: compound, Head: index\n",
      "Word: index, Deprel: nsubj, Head: added\n",
      "Word: added, Deprel: root, Head: ROOT\n",
      "Word: 30.46, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: added\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 2, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,520.15\n",
      "Word: 1,520.15, Deprel: obl, Head: added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Nasdaq had a weekly gain of 17.27 or 1.2 percent closing at 1,520.15 after gaining 30.46 yesterday'\n",
      "Word: The, Deprel: det, Head: Nasdaq\n",
      "Word: Nasdaq, Deprel: nsubj, Head: had\n",
      "Word: had, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: gain\n",
      "Word: weekly, Deprel: amod, Head: gain\n",
      "Word: gain, Deprel: obj, Head: had\n",
      "Word: of, Deprel: case, Head: 17.27\n",
      "Word: 17.27, Deprel: nmod, Head: gain\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.2, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: 17.27\n",
      "Word: closing, Deprel: acl, Head: gain\n",
      "Word: at, Deprel: case, Head: 1,520.15\n",
      "Word: 1,520.15, Deprel: obl, Head: closing\n",
      "Word: after, Deprel: mark, Head: gaining\n",
      "Word: gaining, Deprel: advcl, Head: closing\n",
      "Word: 30.46, Deprel: obj, Head: gaining\n",
      "Word: yesterday, Deprel: obl:tmod, Head: gaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The British Foreign Office said Monday that coalition authorities in Iraq were pleased that the men were freed'\n",
      "Word: The, Deprel: det, Head: Office\n",
      "Word: British, Deprel: amod, Head: Office\n",
      "Word: Foreign, Deprel: amod, Head: Office\n",
      "Word: Office, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Monday, Deprel: obl:tmod, Head: said\n",
      "Word: that, Deprel: mark, Head: pleased\n",
      "Word: coalition, Deprel: compound, Head: authorities\n",
      "Word: authorities, Deprel: nsubj, Head: pleased\n",
      "Word: in, Deprel: case, Head: Iraq\n",
      "Word: Iraq, Deprel: nmod, Head: authorities\n",
      "Word: were, Deprel: cop, Head: pleased\n",
      "Word: pleased, Deprel: ccomp, Head: said\n",
      "Word: that, Deprel: mark, Head: freed\n",
      "Word: the, Deprel: det, Head: men\n",
      "Word: men, Deprel: nsubj:pass, Head: freed\n",
      "Word: were, Deprel: aux:pass, Head: freed\n",
      "Word: freed, Deprel: ccomp, Head: pleased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The British Foreign Office said it had mediated the two men s release'\n",
      "Word: The, Deprel: det, Head: Office\n",
      "Word: British, Deprel: amod, Head: Office\n",
      "Word: Foreign, Deprel: amod, Head: Office\n",
      "Word: Office, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: mediated\n",
      "Word: had, Deprel: aux, Head: mediated\n",
      "Word: mediated, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: men\n",
      "Word: two, Deprel: nummod, Head: men\n",
      "Word: men, Deprel: nmod:poss, Head: release\n",
      "Word: s, Deprel: case, Head: men\n",
      "Word: release, Deprel: obj, Head: mediated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Wal-Mart estimates more than 100 million Americans visit their stores every week'\n",
      "Word: Wal-Mart, Deprel: nsubj, Head: estimates\n",
      "Word: estimates, Deprel: root, Head: ROOT\n",
      "Word: more, Deprel: advmod, Head: million\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 100, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: Americans\n",
      "Word: Americans, Deprel: nsubj, Head: visit\n",
      "Word: visit, Deprel: ccomp, Head: estimates\n",
      "Word: their, Deprel: nmod:poss, Head: stores\n",
      "Word: stores, Deprel: obj, Head: visit\n",
      "Word: every, Deprel: det, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: visit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Each week 138 million shoppers visit Wal-Mart s 4,750 stores'\n",
      "Word: Each, Deprel: det, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: visit\n",
      "Word: 138, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: shoppers\n",
      "Word: shoppers, Deprel: nsubj, Head: visit\n",
      "Word: visit, Deprel: root, Head: ROOT\n",
      "Word: Wal-Mart, Deprel: nmod:poss, Head: stores\n",
      "Word: s, Deprel: case, Head: Wal-Mart\n",
      "Word: 4,750, Deprel: nummod, Head: stores\n",
      "Word: stores, Deprel: obj, Head: visit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Sources within the racing industry have told the Daily Bulletin that Fontana will get a second NASCAR race on Labor Day weekend starting next season'\n",
      "Word: Sources, Deprel: nsubj, Head: told\n",
      "Word: within, Deprel: case, Head: industry\n",
      "Word: the, Deprel: det, Head: industry\n",
      "Word: racing, Deprel: compound, Head: industry\n",
      "Word: industry, Deprel: nmod, Head: Sources\n",
      "Word: have, Deprel: aux, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: Bulletin\n",
      "Word: Daily, Deprel: amod, Head: Bulletin\n",
      "Word: Bulletin, Deprel: iobj, Head: told\n",
      "Word: that, Deprel: mark, Head: get\n",
      "Word: Fontana, Deprel: nsubj, Head: get\n",
      "Word: will, Deprel: aux, Head: get\n",
      "Word: get, Deprel: ccomp, Head: told\n",
      "Word: a, Deprel: det, Head: race\n",
      "Word: second, Deprel: amod, Head: race\n",
      "Word: NASCAR, Deprel: compound, Head: race\n",
      "Word: race, Deprel: obj, Head: get\n",
      "Word: on, Deprel: case, Head: weekend\n",
      "Word: Labor, Deprel: compound, Head: Day\n",
      "Word: Day, Deprel: compound, Head: weekend\n",
      "Word: weekend, Deprel: obl, Head: get\n",
      "Word: starting, Deprel: advcl, Head: get\n",
      "Word: next, Deprel: amod, Head: season\n",
      "Word: season, Deprel: obl:tmod, Head: starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Sources in the racing industry said Fontana will get a second NASCAR race on Labor Day weekend starting next season'\n",
      "Word: Sources, Deprel: nsubj, Head: said\n",
      "Word: in, Deprel: case, Head: industry\n",
      "Word: the, Deprel: det, Head: industry\n",
      "Word: racing, Deprel: compound, Head: industry\n",
      "Word: industry, Deprel: nmod, Head: Sources\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Fontana, Deprel: nsubj, Head: get\n",
      "Word: will, Deprel: aux, Head: get\n",
      "Word: get, Deprel: ccomp, Head: said\n",
      "Word: a, Deprel: det, Head: race\n",
      "Word: second, Deprel: amod, Head: race\n",
      "Word: NASCAR, Deprel: compound, Head: race\n",
      "Word: race, Deprel: obj, Head: get\n",
      "Word: on, Deprel: case, Head: weekend\n",
      "Word: Labor, Deprel: compound, Head: Day\n",
      "Word: Day, Deprel: compound, Head: weekend\n",
      "Word: weekend, Deprel: obl, Head: get\n",
      "Word: starting, Deprel: advcl, Head: get\n",
      "Word: next, Deprel: amod, Head: season\n",
      "Word: season, Deprel: obl:tmod, Head: starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Added Mr Prodi Maybe but the old age helps us to understand our strengths and our weakness'\n",
      "Word: Added, Deprel: root, Head: ROOT\n",
      "Word: Mr, Deprel: obj, Head: Added\n",
      "Word: Prodi, Deprel: obj, Head: Added\n",
      "Word: Maybe, Deprel: advmod, Head: Added\n",
      "Word: but, Deprel: cc, Head: helps\n",
      "Word: the, Deprel: det, Head: age\n",
      "Word: old, Deprel: amod, Head: age\n",
      "Word: age, Deprel: nsubj, Head: helps\n",
      "Word: helps, Deprel: conj, Head: Added\n",
      "Word: us, Deprel: obj, Head: helps\n",
      "Word: to, Deprel: mark, Head: understand\n",
      "Word: understand, Deprel: xcomp, Head: helps\n",
      "Word: our, Deprel: nmod:poss, Head: strengths\n",
      "Word: strengths, Deprel: obj, Head: understand\n",
      "Word: and, Deprel: cc, Head: weakness\n",
      "Word: our, Deprel: nmod:poss, Head: weakness\n",
      "Word: weakness, Deprel: conj, Head: strengths\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Maybe but the old age helps us to understand our strength and our weakness and the reality of the world'\n",
      "Word: Maybe, Deprel: advmod, Head: helps\n",
      "Word: but, Deprel: cc, Head: helps\n",
      "Word: the, Deprel: det, Head: age\n",
      "Word: old, Deprel: amod, Head: age\n",
      "Word: age, Deprel: nsubj, Head: helps\n",
      "Word: helps, Deprel: root, Head: ROOT\n",
      "Word: us, Deprel: obj, Head: helps\n",
      "Word: to, Deprel: mark, Head: understand\n",
      "Word: understand, Deprel: xcomp, Head: helps\n",
      "Word: our, Deprel: nmod:poss, Head: strength\n",
      "Word: strength, Deprel: obj, Head: understand\n",
      "Word: and, Deprel: cc, Head: weakness\n",
      "Word: our, Deprel: nmod:poss, Head: weakness\n",
      "Word: weakness, Deprel: conj, Head: strength\n",
      "Word: and, Deprel: cc, Head: reality\n",
      "Word: the, Deprel: det, Head: reality\n",
      "Word: reality, Deprel: conj, Head: strength\n",
      "Word: of, Deprel: case, Head: world\n",
      "Word: the, Deprel: det, Head: world\n",
      "Word: world, Deprel: nmod, Head: reality\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I am proud that I stood against Richard Nixon not with him Kerry said'\n",
      "Word: I, Deprel: nsubj, Head: proud\n",
      "Word: am, Deprel: cop, Head: proud\n",
      "Word: proud, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: stood\n",
      "Word: I, Deprel: nsubj, Head: stood\n",
      "Word: stood, Deprel: ccomp, Head: proud\n",
      "Word: against, Deprel: case, Head: Richard\n",
      "Word: Richard, Deprel: obl, Head: stood\n",
      "Word: Nixon, Deprel: flat, Head: Richard\n",
      "Word: not, Deprel: advmod, Head: him\n",
      "Word: with, Deprel: case, Head: him\n",
      "Word: him, Deprel: obl, Head: stood\n",
      "Word: Kerry, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: stood\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I marched in the streets against Richard Nixon and the Vietnam War she said'\n",
      "Word: I, Deprel: nsubj, Head: marched\n",
      "Word: marched, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: streets\n",
      "Word: the, Deprel: det, Head: streets\n",
      "Word: streets, Deprel: obl, Head: marched\n",
      "Word: against, Deprel: case, Head: Richard\n",
      "Word: Richard, Deprel: obl, Head: marched\n",
      "Word: Nixon, Deprel: flat, Head: Richard\n",
      "Word: and, Deprel: cc, Head: War\n",
      "Word: the, Deprel: det, Head: War\n",
      "Word: Vietnam, Deprel: compound, Head: War\n",
      "Word: War, Deprel: conj, Head: Richard\n",
      "Word: she, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: marched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He claimed Red Hat and the Free Software Foundation with trying to undermine U.S copyright and patent law'\n",
      "Word: He, Deprel: nsubj, Head: claimed\n",
      "Word: claimed, Deprel: root, Head: ROOT\n",
      "Word: Red, Deprel: amod, Head: Hat\n",
      "Word: Hat, Deprel: obj, Head: claimed\n",
      "Word: and, Deprel: cc, Head: Foundation\n",
      "Word: the, Deprel: det, Head: Foundation\n",
      "Word: Free, Deprel: amod, Head: Software\n",
      "Word: Software, Deprel: compound, Head: Foundation\n",
      "Word: Foundation, Deprel: conj, Head: Hat\n",
      "Word: with, Deprel: mark, Head: trying\n",
      "Word: trying, Deprel: advcl, Head: claimed\n",
      "Word: to, Deprel: mark, Head: undermine\n",
      "Word: undermine, Deprel: xcomp, Head: trying\n",
      "Word: U.S, Deprel: compound, Head: copyright\n",
      "Word: copyright, Deprel: compound, Head: law\n",
      "Word: and, Deprel: cc, Head: patent\n",
      "Word: patent, Deprel: conj, Head: copyright\n",
      "Word: law, Deprel: obj, Head: undermine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In his letter McBride charges the Free Software Foundation and Red Hat with trying to undermine U.S copyright laws'\n",
      "Word: In, Deprel: case, Head: letter\n",
      "Word: his, Deprel: nmod:poss, Head: letter\n",
      "Word: letter, Deprel: obl, Head: charges\n",
      "Word: McBride, Deprel: nsubj, Head: charges\n",
      "Word: charges, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: Foundation\n",
      "Word: Free, Deprel: amod, Head: Software\n",
      "Word: Software, Deprel: compound, Head: Foundation\n",
      "Word: Foundation, Deprel: obj, Head: charges\n",
      "Word: and, Deprel: cc, Head: Hat\n",
      "Word: Red, Deprel: amod, Head: Hat\n",
      "Word: Hat, Deprel: conj, Head: Foundation\n",
      "Word: with, Deprel: mark, Head: trying\n",
      "Word: trying, Deprel: advcl, Head: charges\n",
      "Word: to, Deprel: mark, Head: undermine\n",
      "Word: undermine, Deprel: xcomp, Head: trying\n",
      "Word: U.S, Deprel: compound, Head: laws\n",
      "Word: copyright, Deprel: compound, Head: laws\n",
      "Word: laws, Deprel: obj, Head: undermine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of Corixa were gaining 71 cents or 10 to 7.91 on the Nasdaq'\n",
      "Word: Shares, Deprel: nsubj, Head: gaining\n",
      "Word: of, Deprel: case, Head: Corixa\n",
      "Word: Corixa, Deprel: nmod, Head: Shares\n",
      "Word: were, Deprel: aux, Head: gaining\n",
      "Word: gaining, Deprel: root, Head: ROOT\n",
      "Word: 71, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obj, Head: gaining\n",
      "Word: or, Deprel: cc, Head: 10\n",
      "Word: 10, Deprel: conj, Head: cents\n",
      "Word: to, Deprel: case, Head: 7.91\n",
      "Word: 7.91, Deprel: nmod, Head: 10\n",
      "Word: on, Deprel: case, Head: Nasdaq\n",
      "Word: the, Deprel: det, Head: Nasdaq\n",
      "Word: Nasdaq, Deprel: obl, Head: gaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In late-morning trading on the Nasdaq Stock Market Corixa was up 74 cents or 10 at 7.94'\n",
      "Word: In, Deprel: case, Head: trading\n",
      "Word: late-morning, Deprel: amod, Head: trading\n",
      "Word: trading, Deprel: obl, Head: up\n",
      "Word: on, Deprel: case, Head: Market\n",
      "Word: the, Deprel: det, Head: Corixa\n",
      "Word: Nasdaq, Deprel: compound, Head: Market\n",
      "Word: Stock, Deprel: compound, Head: Market\n",
      "Word: Market, Deprel: compound, Head: Corixa\n",
      "Word: Corixa, Deprel: nsubj, Head: up\n",
      "Word: was, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: 74, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:npmod, Head: up\n",
      "Word: or, Deprel: cc, Head: 10\n",
      "Word: 10, Deprel: conj, Head: cents\n",
      "Word: at, Deprel: case, Head: 7.94\n",
      "Word: 7.94, Deprel: nmod, Head: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Police then called a bomb squad but the device exploded killing Wells before bomb technicians arrived'\n",
      "Word: Police, Deprel: nsubj, Head: called\n",
      "Word: then, Deprel: advmod, Head: called\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: squad\n",
      "Word: bomb, Deprel: compound, Head: squad\n",
      "Word: squad, Deprel: obj, Head: called\n",
      "Word: but, Deprel: cc, Head: exploded\n",
      "Word: the, Deprel: det, Head: device\n",
      "Word: device, Deprel: nsubj, Head: exploded\n",
      "Word: exploded, Deprel: conj, Head: called\n",
      "Word: killing, Deprel: xcomp, Head: exploded\n",
      "Word: Wells, Deprel: obj, Head: killing\n",
      "Word: before, Deprel: mark, Head: arrived\n",
      "Word: bomb, Deprel: compound, Head: technicians\n",
      "Word: technicians, Deprel: nsubj, Head: arrived\n",
      "Word: arrived, Deprel: advcl, Head: exploded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'While waiting for a bomb squad to arrive the bomb exploded killing Wells'\n",
      "Word: While, Deprel: mark, Head: waiting\n",
      "Word: waiting, Deprel: advcl, Head: exploded\n",
      "Word: for, Deprel: case, Head: squad\n",
      "Word: a, Deprel: det, Head: squad\n",
      "Word: bomb, Deprel: compound, Head: squad\n",
      "Word: squad, Deprel: obl, Head: waiting\n",
      "Word: to, Deprel: mark, Head: arrive\n",
      "Word: arrive, Deprel: advcl, Head: waiting\n",
      "Word: the, Deprel: det, Head: bomb\n",
      "Word: bomb, Deprel: nsubj, Head: exploded\n",
      "Word: exploded, Deprel: root, Head: ROOT\n",
      "Word: killing, Deprel: xcomp, Head: exploded\n",
      "Word: Wells, Deprel: obj, Head: killing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Spokesmen for the FBI CIA Canadian Security Intelligence Service and Royal Canadian Mounted Police declined to comment on El Shukrijumah s stay in Canada'\n",
      "Word: Spokesmen, Deprel: nsubj, Head: declined\n",
      "Word: for, Deprel: case, Head: Service\n",
      "Word: the, Deprel: det, Head: Service\n",
      "Word: FBI, Deprel: compound, Head: Service\n",
      "Word: CIA, Deprel: compound, Head: Service\n",
      "Word: Canadian, Deprel: amod, Head: Security\n",
      "Word: Security, Deprel: compound, Head: Intelligence\n",
      "Word: Intelligence, Deprel: compound, Head: Service\n",
      "Word: Service, Deprel: nmod, Head: Spokesmen\n",
      "Word: and, Deprel: cc, Head: Police\n",
      "Word: Royal, Deprel: amod, Head: Police\n",
      "Word: Canadian, Deprel: amod, Head: Mounted\n",
      "Word: Mounted, Deprel: compound, Head: Police\n",
      "Word: Police, Deprel: conj, Head: Service\n",
      "Word: declined, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: comment\n",
      "Word: comment, Deprel: xcomp, Head: declined\n",
      "Word: on, Deprel: case, Head: stay\n",
      "Word: El, Deprel: nmod:poss, Head: stay\n",
      "Word: Shukrijumah, Deprel: flat, Head: El\n",
      "Word: s, Deprel: case, Head: El\n",
      "Word: stay, Deprel: obl, Head: comment\n",
      "Word: in, Deprel: case, Head: Canada\n",
      "Word: Canada, Deprel: nmod, Head: stay\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The FBI CIA Canadian Security Intelligence Service and Royal Canadian Mounted Police declined to comment on the Washington Times report'\n",
      "Word: The, Deprel: det, Head: Service\n",
      "Word: FBI, Deprel: compound, Head: Service\n",
      "Word: CIA, Deprel: compound, Head: Service\n",
      "Word: Canadian, Deprel: amod, Head: Security\n",
      "Word: Security, Deprel: compound, Head: Intelligence\n",
      "Word: Intelligence, Deprel: compound, Head: Service\n",
      "Word: Service, Deprel: nsubj, Head: declined\n",
      "Word: and, Deprel: cc, Head: Police\n",
      "Word: Royal, Deprel: amod, Head: Police\n",
      "Word: Canadian, Deprel: amod, Head: Mounted\n",
      "Word: Mounted, Deprel: compound, Head: Police\n",
      "Word: Police, Deprel: conj, Head: Service\n",
      "Word: declined, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: comment\n",
      "Word: comment, Deprel: xcomp, Head: declined\n",
      "Word: on, Deprel: case, Head: report\n",
      "Word: the, Deprel: det, Head: report\n",
      "Word: Washington, Deprel: compound, Head: Times\n",
      "Word: Times, Deprel: compound, Head: report\n",
      "Word: report, Deprel: obl, Head: comment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This has been a persistent problem that has not been solved investigation board member Steven Wallace said'\n",
      "Word: This, Deprel: nsubj, Head: problem\n",
      "Word: has, Deprel: aux, Head: problem\n",
      "Word: been, Deprel: cop, Head: problem\n",
      "Word: a, Deprel: det, Head: problem\n",
      "Word: persistent, Deprel: amod, Head: problem\n",
      "Word: problem, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: nsubj, Head: solved\n",
      "Word: has, Deprel: aux, Head: solved\n",
      "Word: not, Deprel: advmod, Head: solved\n",
      "Word: been, Deprel: aux:pass, Head: solved\n",
      "Word: solved, Deprel: acl:relcl, Head: problem\n",
      "Word: investigation, Deprel: compound, Head: member\n",
      "Word: board, Deprel: compound, Head: member\n",
      "Word: member, Deprel: obj, Head: solved\n",
      "Word: Steven, Deprel: flat, Head: member\n",
      "Word: Wallace, Deprel: flat, Head: member\n",
      "Word: said, Deprel: acl:relcl, Head: member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This was a persistent problem which has not been solved mechanically and physically said board member Steven Wallace'\n",
      "Word: This, Deprel: nsubj, Head: problem\n",
      "Word: was, Deprel: cop, Head: problem\n",
      "Word: a, Deprel: det, Head: problem\n",
      "Word: persistent, Deprel: amod, Head: problem\n",
      "Word: problem, Deprel: root, Head: ROOT\n",
      "Word: which, Deprel: nsubj:pass, Head: solved\n",
      "Word: has, Deprel: aux, Head: solved\n",
      "Word: not, Deprel: advmod, Head: solved\n",
      "Word: been, Deprel: aux:pass, Head: solved\n",
      "Word: solved, Deprel: acl:relcl, Head: problem\n",
      "Word: mechanically, Deprel: advmod, Head: solved\n",
      "Word: and, Deprel: cc, Head: said\n",
      "Word: physically, Deprel: conj, Head: mechanically\n",
      "Word: said, Deprel: conj, Head: solved\n",
      "Word: board, Deprel: compound, Head: member\n",
      "Word: member, Deprel: obj, Head: said\n",
      "Word: Steven, Deprel: flat, Head: member\n",
      "Word: Wallace, Deprel: flat, Head: member\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Dow Jones industrial average DJI ended up 56.79 points or 0.67 percent at 8,588.36 its highest level since January 17'\n",
      "Word: The, Deprel: det, Head: DJI\n",
      "Word: Dow, Deprel: compound, Head: average\n",
      "Word: Jones, Deprel: flat, Head: Dow\n",
      "Word: industrial, Deprel: compound, Head: average\n",
      "Word: average, Deprel: compound, Head: DJI\n",
      "Word: DJI, Deprel: nsubj, Head: ended\n",
      "Word: ended, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: advmod, Head: ended\n",
      "Word: 56.79, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: ended\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.67, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 8,588.36\n",
      "Word: 8,588.36, Deprel: obl, Head: ended\n",
      "Word: its, Deprel: nmod:poss, Head: level\n",
      "Word: highest, Deprel: amod, Head: level\n",
      "Word: level, Deprel: obl:tmod, Head: ended\n",
      "Word: since, Deprel: case, Head: 17\n",
      "Word: January, Deprel: compound, Head: 17\n",
      "Word: 17, Deprel: nmod, Head: level\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Dow Jones Industrial Average DJ news chart profile rose 56 points or 0.7 percent to 8,588'\n",
      "Word: The, Deprel: det, Head: profile\n",
      "Word: Dow, Deprel: compound, Head: Average\n",
      "Word: Jones, Deprel: compound, Head: Average\n",
      "Word: Industrial, Deprel: amod, Head: Average\n",
      "Word: Average, Deprel: compound, Head: profile\n",
      "Word: DJ, Deprel: compound, Head: profile\n",
      "Word: news, Deprel: compound, Head: profile\n",
      "Word: chart, Deprel: compound, Head: profile\n",
      "Word: profile, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 56, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: rose\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.7, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 8,588\n",
      "Word: 8,588, Deprel: obl, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Americans do n't cut and run we have to see this misadventure through she said'\n",
      "Word: Americans, Deprel: nsubj, Head: cut\n",
      "Word: do, Deprel: aux, Head: cut\n",
      "Word: n't, Deprel: advmod, Head: cut\n",
      "Word: cut, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: run\n",
      "Word: run, Deprel: conj, Head: cut\n",
      "Word: we, Deprel: nsubj, Head: have\n",
      "Word: have, Deprel: parataxis, Head: cut\n",
      "Word: to, Deprel: mark, Head: see\n",
      "Word: see, Deprel: xcomp, Head: have\n",
      "Word: this, Deprel: det, Head: misadventure\n",
      "Word: misadventure, Deprel: obj, Head: see\n",
      "Word: through, Deprel: mark, Head: said\n",
      "Word: she, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: cut\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'She also pledged to bring peace to Iraq Americans do n't cut and run we have to see this misadventure through'\n",
      "Word: She, Deprel: nsubj, Head: pledged\n",
      "Word: also, Deprel: advmod, Head: pledged\n",
      "Word: pledged, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: bring\n",
      "Word: bring, Deprel: xcomp, Head: pledged\n",
      "Word: peace, Deprel: obj, Head: bring\n",
      "Word: to, Deprel: case, Head: Americans\n",
      "Word: Iraq, Deprel: compound, Head: Americans\n",
      "Word: Americans, Deprel: nsubj, Head: cut\n",
      "Word: do, Deprel: aux, Head: cut\n",
      "Word: n't, Deprel: advmod, Head: cut\n",
      "Word: cut, Deprel: advcl, Head: bring\n",
      "Word: and, Deprel: cc, Head: run\n",
      "Word: run, Deprel: conj, Head: cut\n",
      "Word: we, Deprel: nsubj, Head: have\n",
      "Word: have, Deprel: parataxis, Head: pledged\n",
      "Word: to, Deprel: mark, Head: see\n",
      "Word: see, Deprel: xcomp, Head: have\n",
      "Word: this, Deprel: det, Head: misadventure\n",
      "Word: misadventure, Deprel: obj, Head: see\n",
      "Word: through, Deprel: advmod, Head: see\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'At 12 months there was still a difference in function although it was not a significant one'\n",
      "Word: At, Deprel: case, Head: months\n",
      "Word: 12, Deprel: nummod, Head: months\n",
      "Word: months, Deprel: obl, Head: was\n",
      "Word: there, Deprel: expl, Head: was\n",
      "Word: was, Deprel: root, Head: ROOT\n",
      "Word: still, Deprel: advmod, Head: was\n",
      "Word: a, Deprel: det, Head: difference\n",
      "Word: difference, Deprel: nsubj, Head: was\n",
      "Word: in, Deprel: case, Head: function\n",
      "Word: function, Deprel: nmod, Head: difference\n",
      "Word: although, Deprel: mark, Head: one\n",
      "Word: it, Deprel: nsubj, Head: one\n",
      "Word: was, Deprel: cop, Head: one\n",
      "Word: not, Deprel: advmod, Head: one\n",
      "Word: a, Deprel: det, Head: one\n",
      "Word: significant, Deprel: amod, Head: one\n",
      "Word: one, Deprel: advcl, Head: was\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'At 12 months there was still a difference between the groups but it was not considered significant'\n",
      "Word: At, Deprel: case, Head: months\n",
      "Word: 12, Deprel: nummod, Head: months\n",
      "Word: months, Deprel: obl, Head: was\n",
      "Word: there, Deprel: expl, Head: was\n",
      "Word: was, Deprel: root, Head: ROOT\n",
      "Word: still, Deprel: advmod, Head: was\n",
      "Word: a, Deprel: det, Head: difference\n",
      "Word: difference, Deprel: nsubj, Head: was\n",
      "Word: between, Deprel: case, Head: groups\n",
      "Word: the, Deprel: det, Head: groups\n",
      "Word: groups, Deprel: nmod, Head: difference\n",
      "Word: but, Deprel: cc, Head: considered\n",
      "Word: it, Deprel: nsubj:pass, Head: considered\n",
      "Word: was, Deprel: aux:pass, Head: considered\n",
      "Word: not, Deprel: advmod, Head: considered\n",
      "Word: considered, Deprel: conj, Head: was\n",
      "Word: significant, Deprel: xcomp, Head: considered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'There is no doubt about the chemical programme biological programme indeed nuclear programme indeed all that was documented by the UN he said'\n",
      "Word: There, Deprel: expl, Head: is\n",
      "Word: is, Deprel: root, Head: ROOT\n",
      "Word: no, Deprel: det, Head: doubt\n",
      "Word: doubt, Deprel: nsubj, Head: is\n",
      "Word: about, Deprel: case, Head: programme\n",
      "Word: the, Deprel: det, Head: programme\n",
      "Word: chemical, Deprel: amod, Head: programme\n",
      "Word: programme, Deprel: compound, Head: programme\n",
      "Word: biological, Deprel: amod, Head: programme\n",
      "Word: programme, Deprel: nmod, Head: doubt\n",
      "Word: indeed, Deprel: advmod, Head: programme\n",
      "Word: nuclear, Deprel: amod, Head: programme\n",
      "Word: programme, Deprel: appos, Head: programme\n",
      "Word: indeed, Deprel: advmod, Head: all\n",
      "Word: all, Deprel: appos, Head: programme\n",
      "Word: that, Deprel: nsubj:pass, Head: documented\n",
      "Word: was, Deprel: aux:pass, Head: documented\n",
      "Word: documented, Deprel: acl:relcl, Head: all\n",
      "Word: by, Deprel: case, Head: UN\n",
      "Word: the, Deprel: det, Head: UN\n",
      "Word: UN, Deprel: obl, Head: documented\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: UN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He added There is no doubt about the chemical programme the biological programme and indeed the nuclear weapons programme'\n",
      "Word: He, Deprel: nsubj, Head: added\n",
      "Word: added, Deprel: root, Head: ROOT\n",
      "Word: There, Deprel: expl, Head: is\n",
      "Word: is, Deprel: ccomp, Head: added\n",
      "Word: no, Deprel: det, Head: doubt\n",
      "Word: doubt, Deprel: nsubj, Head: is\n",
      "Word: about, Deprel: case, Head: programme\n",
      "Word: the, Deprel: det, Head: programme\n",
      "Word: chemical, Deprel: compound, Head: programme\n",
      "Word: programme, Deprel: nmod, Head: doubt\n",
      "Word: the, Deprel: det, Head: programme\n",
      "Word: biological, Deprel: amod, Head: programme\n",
      "Word: programme, Deprel: appos, Head: programme\n",
      "Word: and, Deprel: cc, Head: programme\n",
      "Word: indeed, Deprel: advmod, Head: programme\n",
      "Word: the, Deprel: det, Head: programme\n",
      "Word: nuclear, Deprel: amod, Head: weapons\n",
      "Word: weapons, Deprel: compound, Head: programme\n",
      "Word: programme, Deprel: conj, Head: programme\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It just seems like all the issues that we support he does n't said Gabriela Lemus of LULAC'\n",
      "Word: It, Deprel: nsubj, Head: seems\n",
      "Word: just, Deprel: advmod, Head: seems\n",
      "Word: seems, Deprel: root, Head: ROOT\n",
      "Word: like, Deprel: case, Head: issues\n",
      "Word: all, Deprel: det:predet, Head: issues\n",
      "Word: the, Deprel: det, Head: issues\n",
      "Word: issues, Deprel: obl, Head: seems\n",
      "Word: that, Deprel: obj, Head: support\n",
      "Word: we, Deprel: nsubj, Head: support\n",
      "Word: support, Deprel: acl:relcl, Head: issues\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: does, Deprel: aux, Head: said\n",
      "Word: n't, Deprel: advmod, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: issues\n",
      "Word: Gabriela, Deprel: obj, Head: said\n",
      "Word: Lemus, Deprel: flat, Head: Gabriela\n",
      "Word: of, Deprel: case, Head: LULAC\n",
      "Word: LULAC, Deprel: nmod, Head: Gabriela\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It just seems like all the issues that we support he does n't said Gabriela Lemus the league s director of policy and legislation'\n",
      "Word: It, Deprel: nsubj, Head: seems\n",
      "Word: just, Deprel: advmod, Head: seems\n",
      "Word: seems, Deprel: root, Head: ROOT\n",
      "Word: like, Deprel: case, Head: issues\n",
      "Word: all, Deprel: det:predet, Head: issues\n",
      "Word: the, Deprel: det, Head: issues\n",
      "Word: issues, Deprel: obl, Head: seems\n",
      "Word: that, Deprel: obj, Head: support\n",
      "Word: we, Deprel: nsubj, Head: support\n",
      "Word: support, Deprel: acl:relcl, Head: issues\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: does, Deprel: aux, Head: said\n",
      "Word: n't, Deprel: advmod, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: issues\n",
      "Word: Gabriela, Deprel: obj, Head: said\n",
      "Word: Lemus, Deprel: flat, Head: Gabriela\n",
      "Word: the, Deprel: det, Head: league\n",
      "Word: league, Deprel: nmod:poss, Head: director\n",
      "Word: s, Deprel: case, Head: league\n",
      "Word: director, Deprel: appos, Head: Gabriela\n",
      "Word: of, Deprel: case, Head: policy\n",
      "Word: policy, Deprel: nmod, Head: director\n",
      "Word: and, Deprel: cc, Head: legislation\n",
      "Word: legislation, Deprel: conj, Head: policy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'City-grown pollution and ozone in particular is tougher on country trees says Cornell University ecologist Jillian Gregg'\n",
      "Word: City-grown, Deprel: amod, Head: pollution\n",
      "Word: pollution, Deprel: nsubj, Head: tougher\n",
      "Word: and, Deprel: cc, Head: ozone\n",
      "Word: ozone, Deprel: conj, Head: pollution\n",
      "Word: in, Deprel: case, Head: particular\n",
      "Word: particular, Deprel: nmod, Head: pollution\n",
      "Word: is, Deprel: cop, Head: tougher\n",
      "Word: tougher, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: trees\n",
      "Word: country, Deprel: compound, Head: trees\n",
      "Word: trees, Deprel: obl, Head: tougher\n",
      "Word: says, Deprel: parataxis, Head: tougher\n",
      "Word: Cornell, Deprel: compound, Head: University\n",
      "Word: University, Deprel: compound, Head: ecologist\n",
      "Word: ecologist, Deprel: nsubj, Head: says\n",
      "Word: Jillian, Deprel: flat, Head: ecologist\n",
      "Word: Gregg, Deprel: flat, Head: Jillian\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I know this sounds counterintuitive but it s true City-grown pollution and ozone in particular is tougher on country trees U.S ecologist Jillian Gregg said'\n",
      "Word: I, Deprel: nsubj, Head: know\n",
      "Word: know, Deprel: root, Head: ROOT\n",
      "Word: this, Deprel: nsubj, Head: sounds\n",
      "Word: sounds, Deprel: ccomp, Head: know\n",
      "Word: counterintuitive, Deprel: xcomp, Head: sounds\n",
      "Word: but, Deprel: cc, Head: true\n",
      "Word: it, Deprel: nsubj, Head: true\n",
      "Word: s, Deprel: cop, Head: true\n",
      "Word: true, Deprel: conj, Head: know\n",
      "Word: City-grown, Deprel: amod, Head: pollution\n",
      "Word: pollution, Deprel: nsubj, Head: tougher\n",
      "Word: and, Deprel: cc, Head: ozone\n",
      "Word: ozone, Deprel: conj, Head: pollution\n",
      "Word: in, Deprel: case, Head: particular\n",
      "Word: particular, Deprel: nmod, Head: pollution\n",
      "Word: is, Deprel: cop, Head: tougher\n",
      "Word: tougher, Deprel: conj, Head: true\n",
      "Word: on, Deprel: case, Head: trees\n",
      "Word: country, Deprel: compound, Head: trees\n",
      "Word: trees, Deprel: obl, Head: tougher\n",
      "Word: U.S, Deprel: compound, Head: ecologist\n",
      "Word: ecologist, Deprel: compound, Head: Jillian\n",
      "Word: Jillian, Deprel: nsubj, Head: said\n",
      "Word: Gregg, Deprel: flat, Head: Jillian\n",
      "Word: said, Deprel: parataxis, Head: know\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Ridge said no real explosives or harmful devices will be used in the exercise'\n",
      "Word: Ridge, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: no, Deprel: det, Head: explosives\n",
      "Word: real, Deprel: amod, Head: explosives\n",
      "Word: explosives, Deprel: nsubj:pass, Head: used\n",
      "Word: or, Deprel: cc, Head: devices\n",
      "Word: harmful, Deprel: amod, Head: devices\n",
      "Word: devices, Deprel: conj, Head: explosives\n",
      "Word: will, Deprel: aux, Head: used\n",
      "Word: be, Deprel: aux:pass, Head: used\n",
      "Word: used, Deprel: ccomp, Head: said\n",
      "Word: in, Deprel: case, Head: exercise\n",
      "Word: the, Deprel: det, Head: exercise\n",
      "Word: exercise, Deprel: obl, Head: used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Ridge said that no actual explosives or other harmful substances will be used'\n",
      "Word: Ridge, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: used\n",
      "Word: no, Deprel: det, Head: explosives\n",
      "Word: actual, Deprel: amod, Head: explosives\n",
      "Word: explosives, Deprel: nsubj:pass, Head: used\n",
      "Word: or, Deprel: cc, Head: substances\n",
      "Word: other, Deprel: amod, Head: substances\n",
      "Word: harmful, Deprel: amod, Head: substances\n",
      "Word: substances, Deprel: conj, Head: explosives\n",
      "Word: will, Deprel: aux, Head: used\n",
      "Word: be, Deprel: aux:pass, Head: used\n",
      "Word: used, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dennehy who transferred to Baylor last year after getting kicked off the University of New Mexico Lobos for temper tantrums had begun to read the Bible daily'\n",
      "Word: Dennehy, Deprel: nsubj, Head: begun\n",
      "Word: who, Deprel: nsubj, Head: transferred\n",
      "Word: transferred, Deprel: acl:relcl, Head: Dennehy\n",
      "Word: to, Deprel: case, Head: Baylor\n",
      "Word: Baylor, Deprel: obl, Head: transferred\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: transferred\n",
      "Word: after, Deprel: mark, Head: kicked\n",
      "Word: getting, Deprel: aux:pass, Head: kicked\n",
      "Word: kicked, Deprel: advcl, Head: transferred\n",
      "Word: off, Deprel: case, Head: University\n",
      "Word: the, Deprel: det, Head: University\n",
      "Word: University, Deprel: obl, Head: kicked\n",
      "Word: of, Deprel: case, Head: Mexico\n",
      "Word: New, Deprel: amod, Head: Mexico\n",
      "Word: Mexico, Deprel: nmod, Head: University\n",
      "Word: Lobos, Deprel: appos, Head: University\n",
      "Word: for, Deprel: case, Head: tantrums\n",
      "Word: temper, Deprel: compound, Head: tantrums\n",
      "Word: tantrums, Deprel: obl, Head: kicked\n",
      "Word: had, Deprel: aux, Head: begun\n",
      "Word: begun, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: read\n",
      "Word: read, Deprel: xcomp, Head: begun\n",
      "Word: the, Deprel: det, Head: Bible\n",
      "Word: Bible, Deprel: obj, Head: read\n",
      "Word: daily, Deprel: advmod, Head: read\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dennehy who transferred to Baylor last year after getting kicked off the University of New Mexico Lobos for temper tantrums became a born-again Christian in June 2002'\n",
      "Word: Dennehy, Deprel: nsubj, Head: became\n",
      "Word: who, Deprel: nsubj, Head: transferred\n",
      "Word: transferred, Deprel: acl:relcl, Head: Dennehy\n",
      "Word: to, Deprel: case, Head: Baylor\n",
      "Word: Baylor, Deprel: obl, Head: transferred\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: transferred\n",
      "Word: after, Deprel: mark, Head: kicked\n",
      "Word: getting, Deprel: aux:pass, Head: kicked\n",
      "Word: kicked, Deprel: advcl, Head: transferred\n",
      "Word: off, Deprel: case, Head: University\n",
      "Word: the, Deprel: det, Head: University\n",
      "Word: University, Deprel: obl, Head: kicked\n",
      "Word: of, Deprel: case, Head: Mexico\n",
      "Word: New, Deprel: amod, Head: Mexico\n",
      "Word: Mexico, Deprel: nmod, Head: University\n",
      "Word: Lobos, Deprel: appos, Head: University\n",
      "Word: for, Deprel: case, Head: tantrums\n",
      "Word: temper, Deprel: compound, Head: tantrums\n",
      "Word: tantrums, Deprel: obl, Head: kicked\n",
      "Word: became, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: Christian\n",
      "Word: born-again, Deprel: amod, Head: Christian\n",
      "Word: Christian, Deprel: xcomp, Head: became\n",
      "Word: in, Deprel: case, Head: June\n",
      "Word: June, Deprel: obl, Head: became\n",
      "Word: 2002, Deprel: nummod, Head: June\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This is America my friends and it should not happen here he said to loud applause'\n",
      "Word: This, Deprel: nsubj, Head: America\n",
      "Word: is, Deprel: cop, Head: America\n",
      "Word: America, Deprel: root, Head: ROOT\n",
      "Word: my, Deprel: nmod:poss, Head: friends\n",
      "Word: friends, Deprel: nsubj, Head: America\n",
      "Word: and, Deprel: cc, Head: happen\n",
      "Word: it, Deprel: nsubj, Head: happen\n",
      "Word: should, Deprel: aux, Head: happen\n",
      "Word: not, Deprel: advmod, Head: happen\n",
      "Word: happen, Deprel: conj, Head: America\n",
      "Word: here, Deprel: advmod, Head: happen\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: America\n",
      "Word: to, Deprel: case, Head: applause\n",
      "Word: loud, Deprel: amod, Head: applause\n",
      "Word: applause, Deprel: obl, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This is America my friends and it should not happen here'\n",
      "Word: This, Deprel: nsubj, Head: America\n",
      "Word: is, Deprel: cop, Head: America\n",
      "Word: America, Deprel: root, Head: ROOT\n",
      "Word: my, Deprel: nmod:poss, Head: friends\n",
      "Word: friends, Deprel: nsubj, Head: happen\n",
      "Word: and, Deprel: cc, Head: happen\n",
      "Word: it, Deprel: nsubj, Head: happen\n",
      "Word: should, Deprel: aux, Head: happen\n",
      "Word: not, Deprel: advmod, Head: happen\n",
      "Word: happen, Deprel: conj, Head: America\n",
      "Word: here, Deprel: advmod, Head: happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bashir felt he was being tried by opinion not on the facts Mahendradatta told Reuters'\n",
      "Word: Bashir, Deprel: nsubj, Head: felt\n",
      "Word: felt, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj:pass, Head: tried\n",
      "Word: was, Deprel: aux, Head: tried\n",
      "Word: being, Deprel: aux:pass, Head: tried\n",
      "Word: tried, Deprel: ccomp, Head: felt\n",
      "Word: by, Deprel: case, Head: opinion\n",
      "Word: opinion, Deprel: obl, Head: tried\n",
      "Word: not, Deprel: advmod, Head: facts\n",
      "Word: on, Deprel: case, Head: facts\n",
      "Word: the, Deprel: det, Head: facts\n",
      "Word: facts, Deprel: nmod, Head: opinion\n",
      "Word: Mahendradatta, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: acl:relcl, Head: facts\n",
      "Word: Reuters, Deprel: iobj, Head: told\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bashir also felt he was being tried by opinion rather than facts of law he added'\n",
      "Word: Bashir, Deprel: nsubj, Head: felt\n",
      "Word: also, Deprel: advmod, Head: felt\n",
      "Word: felt, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj:pass, Head: tried\n",
      "Word: was, Deprel: aux, Head: tried\n",
      "Word: being, Deprel: aux:pass, Head: tried\n",
      "Word: tried, Deprel: ccomp, Head: felt\n",
      "Word: by, Deprel: case, Head: opinion\n",
      "Word: opinion, Deprel: obl, Head: tried\n",
      "Word: rather, Deprel: cc, Head: facts\n",
      "Word: than, Deprel: fixed, Head: rather\n",
      "Word: facts, Deprel: conj, Head: opinion\n",
      "Word: of, Deprel: case, Head: law\n",
      "Word: law, Deprel: nmod, Head: facts\n",
      "Word: he, Deprel: nsubj, Head: added\n",
      "Word: added, Deprel: parataxis, Head: felt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Schofield got Toepfer to admit on cross-examination that she ignored many of O'Donnell s suggestions and projects'\n",
      "Word: Schofield, Deprel: nsubj, Head: got\n",
      "Word: got, Deprel: root, Head: ROOT\n",
      "Word: Toepfer, Deprel: obj, Head: got\n",
      "Word: to, Deprel: mark, Head: admit\n",
      "Word: admit, Deprel: xcomp, Head: got\n",
      "Word: on, Deprel: case, Head: cross-examination\n",
      "Word: cross-examination, Deprel: obl, Head: admit\n",
      "Word: that, Deprel: mark, Head: ignored\n",
      "Word: she, Deprel: nsubj, Head: ignored\n",
      "Word: ignored, Deprel: ccomp, Head: admit\n",
      "Word: many, Deprel: obj, Head: ignored\n",
      "Word: of, Deprel: case, Head: suggestions\n",
      "Word: O'Donnell, Deprel: nmod:poss, Head: suggestions\n",
      "Word: s, Deprel: case, Head: O'Donnell\n",
      "Word: suggestions, Deprel: nmod, Head: many\n",
      "Word: and, Deprel: cc, Head: projects\n",
      "Word: projects, Deprel: conj, Head: suggestions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But under cross-examination by O'Donnell s attorney Lorna Schofield Toepfer conceded she had ignored many of O'Donnell s suggestions and projects'\n",
      "Word: But, Deprel: cc, Head: conceded\n",
      "Word: under, Deprel: case, Head: cross-examination\n",
      "Word: cross-examination, Deprel: obl, Head: conceded\n",
      "Word: by, Deprel: case, Head: attorney\n",
      "Word: O'Donnell, Deprel: nmod:poss, Head: attorney\n",
      "Word: s, Deprel: case, Head: O'Donnell\n",
      "Word: attorney, Deprel: compound, Head: Lorna\n",
      "Word: Lorna, Deprel: nsubj, Head: conceded\n",
      "Word: Schofield, Deprel: flat, Head: Lorna\n",
      "Word: Toepfer, Deprel: flat, Head: Lorna\n",
      "Word: conceded, Deprel: root, Head: ROOT\n",
      "Word: she, Deprel: nsubj, Head: ignored\n",
      "Word: had, Deprel: aux, Head: ignored\n",
      "Word: ignored, Deprel: ccomp, Head: conceded\n",
      "Word: many, Deprel: obj, Head: ignored\n",
      "Word: of, Deprel: case, Head: suggestions\n",
      "Word: O'Donnell, Deprel: nmod:poss, Head: suggestions\n",
      "Word: s, Deprel: case, Head: O'Donnell\n",
      "Word: suggestions, Deprel: nmod, Head: many\n",
      "Word: and, Deprel: cc, Head: projects\n",
      "Word: projects, Deprel: conj, Head: suggestions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Standard Poor s 500 Index slipped 4.77 or 0.5 percent to 929.62'\n",
      "Word: The, Deprel: det, Head: Poor\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: nmod:poss, Head: Index\n",
      "Word: s, Deprel: case, Head: Poor\n",
      "Word: 500, Deprel: nummod, Head: Index\n",
      "Word: Index, Deprel: nsubj, Head: slipped\n",
      "Word: slipped, Deprel: root, Head: ROOT\n",
      "Word: 4.77, Deprel: nummod, Head: percent\n",
      "Word: or, Deprel: cc, Head: 0.5\n",
      "Word: 0.5, Deprel: conj, Head: 4.77\n",
      "Word: percent, Deprel: obl:tmod, Head: slipped\n",
      "Word: to, Deprel: case, Head: 929.62\n",
      "Word: 929.62, Deprel: obl, Head: slipped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broad Standard Poor s 500 Index SPX shed 0.17 of a point or just 0.02 percent to 934'\n",
      "Word: The, Deprel: det, Head: Poor\n",
      "Word: broad, Deprel: amod, Head: Poor\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: nmod:poss, Head: SPX\n",
      "Word: s, Deprel: case, Head: Poor\n",
      "Word: 500, Deprel: nummod, Head: Index\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: shed\n",
      "Word: shed, Deprel: root, Head: ROOT\n",
      "Word: 0.17, Deprel: obj, Head: shed\n",
      "Word: of, Deprel: case, Head: point\n",
      "Word: a, Deprel: det, Head: point\n",
      "Word: point, Deprel: nmod, Head: 0.17\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: just, Deprel: advmod, Head: 0.02\n",
      "Word: 0.02, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: 0.17\n",
      "Word: to, Deprel: case, Head: 934\n",
      "Word: 934, Deprel: obl, Head: shed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On May 1 he crawled through a narrow winding canyon rappelled down a 60-foot cliff and walked some six miles down the canyon'\n",
      "Word: On, Deprel: case, Head: 1\n",
      "Word: May, Deprel: compound, Head: 1\n",
      "Word: 1, Deprel: obl, Head: crawled\n",
      "Word: he, Deprel: nsubj, Head: crawled\n",
      "Word: crawled, Deprel: root, Head: ROOT\n",
      "Word: through, Deprel: case, Head: canyon\n",
      "Word: a, Deprel: det, Head: canyon\n",
      "Word: narrow, Deprel: amod, Head: canyon\n",
      "Word: winding, Deprel: amod, Head: canyon\n",
      "Word: canyon, Deprel: obl, Head: crawled\n",
      "Word: rappelled, Deprel: advcl, Head: crawled\n",
      "Word: down, Deprel: case, Head: cliff\n",
      "Word: a, Deprel: det, Head: cliff\n",
      "Word: 60-foot, Deprel: amod, Head: cliff\n",
      "Word: cliff, Deprel: obl, Head: rappelled\n",
      "Word: and, Deprel: cc, Head: walked\n",
      "Word: walked, Deprel: conj, Head: crawled\n",
      "Word: some, Deprel: det, Head: miles\n",
      "Word: six, Deprel: nummod, Head: miles\n",
      "Word: miles, Deprel: nmod:npmod, Head: canyon\n",
      "Word: down, Deprel: case, Head: canyon\n",
      "Word: the, Deprel: det, Head: canyon\n",
      "Word: canyon, Deprel: obl, Head: walked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He crawled through a narrow winding canyon rappelled down a 60-foot cliff and walked some six miles down the canyon near Canyonlands National Park in southeastern Utah'\n",
      "Word: He, Deprel: nsubj, Head: crawled\n",
      "Word: crawled, Deprel: root, Head: ROOT\n",
      "Word: through, Deprel: case, Head: canyon\n",
      "Word: a, Deprel: det, Head: canyon\n",
      "Word: narrow, Deprel: amod, Head: canyon\n",
      "Word: winding, Deprel: amod, Head: canyon\n",
      "Word: canyon, Deprel: obl, Head: crawled\n",
      "Word: rappelled, Deprel: advcl, Head: crawled\n",
      "Word: down, Deprel: case, Head: cliff\n",
      "Word: a, Deprel: det, Head: cliff\n",
      "Word: 60-foot, Deprel: amod, Head: cliff\n",
      "Word: cliff, Deprel: obl, Head: rappelled\n",
      "Word: and, Deprel: cc, Head: walked\n",
      "Word: walked, Deprel: conj, Head: crawled\n",
      "Word: some, Deprel: det, Head: miles\n",
      "Word: six, Deprel: nummod, Head: miles\n",
      "Word: miles, Deprel: nmod:npmod, Head: canyon\n",
      "Word: down, Deprel: case, Head: canyon\n",
      "Word: the, Deprel: det, Head: canyon\n",
      "Word: canyon, Deprel: obl, Head: walked\n",
      "Word: near, Deprel: case, Head: Park\n",
      "Word: Canyonlands, Deprel: compound, Head: Park\n",
      "Word: National, Deprel: amod, Head: Park\n",
      "Word: Park, Deprel: nmod, Head: canyon\n",
      "Word: in, Deprel: case, Head: Utah\n",
      "Word: southeastern, Deprel: amod, Head: Utah\n",
      "Word: Utah, Deprel: nmod, Head: Park\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Amnesty International has said that over the past 20 years it has collected information about 17,000 disappearances in Iraq but the actual figure may be much higher'\n",
      "Word: Amnesty, Deprel: compound, Head: International\n",
      "Word: International, Deprel: nsubj, Head: said\n",
      "Word: has, Deprel: aux, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: collected\n",
      "Word: over, Deprel: case, Head: years\n",
      "Word: the, Deprel: det, Head: years\n",
      "Word: past, Deprel: amod, Head: years\n",
      "Word: 20, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl, Head: collected\n",
      "Word: it, Deprel: nsubj, Head: collected\n",
      "Word: has, Deprel: aux, Head: collected\n",
      "Word: collected, Deprel: ccomp, Head: said\n",
      "Word: information, Deprel: obj, Head: collected\n",
      "Word: about, Deprel: advmod, Head: 17,000\n",
      "Word: 17,000, Deprel: nummod, Head: disappearances\n",
      "Word: disappearances, Deprel: obj, Head: collected\n",
      "Word: in, Deprel: case, Head: Iraq\n",
      "Word: Iraq, Deprel: nmod, Head: disappearances\n",
      "Word: but, Deprel: cc, Head: higher\n",
      "Word: the, Deprel: det, Head: figure\n",
      "Word: actual, Deprel: amod, Head: figure\n",
      "Word: figure, Deprel: nsubj, Head: higher\n",
      "Word: may, Deprel: aux, Head: higher\n",
      "Word: be, Deprel: cop, Head: higher\n",
      "Word: much, Deprel: advmod, Head: higher\n",
      "Word: higher, Deprel: conj, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Amnesty International said that over the past 20 years it had collected information about 17,000 disappearances in Iraq'\n",
      "Word: Amnesty, Deprel: compound, Head: International\n",
      "Word: International, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: collected\n",
      "Word: over, Deprel: case, Head: years\n",
      "Word: the, Deprel: det, Head: years\n",
      "Word: past, Deprel: amod, Head: years\n",
      "Word: 20, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl, Head: collected\n",
      "Word: it, Deprel: nsubj, Head: collected\n",
      "Word: had, Deprel: aux, Head: collected\n",
      "Word: collected, Deprel: ccomp, Head: said\n",
      "Word: information, Deprel: obj, Head: collected\n",
      "Word: about, Deprel: advmod, Head: 17,000\n",
      "Word: 17,000, Deprel: nummod, Head: disappearances\n",
      "Word: disappearances, Deprel: obj, Head: collected\n",
      "Word: in, Deprel: case, Head: Iraq\n",
      "Word: Iraq, Deprel: nmod, Head: disappearances\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Dow Jones Industrial Average fell 0.7 per cent to 9,547.43 while the S P 500 was 0.8 per cent weaker at 1,025.79'\n",
      "Word: The, Deprel: det, Head: Average\n",
      "Word: Dow, Deprel: compound, Head: Average\n",
      "Word: Jones, Deprel: flat, Head: Dow\n",
      "Word: Industrial, Deprel: amod, Head: Average\n",
      "Word: Average, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 0.7, Deprel: nummod, Head: cent\n",
      "Word: per, Deprel: compound, Head: cent\n",
      "Word: cent, Deprel: obl:tmod, Head: fell\n",
      "Word: to, Deprel: case, Head: 9,547.43\n",
      "Word: 9,547.43, Deprel: obl, Head: fell\n",
      "Word: while, Deprel: mark, Head: weaker\n",
      "Word: the, Deprel: det, Head: 500\n",
      "Word: S, Deprel: compound, Head: P\n",
      "Word: P, Deprel: compound, Head: 500\n",
      "Word: 500, Deprel: nsubj, Head: weaker\n",
      "Word: was, Deprel: cop, Head: weaker\n",
      "Word: 0.8, Deprel: nummod, Head: cent\n",
      "Word: per, Deprel: compound, Head: cent\n",
      "Word: cent, Deprel: obl:npmod, Head: weaker\n",
      "Word: weaker, Deprel: advcl, Head: fell\n",
      "Word: at, Deprel: case, Head: 1,025.79\n",
      "Word: 1,025.79, Deprel: obl, Head: weaker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Dow Jones industrial average DJI fell 44 points or 0.46 percent to 9,568'\n",
      "Word: The, Deprel: det, Head: DJI\n",
      "Word: Dow, Deprel: compound, Head: average\n",
      "Word: Jones, Deprel: flat, Head: Dow\n",
      "Word: industrial, Deprel: amod, Head: average\n",
      "Word: average, Deprel: compound, Head: DJI\n",
      "Word: DJI, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 44, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:tmod, Head: fell\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.46, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 9,568\n",
      "Word: 9,568, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Texas Instruments climbed 1.37 to 19.25 yesterday and Novellus Systems Inc advanced 1.76 to 36.31'\n",
      "Word: Texas, Deprel: compound, Head: Instruments\n",
      "Word: Instruments, Deprel: nsubj, Head: climbed\n",
      "Word: climbed, Deprel: root, Head: ROOT\n",
      "Word: 1.37, Deprel: obj, Head: climbed\n",
      "Word: to, Deprel: case, Head: 19.25\n",
      "Word: 19.25, Deprel: nmod, Head: 1.37\n",
      "Word: yesterday, Deprel: obl:tmod, Head: climbed\n",
      "Word: and, Deprel: cc, Head: advanced\n",
      "Word: Novellus, Deprel: compound, Head: Systems\n",
      "Word: Systems, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: nsubj, Head: advanced\n",
      "Word: advanced, Deprel: conj, Head: climbed\n",
      "Word: 1.76, Deprel: obj, Head: advanced\n",
      "Word: to, Deprel: case, Head: 36.31\n",
      "Word: 36.31, Deprel: nmod, Head: 1.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Texas Instruments climbed US1.37 to US19.25 and Novellus Systems advanced US1.76 to US36.31 each having been raised to overweight by Lehman'\n",
      "Word: Texas, Deprel: compound, Head: Instruments\n",
      "Word: Instruments, Deprel: nsubj, Head: climbed\n",
      "Word: climbed, Deprel: root, Head: ROOT\n",
      "Word: US1.37, Deprel: obj, Head: climbed\n",
      "Word: to, Deprel: case, Head: US19.25\n",
      "Word: US19.25, Deprel: nmod, Head: US1.37\n",
      "Word: and, Deprel: cc, Head: advanced\n",
      "Word: Novellus, Deprel: compound, Head: Systems\n",
      "Word: Systems, Deprel: nsubj, Head: advanced\n",
      "Word: advanced, Deprel: conj, Head: climbed\n",
      "Word: US1.76, Deprel: obj, Head: advanced\n",
      "Word: to, Deprel: case, Head: US36.31\n",
      "Word: US36.31, Deprel: nmod, Head: US1.76\n",
      "Word: each, Deprel: nsubj:pass, Head: raised\n",
      "Word: having, Deprel: aux, Head: raised\n",
      "Word: been, Deprel: aux:pass, Head: raised\n",
      "Word: raised, Deprel: advcl, Head: advanced\n",
      "Word: to, Deprel: case, Head: overweight\n",
      "Word: overweight, Deprel: obl, Head: raised\n",
      "Word: by, Deprel: case, Head: Lehman\n",
      "Word: Lehman, Deprel: obl, Head: raised\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'She asked to be excused from last week s Cabinet session to prepare for a meeting with the presidents of Rwanda and Uganda'\n",
      "Word: She, Deprel: nsubj, Head: asked\n",
      "Word: asked, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: excused\n",
      "Word: be, Deprel: aux:pass, Head: excused\n",
      "Word: excused, Deprel: xcomp, Head: asked\n",
      "Word: from, Deprel: case, Head: session\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: nmod:poss, Head: session\n",
      "Word: s, Deprel: case, Head: week\n",
      "Word: Cabinet, Deprel: compound, Head: session\n",
      "Word: session, Deprel: obl, Head: excused\n",
      "Word: to, Deprel: mark, Head: prepare\n",
      "Word: prepare, Deprel: advcl, Head: excused\n",
      "Word: for, Deprel: case, Head: meeting\n",
      "Word: a, Deprel: det, Head: meeting\n",
      "Word: meeting, Deprel: obl, Head: prepare\n",
      "Word: with, Deprel: case, Head: presidents\n",
      "Word: the, Deprel: det, Head: presidents\n",
      "Word: presidents, Deprel: nmod, Head: meeting\n",
      "Word: of, Deprel: case, Head: Rwanda\n",
      "Word: Rwanda, Deprel: nmod, Head: presidents\n",
      "Word: and, Deprel: cc, Head: Uganda\n",
      "Word: Uganda, Deprel: conj, Head: Rwanda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'She took the highly unusual step of skipping cabinet to attend a meeting with the presidents of Rwanda and Uganda'\n",
      "Word: She, Deprel: nsubj, Head: took\n",
      "Word: took, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: step\n",
      "Word: highly, Deprel: advmod, Head: unusual\n",
      "Word: unusual, Deprel: amod, Head: step\n",
      "Word: step, Deprel: obj, Head: took\n",
      "Word: of, Deprel: mark, Head: skipping\n",
      "Word: skipping, Deprel: acl, Head: step\n",
      "Word: cabinet, Deprel: obj, Head: skipping\n",
      "Word: to, Deprel: mark, Head: attend\n",
      "Word: attend, Deprel: advcl, Head: skipping\n",
      "Word: a, Deprel: det, Head: meeting\n",
      "Word: meeting, Deprel: obj, Head: attend\n",
      "Word: with, Deprel: case, Head: presidents\n",
      "Word: the, Deprel: det, Head: presidents\n",
      "Word: presidents, Deprel: nmod, Head: meeting\n",
      "Word: of, Deprel: case, Head: Rwanda\n",
      "Word: Rwanda, Deprel: nmod, Head: presidents\n",
      "Word: and, Deprel: cc, Head: Uganda\n",
      "Word: Uganda, Deprel: conj, Head: Rwanda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We hope all parties will continue to make efforts and continue the process of dialogue the Chinese Foreign Ministry said in a statement'\n",
      "Word: We, Deprel: nsubj, Head: hope\n",
      "Word: hope, Deprel: root, Head: ROOT\n",
      "Word: all, Deprel: det, Head: parties\n",
      "Word: parties, Deprel: nsubj, Head: continue\n",
      "Word: will, Deprel: aux, Head: continue\n",
      "Word: continue, Deprel: ccomp, Head: hope\n",
      "Word: to, Deprel: mark, Head: make\n",
      "Word: make, Deprel: xcomp, Head: continue\n",
      "Word: efforts, Deprel: obj, Head: make\n",
      "Word: and, Deprel: cc, Head: continue\n",
      "Word: continue, Deprel: conj, Head: make\n",
      "Word: the, Deprel: det, Head: process\n",
      "Word: process, Deprel: obj, Head: continue\n",
      "Word: of, Deprel: case, Head: dialogue\n",
      "Word: dialogue, Deprel: nmod, Head: process\n",
      "Word: the, Deprel: det, Head: Ministry\n",
      "Word: Chinese, Deprel: amod, Head: Ministry\n",
      "Word: Foreign, Deprel: amod, Head: Ministry\n",
      "Word: Ministry, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: dialogue\n",
      "Word: in, Deprel: case, Head: statement\n",
      "Word: a, Deprel: det, Head: statement\n",
      "Word: statement, Deprel: obl, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'China s foreign ministry said We hope all parties will continue to make efforts and continue the process of dialogue'\n",
      "Word: China, Deprel: nmod:poss, Head: ministry\n",
      "Word: s, Deprel: case, Head: China\n",
      "Word: foreign, Deprel: amod, Head: ministry\n",
      "Word: ministry, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: We, Deprel: nsubj, Head: hope\n",
      "Word: hope, Deprel: ccomp, Head: said\n",
      "Word: all, Deprel: det, Head: parties\n",
      "Word: parties, Deprel: nsubj, Head: continue\n",
      "Word: will, Deprel: aux, Head: continue\n",
      "Word: continue, Deprel: ccomp, Head: hope\n",
      "Word: to, Deprel: mark, Head: make\n",
      "Word: make, Deprel: xcomp, Head: continue\n",
      "Word: efforts, Deprel: obj, Head: make\n",
      "Word: and, Deprel: cc, Head: continue\n",
      "Word: continue, Deprel: conj, Head: make\n",
      "Word: the, Deprel: det, Head: process\n",
      "Word: process, Deprel: obj, Head: continue\n",
      "Word: of, Deprel: case, Head: dialogue\n",
      "Word: dialogue, Deprel: nmod, Head: process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'School officials said Van-Vliet reported the accident using the bus ’ radio'\n",
      "Word: School, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Van-Vliet, Deprel: nsubj, Head: reported\n",
      "Word: reported, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: accident\n",
      "Word: accident, Deprel: obj, Head: reported\n",
      "Word: using, Deprel: acl, Head: accident\n",
      "Word: the, Deprel: det, Head: bus\n",
      "Word: bus, Deprel: nmod:poss, Head: radio\n",
      "Word: ’, Deprel: case, Head: bus\n",
      "Word: radio, Deprel: obj, Head: using\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Van-Vliet who was also injured called in the accident on the school bus radio'\n",
      "Word: Van-Vliet, Deprel: nsubj, Head: called\n",
      "Word: who, Deprel: nsubj:pass, Head: injured\n",
      "Word: was, Deprel: aux:pass, Head: injured\n",
      "Word: also, Deprel: advmod, Head: injured\n",
      "Word: injured, Deprel: acl:relcl, Head: Van-Vliet\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: accident\n",
      "Word: the, Deprel: det, Head: accident\n",
      "Word: accident, Deprel: obl, Head: called\n",
      "Word: on, Deprel: case, Head: radio\n",
      "Word: the, Deprel: det, Head: radio\n",
      "Word: school, Deprel: compound, Head: radio\n",
      "Word: bus, Deprel: compound, Head: radio\n",
      "Word: radio, Deprel: nmod, Head: accident\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In a mixture of ancient pagan and modern Christian rites the villagers have staged a series of ceremonies hoping to erase the misfortunes they believe have kept them poor'\n",
      "Word: In, Deprel: case, Head: mixture\n",
      "Word: a, Deprel: det, Head: mixture\n",
      "Word: mixture, Deprel: obl, Head: staged\n",
      "Word: of, Deprel: case, Head: pagan\n",
      "Word: ancient, Deprel: amod, Head: pagan\n",
      "Word: pagan, Deprel: nmod, Head: mixture\n",
      "Word: and, Deprel: cc, Head: rites\n",
      "Word: modern, Deprel: amod, Head: rites\n",
      "Word: Christian, Deprel: amod, Head: rites\n",
      "Word: rites, Deprel: conj, Head: pagan\n",
      "Word: the, Deprel: det, Head: villagers\n",
      "Word: villagers, Deprel: nsubj, Head: staged\n",
      "Word: have, Deprel: aux, Head: staged\n",
      "Word: staged, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: series\n",
      "Word: series, Deprel: obj, Head: staged\n",
      "Word: of, Deprel: case, Head: ceremonies\n",
      "Word: ceremonies, Deprel: nmod, Head: series\n",
      "Word: hoping, Deprel: acl, Head: ceremonies\n",
      "Word: to, Deprel: mark, Head: erase\n",
      "Word: erase, Deprel: xcomp, Head: hoping\n",
      "Word: the, Deprel: det, Head: misfortunes\n",
      "Word: misfortunes, Deprel: obj, Head: erase\n",
      "Word: they, Deprel: nsubj, Head: believe\n",
      "Word: believe, Deprel: acl:relcl, Head: misfortunes\n",
      "Word: have, Deprel: aux, Head: kept\n",
      "Word: kept, Deprel: ccomp, Head: believe\n",
      "Word: them, Deprel: obj, Head: kept\n",
      "Word: poor, Deprel: xcomp, Head: kept\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In a mixture of ancient Melanesian pagan and modern Christian ceremonies the people tried again to erase the misfortunes they believe have kept them poor since that long-ago meal'\n",
      "Word: In, Deprel: case, Head: mixture\n",
      "Word: a, Deprel: det, Head: mixture\n",
      "Word: mixture, Deprel: obl, Head: tried\n",
      "Word: of, Deprel: case, Head: ceremonies\n",
      "Word: ancient, Deprel: amod, Head: pagan\n",
      "Word: Melanesian, Deprel: amod, Head: pagan\n",
      "Word: pagan, Deprel: amod, Head: ceremonies\n",
      "Word: and, Deprel: cc, Head: Christian\n",
      "Word: modern, Deprel: amod, Head: Christian\n",
      "Word: Christian, Deprel: amod, Head: ceremonies\n",
      "Word: ceremonies, Deprel: nmod, Head: mixture\n",
      "Word: the, Deprel: det, Head: people\n",
      "Word: people, Deprel: nsubj, Head: tried\n",
      "Word: tried, Deprel: root, Head: ROOT\n",
      "Word: again, Deprel: advmod, Head: tried\n",
      "Word: to, Deprel: mark, Head: erase\n",
      "Word: erase, Deprel: xcomp, Head: tried\n",
      "Word: the, Deprel: det, Head: misfortunes\n",
      "Word: misfortunes, Deprel: obj, Head: erase\n",
      "Word: they, Deprel: nsubj, Head: believe\n",
      "Word: believe, Deprel: acl:relcl, Head: misfortunes\n",
      "Word: have, Deprel: aux, Head: kept\n",
      "Word: kept, Deprel: ccomp, Head: believe\n",
      "Word: them, Deprel: obj, Head: kept\n",
      "Word: poor, Deprel: xcomp, Head: kept\n",
      "Word: since, Deprel: case, Head: meal\n",
      "Word: that, Deprel: det, Head: meal\n",
      "Word: long-ago, Deprel: amod, Head: meal\n",
      "Word: meal, Deprel: obl, Head: kept\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Dow Jones industrial average DJI edged up 13.33 points or 0.15 percent to 9,196.55'\n",
      "Word: The, Deprel: det, Head: DJI\n",
      "Word: Dow, Deprel: compound, Head: average\n",
      "Word: Jones, Deprel: flat, Head: Dow\n",
      "Word: industrial, Deprel: compound, Head: average\n",
      "Word: average, Deprel: compound, Head: DJI\n",
      "Word: DJI, Deprel: nsubj, Head: edged\n",
      "Word: edged, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: advmod, Head: edged\n",
      "Word: 13.33, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:tmod, Head: edged\n",
      "Word: or, Deprel: case, Head: percent\n",
      "Word: 0.15, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 9,196.55\n",
      "Word: 9,196.55, Deprel: obl, Head: edged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Dow Jones industrial average DJI was off 7.75 points or 0.08 percent at 9,175.47'\n",
      "Word: The, Deprel: det, Head: DJI\n",
      "Word: Dow, Deprel: compound, Head: Jones\n",
      "Word: Jones, Deprel: compound, Head: average\n",
      "Word: industrial, Deprel: compound, Head: average\n",
      "Word: average, Deprel: compound, Head: DJI\n",
      "Word: DJI, Deprel: nsubj, Head: off\n",
      "Word: was, Deprel: cop, Head: off\n",
      "Word: off, Deprel: root, Head: ROOT\n",
      "Word: 7.75, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: off\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.08, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 9,175.47\n",
      "Word: 9,175.47, Deprel: obl, Head: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Monkeypox is usually found only in central and western Africa'\n",
      "Word: Monkeypox, Deprel: nsubj:pass, Head: found\n",
      "Word: is, Deprel: aux:pass, Head: found\n",
      "Word: usually, Deprel: advmod, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: only, Deprel: advmod, Head: found\n",
      "Word: in, Deprel: case, Head: Africa\n",
      "Word: central, Deprel: amod, Head: Africa\n",
      "Word: and, Deprel: cc, Head: western\n",
      "Word: western, Deprel: conj, Head: central\n",
      "Word: Africa, Deprel: obl, Head: found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Prairie dogs usually found in southwestern and western states aren ’ t indigenous to Wisconsin'\n",
      "Word: Prairie, Deprel: amod, Head: dogs\n",
      "Word: dogs, Deprel: nsubj, Head: found\n",
      "Word: usually, Deprel: advmod, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: states\n",
      "Word: southwestern, Deprel: amod, Head: states\n",
      "Word: and, Deprel: cc, Head: western\n",
      "Word: western, Deprel: conj, Head: southwestern\n",
      "Word: states, Deprel: obl, Head: found\n",
      "Word: aren, Deprel: nsubj, Head: indigenous\n",
      "Word: ’, Deprel: case, Head: aren\n",
      "Word: t, Deprel: advmod, Head: indigenous\n",
      "Word: indigenous, Deprel: ccomp, Head: found\n",
      "Word: to, Deprel: case, Head: Wisconsin\n",
      "Word: Wisconsin, Deprel: obl, Head: indigenous\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Board Chancellor Robert Bennett declined to comment on personnel matters Tuesday'\n",
      "Word: Board, Deprel: compound, Head: Chancellor\n",
      "Word: Chancellor, Deprel: nsubj, Head: declined\n",
      "Word: Robert, Deprel: flat, Head: Chancellor\n",
      "Word: Bennett, Deprel: flat, Head: Robert\n",
      "Word: declined, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: comment\n",
      "Word: comment, Deprel: xcomp, Head: declined\n",
      "Word: on, Deprel: case, Head: matters\n",
      "Word: personnel, Deprel: compound, Head: matters\n",
      "Word: matters, Deprel: obl, Head: comment\n",
      "Word: Tuesday, Deprel: obl:tmod, Head: comment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Mills declined to comment yesterday saying that he never discussed personnel matters'\n",
      "Word: Mr, Deprel: nsubj, Head: declined\n",
      "Word: Mills, Deprel: flat, Head: Mr\n",
      "Word: declined, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: comment\n",
      "Word: comment, Deprel: xcomp, Head: declined\n",
      "Word: yesterday, Deprel: obl:tmod, Head: comment\n",
      "Word: saying, Deprel: advcl, Head: comment\n",
      "Word: that, Deprel: mark, Head: discussed\n",
      "Word: he, Deprel: nsubj, Head: discussed\n",
      "Word: never, Deprel: advmod, Head: discussed\n",
      "Word: discussed, Deprel: ccomp, Head: saying\n",
      "Word: personnel, Deprel: compound, Head: matters\n",
      "Word: matters, Deprel: obj, Head: discussed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In that case the court held that Cincinnati had violated the First Amendment in banning only the advertising pamphlets in the interest of aesthetics'\n",
      "Word: In, Deprel: case, Head: case\n",
      "Word: that, Deprel: det, Head: case\n",
      "Word: case, Deprel: obl, Head: held\n",
      "Word: the, Deprel: det, Head: court\n",
      "Word: court, Deprel: nsubj, Head: held\n",
      "Word: held, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: violated\n",
      "Word: Cincinnati, Deprel: nsubj, Head: violated\n",
      "Word: had, Deprel: aux, Head: violated\n",
      "Word: violated, Deprel: ccomp, Head: held\n",
      "Word: the, Deprel: det, Head: Amendment\n",
      "Word: First, Deprel: amod, Head: Amendment\n",
      "Word: Amendment, Deprel: obj, Head: violated\n",
      "Word: in, Deprel: mark, Head: banning\n",
      "Word: banning, Deprel: advcl, Head: violated\n",
      "Word: only, Deprel: advmod, Head: pamphlets\n",
      "Word: the, Deprel: det, Head: pamphlets\n",
      "Word: advertising, Deprel: compound, Head: pamphlets\n",
      "Word: pamphlets, Deprel: obj, Head: banning\n",
      "Word: in, Deprel: case, Head: interest\n",
      "Word: the, Deprel: det, Head: interest\n",
      "Word: interest, Deprel: obl, Head: banning\n",
      "Word: of, Deprel: case, Head: aesthetics\n",
      "Word: aesthetics, Deprel: nmod, Head: interest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In that case the court held that the city of Cincinnati had violated the First Amendment in banning in the interest of aesthetics only the advertising pamphlets'\n",
      "Word: In, Deprel: case, Head: case\n",
      "Word: that, Deprel: det, Head: case\n",
      "Word: case, Deprel: obl, Head: held\n",
      "Word: the, Deprel: det, Head: court\n",
      "Word: court, Deprel: nsubj, Head: held\n",
      "Word: held, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: violated\n",
      "Word: the, Deprel: det, Head: city\n",
      "Word: city, Deprel: nsubj, Head: violated\n",
      "Word: of, Deprel: case, Head: Cincinnati\n",
      "Word: Cincinnati, Deprel: nmod, Head: city\n",
      "Word: had, Deprel: aux, Head: violated\n",
      "Word: violated, Deprel: ccomp, Head: held\n",
      "Word: the, Deprel: det, Head: Amendment\n",
      "Word: First, Deprel: amod, Head: Amendment\n",
      "Word: Amendment, Deprel: obj, Head: violated\n",
      "Word: in, Deprel: mark, Head: banning\n",
      "Word: banning, Deprel: advcl, Head: violated\n",
      "Word: in, Deprel: case, Head: interest\n",
      "Word: the, Deprel: det, Head: interest\n",
      "Word: interest, Deprel: obl, Head: banning\n",
      "Word: of, Deprel: case, Head: aesthetics\n",
      "Word: aesthetics, Deprel: nmod, Head: interest\n",
      "Word: only, Deprel: advmod, Head: pamphlets\n",
      "Word: the, Deprel: det, Head: pamphlets\n",
      "Word: advertising, Deprel: compound, Head: pamphlets\n",
      "Word: pamphlets, Deprel: appos, Head: aesthetics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The film is the second of a trilogy which will wrap up in November with The Matrix Revolutions'\n",
      "Word: The, Deprel: det, Head: film\n",
      "Word: film, Deprel: nsubj, Head: second\n",
      "Word: is, Deprel: cop, Head: second\n",
      "Word: the, Deprel: det, Head: second\n",
      "Word: second, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: trilogy\n",
      "Word: a, Deprel: det, Head: trilogy\n",
      "Word: trilogy, Deprel: nmod, Head: second\n",
      "Word: which, Deprel: nsubj, Head: wrap\n",
      "Word: will, Deprel: aux, Head: wrap\n",
      "Word: wrap, Deprel: acl:relcl, Head: trilogy\n",
      "Word: up, Deprel: compound:prt, Head: wrap\n",
      "Word: in, Deprel: case, Head: November\n",
      "Word: November, Deprel: obl, Head: wrap\n",
      "Word: with, Deprel: case, Head: Revolutions\n",
      "Word: The, Deprel: det, Head: Revolutions\n",
      "Word: Matrix, Deprel: compound, Head: Revolutions\n",
      "Word: Revolutions, Deprel: obl, Head: wrap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Reloaded is the second installment of a trilogy The Matrix Revolutions is slated for debut in November'\n",
      "Word: Reloaded, Deprel: csubj, Head: installment\n",
      "Word: is, Deprel: cop, Head: installment\n",
      "Word: the, Deprel: det, Head: installment\n",
      "Word: second, Deprel: amod, Head: installment\n",
      "Word: installment, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: trilogy\n",
      "Word: a, Deprel: det, Head: trilogy\n",
      "Word: trilogy, Deprel: nmod, Head: installment\n",
      "Word: The, Deprel: det, Head: Revolutions\n",
      "Word: Matrix, Deprel: compound, Head: Revolutions\n",
      "Word: Revolutions, Deprel: nsubj:pass, Head: slated\n",
      "Word: is, Deprel: aux:pass, Head: slated\n",
      "Word: slated, Deprel: acl:relcl, Head: trilogy\n",
      "Word: for, Deprel: case, Head: debut\n",
      "Word: debut, Deprel: obl, Head: slated\n",
      "Word: in, Deprel: case, Head: November\n",
      "Word: November, Deprel: obl, Head: slated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In addition the Justice Department said that the FBI has conducted fewer than 10 investigations involving visits to mosques'\n",
      "Word: In, Deprel: case, Head: addition\n",
      "Word: addition, Deprel: obl, Head: said\n",
      "Word: the, Deprel: det, Head: Department\n",
      "Word: Justice, Deprel: compound, Head: Department\n",
      "Word: Department, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: conducted\n",
      "Word: the, Deprel: det, Head: FBI\n",
      "Word: FBI, Deprel: nsubj, Head: conducted\n",
      "Word: has, Deprel: aux, Head: conducted\n",
      "Word: conducted, Deprel: ccomp, Head: said\n",
      "Word: fewer, Deprel: advmod, Head: 10\n",
      "Word: than, Deprel: fixed, Head: fewer\n",
      "Word: 10, Deprel: nummod, Head: investigations\n",
      "Word: investigations, Deprel: obj, Head: conducted\n",
      "Word: involving, Deprel: acl, Head: investigations\n",
      "Word: visits, Deprel: obj, Head: involving\n",
      "Word: to, Deprel: case, Head: mosques\n",
      "Word: mosques, Deprel: nmod, Head: visits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In addition fewer than 10 FBI offices have conducted investigations involving visits to Islamic mosques the Justice Department said'\n",
      "Word: In, Deprel: case, Head: addition\n",
      "Word: addition, Deprel: obl, Head: conducted\n",
      "Word: fewer, Deprel: advmod, Head: 10\n",
      "Word: than, Deprel: fixed, Head: fewer\n",
      "Word: 10, Deprel: nummod, Head: offices\n",
      "Word: FBI, Deprel: compound, Head: offices\n",
      "Word: offices, Deprel: nsubj, Head: conducted\n",
      "Word: have, Deprel: aux, Head: conducted\n",
      "Word: conducted, Deprel: root, Head: ROOT\n",
      "Word: investigations, Deprel: obj, Head: conducted\n",
      "Word: involving, Deprel: acl, Head: investigations\n",
      "Word: visits, Deprel: obj, Head: involving\n",
      "Word: to, Deprel: case, Head: mosques\n",
      "Word: Islamic, Deprel: amod, Head: mosques\n",
      "Word: mosques, Deprel: nmod, Head: visits\n",
      "Word: the, Deprel: det, Head: Department\n",
      "Word: Justice, Deprel: compound, Head: Department\n",
      "Word: Department, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: mosques\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The launch coincides with the JavaOne developers conference in San Francisco this week'\n",
      "Word: The, Deprel: det, Head: launch\n",
      "Word: launch, Deprel: nsubj, Head: coincides\n",
      "Word: coincides, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: conference\n",
      "Word: the, Deprel: det, Head: conference\n",
      "Word: JavaOne, Deprel: compound, Head: conference\n",
      "Word: developers, Deprel: compound, Head: conference\n",
      "Word: conference, Deprel: obl, Head: coincides\n",
      "Word: in, Deprel: case, Head: Francisco\n",
      "Word: San, Deprel: compound, Head: Francisco\n",
      "Word: Francisco, Deprel: nmod, Head: conference\n",
      "Word: this, Deprel: det, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: coincides\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The news also comes in conjunction with Suns annual JavaOne developers conference in San Francisco'\n",
      "Word: The, Deprel: det, Head: news\n",
      "Word: news, Deprel: nsubj, Head: comes\n",
      "Word: also, Deprel: advmod, Head: comes\n",
      "Word: comes, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: conjunction\n",
      "Word: conjunction, Deprel: obl, Head: comes\n",
      "Word: with, Deprel: case, Head: conference\n",
      "Word: Suns, Deprel: compound, Head: conference\n",
      "Word: annual, Deprel: amod, Head: conference\n",
      "Word: JavaOne, Deprel: compound, Head: developers\n",
      "Word: developers, Deprel: compound, Head: conference\n",
      "Word: conference, Deprel: nmod, Head: conjunction\n",
      "Word: in, Deprel: case, Head: San\n",
      "Word: San, Deprel: nmod, Head: conference\n",
      "Word: Francisco, Deprel: flat, Head: San\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A Royal Duty is based on his experiences with Diana Princess of Wales and letters allegedly to and from her'\n",
      "Word: A, Deprel: det, Head: Duty\n",
      "Word: Royal, Deprel: amod, Head: Duty\n",
      "Word: Duty, Deprel: nsubj:pass, Head: based\n",
      "Word: is, Deprel: aux:pass, Head: based\n",
      "Word: based, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: experiences\n",
      "Word: his, Deprel: nmod:poss, Head: experiences\n",
      "Word: experiences, Deprel: obl, Head: based\n",
      "Word: with, Deprel: case, Head: Princess\n",
      "Word: Diana, Deprel: compound, Head: Princess\n",
      "Word: Princess, Deprel: nmod, Head: experiences\n",
      "Word: of, Deprel: case, Head: Wales\n",
      "Word: Wales, Deprel: nmod, Head: Princess\n",
      "Word: and, Deprel: cc, Head: letters\n",
      "Word: letters, Deprel: conj, Head: Princess\n",
      "Word: allegedly, Deprel: advmod, Head: to\n",
      "Word: to, Deprel: case, Head: her\n",
      "Word: and, Deprel: cc, Head: from\n",
      "Word: from, Deprel: conj, Head: to\n",
      "Word: her, Deprel: nmod, Head: letters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The royal household was bracing itself for any more revelations in A Royal Duty based on the former servant ’ s time with Diana Princess of Wales'\n",
      "Word: The, Deprel: det, Head: household\n",
      "Word: royal, Deprel: amod, Head: household\n",
      "Word: household, Deprel: nsubj, Head: bracing\n",
      "Word: was, Deprel: aux, Head: bracing\n",
      "Word: bracing, Deprel: root, Head: ROOT\n",
      "Word: itself, Deprel: obj, Head: bracing\n",
      "Word: for, Deprel: case, Head: revelations\n",
      "Word: any, Deprel: det, Head: revelations\n",
      "Word: more, Deprel: amod, Head: revelations\n",
      "Word: revelations, Deprel: obl, Head: bracing\n",
      "Word: in, Deprel: case, Head: Duty\n",
      "Word: A, Deprel: det, Head: Duty\n",
      "Word: Royal, Deprel: amod, Head: Duty\n",
      "Word: Duty, Deprel: nmod, Head: revelations\n",
      "Word: based, Deprel: acl, Head: revelations\n",
      "Word: on, Deprel: case, Head: time\n",
      "Word: the, Deprel: det, Head: servant\n",
      "Word: former, Deprel: amod, Head: servant\n",
      "Word: servant, Deprel: nmod:poss, Head: time\n",
      "Word: ’, Deprel: case, Head: servant\n",
      "Word: s, Deprel: case, Head: servant\n",
      "Word: time, Deprel: obl, Head: based\n",
      "Word: with, Deprel: case, Head: Diana\n",
      "Word: Diana, Deprel: nmod, Head: time\n",
      "Word: Princess, Deprel: flat, Head: Diana\n",
      "Word: of, Deprel: case, Head: Wales\n",
      "Word: Wales, Deprel: nmod, Head: Diana\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The army said the raid which comes just days after Israeli troops shot and killed Abdullah Kawasme the Hamas leader in the city targeted militants in Hamas'\n",
      "Word: The, Deprel: det, Head: army\n",
      "Word: army, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: raid\n",
      "Word: raid, Deprel: obj, Head: said\n",
      "Word: which, Deprel: nsubj, Head: comes\n",
      "Word: comes, Deprel: acl:relcl, Head: raid\n",
      "Word: just, Deprel: advmod, Head: days\n",
      "Word: days, Deprel: obl:tmod, Head: comes\n",
      "Word: after, Deprel: mark, Head: shot\n",
      "Word: Israeli, Deprel: amod, Head: troops\n",
      "Word: troops, Deprel: nsubj, Head: shot\n",
      "Word: shot, Deprel: advcl, Head: comes\n",
      "Word: and, Deprel: cc, Head: killed\n",
      "Word: killed, Deprel: conj, Head: shot\n",
      "Word: Abdullah, Deprel: obj, Head: killed\n",
      "Word: Kawasme, Deprel: flat, Head: Abdullah\n",
      "Word: the, Deprel: det, Head: leader\n",
      "Word: Hamas, Deprel: compound, Head: leader\n",
      "Word: leader, Deprel: appos, Head: Abdullah\n",
      "Word: in, Deprel: case, Head: city\n",
      "Word: the, Deprel: det, Head: city\n",
      "Word: city, Deprel: obl, Head: killed\n",
      "Word: targeted, Deprel: ccomp, Head: said\n",
      "Word: militants, Deprel: obj, Head: targeted\n",
      "Word: in, Deprel: case, Head: Hamas\n",
      "Word: Hamas, Deprel: nmod, Head: militants\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The arrests came just days after Israeli troops shot and killed Abdullah Kawasme the militant group s leader in Hebron'\n",
      "Word: The, Deprel: det, Head: arrests\n",
      "Word: arrests, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: root, Head: ROOT\n",
      "Word: just, Deprel: advmod, Head: days\n",
      "Word: days, Deprel: obl:tmod, Head: came\n",
      "Word: after, Deprel: mark, Head: shot\n",
      "Word: Israeli, Deprel: amod, Head: troops\n",
      "Word: troops, Deprel: nsubj, Head: shot\n",
      "Word: shot, Deprel: advcl, Head: came\n",
      "Word: and, Deprel: cc, Head: killed\n",
      "Word: killed, Deprel: conj, Head: shot\n",
      "Word: Abdullah, Deprel: obj, Head: killed\n",
      "Word: Kawasme, Deprel: flat, Head: Abdullah\n",
      "Word: the, Deprel: det, Head: group\n",
      "Word: militant, Deprel: amod, Head: group\n",
      "Word: group, Deprel: nmod:poss, Head: leader\n",
      "Word: s, Deprel: case, Head: group\n",
      "Word: leader, Deprel: appos, Head: Abdullah\n",
      "Word: in, Deprel: case, Head: Hebron\n",
      "Word: Hebron, Deprel: nmod, Head: leader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Its former chief Mickey Robinson was fired for cause when he left in September the company said'\n",
      "Word: Its, Deprel: nmod:poss, Head: chief\n",
      "Word: former, Deprel: amod, Head: chief\n",
      "Word: chief, Deprel: compound, Head: Mickey\n",
      "Word: Mickey, Deprel: nsubj:pass, Head: fired\n",
      "Word: Robinson, Deprel: flat, Head: Mickey\n",
      "Word: was, Deprel: aux:pass, Head: fired\n",
      "Word: fired, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: cause\n",
      "Word: cause, Deprel: obl, Head: fired\n",
      "Word: when, Deprel: advmod, Head: left\n",
      "Word: he, Deprel: nsubj, Head: left\n",
      "Word: left, Deprel: advcl, Head: fired\n",
      "Word: in, Deprel: case, Head: September\n",
      "Word: September, Deprel: obl, Head: left\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: ccomp, Head: left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Chief Executive Mickey Robinson was fired for cause in September the company said last month'\n",
      "Word: Chief, Deprel: amod, Head: Executive\n",
      "Word: Executive, Deprel: compound, Head: Mickey\n",
      "Word: Mickey, Deprel: nsubj:pass, Head: fired\n",
      "Word: Robinson, Deprel: flat, Head: Mickey\n",
      "Word: was, Deprel: aux:pass, Head: fired\n",
      "Word: fired, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: mark, Head: said\n",
      "Word: cause, Deprel: mark, Head: said\n",
      "Word: in, Deprel: case, Head: September\n",
      "Word: September, Deprel: obl, Head: said\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: advcl, Head: fired\n",
      "Word: last, Deprel: amod, Head: month\n",
      "Word: month, Deprel: obl:tmod, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'SARS went on to claim the lives of 44 people in the Toronto area including two nurses and a doctor'\n",
      "Word: SARS, Deprel: nsubj, Head: went\n",
      "Word: went, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: advmod, Head: went\n",
      "Word: to, Deprel: mark, Head: claim\n",
      "Word: claim, Deprel: advcl, Head: went\n",
      "Word: the, Deprel: det, Head: lives\n",
      "Word: lives, Deprel: obj, Head: claim\n",
      "Word: of, Deprel: case, Head: people\n",
      "Word: 44, Deprel: nummod, Head: people\n",
      "Word: people, Deprel: nmod, Head: lives\n",
      "Word: in, Deprel: case, Head: area\n",
      "Word: the, Deprel: det, Head: area\n",
      "Word: Toronto, Deprel: compound, Head: area\n",
      "Word: area, Deprel: nmod, Head: people\n",
      "Word: including, Deprel: case, Head: nurses\n",
      "Word: two, Deprel: nummod, Head: nurses\n",
      "Word: nurses, Deprel: nmod, Head: people\n",
      "Word: and, Deprel: cc, Head: doctor\n",
      "Word: a, Deprel: det, Head: doctor\n",
      "Word: doctor, Deprel: conj, Head: nurses\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The virus killed 44 people in the Toronto area including one doctor and two nurses'\n",
      "Word: The, Deprel: det, Head: virus\n",
      "Word: virus, Deprel: nsubj, Head: killed\n",
      "Word: killed, Deprel: root, Head: ROOT\n",
      "Word: 44, Deprel: nummod, Head: people\n",
      "Word: people, Deprel: obj, Head: killed\n",
      "Word: in, Deprel: case, Head: area\n",
      "Word: the, Deprel: det, Head: area\n",
      "Word: Toronto, Deprel: compound, Head: area\n",
      "Word: area, Deprel: nmod, Head: people\n",
      "Word: including, Deprel: case, Head: doctor\n",
      "Word: one, Deprel: nummod, Head: doctor\n",
      "Word: doctor, Deprel: obl, Head: killed\n",
      "Word: and, Deprel: cc, Head: nurses\n",
      "Word: two, Deprel: nummod, Head: nurses\n",
      "Word: nurses, Deprel: conj, Head: doctor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Apple Computer s new online music service sold more than 1 million songs during its first week of operation the company said Monday'\n",
      "Word: Apple, Deprel: compound, Head: Computer\n",
      "Word: Computer, Deprel: nmod:poss, Head: service\n",
      "Word: s, Deprel: case, Head: Computer\n",
      "Word: new, Deprel: amod, Head: service\n",
      "Word: online, Deprel: amod, Head: service\n",
      "Word: music, Deprel: compound, Head: service\n",
      "Word: service, Deprel: nsubj, Head: sold\n",
      "Word: sold, Deprel: root, Head: ROOT\n",
      "Word: more, Deprel: advmod, Head: million\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 1, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: songs\n",
      "Word: songs, Deprel: obj, Head: sold\n",
      "Word: during, Deprel: case, Head: week\n",
      "Word: its, Deprel: nmod:poss, Head: week\n",
      "Word: first, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl, Head: sold\n",
      "Word: of, Deprel: case, Head: operation\n",
      "Word: operation, Deprel: nmod, Head: week\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: sold\n",
      "Word: Monday, Deprel: obj, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Apple Computer Inc said Monday it exceeded record industry expectations by selling more than 1 million songs since the launch of its online music store a week ago'\n",
      "Word: Apple, Deprel: compound, Head: Inc\n",
      "Word: Computer, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Monday, Deprel: obl:tmod, Head: said\n",
      "Word: it, Deprel: nsubj, Head: exceeded\n",
      "Word: exceeded, Deprel: ccomp, Head: said\n",
      "Word: record, Deprel: compound, Head: expectations\n",
      "Word: industry, Deprel: compound, Head: expectations\n",
      "Word: expectations, Deprel: obj, Head: exceeded\n",
      "Word: by, Deprel: mark, Head: selling\n",
      "Word: selling, Deprel: advcl, Head: exceeded\n",
      "Word: more, Deprel: advmod, Head: million\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 1, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: songs\n",
      "Word: songs, Deprel: obj, Head: selling\n",
      "Word: since, Deprel: case, Head: launch\n",
      "Word: the, Deprel: det, Head: launch\n",
      "Word: launch, Deprel: obl, Head: selling\n",
      "Word: of, Deprel: case, Head: store\n",
      "Word: its, Deprel: nmod:poss, Head: store\n",
      "Word: online, Deprel: amod, Head: store\n",
      "Word: music, Deprel: compound, Head: store\n",
      "Word: store, Deprel: nmod, Head: launch\n",
      "Word: a, Deprel: det, Head: week\n",
      "Word: week, Deprel: obl:npmod, Head: ago\n",
      "Word: ago, Deprel: advmod, Head: launch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He had been arrested twice before for trespassing and barred from the complex home to his mother and two children'\n",
      "Word: He, Deprel: nsubj:pass, Head: arrested\n",
      "Word: had, Deprel: aux, Head: arrested\n",
      "Word: been, Deprel: aux:pass, Head: arrested\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: twice, Deprel: advmod, Head: before\n",
      "Word: before, Deprel: advmod, Head: arrested\n",
      "Word: for, Deprel: case, Head: trespassing\n",
      "Word: trespassing, Deprel: obl, Head: arrested\n",
      "Word: and, Deprel: cc, Head: barred\n",
      "Word: barred, Deprel: conj, Head: arrested\n",
      "Word: from, Deprel: case, Head: complex\n",
      "Word: the, Deprel: det, Head: complex\n",
      "Word: complex, Deprel: obl, Head: barred\n",
      "Word: home, Deprel: advmod, Head: complex\n",
      "Word: to, Deprel: case, Head: mother\n",
      "Word: his, Deprel: nmod:poss, Head: mother\n",
      "Word: mother, Deprel: obl, Head: barred\n",
      "Word: and, Deprel: cc, Head: children\n",
      "Word: two, Deprel: nummod, Head: children\n",
      "Word: children, Deprel: conj, Head: mother\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He had been arrested twice before for trespassing and was barred from the complex'\n",
      "Word: He, Deprel: nsubj:pass, Head: arrested\n",
      "Word: had, Deprel: aux, Head: arrested\n",
      "Word: been, Deprel: aux:pass, Head: arrested\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: twice, Deprel: advmod, Head: before\n",
      "Word: before, Deprel: advmod, Head: arrested\n",
      "Word: for, Deprel: case, Head: trespassing\n",
      "Word: trespassing, Deprel: obl, Head: arrested\n",
      "Word: and, Deprel: cc, Head: barred\n",
      "Word: was, Deprel: aux:pass, Head: barred\n",
      "Word: barred, Deprel: conj, Head: arrested\n",
      "Word: from, Deprel: case, Head: complex\n",
      "Word: the, Deprel: det, Head: complex\n",
      "Word: complex, Deprel: obl, Head: barred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Oracle Corp s Chairman and CEO Larry Ellison did n't rule out sweetening the company s unsolicited offer to acquire rival PeopleSoft Inc'\n",
      "Word: Oracle, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: nmod:poss, Head: Chairman\n",
      "Word: s, Deprel: case, Head: Corp\n",
      "Word: Chairman, Deprel: compound, Head: Larry\n",
      "Word: and, Deprel: cc, Head: CEO\n",
      "Word: CEO, Deprel: conj, Head: Chairman\n",
      "Word: Larry, Deprel: nsubj, Head: rule\n",
      "Word: Ellison, Deprel: flat, Head: Larry\n",
      "Word: did, Deprel: aux, Head: rule\n",
      "Word: n't, Deprel: advmod, Head: rule\n",
      "Word: rule, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: compound:prt, Head: rule\n",
      "Word: sweetening, Deprel: xcomp, Head: rule\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nmod:poss, Head: offer\n",
      "Word: s, Deprel: case, Head: company\n",
      "Word: unsolicited, Deprel: amod, Head: offer\n",
      "Word: offer, Deprel: obj, Head: sweetening\n",
      "Word: to, Deprel: mark, Head: acquire\n",
      "Word: acquire, Deprel: acl, Head: offer\n",
      "Word: rival, Deprel: amod, Head: Inc\n",
      "Word: PeopleSoft, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: obj, Head: acquire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Oracle chairman Larry Ellison has hinted that the company could yet again increase its offer for rival PeopleSoft'\n",
      "Word: Oracle, Deprel: compound, Head: chairman\n",
      "Word: chairman, Deprel: compound, Head: Larry\n",
      "Word: Larry, Deprel: nsubj, Head: hinted\n",
      "Word: Ellison, Deprel: flat, Head: Larry\n",
      "Word: has, Deprel: aux, Head: hinted\n",
      "Word: hinted, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: increase\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: increase\n",
      "Word: could, Deprel: aux, Head: increase\n",
      "Word: yet, Deprel: advmod, Head: again\n",
      "Word: again, Deprel: advmod, Head: increase\n",
      "Word: increase, Deprel: ccomp, Head: hinted\n",
      "Word: its, Deprel: nmod:poss, Head: offer\n",
      "Word: offer, Deprel: obj, Head: increase\n",
      "Word: for, Deprel: case, Head: PeopleSoft\n",
      "Word: rival, Deprel: amod, Head: PeopleSoft\n",
      "Word: PeopleSoft, Deprel: nmod, Head: offer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Box cutters were used as a weapon by the Sept 11 2001 hijackers and have since been banned as carry-on items'\n",
      "Word: Box, Deprel: compound, Head: cutters\n",
      "Word: cutters, Deprel: nsubj:pass, Head: used\n",
      "Word: were, Deprel: aux:pass, Head: used\n",
      "Word: used, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: case, Head: weapon\n",
      "Word: a, Deprel: det, Head: weapon\n",
      "Word: weapon, Deprel: obl, Head: used\n",
      "Word: by, Deprel: case, Head: hijackers\n",
      "Word: the, Deprel: det, Head: hijackers\n",
      "Word: Sept, Deprel: compound, Head: hijackers\n",
      "Word: 11, Deprel: nummod, Head: Sept\n",
      "Word: 2001, Deprel: nummod, Head: Sept\n",
      "Word: hijackers, Deprel: obl, Head: used\n",
      "Word: and, Deprel: cc, Head: banned\n",
      "Word: have, Deprel: aux, Head: banned\n",
      "Word: since, Deprel: advmod, Head: banned\n",
      "Word: been, Deprel: aux:pass, Head: banned\n",
      "Word: banned, Deprel: conj, Head: used\n",
      "Word: as, Deprel: case, Head: items\n",
      "Word: carry-on, Deprel: amod, Head: items\n",
      "Word: items, Deprel: obl, Head: banned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Box cutters were the weapons used by the 19 hijackers in the Sept 11 2001 attacks'\n",
      "Word: Box, Deprel: compound, Head: cutters\n",
      "Word: cutters, Deprel: nsubj, Head: weapons\n",
      "Word: were, Deprel: cop, Head: weapons\n",
      "Word: the, Deprel: det, Head: weapons\n",
      "Word: weapons, Deprel: root, Head: ROOT\n",
      "Word: used, Deprel: acl, Head: weapons\n",
      "Word: by, Deprel: case, Head: hijackers\n",
      "Word: the, Deprel: det, Head: hijackers\n",
      "Word: 19, Deprel: nummod, Head: hijackers\n",
      "Word: hijackers, Deprel: obl:agent, Head: used\n",
      "Word: in, Deprel: case, Head: attacks\n",
      "Word: the, Deprel: det, Head: attacks\n",
      "Word: Sept, Deprel: compound, Head: attacks\n",
      "Word: 11, Deprel: nummod, Head: Sept\n",
      "Word: 2001, Deprel: nummod, Head: Sept\n",
      "Word: attacks, Deprel: nmod, Head: hijackers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Portuguese weather service said Europe s heatwave was caused by a mass of hot dry air moving from the southeast'\n",
      "Word: The, Deprel: det, Head: service\n",
      "Word: Portuguese, Deprel: amod, Head: service\n",
      "Word: weather, Deprel: compound, Head: service\n",
      "Word: service, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Europe, Deprel: nmod:poss, Head: heatwave\n",
      "Word: s, Deprel: case, Head: Europe\n",
      "Word: heatwave, Deprel: nsubj:pass, Head: caused\n",
      "Word: was, Deprel: aux:pass, Head: caused\n",
      "Word: caused, Deprel: ccomp, Head: said\n",
      "Word: by, Deprel: case, Head: mass\n",
      "Word: a, Deprel: det, Head: mass\n",
      "Word: mass, Deprel: obl:agent, Head: caused\n",
      "Word: of, Deprel: case, Head: air\n",
      "Word: hot, Deprel: amod, Head: air\n",
      "Word: dry, Deprel: amod, Head: air\n",
      "Word: air, Deprel: nmod, Head: mass\n",
      "Word: moving, Deprel: acl, Head: air\n",
      "Word: from, Deprel: case, Head: southeast\n",
      "Word: the, Deprel: det, Head: southeast\n",
      "Word: southeast, Deprel: obl, Head: moving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The heatwave was due to a mass of hot dry air from the southeast said Mario Almeida of Portugal s weather service'\n",
      "Word: The, Deprel: det, Head: heatwave\n",
      "Word: heatwave, Deprel: nsubj, Head: mass\n",
      "Word: was, Deprel: cop, Head: mass\n",
      "Word: due, Deprel: case, Head: mass\n",
      "Word: to, Deprel: fixed, Head: due\n",
      "Word: a, Deprel: det, Head: mass\n",
      "Word: mass, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: air\n",
      "Word: hot, Deprel: amod, Head: air\n",
      "Word: dry, Deprel: amod, Head: air\n",
      "Word: air, Deprel: nmod, Head: mass\n",
      "Word: from, Deprel: case, Head: southeast\n",
      "Word: the, Deprel: det, Head: southeast\n",
      "Word: southeast, Deprel: nmod, Head: air\n",
      "Word: said, Deprel: parataxis, Head: mass\n",
      "Word: Mario, Deprel: obj, Head: said\n",
      "Word: Almeida, Deprel: flat, Head: Mario\n",
      "Word: of, Deprel: case, Head: service\n",
      "Word: Portugal, Deprel: nmod:poss, Head: service\n",
      "Word: s, Deprel: case, Head: Portugal\n",
      "Word: weather, Deprel: compound, Head: service\n",
      "Word: service, Deprel: nmod, Head: Mario\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Spending taxpayer dollars to create terrorism betting parlors is as wasteful as it is repugnant they announced at a press conference yesterday'\n",
      "Word: Spending, Deprel: csubj, Head: wasteful\n",
      "Word: taxpayer, Deprel: compound, Head: dollars\n",
      "Word: dollars, Deprel: obj, Head: Spending\n",
      "Word: to, Deprel: mark, Head: create\n",
      "Word: create, Deprel: advcl, Head: Spending\n",
      "Word: terrorism, Deprel: compound, Head: betting\n",
      "Word: betting, Deprel: compound, Head: parlors\n",
      "Word: parlors, Deprel: obj, Head: create\n",
      "Word: is, Deprel: cop, Head: wasteful\n",
      "Word: as, Deprel: advmod, Head: wasteful\n",
      "Word: wasteful, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: mark, Head: repugnant\n",
      "Word: it, Deprel: nsubj, Head: repugnant\n",
      "Word: is, Deprel: cop, Head: repugnant\n",
      "Word: repugnant, Deprel: advcl, Head: wasteful\n",
      "Word: they, Deprel: nsubj, Head: announced\n",
      "Word: announced, Deprel: ccomp, Head: repugnant\n",
      "Word: at, Deprel: case, Head: conference\n",
      "Word: a, Deprel: det, Head: conference\n",
      "Word: press, Deprel: compound, Head: conference\n",
      "Word: conference, Deprel: obl, Head: announced\n",
      "Word: yesterday, Deprel: nmod:tmod, Head: conference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Spending taxpayer dollars to create terrorism betting parlors is as wasteful as it is repugnant Wyden and Dorgan said Monday in a letter to the Pentagon'\n",
      "Word: Spending, Deprel: csubj, Head: wasteful\n",
      "Word: taxpayer, Deprel: compound, Head: dollars\n",
      "Word: dollars, Deprel: obj, Head: Spending\n",
      "Word: to, Deprel: mark, Head: create\n",
      "Word: create, Deprel: advcl, Head: Spending\n",
      "Word: terrorism, Deprel: compound, Head: betting\n",
      "Word: betting, Deprel: compound, Head: parlors\n",
      "Word: parlors, Deprel: obj, Head: create\n",
      "Word: is, Deprel: cop, Head: wasteful\n",
      "Word: as, Deprel: advmod, Head: wasteful\n",
      "Word: wasteful, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: mark, Head: repugnant\n",
      "Word: it, Deprel: nsubj, Head: repugnant\n",
      "Word: is, Deprel: cop, Head: repugnant\n",
      "Word: repugnant, Deprel: advcl, Head: wasteful\n",
      "Word: Wyden, Deprel: nsubj, Head: said\n",
      "Word: and, Deprel: cc, Head: Dorgan\n",
      "Word: Dorgan, Deprel: conj, Head: Wyden\n",
      "Word: said, Deprel: advcl, Head: wasteful\n",
      "Word: Monday, Deprel: obl:tmod, Head: said\n",
      "Word: in, Deprel: case, Head: letter\n",
      "Word: a, Deprel: det, Head: letter\n",
      "Word: letter, Deprel: obl, Head: said\n",
      "Word: to, Deprel: case, Head: Pentagon\n",
      "Word: the, Deprel: det, Head: Pentagon\n",
      "Word: Pentagon, Deprel: nmod, Head: letter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Still the somewhat ambiguous ruling might be a setback for Static Control depending on how it developed its competing product Merrill Lynch analyst Steven Milunovich said'\n",
      "Word: Still, Deprel: advmod, Head: setback\n",
      "Word: the, Deprel: det, Head: ruling\n",
      "Word: somewhat, Deprel: advmod, Head: ambiguous\n",
      "Word: ambiguous, Deprel: amod, Head: ruling\n",
      "Word: ruling, Deprel: nsubj, Head: setback\n",
      "Word: might, Deprel: aux, Head: setback\n",
      "Word: be, Deprel: cop, Head: setback\n",
      "Word: a, Deprel: det, Head: setback\n",
      "Word: setback, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: Control\n",
      "Word: Static, Deprel: amod, Head: Control\n",
      "Word: Control, Deprel: nmod, Head: setback\n",
      "Word: depending, Deprel: case, Head: how\n",
      "Word: on, Deprel: fixed, Head: depending\n",
      "Word: how, Deprel: nmod, Head: setback\n",
      "Word: it, Deprel: nsubj, Head: developed\n",
      "Word: developed, Deprel: advcl:relcl, Head: how\n",
      "Word: its, Deprel: nmod:poss, Head: analyst\n",
      "Word: competing, Deprel: amod, Head: product\n",
      "Word: product, Deprel: compound, Head: analyst\n",
      "Word: Merrill, Deprel: compound, Head: Lynch\n",
      "Word: Lynch, Deprel: compound, Head: analyst\n",
      "Word: analyst, Deprel: obj, Head: developed\n",
      "Word: Steven, Deprel: flat, Head: analyst\n",
      "Word: Milunovich, Deprel: flat, Head: Steven\n",
      "Word: said, Deprel: acl:relcl, Head: analyst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But Merrill Lynch analyst Steven Milunovich said the somewhat ambiguous ruling by regulators might be a setback for Static Control depending on how it developed its competing product'\n",
      "Word: But, Deprel: cc, Head: said\n",
      "Word: Merrill, Deprel: compound, Head: Lynch\n",
      "Word: Lynch, Deprel: compound, Head: analyst\n",
      "Word: analyst, Deprel: compound, Head: Steven\n",
      "Word: Steven, Deprel: nsubj, Head: said\n",
      "Word: Milunovich, Deprel: flat, Head: Steven\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: ruling\n",
      "Word: somewhat, Deprel: advmod, Head: ambiguous\n",
      "Word: ambiguous, Deprel: amod, Head: ruling\n",
      "Word: ruling, Deprel: nsubj, Head: setback\n",
      "Word: by, Deprel: case, Head: regulators\n",
      "Word: regulators, Deprel: nmod, Head: ruling\n",
      "Word: might, Deprel: aux, Head: setback\n",
      "Word: be, Deprel: cop, Head: setback\n",
      "Word: a, Deprel: det, Head: setback\n",
      "Word: setback, Deprel: ccomp, Head: said\n",
      "Word: for, Deprel: case, Head: Control\n",
      "Word: Static, Deprel: amod, Head: Control\n",
      "Word: Control, Deprel: nmod, Head: setback\n",
      "Word: depending, Deprel: mark, Head: developed\n",
      "Word: on, Deprel: fixed, Head: depending\n",
      "Word: how, Deprel: advmod, Head: developed\n",
      "Word: it, Deprel: nsubj, Head: developed\n",
      "Word: developed, Deprel: advcl, Head: setback\n",
      "Word: its, Deprel: nmod:poss, Head: product\n",
      "Word: competing, Deprel: amod, Head: product\n",
      "Word: product, Deprel: obj, Head: developed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Police believe Wilson shot Reynolds then her mother once in the head before fatally turning the gun on herself'\n",
      "Word: Police, Deprel: nsubj, Head: believe\n",
      "Word: believe, Deprel: root, Head: ROOT\n",
      "Word: Wilson, Deprel: nsubj, Head: shot\n",
      "Word: shot, Deprel: ccomp, Head: believe\n",
      "Word: Reynolds, Deprel: obj, Head: shot\n",
      "Word: then, Deprel: advmod, Head: mother\n",
      "Word: her, Deprel: nmod:poss, Head: mother\n",
      "Word: mother, Deprel: obj, Head: shot\n",
      "Word: once, Deprel: advmod, Head: shot\n",
      "Word: in, Deprel: case, Head: head\n",
      "Word: the, Deprel: det, Head: head\n",
      "Word: head, Deprel: obl, Head: once\n",
      "Word: before, Deprel: mark, Head: turning\n",
      "Word: fatally, Deprel: advmod, Head: turning\n",
      "Word: turning, Deprel: advcl, Head: shot\n",
      "Word: the, Deprel: det, Head: gun\n",
      "Word: gun, Deprel: obj, Head: turning\n",
      "Word: on, Deprel: case, Head: herself\n",
      "Word: herself, Deprel: obl, Head: turning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Police believe Wilson then shot Jennie Mae Robinson once in the head before turning the gun on herself'\n",
      "Word: Police, Deprel: nsubj, Head: believe\n",
      "Word: believe, Deprel: root, Head: ROOT\n",
      "Word: Wilson, Deprel: nsubj, Head: shot\n",
      "Word: then, Deprel: advmod, Head: shot\n",
      "Word: shot, Deprel: ccomp, Head: believe\n",
      "Word: Jennie, Deprel: obj, Head: shot\n",
      "Word: Mae, Deprel: flat, Head: Jennie\n",
      "Word: Robinson, Deprel: flat, Head: Jennie\n",
      "Word: once, Deprel: advmod, Head: shot\n",
      "Word: in, Deprel: case, Head: head\n",
      "Word: the, Deprel: det, Head: head\n",
      "Word: head, Deprel: obl, Head: once\n",
      "Word: before, Deprel: mark, Head: turning\n",
      "Word: turning, Deprel: advcl, Head: shot\n",
      "Word: the, Deprel: det, Head: gun\n",
      "Word: gun, Deprel: obj, Head: turning\n",
      "Word: on, Deprel: case, Head: herself\n",
      "Word: herself, Deprel: obl, Head: turning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On July 22 Moore announced he would appeal the case directly to the U.S Supreme Court'\n",
      "Word: On, Deprel: case, Head: July\n",
      "Word: July, Deprel: obl, Head: announced\n",
      "Word: 22, Deprel: nummod, Head: July\n",
      "Word: Moore, Deprel: nsubj, Head: announced\n",
      "Word: announced, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: appeal\n",
      "Word: would, Deprel: aux, Head: appeal\n",
      "Word: appeal, Deprel: ccomp, Head: announced\n",
      "Word: the, Deprel: det, Head: case\n",
      "Word: case, Deprel: obj, Head: appeal\n",
      "Word: directly, Deprel: advmod, Head: appeal\n",
      "Word: to, Deprel: case, Head: Court\n",
      "Word: the, Deprel: det, Head: Court\n",
      "Word: U.S, Deprel: compound, Head: Court\n",
      "Word: Supreme, Deprel: amod, Head: Court\n",
      "Word: Court, Deprel: obl, Head: appeal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Moore of Alabama says he will appeal his case to the nation s highest court'\n",
      "Word: Moore, Deprel: nsubj, Head: says\n",
      "Word: of, Deprel: case, Head: Alabama\n",
      "Word: Alabama, Deprel: nmod, Head: Moore\n",
      "Word: says, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: appeal\n",
      "Word: will, Deprel: aux, Head: appeal\n",
      "Word: appeal, Deprel: ccomp, Head: says\n",
      "Word: his, Deprel: nmod:poss, Head: case\n",
      "Word: case, Deprel: obj, Head: appeal\n",
      "Word: to, Deprel: case, Head: court\n",
      "Word: the, Deprel: det, Head: nation\n",
      "Word: nation, Deprel: nmod:poss, Head: court\n",
      "Word: s, Deprel: case, Head: nation\n",
      "Word: highest, Deprel: amod, Head: court\n",
      "Word: court, Deprel: obl, Head: appeal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The monkeys could track their progress by watching a schematic representation of the arm and its motions on a video screen'\n",
      "Word: The, Deprel: det, Head: monkeys\n",
      "Word: monkeys, Deprel: nsubj, Head: track\n",
      "Word: could, Deprel: aux, Head: track\n",
      "Word: track, Deprel: root, Head: ROOT\n",
      "Word: their, Deprel: nmod:poss, Head: progress\n",
      "Word: progress, Deprel: obj, Head: track\n",
      "Word: by, Deprel: mark, Head: watching\n",
      "Word: watching, Deprel: advcl, Head: track\n",
      "Word: a, Deprel: det, Head: representation\n",
      "Word: schematic, Deprel: amod, Head: representation\n",
      "Word: representation, Deprel: obj, Head: watching\n",
      "Word: of, Deprel: case, Head: arm\n",
      "Word: the, Deprel: det, Head: arm\n",
      "Word: arm, Deprel: nmod, Head: representation\n",
      "Word: and, Deprel: cc, Head: motions\n",
      "Word: its, Deprel: nmod:poss, Head: motions\n",
      "Word: motions, Deprel: conj, Head: representation\n",
      "Word: on, Deprel: case, Head: screen\n",
      "Word: a, Deprel: det, Head: screen\n",
      "Word: video, Deprel: compound, Head: screen\n",
      "Word: screen, Deprel: nmod, Head: motions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The arm was kept in a separate room but the monkeys could track their progress by watching a representation of the arm and its motions on a video screen'\n",
      "Word: The, Deprel: det, Head: arm\n",
      "Word: arm, Deprel: nsubj:pass, Head: kept\n",
      "Word: was, Deprel: aux:pass, Head: kept\n",
      "Word: kept, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: room\n",
      "Word: a, Deprel: det, Head: room\n",
      "Word: separate, Deprel: amod, Head: room\n",
      "Word: room, Deprel: obl, Head: kept\n",
      "Word: but, Deprel: cc, Head: track\n",
      "Word: the, Deprel: det, Head: monkeys\n",
      "Word: monkeys, Deprel: nsubj, Head: track\n",
      "Word: could, Deprel: aux, Head: track\n",
      "Word: track, Deprel: conj, Head: kept\n",
      "Word: their, Deprel: nmod:poss, Head: progress\n",
      "Word: progress, Deprel: obj, Head: track\n",
      "Word: by, Deprel: mark, Head: watching\n",
      "Word: watching, Deprel: advcl, Head: track\n",
      "Word: a, Deprel: det, Head: representation\n",
      "Word: representation, Deprel: obj, Head: watching\n",
      "Word: of, Deprel: case, Head: arm\n",
      "Word: the, Deprel: det, Head: arm\n",
      "Word: arm, Deprel: nmod, Head: representation\n",
      "Word: and, Deprel: cc, Head: motions\n",
      "Word: its, Deprel: nmod:poss, Head: motions\n",
      "Word: motions, Deprel: conj, Head: representation\n",
      "Word: on, Deprel: case, Head: screen\n",
      "Word: a, Deprel: det, Head: screen\n",
      "Word: video, Deprel: compound, Head: screen\n",
      "Word: screen, Deprel: nmod, Head: motions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'That triggered a 47-hour police standoff that inconvenienced thousands of commuters as traffic backed up in Downtown Washington and northern Virginia'\n",
      "Word: That, Deprel: nsubj, Head: triggered\n",
      "Word: triggered, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: standoff\n",
      "Word: 47-hour, Deprel: amod, Head: standoff\n",
      "Word: police, Deprel: compound, Head: standoff\n",
      "Word: standoff, Deprel: obj, Head: triggered\n",
      "Word: that, Deprel: nsubj, Head: inconvenienced\n",
      "Word: inconvenienced, Deprel: acl:relcl, Head: standoff\n",
      "Word: thousands, Deprel: obj, Head: inconvenienced\n",
      "Word: of, Deprel: case, Head: commuters\n",
      "Word: commuters, Deprel: nmod, Head: thousands\n",
      "Word: as, Deprel: mark, Head: backed\n",
      "Word: traffic, Deprel: nsubj, Head: backed\n",
      "Word: backed, Deprel: advcl, Head: inconvenienced\n",
      "Word: up, Deprel: compound:prt, Head: backed\n",
      "Word: in, Deprel: case, Head: Washington\n",
      "Word: Downtown, Deprel: compound, Head: Washington\n",
      "Word: Washington, Deprel: obl, Head: backed\n",
      "Word: and, Deprel: cc, Head: Virginia\n",
      "Word: northern, Deprel: amod, Head: Virginia\n",
      "Word: Virginia, Deprel: conj, Head: Washington\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'His protest led to a 47-hour standoff with police that caused huge traffic jams in downtown Washington and northern Virginia'\n",
      "Word: His, Deprel: nmod:poss, Head: protest\n",
      "Word: protest, Deprel: nsubj, Head: led\n",
      "Word: led, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: standoff\n",
      "Word: a, Deprel: det, Head: standoff\n",
      "Word: 47-hour, Deprel: amod, Head: standoff\n",
      "Word: standoff, Deprel: obl, Head: led\n",
      "Word: with, Deprel: case, Head: police\n",
      "Word: police, Deprel: nmod, Head: standoff\n",
      "Word: that, Deprel: nsubj, Head: caused\n",
      "Word: caused, Deprel: acl:relcl, Head: standoff\n",
      "Word: huge, Deprel: amod, Head: jams\n",
      "Word: traffic, Deprel: compound, Head: jams\n",
      "Word: jams, Deprel: obj, Head: caused\n",
      "Word: in, Deprel: case, Head: Washington\n",
      "Word: downtown, Deprel: amod, Head: Washington\n",
      "Word: Washington, Deprel: nmod, Head: jams\n",
      "Word: and, Deprel: cc, Head: Virginia\n",
      "Word: northern, Deprel: amod, Head: Virginia\n",
      "Word: Virginia, Deprel: conj, Head: Washington\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Standard Poor s 500 index advanced 6.48 or 0.7 per cent to 990.51'\n",
      "Word: The, Deprel: det, Head: index\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: compound, Head: index\n",
      "Word: s, Deprel: compound, Head: index\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: index, Deprel: nsubj, Head: advanced\n",
      "Word: advanced, Deprel: root, Head: ROOT\n",
      "Word: 6.48, Deprel: nummod, Head: cent\n",
      "Word: or, Deprel: cc, Head: 0.7\n",
      "Word: 0.7, Deprel: conj, Head: 6.48\n",
      "Word: per, Deprel: compound, Head: cent\n",
      "Word: cent, Deprel: obj, Head: advanced\n",
      "Word: to, Deprel: case, Head: 990.51\n",
      "Word: 990.51, Deprel: obl, Head: advanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index SPX rose 6.48 points or 0.66 percent to 990.51'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broader, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: compound, Head: s\n",
      "Word: s, Deprel: compound, Head: SPX\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 6.48, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: rose\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.66, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 990.51\n",
      "Word: 990.51, Deprel: obl, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Agriculture ministers from more than one hundred nations are expected to attend the three-day Ministerial Conference and Expo on Agricultural Science and Technology sponsored by the U.S Department of Agriculture'\n",
      "Word: Agriculture, Deprel: compound, Head: ministers\n",
      "Word: ministers, Deprel: nsubj:pass, Head: expected\n",
      "Word: from, Deprel: case, Head: nations\n",
      "Word: more, Deprel: advmod, Head: hundred\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: one, Deprel: compound, Head: hundred\n",
      "Word: hundred, Deprel: nummod, Head: nations\n",
      "Word: nations, Deprel: nmod, Head: ministers\n",
      "Word: are, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: attend\n",
      "Word: attend, Deprel: xcomp, Head: expected\n",
      "Word: the, Deprel: det, Head: Conference\n",
      "Word: three-day, Deprel: amod, Head: Conference\n",
      "Word: Ministerial, Deprel: amod, Head: Conference\n",
      "Word: Conference, Deprel: obj, Head: attend\n",
      "Word: and, Deprel: cc, Head: Expo\n",
      "Word: Expo, Deprel: conj, Head: Conference\n",
      "Word: on, Deprel: case, Head: Science\n",
      "Word: Agricultural, Deprel: amod, Head: Science\n",
      "Word: Science, Deprel: nmod, Head: Conference\n",
      "Word: and, Deprel: cc, Head: Technology\n",
      "Word: Technology, Deprel: conj, Head: Science\n",
      "Word: sponsored, Deprel: acl, Head: Science\n",
      "Word: by, Deprel: case, Head: Department\n",
      "Word: the, Deprel: det, Head: Department\n",
      "Word: U.S, Deprel: compound, Head: Department\n",
      "Word: Department, Deprel: obl, Head: sponsored\n",
      "Word: of, Deprel: case, Head: Agriculture\n",
      "Word: Agriculture, Deprel: nmod, Head: Department\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'U.S Agriculture Secretary Ann Veneman kicks off the three-day Ministerial Conference and Expo on Agricultural Science and Technology on Monday'\n",
      "Word: U.S, Deprel: compound, Head: Secretary\n",
      "Word: Agriculture, Deprel: compound, Head: Secretary\n",
      "Word: Secretary, Deprel: nsubj, Head: kicks\n",
      "Word: Ann, Deprel: flat, Head: Secretary\n",
      "Word: Veneman, Deprel: flat, Head: Secretary\n",
      "Word: kicks, Deprel: root, Head: ROOT\n",
      "Word: off, Deprel: compound:prt, Head: kicks\n",
      "Word: the, Deprel: det, Head: Conference\n",
      "Word: three-day, Deprel: amod, Head: Conference\n",
      "Word: Ministerial, Deprel: amod, Head: Conference\n",
      "Word: Conference, Deprel: obj, Head: kicks\n",
      "Word: and, Deprel: cc, Head: Expo\n",
      "Word: Expo, Deprel: conj, Head: Conference\n",
      "Word: on, Deprel: case, Head: Science\n",
      "Word: Agricultural, Deprel: amod, Head: Science\n",
      "Word: Science, Deprel: nmod, Head: Conference\n",
      "Word: and, Deprel: cc, Head: Technology\n",
      "Word: Technology, Deprel: conj, Head: Science\n",
      "Word: on, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: kicks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'According to security sources London Metropolitan Police Commissioner John Stevens placed his force on its highest state of alert last week following the warning'\n",
      "Word: According, Deprel: case, Head: sources\n",
      "Word: to, Deprel: fixed, Head: According\n",
      "Word: security, Deprel: compound, Head: sources\n",
      "Word: sources, Deprel: obl, Head: placed\n",
      "Word: London, Deprel: compound, Head: Commissioner\n",
      "Word: Metropolitan, Deprel: amod, Head: Commissioner\n",
      "Word: Police, Deprel: compound, Head: Commissioner\n",
      "Word: Commissioner, Deprel: compound, Head: John\n",
      "Word: John, Deprel: nsubj, Head: placed\n",
      "Word: Stevens, Deprel: flat, Head: John\n",
      "Word: placed, Deprel: root, Head: ROOT\n",
      "Word: his, Deprel: nmod:poss, Head: force\n",
      "Word: force, Deprel: obj, Head: placed\n",
      "Word: on, Deprel: case, Head: state\n",
      "Word: its, Deprel: nmod:poss, Head: state\n",
      "Word: highest, Deprel: amod, Head: state\n",
      "Word: state, Deprel: obl, Head: placed\n",
      "Word: of, Deprel: case, Head: alert\n",
      "Word: alert, Deprel: nmod, Head: state\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: placed\n",
      "Word: following, Deprel: case, Head: warning\n",
      "Word: the, Deprel: det, Head: warning\n",
      "Word: warning, Deprel: obl, Head: placed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Telegraph can reveal that Sir John Stevens the Metropolitan Police Commissioner placed his force on its highest alert last week'\n",
      "Word: The, Deprel: det, Head: Telegraph\n",
      "Word: Telegraph, Deprel: nsubj, Head: reveal\n",
      "Word: can, Deprel: aux, Head: reveal\n",
      "Word: reveal, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: placed\n",
      "Word: Sir, Deprel: compound, Head: Commissioner\n",
      "Word: John, Deprel: flat, Head: Sir\n",
      "Word: Stevens, Deprel: flat, Head: Sir\n",
      "Word: the, Deprel: det, Head: Commissioner\n",
      "Word: Metropolitan, Deprel: amod, Head: Commissioner\n",
      "Word: Police, Deprel: compound, Head: Commissioner\n",
      "Word: Commissioner, Deprel: nsubj, Head: placed\n",
      "Word: placed, Deprel: ccomp, Head: reveal\n",
      "Word: his, Deprel: nmod:poss, Head: force\n",
      "Word: force, Deprel: obj, Head: placed\n",
      "Word: on, Deprel: case, Head: alert\n",
      "Word: its, Deprel: nmod:poss, Head: alert\n",
      "Word: highest, Deprel: amod, Head: alert\n",
      "Word: alert, Deprel: obl, Head: placed\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: placed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Complicating the situation is the presence of battle-hardened Liberians who have been fighting on both sides'\n",
      "Word: Complicating, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: situation\n",
      "Word: situation, Deprel: obj, Head: Complicating\n",
      "Word: is, Deprel: aux, Head: Complicating\n",
      "Word: the, Deprel: det, Head: presence\n",
      "Word: presence, Deprel: nsubj, Head: Complicating\n",
      "Word: of, Deprel: case, Head: Liberians\n",
      "Word: battle-hardened, Deprel: amod, Head: Liberians\n",
      "Word: Liberians, Deprel: nmod, Head: presence\n",
      "Word: who, Deprel: nsubj, Head: fighting\n",
      "Word: have, Deprel: aux, Head: fighting\n",
      "Word: been, Deprel: aux, Head: fighting\n",
      "Word: fighting, Deprel: acl:relcl, Head: Liberians\n",
      "Word: on, Deprel: case, Head: sides\n",
      "Word: both, Deprel: det, Head: sides\n",
      "Word: sides, Deprel: obl, Head: fighting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Fighting has continued sporadically in the west where it is complicated by the presence of battle-hardened Liberians on both sides'\n",
      "Word: Fighting, Deprel: nsubj, Head: continued\n",
      "Word: has, Deprel: aux, Head: continued\n",
      "Word: continued, Deprel: root, Head: ROOT\n",
      "Word: sporadically, Deprel: advmod, Head: continued\n",
      "Word: in, Deprel: case, Head: west\n",
      "Word: the, Deprel: det, Head: west\n",
      "Word: west, Deprel: obl, Head: continued\n",
      "Word: where, Deprel: advmod, Head: complicated\n",
      "Word: it, Deprel: nsubj:pass, Head: complicated\n",
      "Word: is, Deprel: aux:pass, Head: complicated\n",
      "Word: complicated, Deprel: acl:relcl, Head: west\n",
      "Word: by, Deprel: case, Head: presence\n",
      "Word: the, Deprel: det, Head: presence\n",
      "Word: presence, Deprel: obl, Head: complicated\n",
      "Word: of, Deprel: case, Head: Liberians\n",
      "Word: battle-hardened, Deprel: amod, Head: Liberians\n",
      "Word: Liberians, Deprel: nmod, Head: presence\n",
      "Word: on, Deprel: case, Head: sides\n",
      "Word: both, Deprel: det, Head: sides\n",
      "Word: sides, Deprel: nmod, Head: presence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This year the Audubon Society once again hosts its annual Christmas Bird Count'\n",
      "Word: This, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: hosts\n",
      "Word: the, Deprel: det, Head: Society\n",
      "Word: Audubon, Deprel: compound, Head: Society\n",
      "Word: Society, Deprel: nsubj, Head: hosts\n",
      "Word: once, Deprel: advmod, Head: again\n",
      "Word: again, Deprel: advmod, Head: hosts\n",
      "Word: hosts, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: Count\n",
      "Word: annual, Deprel: amod, Head: Count\n",
      "Word: Christmas, Deprel: compound, Head: Count\n",
      "Word: Bird, Deprel: compound, Head: Count\n",
      "Word: Count, Deprel: obj, Head: hosts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It s the National Audubon Society s annual Christmas Bird Count now in its 104th season'\n",
      "Word: It, Deprel: nsubj, Head: Count\n",
      "Word: s, Deprel: cop, Head: Count\n",
      "Word: the, Deprel: det, Head: Society\n",
      "Word: National, Deprel: amod, Head: Society\n",
      "Word: Audubon, Deprel: compound, Head: Society\n",
      "Word: Society, Deprel: nmod:poss, Head: Count\n",
      "Word: s, Deprel: case, Head: Society\n",
      "Word: annual, Deprel: amod, Head: Count\n",
      "Word: Christmas, Deprel: compound, Head: Bird\n",
      "Word: Bird, Deprel: compound, Head: Count\n",
      "Word: Count, Deprel: root, Head: ROOT\n",
      "Word: now, Deprel: advmod, Head: Count\n",
      "Word: in, Deprel: case, Head: season\n",
      "Word: its, Deprel: nmod:poss, Head: season\n",
      "Word: 104th, Deprel: amod, Head: season\n",
      "Word: season, Deprel: nmod, Head: Count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Before it was removed the site listed in broken English the rules for hackers who might participate'\n",
      "Word: Before, Deprel: mark, Head: removed\n",
      "Word: it, Deprel: nsubj:pass, Head: removed\n",
      "Word: was, Deprel: aux:pass, Head: removed\n",
      "Word: removed, Deprel: advcl, Head: listed\n",
      "Word: the, Deprel: det, Head: site\n",
      "Word: site, Deprel: nsubj:pass, Head: listed\n",
      "Word: listed, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: English\n",
      "Word: broken, Deprel: amod, Head: English\n",
      "Word: English, Deprel: obl, Head: listed\n",
      "Word: the, Deprel: det, Head: rules\n",
      "Word: rules, Deprel: obj, Head: listed\n",
      "Word: for, Deprel: case, Head: hackers\n",
      "Word: hackers, Deprel: nmod, Head: rules\n",
      "Word: who, Deprel: nsubj, Head: participate\n",
      "Word: might, Deprel: aux, Head: participate\n",
      "Word: participate, Deprel: acl:relcl, Head: hackers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Organizers established a Web site http defacerschallenge.com listing in broken English the rules for hackers who might participate'\n",
      "Word: Organizers, Deprel: nsubj, Head: established\n",
      "Word: established, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: site\n",
      "Word: Web, Deprel: compound, Head: site\n",
      "Word: site, Deprel: compound, Head: http\n",
      "Word: http, Deprel: compound, Head: defacerschallenge.com\n",
      "Word: defacerschallenge.com, Deprel: obj, Head: established\n",
      "Word: listing, Deprel: advcl, Head: established\n",
      "Word: in, Deprel: case, Head: English\n",
      "Word: broken, Deprel: amod, Head: English\n",
      "Word: English, Deprel: obl, Head: listing\n",
      "Word: the, Deprel: det, Head: rules\n",
      "Word: rules, Deprel: obj, Head: listing\n",
      "Word: for, Deprel: case, Head: hackers\n",
      "Word: hackers, Deprel: nmod, Head: rules\n",
      "Word: who, Deprel: nsubj, Head: participate\n",
      "Word: might, Deprel: aux, Head: participate\n",
      "Word: participate, Deprel: acl:relcl, Head: hackers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Southwest said its traffic was up 4.6 percent in the quarter and it ended the quarter with 2.2 billion in cash'\n",
      "Word: Southwest, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: traffic\n",
      "Word: traffic, Deprel: nsubj, Head: up\n",
      "Word: was, Deprel: cop, Head: up\n",
      "Word: up, Deprel: ccomp, Head: said\n",
      "Word: 4.6, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:npmod, Head: up\n",
      "Word: in, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: up\n",
      "Word: and, Deprel: cc, Head: ended\n",
      "Word: it, Deprel: nsubj, Head: ended\n",
      "Word: ended, Deprel: conj, Head: up\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: quarter, Deprel: obj, Head: ended\n",
      "Word: with, Deprel: case, Head: billion\n",
      "Word: 2.2, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obl, Head: ended\n",
      "Word: in, Deprel: case, Head: cash\n",
      "Word: cash, Deprel: nmod, Head: billion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Southwest said its traffic was up 4.6 percent in the quarter on a capacity increase of 4.2 percent'\n",
      "Word: Southwest, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: traffic\n",
      "Word: traffic, Deprel: nsubj, Head: up\n",
      "Word: was, Deprel: cop, Head: up\n",
      "Word: up, Deprel: ccomp, Head: said\n",
      "Word: 4.6, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:npmod, Head: up\n",
      "Word: in, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: up\n",
      "Word: on, Deprel: case, Head: increase\n",
      "Word: a, Deprel: det, Head: increase\n",
      "Word: capacity, Deprel: compound, Head: increase\n",
      "Word: increase, Deprel: obl, Head: up\n",
      "Word: of, Deprel: case, Head: percent\n",
      "Word: 4.2, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: nmod, Head: increase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Doctors have speculated that the body ’ s own estrogen protects against cell damage and improves blood flow'\n",
      "Word: Doctors, Deprel: nsubj, Head: speculated\n",
      "Word: have, Deprel: aux, Head: speculated\n",
      "Word: speculated, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: protects\n",
      "Word: the, Deprel: det, Head: body\n",
      "Word: body, Deprel: nmod:poss, Head: estrogen\n",
      "Word: ’, Deprel: case, Head: body\n",
      "Word: s, Deprel: case, Head: body\n",
      "Word: own, Deprel: amod, Head: estrogen\n",
      "Word: estrogen, Deprel: nsubj, Head: protects\n",
      "Word: protects, Deprel: ccomp, Head: speculated\n",
      "Word: against, Deprel: case, Head: damage\n",
      "Word: cell, Deprel: compound, Head: damage\n",
      "Word: damage, Deprel: obl, Head: protects\n",
      "Word: and, Deprel: cc, Head: improves\n",
      "Word: improves, Deprel: conj, Head: protects\n",
      "Word: blood, Deprel: compound, Head: flow\n",
      "Word: flow, Deprel: obj, Head: improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Their belief was based on speculation that estrogen prevents cell damage and improves blood flow'\n",
      "Word: Their, Deprel: nmod:poss, Head: belief\n",
      "Word: belief, Deprel: nsubj, Head: based\n",
      "Word: was, Deprel: cop, Head: based\n",
      "Word: based, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: speculation\n",
      "Word: speculation, Deprel: obl, Head: based\n",
      "Word: that, Deprel: mark, Head: prevents\n",
      "Word: estrogen, Deprel: nsubj, Head: prevents\n",
      "Word: prevents, Deprel: acl, Head: speculation\n",
      "Word: cell, Deprel: compound, Head: damage\n",
      "Word: damage, Deprel: obj, Head: prevents\n",
      "Word: and, Deprel: cc, Head: improves\n",
      "Word: improves, Deprel: conj, Head: prevents\n",
      "Word: blood, Deprel: compound, Head: flow\n",
      "Word: flow, Deprel: obj, Head: improves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'They also found shortness was associated with a family history of hearing loss'\n",
      "Word: They, Deprel: nsubj, Head: found\n",
      "Word: also, Deprel: advmod, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: shortness, Deprel: nsubj:pass, Head: associated\n",
      "Word: was, Deprel: aux:pass, Head: associated\n",
      "Word: associated, Deprel: ccomp, Head: found\n",
      "Word: with, Deprel: case, Head: history\n",
      "Word: a, Deprel: det, Head: history\n",
      "Word: family, Deprel: compound, Head: history\n",
      "Word: history, Deprel: obl, Head: associated\n",
      "Word: of, Deprel: case, Head: loss\n",
      "Word: hearing, Deprel: compound, Head: loss\n",
      "Word: loss, Deprel: nmod, Head: history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shortness was found twice as often in those with hearing loss'\n",
      "Word: Shortness, Deprel: nsubj:pass, Head: found\n",
      "Word: was, Deprel: aux:pass, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: twice, Deprel: advmod, Head: found\n",
      "Word: as, Deprel: advmod, Head: often\n",
      "Word: often, Deprel: advmod, Head: found\n",
      "Word: in, Deprel: case, Head: those\n",
      "Word: those, Deprel: obl, Head: found\n",
      "Word: with, Deprel: case, Head: loss\n",
      "Word: hearing, Deprel: compound, Head: loss\n",
      "Word: loss, Deprel: nmod, Head: those\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Cisco executives said they were encouraged by 1.3 billion in cash flow and the increase in net income but hoped for a rebound'\n",
      "Word: Cisco, Deprel: compound, Head: executives\n",
      "Word: executives, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: they, Deprel: nsubj:pass, Head: encouraged\n",
      "Word: were, Deprel: aux:pass, Head: encouraged\n",
      "Word: encouraged, Deprel: ccomp, Head: said\n",
      "Word: by, Deprel: case, Head: billion\n",
      "Word: 1.3, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obl, Head: encouraged\n",
      "Word: in, Deprel: case, Head: flow\n",
      "Word: cash, Deprel: compound, Head: flow\n",
      "Word: flow, Deprel: nmod, Head: billion\n",
      "Word: and, Deprel: cc, Head: increase\n",
      "Word: the, Deprel: det, Head: increase\n",
      "Word: increase, Deprel: conj, Head: billion\n",
      "Word: in, Deprel: case, Head: income\n",
      "Word: net, Deprel: compound, Head: income\n",
      "Word: income, Deprel: nmod, Head: increase\n",
      "Word: but, Deprel: cc, Head: hoped\n",
      "Word: hoped, Deprel: conj, Head: encouraged\n",
      "Word: for, Deprel: case, Head: rebound\n",
      "Word: a, Deprel: det, Head: rebound\n",
      "Word: rebound, Deprel: obl, Head: hoped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Cisco executives were encouraged by 1.3 billion in cash flow and the increase in net income but said they remained cautiously optimistic about a rebound'\n",
      "Word: Cisco, Deprel: compound, Head: executives\n",
      "Word: executives, Deprel: nsubj:pass, Head: encouraged\n",
      "Word: were, Deprel: aux:pass, Head: encouraged\n",
      "Word: encouraged, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: billion\n",
      "Word: 1.3, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obl, Head: encouraged\n",
      "Word: in, Deprel: case, Head: flow\n",
      "Word: cash, Deprel: compound, Head: flow\n",
      "Word: flow, Deprel: nmod, Head: billion\n",
      "Word: and, Deprel: cc, Head: increase\n",
      "Word: the, Deprel: det, Head: increase\n",
      "Word: increase, Deprel: conj, Head: billion\n",
      "Word: in, Deprel: case, Head: income\n",
      "Word: net, Deprel: compound, Head: income\n",
      "Word: income, Deprel: nmod, Head: increase\n",
      "Word: but, Deprel: cc, Head: said\n",
      "Word: said, Deprel: conj, Head: encouraged\n",
      "Word: they, Deprel: nsubj, Head: remained\n",
      "Word: remained, Deprel: ccomp, Head: said\n",
      "Word: cautiously, Deprel: advmod, Head: optimistic\n",
      "Word: optimistic, Deprel: xcomp, Head: remained\n",
      "Word: about, Deprel: case, Head: rebound\n",
      "Word: a, Deprel: det, Head: rebound\n",
      "Word: rebound, Deprel: obl, Head: optimistic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In an E-mail statement to the Knoxville News Sentinel Shumaker said I am not giving any consideration to resignation'\n",
      "Word: In, Deprel: case, Head: statement\n",
      "Word: an, Deprel: det, Head: statement\n",
      "Word: E-mail, Deprel: compound, Head: statement\n",
      "Word: statement, Deprel: obl, Head: said\n",
      "Word: to, Deprel: case, Head: Sentinel\n",
      "Word: the, Deprel: det, Head: Sentinel\n",
      "Word: Knoxville, Deprel: compound, Head: Sentinel\n",
      "Word: News, Deprel: compound, Head: Sentinel\n",
      "Word: Sentinel, Deprel: compound, Head: Shumaker\n",
      "Word: Shumaker, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: I, Deprel: nsubj, Head: giving\n",
      "Word: am, Deprel: aux, Head: giving\n",
      "Word: not, Deprel: advmod, Head: giving\n",
      "Word: giving, Deprel: ccomp, Head: said\n",
      "Word: any, Deprel: det, Head: consideration\n",
      "Word: consideration, Deprel: obj, Head: giving\n",
      "Word: to, Deprel: case, Head: resignation\n",
      "Word: resignation, Deprel: nmod, Head: consideration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I am not giving any consideration to resignation Shumaker said in a statement'\n",
      "Word: I, Deprel: nsubj, Head: giving\n",
      "Word: am, Deprel: aux, Head: giving\n",
      "Word: not, Deprel: advmod, Head: giving\n",
      "Word: giving, Deprel: root, Head: ROOT\n",
      "Word: any, Deprel: det, Head: consideration\n",
      "Word: consideration, Deprel: obj, Head: giving\n",
      "Word: to, Deprel: case, Head: resignation\n",
      "Word: resignation, Deprel: nmod, Head: consideration\n",
      "Word: Shumaker, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl, Head: consideration\n",
      "Word: in, Deprel: case, Head: statement\n",
      "Word: a, Deprel: det, Head: statement\n",
      "Word: statement, Deprel: obl, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A poll showed that the FBI bugging of the mayor had given a boost to his reelection effort against GOP opponent Sam Katz'\n",
      "Word: A, Deprel: det, Head: poll\n",
      "Word: poll, Deprel: nsubj, Head: showed\n",
      "Word: showed, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: given\n",
      "Word: the, Deprel: det, Head: bugging\n",
      "Word: FBI, Deprel: compound, Head: bugging\n",
      "Word: bugging, Deprel: nsubj, Head: given\n",
      "Word: of, Deprel: case, Head: mayor\n",
      "Word: the, Deprel: det, Head: mayor\n",
      "Word: mayor, Deprel: nmod, Head: bugging\n",
      "Word: had, Deprel: aux, Head: given\n",
      "Word: given, Deprel: ccomp, Head: showed\n",
      "Word: a, Deprel: det, Head: boost\n",
      "Word: boost, Deprel: obj, Head: given\n",
      "Word: to, Deprel: case, Head: effort\n",
      "Word: his, Deprel: nmod:poss, Head: effort\n",
      "Word: reelection, Deprel: compound, Head: effort\n",
      "Word: effort, Deprel: nmod, Head: boost\n",
      "Word: against, Deprel: case, Head: opponent\n",
      "Word: GOP, Deprel: compound, Head: opponent\n",
      "Word: opponent, Deprel: nmod, Head: effort\n",
      "Word: Sam, Deprel: flat, Head: opponent\n",
      "Word: Katz, Deprel: flat, Head: Sam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A poll released this week showed that the FBI bugging of the mayor has given a boost to his re-election effort'\n",
      "Word: A, Deprel: det, Head: poll\n",
      "Word: poll, Deprel: nsubj, Head: showed\n",
      "Word: released, Deprel: acl, Head: poll\n",
      "Word: this, Deprel: det, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: released\n",
      "Word: showed, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: given\n",
      "Word: the, Deprel: det, Head: bugging\n",
      "Word: FBI, Deprel: compound, Head: bugging\n",
      "Word: bugging, Deprel: nsubj, Head: given\n",
      "Word: of, Deprel: case, Head: mayor\n",
      "Word: the, Deprel: det, Head: mayor\n",
      "Word: mayor, Deprel: nmod, Head: bugging\n",
      "Word: has, Deprel: aux, Head: given\n",
      "Word: given, Deprel: ccomp, Head: showed\n",
      "Word: a, Deprel: det, Head: boost\n",
      "Word: boost, Deprel: obj, Head: given\n",
      "Word: to, Deprel: case, Head: effort\n",
      "Word: his, Deprel: nmod:poss, Head: effort\n",
      "Word: re-election, Deprel: compound, Head: effort\n",
      "Word: effort, Deprel: nmod, Head: boost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bulger s brother is now on the agency s 10 Most Wanted list sought in connection with 21 murders'\n",
      "Word: Bulger, Deprel: nmod:poss, Head: brother\n",
      "Word: s, Deprel: case, Head: Bulger\n",
      "Word: brother, Deprel: nsubj, Head: list\n",
      "Word: is, Deprel: cop, Head: list\n",
      "Word: now, Deprel: advmod, Head: list\n",
      "Word: on, Deprel: case, Head: list\n",
      "Word: the, Deprel: det, Head: agency\n",
      "Word: agency, Deprel: nmod:poss, Head: list\n",
      "Word: s, Deprel: case, Head: agency\n",
      "Word: 10, Deprel: nummod, Head: Wanted\n",
      "Word: Most, Deprel: advmod, Head: Wanted\n",
      "Word: Wanted, Deprel: amod, Head: list\n",
      "Word: list, Deprel: root, Head: ROOT\n",
      "Word: sought, Deprel: acl, Head: list\n",
      "Word: in, Deprel: case, Head: connection\n",
      "Word: connection, Deprel: obl, Head: sought\n",
      "Word: with, Deprel: case, Head: murders\n",
      "Word: 21, Deprel: nummod, Head: murders\n",
      "Word: murders, Deprel: nmod, Head: connection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bulger s brother a former FBI informant is now on the law enforcement agency s 10 Most Wanted list'\n",
      "Word: Bulger, Deprel: nmod:poss, Head: brother\n",
      "Word: s, Deprel: case, Head: Bulger\n",
      "Word: brother, Deprel: nsubj, Head: list\n",
      "Word: a, Deprel: det, Head: informant\n",
      "Word: former, Deprel: amod, Head: informant\n",
      "Word: FBI, Deprel: compound, Head: informant\n",
      "Word: informant, Deprel: appos, Head: brother\n",
      "Word: is, Deprel: cop, Head: list\n",
      "Word: now, Deprel: advmod, Head: list\n",
      "Word: on, Deprel: case, Head: list\n",
      "Word: the, Deprel: det, Head: agency\n",
      "Word: law, Deprel: compound, Head: enforcement\n",
      "Word: enforcement, Deprel: compound, Head: agency\n",
      "Word: agency, Deprel: nmod:poss, Head: list\n",
      "Word: s, Deprel: case, Head: agency\n",
      "Word: 10, Deprel: nummod, Head: Wanted\n",
      "Word: Most, Deprel: advmod, Head: Wanted\n",
      "Word: Wanted, Deprel: amod, Head: list\n",
      "Word: list, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The injured passenger at John Peter Smith Hospital died later Friday morning Jones said'\n",
      "Word: The, Deprel: det, Head: passenger\n",
      "Word: injured, Deprel: amod, Head: passenger\n",
      "Word: passenger, Deprel: nsubj, Head: died\n",
      "Word: at, Deprel: case, Head: Hospital\n",
      "Word: John, Deprel: compound, Head: Hospital\n",
      "Word: Peter, Deprel: flat, Head: John\n",
      "Word: Smith, Deprel: flat, Head: John\n",
      "Word: Hospital, Deprel: nmod, Head: passenger\n",
      "Word: died, Deprel: root, Head: ROOT\n",
      "Word: later, Deprel: advmod, Head: morning\n",
      "Word: Friday, Deprel: compound, Head: morning\n",
      "Word: morning, Deprel: obl:tmod, Head: died\n",
      "Word: Jones, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: died\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The injured passenger at John Peter Smith died later in the morning his name has not been released Jones said'\n",
      "Word: The, Deprel: det, Head: passenger\n",
      "Word: injured, Deprel: amod, Head: passenger\n",
      "Word: passenger, Deprel: nsubj, Head: died\n",
      "Word: at, Deprel: case, Head: John\n",
      "Word: John, Deprel: nmod, Head: passenger\n",
      "Word: Peter, Deprel: flat, Head: John\n",
      "Word: Smith, Deprel: flat, Head: John\n",
      "Word: died, Deprel: root, Head: ROOT\n",
      "Word: later, Deprel: advmod, Head: died\n",
      "Word: in, Deprel: case, Head: morning\n",
      "Word: the, Deprel: det, Head: morning\n",
      "Word: morning, Deprel: obl, Head: died\n",
      "Word: his, Deprel: nmod:poss, Head: name\n",
      "Word: name, Deprel: nsubj:pass, Head: released\n",
      "Word: has, Deprel: aux, Head: released\n",
      "Word: not, Deprel: advmod, Head: released\n",
      "Word: been, Deprel: aux:pass, Head: released\n",
      "Word: released, Deprel: parataxis, Head: died\n",
      "Word: Jones, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: died\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Doctors had planned to deliver him two weeks early on or around November 14'\n",
      "Word: Doctors, Deprel: nsubj, Head: planned\n",
      "Word: had, Deprel: aux, Head: planned\n",
      "Word: planned, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: deliver\n",
      "Word: deliver, Deprel: xcomp, Head: planned\n",
      "Word: him, Deprel: obj, Head: deliver\n",
      "Word: two, Deprel: nummod, Head: weeks\n",
      "Word: weeks, Deprel: obl:npmod, Head: early\n",
      "Word: early, Deprel: advmod, Head: deliver\n",
      "Word: on, Deprel: case, Head: November\n",
      "Word: or, Deprel: cc, Head: around\n",
      "Word: around, Deprel: conj, Head: on\n",
      "Word: November, Deprel: obl, Head: deliver\n",
      "Word: 14, Deprel: nummod, Head: November\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A Caesarean had originally been planned in mid November two weeks early'\n",
      "Word: A, Deprel: det, Head: Caesarean\n",
      "Word: Caesarean, Deprel: nsubj:pass, Head: planned\n",
      "Word: had, Deprel: aux, Head: planned\n",
      "Word: originally, Deprel: advmod, Head: planned\n",
      "Word: been, Deprel: aux:pass, Head: planned\n",
      "Word: planned, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: November\n",
      "Word: mid, Deprel: compound, Head: November\n",
      "Word: November, Deprel: obl, Head: planned\n",
      "Word: two, Deprel: nummod, Head: weeks\n",
      "Word: weeks, Deprel: obl:npmod, Head: early\n",
      "Word: early, Deprel: advmod, Head: planned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Sobig.F spreads when unsuspecting computer users open file attachments in emails that contain such familiar headings as Thank You Re Details or Re That Movie'\n",
      "Word: Sobig.F, Deprel: nsubj, Head: spreads\n",
      "Word: spreads, Deprel: root, Head: ROOT\n",
      "Word: when, Deprel: advmod, Head: open\n",
      "Word: unsuspecting, Deprel: amod, Head: users\n",
      "Word: computer, Deprel: compound, Head: users\n",
      "Word: users, Deprel: nsubj, Head: open\n",
      "Word: open, Deprel: advcl, Head: spreads\n",
      "Word: file, Deprel: compound, Head: attachments\n",
      "Word: attachments, Deprel: obj, Head: open\n",
      "Word: in, Deprel: case, Head: emails\n",
      "Word: emails, Deprel: nmod, Head: attachments\n",
      "Word: that, Deprel: nsubj, Head: contain\n",
      "Word: contain, Deprel: acl:relcl, Head: emails\n",
      "Word: such, Deprel: amod, Head: headings\n",
      "Word: familiar, Deprel: amod, Head: headings\n",
      "Word: headings, Deprel: obj, Head: contain\n",
      "Word: as, Deprel: mark, Head: Thank\n",
      "Word: Thank, Deprel: acl, Head: headings\n",
      "Word: You, Deprel: obj, Head: Thank\n",
      "Word: Re, Deprel: case, Head: Details\n",
      "Word: Details, Deprel: obl, Head: Thank\n",
      "Word: or, Deprel: cc, Head: Movie\n",
      "Word: Re, Deprel: case, Head: Movie\n",
      "Word: That, Deprel: det, Head: Movie\n",
      "Word: Movie, Deprel: conj, Head: Details\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The virus spreads when unsuspecting computer users open file attachments in emails that contain familiar headings like Thank You and Re Details'\n",
      "Word: The, Deprel: det, Head: virus\n",
      "Word: virus, Deprel: nsubj, Head: spreads\n",
      "Word: spreads, Deprel: root, Head: ROOT\n",
      "Word: when, Deprel: advmod, Head: open\n",
      "Word: unsuspecting, Deprel: amod, Head: users\n",
      "Word: computer, Deprel: compound, Head: users\n",
      "Word: users, Deprel: nsubj, Head: open\n",
      "Word: open, Deprel: advcl, Head: spreads\n",
      "Word: file, Deprel: compound, Head: attachments\n",
      "Word: attachments, Deprel: obj, Head: open\n",
      "Word: in, Deprel: case, Head: emails\n",
      "Word: emails, Deprel: nmod, Head: attachments\n",
      "Word: that, Deprel: nsubj, Head: contain\n",
      "Word: contain, Deprel: acl:relcl, Head: emails\n",
      "Word: familiar, Deprel: amod, Head: headings\n",
      "Word: headings, Deprel: obj, Head: contain\n",
      "Word: like, Deprel: mark, Head: Thank\n",
      "Word: Thank, Deprel: acl, Head: headings\n",
      "Word: You, Deprel: obj, Head: Thank\n",
      "Word: and, Deprel: cc, Head: Details\n",
      "Word: Re, Deprel: case, Head: Details\n",
      "Word: Details, Deprel: conj, Head: You\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index IXIC rose 17.26 points or 1.06 percent to 1,640.06 based on the latest data'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-laced, Deprel: amod, Head: IXIC\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 17.26, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: rose\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.06, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,640.06\n",
      "Word: 1,640.06, Deprel: obl, Head: rose\n",
      "Word: based, Deprel: case, Head: data\n",
      "Word: on, Deprel: case, Head: data\n",
      "Word: the, Deprel: det, Head: data\n",
      "Word: latest, Deprel: amod, Head: data\n",
      "Word: data, Deprel: obl, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index SPX gained 5.51 points or 0.56 percent to 981.73'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broader, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: s\n",
      "Word: Poor, Deprel: amod, Head: s\n",
      "Word: s, Deprel: compound, Head: SPX\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: gained\n",
      "Word: gained, Deprel: root, Head: ROOT\n",
      "Word: 5.51, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: gained\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.56, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 981.73\n",
      "Word: 981.73, Deprel: obl, Head: gained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Founders of the group are Matsushita Electric Sony Hitachi NEC Royal Philips Electronics Samsung Sharp and Toshiba'\n",
      "Word: Founders, Deprel: nsubj, Head: Sharp\n",
      "Word: of, Deprel: case, Head: group\n",
      "Word: the, Deprel: det, Head: group\n",
      "Word: group, Deprel: nmod, Head: Founders\n",
      "Word: are, Deprel: cop, Head: Sharp\n",
      "Word: Matsushita, Deprel: compound, Head: Sharp\n",
      "Word: Electric, Deprel: amod, Head: Hitachi\n",
      "Word: Sony, Deprel: compound, Head: Hitachi\n",
      "Word: Hitachi, Deprel: compound, Head: NEC\n",
      "Word: NEC, Deprel: compound, Head: Sharp\n",
      "Word: Royal, Deprel: amod, Head: Philips\n",
      "Word: Philips, Deprel: compound, Head: Electronics\n",
      "Word: Electronics, Deprel: compound, Head: Samsung\n",
      "Word: Samsung, Deprel: compound, Head: Sharp\n",
      "Word: Sharp, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: Toshiba\n",
      "Word: Toshiba, Deprel: conj, Head: Sharp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'CELF s founding members are Hitachi Matsushita NEC Philips Samsung Sharp Sony and Toshiba'\n",
      "Word: CELF, Deprel: nmod:poss, Head: members\n",
      "Word: s, Deprel: case, Head: CELF\n",
      "Word: founding, Deprel: amod, Head: members\n",
      "Word: members, Deprel: nsubj, Head: Sony\n",
      "Word: are, Deprel: cop, Head: Sony\n",
      "Word: Hitachi, Deprel: compound, Head: Sony\n",
      "Word: Matsushita, Deprel: compound, Head: Sony\n",
      "Word: NEC, Deprel: compound, Head: Philips\n",
      "Word: Philips, Deprel: compound, Head: Sony\n",
      "Word: Samsung, Deprel: compound, Head: Sony\n",
      "Word: Sharp, Deprel: amod, Head: Sony\n",
      "Word: Sony, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: Toshiba\n",
      "Word: Toshiba, Deprel: conj, Head: Sony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Is it in the food supply says David Ropeik director of risk communication at the Harvard Center for Risk Analysis'\n",
      "Word: Is, Deprel: cop, Head: says\n",
      "Word: it, Deprel: nsubj, Head: says\n",
      "Word: in, Deprel: case, Head: supply\n",
      "Word: the, Deprel: det, Head: supply\n",
      "Word: food, Deprel: compound, Head: supply\n",
      "Word: supply, Deprel: obl, Head: says\n",
      "Word: says, Deprel: root, Head: ROOT\n",
      "Word: David, Deprel: obj, Head: says\n",
      "Word: Ropeik, Deprel: flat, Head: David\n",
      "Word: director, Deprel: appos, Head: David\n",
      "Word: of, Deprel: case, Head: communication\n",
      "Word: risk, Deprel: compound, Head: communication\n",
      "Word: communication, Deprel: nmod, Head: director\n",
      "Word: at, Deprel: case, Head: Center\n",
      "Word: the, Deprel: det, Head: Center\n",
      "Word: Harvard, Deprel: compound, Head: Center\n",
      "Word: Center, Deprel: nmod, Head: communication\n",
      "Word: for, Deprel: case, Head: Analysis\n",
      "Word: Risk, Deprel: compound, Head: Analysis\n",
      "Word: Analysis, Deprel: nmod, Head: Center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It s not zero said David Ropeik director of risk communication at the Harvard Center for Risk Analysis'\n",
      "Word: It, Deprel: nsubj, Head: zero\n",
      "Word: s, Deprel: cop, Head: said\n",
      "Word: not, Deprel: advmod, Head: zero\n",
      "Word: zero, Deprel: advmod, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: David, Deprel: obj, Head: said\n",
      "Word: Ropeik, Deprel: flat, Head: David\n",
      "Word: director, Deprel: appos, Head: David\n",
      "Word: of, Deprel: case, Head: communication\n",
      "Word: risk, Deprel: compound, Head: communication\n",
      "Word: communication, Deprel: nmod, Head: director\n",
      "Word: at, Deprel: case, Head: Center\n",
      "Word: the, Deprel: det, Head: Center\n",
      "Word: Harvard, Deprel: compound, Head: Center\n",
      "Word: Center, Deprel: nmod, Head: communication\n",
      "Word: for, Deprel: case, Head: Analysis\n",
      "Word: Risk, Deprel: compound, Head: Analysis\n",
      "Word: Analysis, Deprel: nmod, Head: Center\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'During a screaming match in 1999 Carolyn told John she was still sleeping with Bergin'\n",
      "Word: During, Deprel: case, Head: match\n",
      "Word: a, Deprel: det, Head: match\n",
      "Word: screaming, Deprel: amod, Head: match\n",
      "Word: match, Deprel: obl, Head: told\n",
      "Word: in, Deprel: case, Head: 1999\n",
      "Word: 1999, Deprel: nmod, Head: match\n",
      "Word: Carolyn, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: John, Deprel: iobj, Head: told\n",
      "Word: she, Deprel: nsubj, Head: sleeping\n",
      "Word: was, Deprel: aux, Head: sleeping\n",
      "Word: still, Deprel: advmod, Head: sleeping\n",
      "Word: sleeping, Deprel: ccomp, Head: told\n",
      "Word: with, Deprel: case, Head: Bergin\n",
      "Word: Bergin, Deprel: obl, Head: sleeping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'She in turn occasionally told John that she was still sleeping with an ex-boyfriend Baywatch hunk Michael Bergin'\n",
      "Word: She, Deprel: nsubj, Head: told\n",
      "Word: in, Deprel: case, Head: turn\n",
      "Word: turn, Deprel: obl, Head: told\n",
      "Word: occasionally, Deprel: advmod, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: John, Deprel: iobj, Head: told\n",
      "Word: that, Deprel: mark, Head: sleeping\n",
      "Word: she, Deprel: nsubj, Head: sleeping\n",
      "Word: was, Deprel: aux, Head: sleeping\n",
      "Word: still, Deprel: advmod, Head: sleeping\n",
      "Word: sleeping, Deprel: ccomp, Head: told\n",
      "Word: with, Deprel: case, Head: Michael\n",
      "Word: an, Deprel: det, Head: Michael\n",
      "Word: ex-boyfriend, Deprel: compound, Head: hunk\n",
      "Word: Baywatch, Deprel: compound, Head: hunk\n",
      "Word: hunk, Deprel: compound, Head: Michael\n",
      "Word: Michael, Deprel: obl, Head: sleeping\n",
      "Word: Bergin, Deprel: flat, Head: Michael\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On the other hand if this will help further establish Steve s innocence we welcome it'\n",
      "Word: On, Deprel: case, Head: hand\n",
      "Word: the, Deprel: det, Head: hand\n",
      "Word: other, Deprel: amod, Head: hand\n",
      "Word: hand, Deprel: obl, Head: welcome\n",
      "Word: if, Deprel: mark, Head: help\n",
      "Word: this, Deprel: nsubj, Head: help\n",
      "Word: will, Deprel: aux, Head: help\n",
      "Word: help, Deprel: advcl, Head: welcome\n",
      "Word: further, Deprel: advmod, Head: establish\n",
      "Word: establish, Deprel: xcomp, Head: help\n",
      "Word: Steve, Deprel: nmod:poss, Head: innocence\n",
      "Word: s, Deprel: case, Head: Steve\n",
      "Word: innocence, Deprel: obj, Head: establish\n",
      "Word: we, Deprel: nsubj, Head: welcome\n",
      "Word: welcome, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: obj, Head: welcome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'If draining the ponds in Maryland will further help establish Steve s innocence we welcome it'\n",
      "Word: If, Deprel: mark, Head: draining\n",
      "Word: draining, Deprel: csubj, Head: help\n",
      "Word: the, Deprel: det, Head: ponds\n",
      "Word: ponds, Deprel: obj, Head: draining\n",
      "Word: in, Deprel: case, Head: Maryland\n",
      "Word: Maryland, Deprel: obl, Head: draining\n",
      "Word: will, Deprel: aux, Head: help\n",
      "Word: further, Deprel: advmod, Head: help\n",
      "Word: help, Deprel: root, Head: ROOT\n",
      "Word: establish, Deprel: xcomp, Head: help\n",
      "Word: Steve, Deprel: nmod:poss, Head: innocence\n",
      "Word: s, Deprel: case, Head: Steve\n",
      "Word: innocence, Deprel: obj, Head: establish\n",
      "Word: we, Deprel: nsubj, Head: welcome\n",
      "Word: welcome, Deprel: acl:relcl, Head: innocence\n",
      "Word: it, Deprel: obj, Head: welcome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Florida s Supreme Court has twice refused to hear the case'\n",
      "Word: Florida, Deprel: nmod:poss, Head: Court\n",
      "Word: s, Deprel: case, Head: Florida\n",
      "Word: Supreme, Deprel: amod, Head: Court\n",
      "Word: Court, Deprel: nsubj, Head: refused\n",
      "Word: has, Deprel: aux, Head: refused\n",
      "Word: twice, Deprel: advmod, Head: refused\n",
      "Word: refused, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: hear\n",
      "Word: hear, Deprel: xcomp, Head: refused\n",
      "Word: the, Deprel: det, Head: case\n",
      "Word: case, Deprel: obj, Head: hear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Tuesday a Florida appeals court again refused to block removal of the tube'\n",
      "Word: On, Deprel: case, Head: Tuesday\n",
      "Word: Tuesday, Deprel: obl, Head: refused\n",
      "Word: a, Deprel: det, Head: court\n",
      "Word: Florida, Deprel: compound, Head: court\n",
      "Word: appeals, Deprel: compound, Head: court\n",
      "Word: court, Deprel: nsubj, Head: refused\n",
      "Word: again, Deprel: advmod, Head: refused\n",
      "Word: refused, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: block\n",
      "Word: block, Deprel: xcomp, Head: refused\n",
      "Word: removal, Deprel: obj, Head: block\n",
      "Word: of, Deprel: case, Head: tube\n",
      "Word: the, Deprel: det, Head: tube\n",
      "Word: tube, Deprel: nmod, Head: removal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Fletcher said he expects to have the support of lawmakers from agricultural states many of whom are on the committee'\n",
      "Word: Fletcher, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: expects\n",
      "Word: expects, Deprel: ccomp, Head: said\n",
      "Word: to, Deprel: mark, Head: have\n",
      "Word: have, Deprel: xcomp, Head: expects\n",
      "Word: the, Deprel: det, Head: support\n",
      "Word: support, Deprel: obj, Head: have\n",
      "Word: of, Deprel: case, Head: lawmakers\n",
      "Word: lawmakers, Deprel: nmod, Head: support\n",
      "Word: from, Deprel: case, Head: states\n",
      "Word: agricultural, Deprel: amod, Head: states\n",
      "Word: states, Deprel: nmod, Head: lawmakers\n",
      "Word: many, Deprel: nsubj, Head: committee\n",
      "Word: of, Deprel: case, Head: whom\n",
      "Word: whom, Deprel: nmod, Head: many\n",
      "Word: are, Deprel: cop, Head: committee\n",
      "Word: on, Deprel: case, Head: committee\n",
      "Word: the, Deprel: det, Head: committee\n",
      "Word: committee, Deprel: acl:relcl, Head: states\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He said he also expects to have the support of lawmakers from other agricultural states'\n",
      "Word: He, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: expects\n",
      "Word: also, Deprel: advmod, Head: expects\n",
      "Word: expects, Deprel: ccomp, Head: said\n",
      "Word: to, Deprel: mark, Head: have\n",
      "Word: have, Deprel: xcomp, Head: expects\n",
      "Word: the, Deprel: det, Head: support\n",
      "Word: support, Deprel: obj, Head: have\n",
      "Word: of, Deprel: case, Head: lawmakers\n",
      "Word: lawmakers, Deprel: nmod, Head: support\n",
      "Word: from, Deprel: case, Head: states\n",
      "Word: other, Deprel: amod, Head: states\n",
      "Word: agricultural, Deprel: amod, Head: states\n",
      "Word: states, Deprel: nmod, Head: lawmakers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Four versions of Windows operating systems are targeted Windows NT Windows 2000 Windows XP and Windows Server 2003'\n",
      "Word: Four, Deprel: nummod, Head: versions\n",
      "Word: versions, Deprel: nsubj:pass, Head: targeted\n",
      "Word: of, Deprel: case, Head: systems\n",
      "Word: Windows, Deprel: compound, Head: systems\n",
      "Word: operating, Deprel: compound, Head: systems\n",
      "Word: systems, Deprel: nmod, Head: versions\n",
      "Word: are, Deprel: aux:pass, Head: targeted\n",
      "Word: targeted, Deprel: root, Head: ROOT\n",
      "Word: Windows, Deprel: compound, Head: NT\n",
      "Word: NT, Deprel: compound, Head: Windows\n",
      "Word: Windows, Deprel: compound, Head: XP\n",
      "Word: 2000, Deprel: nummod, Head: Windows\n",
      "Word: Windows, Deprel: compound, Head: XP\n",
      "Word: XP, Deprel: obj, Head: targeted\n",
      "Word: and, Deprel: cc, Head: Server\n",
      "Word: Windows, Deprel: compound, Head: Server\n",
      "Word: Server, Deprel: conj, Head: XP\n",
      "Word: 2003, Deprel: nummod, Head: Server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new worm affects these Windows systems 2000 XP NT 4.0 and Server 2003'\n",
      "Word: The, Deprel: det, Head: worm\n",
      "Word: new, Deprel: amod, Head: worm\n",
      "Word: worm, Deprel: nsubj, Head: affects\n",
      "Word: affects, Deprel: root, Head: ROOT\n",
      "Word: these, Deprel: det, Head: systems\n",
      "Word: Windows, Deprel: compound, Head: systems\n",
      "Word: systems, Deprel: obj, Head: affects\n",
      "Word: 2000, Deprel: nummod, Head: NT\n",
      "Word: XP, Deprel: compound, Head: NT\n",
      "Word: NT, Deprel: appos, Head: systems\n",
      "Word: 4.0, Deprel: nummod, Head: NT\n",
      "Word: and, Deprel: cc, Head: Server\n",
      "Word: Server, Deprel: conj, Head: NT\n",
      "Word: 2003, Deprel: nummod, Head: Server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Seven 20 and 21-year-old cadets were ticketed by police for drinking alcohol in an off-campus hotel room early Saturday with two young women aged 16 and 18'\n",
      "Word: Seven, Deprel: nummod, Head: cadets\n",
      "Word: 20, Deprel: nummod, Head: cadets\n",
      "Word: and, Deprel: cc, Head: 21-year-old\n",
      "Word: 21-year-old, Deprel: conj, Head: 20\n",
      "Word: cadets, Deprel: nsubj:pass, Head: ticketed\n",
      "Word: were, Deprel: aux:pass, Head: ticketed\n",
      "Word: ticketed, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: police\n",
      "Word: police, Deprel: obl, Head: ticketed\n",
      "Word: for, Deprel: mark, Head: drinking\n",
      "Word: drinking, Deprel: advcl, Head: ticketed\n",
      "Word: alcohol, Deprel: obj, Head: drinking\n",
      "Word: in, Deprel: case, Head: room\n",
      "Word: an, Deprel: det, Head: room\n",
      "Word: off-campus, Deprel: amod, Head: room\n",
      "Word: hotel, Deprel: compound, Head: room\n",
      "Word: room, Deprel: obl, Head: drinking\n",
      "Word: early, Deprel: advmod, Head: Saturday\n",
      "Word: Saturday, Deprel: obl:tmod, Head: drinking\n",
      "Word: with, Deprel: case, Head: women\n",
      "Word: two, Deprel: nummod, Head: women\n",
      "Word: young, Deprel: amod, Head: women\n",
      "Word: women, Deprel: obl, Head: drinking\n",
      "Word: aged, Deprel: acl, Head: women\n",
      "Word: 16, Deprel: obj, Head: aged\n",
      "Word: and, Deprel: cc, Head: 18\n",
      "Word: 18, Deprel: conj, Head: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Seven 20 and 21-year-old male cadets were caught in an off-campus hotel room early Saturday with two female teens 16 and 18 years'\n",
      "Word: Seven, Deprel: nummod, Head: cadets\n",
      "Word: 20, Deprel: nummod, Head: cadets\n",
      "Word: and, Deprel: cc, Head: 21-year-old\n",
      "Word: 21-year-old, Deprel: conj, Head: 20\n",
      "Word: male, Deprel: amod, Head: cadets\n",
      "Word: cadets, Deprel: nsubj:pass, Head: caught\n",
      "Word: were, Deprel: aux:pass, Head: caught\n",
      "Word: caught, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: room\n",
      "Word: an, Deprel: det, Head: room\n",
      "Word: off-campus, Deprel: amod, Head: room\n",
      "Word: hotel, Deprel: compound, Head: room\n",
      "Word: room, Deprel: obl, Head: caught\n",
      "Word: early, Deprel: advmod, Head: Saturday\n",
      "Word: Saturday, Deprel: obl:tmod, Head: caught\n",
      "Word: with, Deprel: case, Head: teens\n",
      "Word: two, Deprel: nummod, Head: teens\n",
      "Word: female, Deprel: amod, Head: teens\n",
      "Word: teens, Deprel: obl, Head: caught\n",
      "Word: 16, Deprel: nummod, Head: teens\n",
      "Word: and, Deprel: cc, Head: 18\n",
      "Word: 18, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: conj, Head: teens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of McDonald s Corp and Wendy s International Inc continued a modest run-up on the New York Stock Exchange Monday'\n",
      "Word: Shares, Deprel: nsubj, Head: continued\n",
      "Word: of, Deprel: case, Head: Inc\n",
      "Word: McDonald, Deprel: nmod:poss, Head: Corp\n",
      "Word: s, Deprel: case, Head: McDonald\n",
      "Word: Corp, Deprel: nmod:poss, Head: Inc\n",
      "Word: and, Deprel: cc, Head: Wendy\n",
      "Word: Wendy, Deprel: conj, Head: Corp\n",
      "Word: s, Deprel: case, Head: Wendy\n",
      "Word: International, Deprel: amod, Head: Inc\n",
      "Word: Inc, Deprel: nmod, Head: Shares\n",
      "Word: continued, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: run-up\n",
      "Word: modest, Deprel: amod, Head: run-up\n",
      "Word: run-up, Deprel: obj, Head: continued\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: nmod, Head: run-up\n",
      "Word: Monday, Deprel: nmod:npmod, Head: Exchange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of McDonald s and Wendy s continued their recent recovery Monday rising more than 1 percent on the New York Stock Exchange in afternoon trade'\n",
      "Word: Shares, Deprel: nsubj, Head: continued\n",
      "Word: of, Deprel: case, Head: McDonald\n",
      "Word: McDonald, Deprel: nmod, Head: Shares\n",
      "Word: s, Deprel: case, Head: McDonald\n",
      "Word: and, Deprel: cc, Head: Wendy\n",
      "Word: Wendy, Deprel: conj, Head: McDonald\n",
      "Word: s, Deprel: case, Head: Wendy\n",
      "Word: continued, Deprel: root, Head: ROOT\n",
      "Word: their, Deprel: nmod:poss, Head: recovery\n",
      "Word: recent, Deprel: amod, Head: recovery\n",
      "Word: recovery, Deprel: obj, Head: continued\n",
      "Word: Monday, Deprel: obl:tmod, Head: continued\n",
      "Word: rising, Deprel: advcl, Head: continued\n",
      "Word: more, Deprel: advmod, Head: 1\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 1, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: rising\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: rising\n",
      "Word: in, Deprel: case, Head: trade\n",
      "Word: afternoon, Deprel: compound, Head: trade\n",
      "Word: trade, Deprel: nmod, Head: Exchange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Such a step could put the issue before the UN Security Council'\n",
      "Word: Such, Deprel: det:predet, Head: step\n",
      "Word: a, Deprel: det, Head: step\n",
      "Word: step, Deprel: nsubj, Head: put\n",
      "Word: could, Deprel: aux, Head: put\n",
      "Word: put, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: issue\n",
      "Word: issue, Deprel: obj, Head: put\n",
      "Word: before, Deprel: case, Head: Council\n",
      "Word: the, Deprel: det, Head: Council\n",
      "Word: UN, Deprel: compound, Head: Council\n",
      "Word: Security, Deprel: compound, Head: Council\n",
      "Word: Council, Deprel: obl, Head: put\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The matter could then be sent to the U.N Security Council'\n",
      "Word: The, Deprel: det, Head: matter\n",
      "Word: matter, Deprel: nsubj:pass, Head: sent\n",
      "Word: could, Deprel: aux, Head: sent\n",
      "Word: then, Deprel: advmod, Head: sent\n",
      "Word: be, Deprel: aux:pass, Head: sent\n",
      "Word: sent, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Council\n",
      "Word: the, Deprel: det, Head: Council\n",
      "Word: U.N, Deprel: compound, Head: Council\n",
      "Word: Security, Deprel: compound, Head: Council\n",
      "Word: Council, Deprel: obl, Head: sent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He planned to stay all day until the river crested which was forecast for late last night'\n",
      "Word: He, Deprel: nsubj, Head: planned\n",
      "Word: planned, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: stay\n",
      "Word: stay, Deprel: xcomp, Head: planned\n",
      "Word: all, Deprel: det, Head: day\n",
      "Word: day, Deprel: obl:tmod, Head: stay\n",
      "Word: until, Deprel: mark, Head: crested\n",
      "Word: the, Deprel: det, Head: river\n",
      "Word: river, Deprel: nsubj, Head: crested\n",
      "Word: crested, Deprel: advcl, Head: stay\n",
      "Word: which, Deprel: nsubj:pass, Head: forecast\n",
      "Word: was, Deprel: aux:pass, Head: forecast\n",
      "Word: forecast, Deprel: ccomp, Head: crested\n",
      "Word: for, Deprel: case, Head: night\n",
      "Word: late, Deprel: advmod, Head: night\n",
      "Word: last, Deprel: amod, Head: night\n",
      "Word: night, Deprel: obl, Head: forecast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He and the other lawyers planned to stay until the river starts receding'\n",
      "Word: He, Deprel: nsubj, Head: planned\n",
      "Word: and, Deprel: cc, Head: lawyers\n",
      "Word: the, Deprel: det, Head: lawyers\n",
      "Word: other, Deprel: amod, Head: lawyers\n",
      "Word: lawyers, Deprel: conj, Head: He\n",
      "Word: planned, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: stay\n",
      "Word: stay, Deprel: xcomp, Head: planned\n",
      "Word: until, Deprel: mark, Head: starts\n",
      "Word: the, Deprel: det, Head: river\n",
      "Word: river, Deprel: nsubj, Head: starts\n",
      "Word: starts, Deprel: advcl, Head: stay\n",
      "Word: receding, Deprel: xcomp, Head: starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The camp hosts summer religious retreats for children and other events year-round according to its Web site'\n",
      "Word: The, Deprel: det, Head: camp\n",
      "Word: camp, Deprel: nsubj, Head: hosts\n",
      "Word: hosts, Deprel: root, Head: ROOT\n",
      "Word: summer, Deprel: compound, Head: retreats\n",
      "Word: religious, Deprel: amod, Head: retreats\n",
      "Word: retreats, Deprel: obj, Head: hosts\n",
      "Word: for, Deprel: case, Head: children\n",
      "Word: children, Deprel: nmod, Head: retreats\n",
      "Word: and, Deprel: cc, Head: events\n",
      "Word: other, Deprel: amod, Head: events\n",
      "Word: events, Deprel: conj, Head: children\n",
      "Word: year-round, Deprel: advmod, Head: hosts\n",
      "Word: according, Deprel: case, Head: site\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: its, Deprel: nmod:poss, Head: site\n",
      "Word: Web, Deprel: compound, Head: site\n",
      "Word: site, Deprel: obl, Head: hosts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Saint Sophia Camp hosts religious retreats for children during the summer months as well as other events year round according to its Web site'\n",
      "Word: The, Deprel: det, Head: Camp\n",
      "Word: Saint, Deprel: compound, Head: Camp\n",
      "Word: Sophia, Deprel: flat, Head: Saint\n",
      "Word: Camp, Deprel: nsubj, Head: hosts\n",
      "Word: hosts, Deprel: root, Head: ROOT\n",
      "Word: religious, Deprel: amod, Head: retreats\n",
      "Word: retreats, Deprel: obj, Head: hosts\n",
      "Word: for, Deprel: case, Head: children\n",
      "Word: children, Deprel: nmod, Head: retreats\n",
      "Word: during, Deprel: case, Head: months\n",
      "Word: the, Deprel: det, Head: months\n",
      "Word: summer, Deprel: compound, Head: months\n",
      "Word: months, Deprel: obl, Head: hosts\n",
      "Word: as, Deprel: cc, Head: events\n",
      "Word: well, Deprel: fixed, Head: as\n",
      "Word: as, Deprel: fixed, Head: as\n",
      "Word: other, Deprel: amod, Head: events\n",
      "Word: events, Deprel: conj, Head: retreats\n",
      "Word: year, Deprel: nmod:tmod, Head: events\n",
      "Word: round, Deprel: advmod, Head: events\n",
      "Word: according, Deprel: case, Head: site\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: its, Deprel: nmod:poss, Head: site\n",
      "Word: Web, Deprel: compound, Head: site\n",
      "Word: site, Deprel: nmod, Head: events\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dealers said the single currency s downward momentum against the dollar could pick up speed if it broke below 1.15'\n",
      "Word: Dealers, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: currency\n",
      "Word: single, Deprel: amod, Head: currency\n",
      "Word: currency, Deprel: nmod:poss, Head: momentum\n",
      "Word: s, Deprel: case, Head: currency\n",
      "Word: downward, Deprel: amod, Head: momentum\n",
      "Word: momentum, Deprel: nsubj, Head: pick\n",
      "Word: against, Deprel: case, Head: dollar\n",
      "Word: the, Deprel: det, Head: dollar\n",
      "Word: dollar, Deprel: nmod, Head: momentum\n",
      "Word: could, Deprel: aux, Head: pick\n",
      "Word: pick, Deprel: ccomp, Head: said\n",
      "Word: up, Deprel: compound:prt, Head: pick\n",
      "Word: speed, Deprel: obj, Head: pick\n",
      "Word: if, Deprel: mark, Head: broke\n",
      "Word: it, Deprel: nsubj, Head: broke\n",
      "Word: broke, Deprel: advcl, Head: pick\n",
      "Word: below, Deprel: case, Head: 1.15\n",
      "Word: 1.15, Deprel: obl, Head: broke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dealers said the euro s downward momentum may pick up speed should it break below 1.15'\n",
      "Word: Dealers, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: euro\n",
      "Word: euro, Deprel: nmod:poss, Head: momentum\n",
      "Word: s, Deprel: case, Head: euro\n",
      "Word: downward, Deprel: amod, Head: momentum\n",
      "Word: momentum, Deprel: nsubj, Head: pick\n",
      "Word: may, Deprel: aux, Head: pick\n",
      "Word: pick, Deprel: ccomp, Head: said\n",
      "Word: up, Deprel: compound:prt, Head: pick\n",
      "Word: speed, Deprel: obj, Head: pick\n",
      "Word: should, Deprel: aux, Head: break\n",
      "Word: it, Deprel: nsubj, Head: break\n",
      "Word: break, Deprel: advcl, Head: pick\n",
      "Word: below, Deprel: case, Head: 1.15\n",
      "Word: 1.15, Deprel: obl, Head: break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Gemstar s shares gathered up 2.6 percent adding 14 cents to 5.49 at the close'\n",
      "Word: Gemstar, Deprel: nmod:poss, Head: shares\n",
      "Word: s, Deprel: case, Head: Gemstar\n",
      "Word: shares, Deprel: nsubj, Head: gathered\n",
      "Word: gathered, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: advmod, Head: gathered\n",
      "Word: 2.6, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:npmod, Head: adding\n",
      "Word: adding, Deprel: advcl, Head: gathered\n",
      "Word: 14, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obj, Head: adding\n",
      "Word: to, Deprel: case, Head: 5.49\n",
      "Word: 5.49, Deprel: obl, Head: adding\n",
      "Word: at, Deprel: case, Head: close\n",
      "Word: the, Deprel: det, Head: close\n",
      "Word: close, Deprel: obl, Head: adding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Gemstar shares moved higher on the news closing up 2.6 percent at 5.49 on Nasdaq'\n",
      "Word: Gemstar, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: moved\n",
      "Word: moved, Deprel: root, Head: ROOT\n",
      "Word: higher, Deprel: advmod, Head: moved\n",
      "Word: on, Deprel: case, Head: news\n",
      "Word: the, Deprel: det, Head: news\n",
      "Word: news, Deprel: obl, Head: moved\n",
      "Word: closing, Deprel: acl, Head: news\n",
      "Word: up, Deprel: advmod, Head: closing\n",
      "Word: 2.6, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: closing\n",
      "Word: at, Deprel: case, Head: 5.49\n",
      "Word: 5.49, Deprel: obl, Head: closing\n",
      "Word: on, Deprel: case, Head: Nasdaq\n",
      "Word: Nasdaq, Deprel: obl, Head: closing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The European Union is basically absent said Tito Barbini regional minister for agriculture in Tuscany Italy'\n",
      "Word: The, Deprel: det, Head: Union\n",
      "Word: European, Deprel: amod, Head: Union\n",
      "Word: Union, Deprel: nsubj, Head: absent\n",
      "Word: is, Deprel: cop, Head: absent\n",
      "Word: basically, Deprel: advmod, Head: absent\n",
      "Word: absent, Deprel: root, Head: ROOT\n",
      "Word: said, Deprel: parataxis, Head: absent\n",
      "Word: Tito, Deprel: compound, Head: minister\n",
      "Word: Barbini, Deprel: flat, Head: Tito\n",
      "Word: regional, Deprel: amod, Head: minister\n",
      "Word: minister, Deprel: obj, Head: said\n",
      "Word: for, Deprel: case, Head: agriculture\n",
      "Word: agriculture, Deprel: nmod, Head: minister\n",
      "Word: in, Deprel: case, Head: Italy\n",
      "Word: Tuscany, Deprel: compound, Head: Italy\n",
      "Word: Italy, Deprel: nmod, Head: minister\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Tito Barbini a regional minister for agriculture in Tuscany Italy criticized the absence Tuesday in Sacramento'\n",
      "Word: Tito, Deprel: nsubj, Head: criticized\n",
      "Word: Barbini, Deprel: flat, Head: Tito\n",
      "Word: a, Deprel: det, Head: minister\n",
      "Word: regional, Deprel: amod, Head: minister\n",
      "Word: minister, Deprel: appos, Head: Tito\n",
      "Word: for, Deprel: case, Head: agriculture\n",
      "Word: agriculture, Deprel: nmod, Head: minister\n",
      "Word: in, Deprel: case, Head: Italy\n",
      "Word: Tuscany, Deprel: compound, Head: Italy\n",
      "Word: Italy, Deprel: nmod, Head: agriculture\n",
      "Word: criticized, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: absence\n",
      "Word: absence, Deprel: obj, Head: criticized\n",
      "Word: Tuesday, Deprel: obl:tmod, Head: criticized\n",
      "Word: in, Deprel: case, Head: Sacramento\n",
      "Word: Sacramento, Deprel: nmod, Head: Tuesday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Along with chipmaker Intel the companies include Sony Corp Microsoft Corp Hewlett-Packard Co IBM Corp Gateway Inc and Nokia Corp'\n",
      "Word: Along, Deprel: case, Head: Intel\n",
      "Word: with, Deprel: case, Head: Intel\n",
      "Word: chipmaker, Deprel: compound, Head: Intel\n",
      "Word: Intel, Deprel: obl, Head: include\n",
      "Word: the, Deprel: det, Head: companies\n",
      "Word: companies, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: Sony, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: compound, Head: Corp\n",
      "Word: Microsoft, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: compound, Head: Co\n",
      "Word: Hewlett-Packard, Deprel: compound, Head: Co\n",
      "Word: Co, Deprel: compound, Head: Inc\n",
      "Word: IBM, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: compound, Head: Inc\n",
      "Word: Gateway, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: obj, Head: include\n",
      "Word: and, Deprel: cc, Head: Corp\n",
      "Word: Nokia, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: conj, Head: Inc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Along with chip maker Intel the companies include Sony Microsoft Hewlett-Packard International Business Machines Gateway Nokia and others'\n",
      "Word: Along, Deprel: case, Head: Intel\n",
      "Word: with, Deprel: case, Head: Intel\n",
      "Word: chip, Deprel: compound, Head: maker\n",
      "Word: maker, Deprel: compound, Head: Intel\n",
      "Word: Intel, Deprel: obl, Head: include\n",
      "Word: the, Deprel: det, Head: companies\n",
      "Word: companies, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: Sony, Deprel: compound, Head: Hewlett-Packard\n",
      "Word: Microsoft, Deprel: compound, Head: Hewlett-Packard\n",
      "Word: Hewlett-Packard, Deprel: compound, Head: Nokia\n",
      "Word: International, Deprel: amod, Head: Machines\n",
      "Word: Business, Deprel: compound, Head: Machines\n",
      "Word: Machines, Deprel: compound, Head: Gateway\n",
      "Word: Gateway, Deprel: compound, Head: Nokia\n",
      "Word: Nokia, Deprel: obj, Head: include\n",
      "Word: and, Deprel: cc, Head: others\n",
      "Word: others, Deprel: conj, Head: Nokia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Kroger Co which owns Ralphs and Albertsons Inc bargain jointly with Safeway and locked out their union workers the next day'\n",
      "Word: Kroger, Deprel: compound, Head: Co\n",
      "Word: Co, Deprel: root, Head: ROOT\n",
      "Word: which, Deprel: nsubj, Head: owns\n",
      "Word: owns, Deprel: acl:relcl, Head: Co\n",
      "Word: Ralphs, Deprel: compound, Head: bargain\n",
      "Word: and, Deprel: cc, Head: Inc\n",
      "Word: Albertsons, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: conj, Head: Ralphs\n",
      "Word: bargain, Deprel: obj, Head: owns\n",
      "Word: jointly, Deprel: advmod, Head: owns\n",
      "Word: with, Deprel: case, Head: Safeway\n",
      "Word: Safeway, Deprel: obl, Head: owns\n",
      "Word: and, Deprel: cc, Head: locked\n",
      "Word: locked, Deprel: conj, Head: owns\n",
      "Word: out, Deprel: compound:prt, Head: locked\n",
      "Word: their, Deprel: nmod:poss, Head: workers\n",
      "Word: union, Deprel: compound, Head: workers\n",
      "Word: workers, Deprel: obj, Head: locked\n",
      "Word: the, Deprel: det, Head: day\n",
      "Word: next, Deprel: amod, Head: day\n",
      "Word: day, Deprel: obl:tmod, Head: locked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In a show of corporate solidarity Kroger Co which owns Ralphs and Albertson Inc locked out their workers the next morning'\n",
      "Word: In, Deprel: case, Head: show\n",
      "Word: a, Deprel: det, Head: show\n",
      "Word: show, Deprel: obl, Head: locked\n",
      "Word: of, Deprel: case, Head: solidarity\n",
      "Word: corporate, Deprel: amod, Head: solidarity\n",
      "Word: solidarity, Deprel: nmod, Head: show\n",
      "Word: Kroger, Deprel: compound, Head: Co\n",
      "Word: Co, Deprel: nsubj, Head: locked\n",
      "Word: which, Deprel: nsubj, Head: owns\n",
      "Word: owns, Deprel: acl:relcl, Head: Co\n",
      "Word: Ralphs, Deprel: compound, Head: Inc\n",
      "Word: and, Deprel: cc, Head: Inc\n",
      "Word: Albertson, Deprel: conj, Head: Ralphs\n",
      "Word: Inc, Deprel: obj, Head: owns\n",
      "Word: locked, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: compound:prt, Head: locked\n",
      "Word: their, Deprel: nmod:poss, Head: workers\n",
      "Word: workers, Deprel: obj, Head: locked\n",
      "Word: the, Deprel: det, Head: morning\n",
      "Word: next, Deprel: amod, Head: morning\n",
      "Word: morning, Deprel: obl:tmod, Head: locked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'According to the Census Bureau the Hispanic population increased by 9.8 percent from the April 2000 census figures'\n",
      "Word: According, Deprel: case, Head: Bureau\n",
      "Word: to, Deprel: fixed, Head: According\n",
      "Word: the, Deprel: det, Head: Bureau\n",
      "Word: Census, Deprel: compound, Head: Bureau\n",
      "Word: Bureau, Deprel: obl, Head: increased\n",
      "Word: the, Deprel: det, Head: population\n",
      "Word: Hispanic, Deprel: amod, Head: population\n",
      "Word: population, Deprel: nsubj, Head: increased\n",
      "Word: increased, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: percent\n",
      "Word: 9.8, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: increased\n",
      "Word: from, Deprel: case, Head: figures\n",
      "Word: the, Deprel: det, Head: figures\n",
      "Word: April, Deprel: compound, Head: figures\n",
      "Word: 2000, Deprel: nummod, Head: April\n",
      "Word: census, Deprel: compound, Head: figures\n",
      "Word: figures, Deprel: obl, Head: increased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Hispanic population increased by 9.8per cent from the April 2000 census figures despite less favourable social and economic conditions than in the 1990s'\n",
      "Word: The, Deprel: det, Head: population\n",
      "Word: Hispanic, Deprel: amod, Head: population\n",
      "Word: population, Deprel: nsubj, Head: increased\n",
      "Word: increased, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: cent\n",
      "Word: 9.8per, Deprel: nummod, Head: cent\n",
      "Word: cent, Deprel: obl, Head: increased\n",
      "Word: from, Deprel: case, Head: figures\n",
      "Word: the, Deprel: det, Head: figures\n",
      "Word: April, Deprel: compound, Head: figures\n",
      "Word: 2000, Deprel: nummod, Head: April\n",
      "Word: census, Deprel: compound, Head: figures\n",
      "Word: figures, Deprel: obl, Head: increased\n",
      "Word: despite, Deprel: case, Head: conditions\n",
      "Word: less, Deprel: advmod, Head: favourable\n",
      "Word: favourable, Deprel: amod, Head: conditions\n",
      "Word: social, Deprel: amod, Head: conditions\n",
      "Word: and, Deprel: cc, Head: economic\n",
      "Word: economic, Deprel: conj, Head: social\n",
      "Word: conditions, Deprel: obl, Head: increased\n",
      "Word: than, Deprel: mark, Head: 1990s\n",
      "Word: in, Deprel: case, Head: 1990s\n",
      "Word: the, Deprel: det, Head: 1990s\n",
      "Word: 1990s, Deprel: advcl, Head: increased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Its shares jumped to 54.50 in pre-open trading from 50.90 at Wednesday s close'\n",
      "Word: Its, Deprel: nmod:poss, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: jumped\n",
      "Word: jumped, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: 54.50\n",
      "Word: 54.50, Deprel: obl, Head: jumped\n",
      "Word: in, Deprel: case, Head: trading\n",
      "Word: pre-open, Deprel: amod, Head: trading\n",
      "Word: trading, Deprel: obl, Head: jumped\n",
      "Word: from, Deprel: case, Head: 50.90\n",
      "Word: 50.90, Deprel: obl, Head: jumped\n",
      "Word: at, Deprel: case, Head: close\n",
      "Word: Wednesday, Deprel: nmod:poss, Head: close\n",
      "Word: s, Deprel: case, Head: Wednesday\n",
      "Word: close, Deprel: obl, Head: jumped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares jumped almost 7 percent in pre-open trading rising to 18.26 from 17.05 at Tuesday s close'\n",
      "Word: Shares, Deprel: nsubj, Head: jumped\n",
      "Word: jumped, Deprel: root, Head: ROOT\n",
      "Word: almost, Deprel: advmod, Head: 7\n",
      "Word: 7, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: jumped\n",
      "Word: in, Deprel: case, Head: trading\n",
      "Word: pre-open, Deprel: amod, Head: trading\n",
      "Word: trading, Deprel: obl, Head: jumped\n",
      "Word: rising, Deprel: advcl, Head: jumped\n",
      "Word: to, Deprel: case, Head: 18.26\n",
      "Word: 18.26, Deprel: obl, Head: rising\n",
      "Word: from, Deprel: case, Head: 17.05\n",
      "Word: 17.05, Deprel: nmod, Head: 18.26\n",
      "Word: at, Deprel: case, Head: close\n",
      "Word: Tuesday, Deprel: nmod:poss, Head: close\n",
      "Word: s, Deprel: case, Head: Tuesday\n",
      "Word: close, Deprel: obl, Head: rising\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He playfully chided the Senate s little bitty tax relief plan'\n",
      "Word: He, Deprel: nsubj, Head: chided\n",
      "Word: playfully, Deprel: advmod, Head: chided\n",
      "Word: chided, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: Senate\n",
      "Word: Senate, Deprel: nmod:poss, Head: plan\n",
      "Word: s, Deprel: case, Head: Senate\n",
      "Word: little, Deprel: amod, Head: plan\n",
      "Word: bitty, Deprel: amod, Head: plan\n",
      "Word: tax, Deprel: compound, Head: relief\n",
      "Word: relief, Deprel: compound, Head: plan\n",
      "Word: plan, Deprel: obj, Head: chided\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We do n't need a little bitty tax relief plan'\n",
      "Word: We, Deprel: nsubj, Head: need\n",
      "Word: do, Deprel: aux, Head: need\n",
      "Word: n't, Deprel: advmod, Head: need\n",
      "Word: need, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: plan\n",
      "Word: little, Deprel: amod, Head: plan\n",
      "Word: bitty, Deprel: amod, Head: plan\n",
      "Word: tax, Deprel: compound, Head: relief\n",
      "Word: relief, Deprel: compound, Head: plan\n",
      "Word: plan, Deprel: obj, Head: need\n",
      "\n",
      "Dependencies for Sentence: 'Looking to buy the latest Harry Potter'\n",
      "Word: Looking, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: buy\n",
      "Word: buy, Deprel: xcomp, Head: Looking\n",
      "Word: the, Deprel: det, Head: Harry\n",
      "Word: latest, Deprel: amod, Head: Harry\n",
      "Word: Harry, Deprel: obj, Head: buy\n",
      "Word: Potter, Deprel: flat, Head: Harry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Harry Potter s latest wizard trick'\n",
      "Word: Harry, Deprel: nmod:poss, Head: trick\n",
      "Word: Potter, Deprel: flat, Head: Harry\n",
      "Word: s, Deprel: case, Head: Harry\n",
      "Word: latest, Deprel: amod, Head: trick\n",
      "Word: wizard, Deprel: compound, Head: trick\n",
      "Word: trick, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'MediaQ s customers include major handheld makers Mitsubishi Siemens Palm Sharp Philips Dell and Sony'\n",
      "Word: MediaQ, Deprel: nmod:poss, Head: customers\n",
      "Word: s, Deprel: case, Head: MediaQ\n",
      "Word: customers, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: major, Deprel: amod, Head: makers\n",
      "Word: handheld, Deprel: compound, Head: makers\n",
      "Word: makers, Deprel: compound, Head: Dell\n",
      "Word: Mitsubishi, Deprel: compound, Head: Siemens\n",
      "Word: Siemens, Deprel: compound, Head: Dell\n",
      "Word: Palm, Deprel: compound, Head: Sharp\n",
      "Word: Sharp, Deprel: compound, Head: Philips\n",
      "Word: Philips, Deprel: compound, Head: Dell\n",
      "Word: Dell, Deprel: obj, Head: include\n",
      "Word: and, Deprel: cc, Head: Sony\n",
      "Word: Sony, Deprel: conj, Head: Dell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Nvidia will take advantage of MediaQ customers which include such players as Siemens AG Sharp Philips Dell Mitsubishi and Sony Corp'\n",
      "Word: Nvidia, Deprel: nsubj, Head: take\n",
      "Word: will, Deprel: aux, Head: take\n",
      "Word: take, Deprel: root, Head: ROOT\n",
      "Word: advantage, Deprel: obj, Head: take\n",
      "Word: of, Deprel: case, Head: customers\n",
      "Word: MediaQ, Deprel: compound, Head: customers\n",
      "Word: customers, Deprel: nmod, Head: advantage\n",
      "Word: which, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: acl:relcl, Head: customers\n",
      "Word: such, Deprel: amod, Head: players\n",
      "Word: players, Deprel: obj, Head: include\n",
      "Word: as, Deprel: case, Head: Mitsubishi\n",
      "Word: Siemens, Deprel: compound, Head: Mitsubishi\n",
      "Word: AG, Deprel: compound, Head: Mitsubishi\n",
      "Word: Sharp, Deprel: amod, Head: Mitsubishi\n",
      "Word: Philips, Deprel: compound, Head: Mitsubishi\n",
      "Word: Dell, Deprel: compound, Head: Mitsubishi\n",
      "Word: Mitsubishi, Deprel: nmod, Head: players\n",
      "Word: and, Deprel: cc, Head: Corp\n",
      "Word: Sony, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: conj, Head: Mitsubishi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Aventis based in Strasbourg France is one of a handful of companies that still make the flu vaccine'\n",
      "Word: Aventis, Deprel: nsubj, Head: one\n",
      "Word: based, Deprel: acl, Head: Aventis\n",
      "Word: in, Deprel: case, Head: France\n",
      "Word: Strasbourg, Deprel: compound, Head: France\n",
      "Word: France, Deprel: obl, Head: based\n",
      "Word: is, Deprel: cop, Head: one\n",
      "Word: one, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: handful\n",
      "Word: a, Deprel: det, Head: handful\n",
      "Word: handful, Deprel: nmod, Head: one\n",
      "Word: of, Deprel: case, Head: companies\n",
      "Word: companies, Deprel: nmod, Head: handful\n",
      "Word: that, Deprel: nsubj, Head: make\n",
      "Word: still, Deprel: advmod, Head: make\n",
      "Word: make, Deprel: acl:relcl, Head: handful\n",
      "Word: the, Deprel: det, Head: vaccine\n",
      "Word: flu, Deprel: compound, Head: vaccine\n",
      "Word: vaccine, Deprel: obj, Head: make\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Aventis based in Strasbourg France is one of the leading producers of the vaccine and one of a handful of companies that still make it'\n",
      "Word: Aventis, Deprel: nsubj, Head: one\n",
      "Word: based, Deprel: acl, Head: Aventis\n",
      "Word: in, Deprel: case, Head: France\n",
      "Word: Strasbourg, Deprel: compound, Head: France\n",
      "Word: France, Deprel: obl, Head: based\n",
      "Word: is, Deprel: cop, Head: one\n",
      "Word: one, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: producers\n",
      "Word: the, Deprel: det, Head: producers\n",
      "Word: leading, Deprel: amod, Head: producers\n",
      "Word: producers, Deprel: nmod, Head: one\n",
      "Word: of, Deprel: case, Head: vaccine\n",
      "Word: the, Deprel: det, Head: vaccine\n",
      "Word: vaccine, Deprel: nmod, Head: producers\n",
      "Word: and, Deprel: cc, Head: one\n",
      "Word: one, Deprel: conj, Head: producers\n",
      "Word: of, Deprel: case, Head: handful\n",
      "Word: a, Deprel: det, Head: handful\n",
      "Word: handful, Deprel: nmod, Head: one\n",
      "Word: of, Deprel: case, Head: companies\n",
      "Word: companies, Deprel: nmod, Head: handful\n",
      "Word: that, Deprel: nsubj, Head: make\n",
      "Word: still, Deprel: advmod, Head: make\n",
      "Word: make, Deprel: acl:relcl, Head: companies\n",
      "Word: it, Deprel: obj, Head: make\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Dow Jones industrial average DJI was off 58.69 points or 0.64 percent at 9,137.86'\n",
      "Word: The, Deprel: det, Head: DJI\n",
      "Word: Dow, Deprel: compound, Head: Jones\n",
      "Word: Jones, Deprel: compound, Head: average\n",
      "Word: industrial, Deprel: compound, Head: average\n",
      "Word: average, Deprel: compound, Head: DJI\n",
      "Word: DJI, Deprel: nsubj, Head: off\n",
      "Word: was, Deprel: cop, Head: off\n",
      "Word: off, Deprel: root, Head: ROOT\n",
      "Word: 58.69, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: off\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.64, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 9,137.86\n",
      "Word: 9,137.86, Deprel: obl, Head: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Dow Jones industrial average DJI fell 79.43 points or 0.86 percent to 9,117.12 on Friday'\n",
      "Word: The, Deprel: det, Head: DJI\n",
      "Word: Dow, Deprel: compound, Head: average\n",
      "Word: Jones, Deprel: flat, Head: Dow\n",
      "Word: industrial, Deprel: compound, Head: average\n",
      "Word: average, Deprel: compound, Head: DJI\n",
      "Word: DJI, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 79.43, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: fell\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.86, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 9,117.12\n",
      "Word: 9,117.12, Deprel: obl, Head: fell\n",
      "Word: on, Deprel: case, Head: Friday\n",
      "Word: Friday, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It was a little bit embarrassing the way we played in the first two games Thomas said'\n",
      "Word: It, Deprel: nsubj, Head: embarrassing\n",
      "Word: was, Deprel: cop, Head: embarrassing\n",
      "Word: a, Deprel: det, Head: bit\n",
      "Word: little, Deprel: amod, Head: bit\n",
      "Word: bit, Deprel: obl:npmod, Head: embarrassing\n",
      "Word: embarrassing, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: way\n",
      "Word: way, Deprel: obl:npmod, Head: embarrassing\n",
      "Word: we, Deprel: nsubj, Head: played\n",
      "Word: played, Deprel: acl:relcl, Head: way\n",
      "Word: in, Deprel: case, Head: games\n",
      "Word: the, Deprel: det, Head: games\n",
      "Word: first, Deprel: amod, Head: games\n",
      "Word: two, Deprel: nummod, Head: games\n",
      "Word: games, Deprel: obl, Head: played\n",
      "Word: Thomas, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: embarrassing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We re in the Stanley Cup finals and it was a little bit embarrassing the way we played in the first two games'\n",
      "Word: We, Deprel: nsubj, Head: finals\n",
      "Word: re, Deprel: cop, Head: finals\n",
      "Word: in, Deprel: case, Head: finals\n",
      "Word: the, Deprel: det, Head: finals\n",
      "Word: Stanley, Deprel: compound, Head: Cup\n",
      "Word: Cup, Deprel: compound, Head: finals\n",
      "Word: finals, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: embarrassing\n",
      "Word: it, Deprel: nsubj, Head: embarrassing\n",
      "Word: was, Deprel: cop, Head: embarrassing\n",
      "Word: a, Deprel: det, Head: bit\n",
      "Word: little, Deprel: amod, Head: bit\n",
      "Word: bit, Deprel: obl:npmod, Head: embarrassing\n",
      "Word: embarrassing, Deprel: conj, Head: finals\n",
      "Word: the, Deprel: det, Head: way\n",
      "Word: way, Deprel: obl:npmod, Head: embarrassing\n",
      "Word: we, Deprel: nsubj, Head: played\n",
      "Word: played, Deprel: acl:relcl, Head: way\n",
      "Word: in, Deprel: case, Head: games\n",
      "Word: the, Deprel: det, Head: games\n",
      "Word: first, Deprel: amod, Head: games\n",
      "Word: two, Deprel: nummod, Head: games\n",
      "Word: games, Deprel: obl, Head: played\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'From Broadway comedies like The Seven Year Itch 1952 Will Success Spoil Rock Hunter'\n",
      "Word: From, Deprel: case, Head: comedies\n",
      "Word: Broadway, Deprel: compound, Head: comedies\n",
      "Word: comedies, Deprel: root, Head: ROOT\n",
      "Word: like, Deprel: case, Head: Hunter\n",
      "Word: The, Deprel: det, Head: Itch\n",
      "Word: Seven, Deprel: nummod, Head: Year\n",
      "Word: Year, Deprel: compound, Head: Itch\n",
      "Word: Itch, Deprel: nmod, Head: comedies\n",
      "Word: 1952, Deprel: nummod, Head: Itch\n",
      "Word: Will, Deprel: compound, Head: Hunter\n",
      "Word: Success, Deprel: compound, Head: Spoil\n",
      "Word: Spoil, Deprel: compound, Head: Hunter\n",
      "Word: Rock, Deprel: compound, Head: Hunter\n",
      "Word: Hunter, Deprel: nmod, Head: comedies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Playwright George Axelrod who anticipated the sexual revolution with The Seven Year Itch and Will Success Spoil Rock Hunter'\n",
      "Word: Playwright, Deprel: root, Head: ROOT\n",
      "Word: George, Deprel: flat, Head: Playwright\n",
      "Word: Axelrod, Deprel: flat, Head: Playwright\n",
      "Word: who, Deprel: nsubj, Head: anticipated\n",
      "Word: anticipated, Deprel: acl:relcl, Head: Playwright\n",
      "Word: the, Deprel: det, Head: revolution\n",
      "Word: sexual, Deprel: amod, Head: revolution\n",
      "Word: revolution, Deprel: obj, Head: anticipated\n",
      "Word: with, Deprel: case, Head: Itch\n",
      "Word: The, Deprel: det, Head: Itch\n",
      "Word: Seven, Deprel: nummod, Head: Year\n",
      "Word: Year, Deprel: compound, Head: Itch\n",
      "Word: Itch, Deprel: nmod, Head: revolution\n",
      "Word: and, Deprel: cc, Head: Hunter\n",
      "Word: Will, Deprel: compound, Head: Hunter\n",
      "Word: Success, Deprel: compound, Head: Spoil\n",
      "Word: Spoil, Deprel: compound, Head: Hunter\n",
      "Word: Rock, Deprel: compound, Head: Hunter\n",
      "Word: Hunter, Deprel: conj, Head: Itch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'His lawyer Pamela MacKey said Bryant expects to be completely exonerated'\n",
      "Word: His, Deprel: nmod:poss, Head: lawyer\n",
      "Word: lawyer, Deprel: nsubj, Head: said\n",
      "Word: Pamela, Deprel: appos, Head: lawyer\n",
      "Word: MacKey, Deprel: flat, Head: Pamela\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Bryant, Deprel: nsubj, Head: expects\n",
      "Word: expects, Deprel: ccomp, Head: said\n",
      "Word: to, Deprel: mark, Head: exonerated\n",
      "Word: be, Deprel: aux:pass, Head: exonerated\n",
      "Word: completely, Deprel: advmod, Head: exonerated\n",
      "Word: exonerated, Deprel: xcomp, Head: expects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Bryant is innocent and expects to be completely exonerated Mackey said in a statement'\n",
      "Word: Mr, Deprel: nsubj, Head: innocent\n",
      "Word: Bryant, Deprel: flat, Head: Mr\n",
      "Word: is, Deprel: cop, Head: innocent\n",
      "Word: innocent, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: expects\n",
      "Word: expects, Deprel: conj, Head: innocent\n",
      "Word: to, Deprel: mark, Head: exonerated\n",
      "Word: be, Deprel: aux:pass, Head: exonerated\n",
      "Word: completely, Deprel: advmod, Head: exonerated\n",
      "Word: exonerated, Deprel: xcomp, Head: expects\n",
      "Word: Mackey, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: innocent\n",
      "Word: in, Deprel: case, Head: statement\n",
      "Word: a, Deprel: det, Head: statement\n",
      "Word: statement, Deprel: obl, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It was the best advance since Oct 1 when the index gained 22.25'\n",
      "Word: It, Deprel: nsubj, Head: advance\n",
      "Word: was, Deprel: cop, Head: advance\n",
      "Word: the, Deprel: det, Head: advance\n",
      "Word: best, Deprel: amod, Head: advance\n",
      "Word: advance, Deprel: root, Head: ROOT\n",
      "Word: since, Deprel: case, Head: Oct\n",
      "Word: Oct, Deprel: obl, Head: advance\n",
      "Word: 1, Deprel: nummod, Head: Oct\n",
      "Word: when, Deprel: advmod, Head: gained\n",
      "Word: the, Deprel: det, Head: index\n",
      "Word: index, Deprel: nsubj, Head: gained\n",
      "Word: gained, Deprel: advcl, Head: advance\n",
      "Word: 22.25, Deprel: obj, Head: gained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Standard Poor s 500 index rose 15.66 to 1,046.79 its best advance since Oct 1 when it gained 22.25'\n",
      "Word: Standard, Deprel: amod, Head: Poor\n",
      "Word: Poor, Deprel: compound, Head: index\n",
      "Word: s, Deprel: nmod:npmod, Head: Poor\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: index, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 15.66, Deprel: obj, Head: rose\n",
      "Word: to, Deprel: case, Head: 1,046.79\n",
      "Word: 1,046.79, Deprel: nmod, Head: 15.66\n",
      "Word: its, Deprel: nmod:poss, Head: advance\n",
      "Word: best, Deprel: amod, Head: advance\n",
      "Word: advance, Deprel: obj, Head: rose\n",
      "Word: since, Deprel: case, Head: Oct\n",
      "Word: Oct, Deprel: obl, Head: rose\n",
      "Word: 1, Deprel: nummod, Head: Oct\n",
      "Word: when, Deprel: advmod, Head: gained\n",
      "Word: it, Deprel: nsubj, Head: gained\n",
      "Word: gained, Deprel: advcl, Head: rose\n",
      "Word: 22.25, Deprel: obj, Head: gained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Mask said Mr Cullen would be taken from the Somerset County Jail by Thursday and moved to the Ann Klein Forensic Hospital just outside Trenton for psychiatric care'\n",
      "Word: Mr, Deprel: nsubj, Head: said\n",
      "Word: Mask, Deprel: flat, Head: Mr\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Mr, Deprel: nsubj:pass, Head: taken\n",
      "Word: Cullen, Deprel: flat, Head: Mr\n",
      "Word: would, Deprel: aux, Head: taken\n",
      "Word: be, Deprel: aux:pass, Head: taken\n",
      "Word: taken, Deprel: ccomp, Head: said\n",
      "Word: from, Deprel: case, Head: Jail\n",
      "Word: the, Deprel: det, Head: Jail\n",
      "Word: Somerset, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: Jail\n",
      "Word: Jail, Deprel: obl, Head: taken\n",
      "Word: by, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: taken\n",
      "Word: and, Deprel: cc, Head: moved\n",
      "Word: moved, Deprel: conj, Head: taken\n",
      "Word: to, Deprel: case, Head: Hospital\n",
      "Word: the, Deprel: det, Head: Hospital\n",
      "Word: Ann, Deprel: compound, Head: Hospital\n",
      "Word: Klein, Deprel: flat, Head: Ann\n",
      "Word: Forensic, Deprel: amod, Head: Hospital\n",
      "Word: Hospital, Deprel: obl, Head: moved\n",
      "Word: just, Deprel: advmod, Head: Trenton\n",
      "Word: outside, Deprel: case, Head: Trenton\n",
      "Word: Trenton, Deprel: obl, Head: moved\n",
      "Word: for, Deprel: case, Head: care\n",
      "Word: psychiatric, Deprel: amod, Head: care\n",
      "Word: care, Deprel: obl, Head: moved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Charles Cullen 43 was transferred from the Somerset County Jail in Somerville to the Anne Klein Forensic Center a 150-bed psychiatric treatment facility in Trenton'\n",
      "Word: Charles, Deprel: nsubj:pass, Head: transferred\n",
      "Word: Cullen, Deprel: flat, Head: Charles\n",
      "Word: 43, Deprel: nmod:npmod, Head: Charles\n",
      "Word: was, Deprel: aux:pass, Head: transferred\n",
      "Word: transferred, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: Jail\n",
      "Word: the, Deprel: det, Head: Jail\n",
      "Word: Somerset, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: Jail\n",
      "Word: Jail, Deprel: obl, Head: transferred\n",
      "Word: in, Deprel: case, Head: Somerville\n",
      "Word: Somerville, Deprel: obl, Head: transferred\n",
      "Word: to, Deprel: case, Head: Center\n",
      "Word: the, Deprel: det, Head: Center\n",
      "Word: Anne, Deprel: compound, Head: Center\n",
      "Word: Klein, Deprel: flat, Head: Anne\n",
      "Word: Forensic, Deprel: amod, Head: Center\n",
      "Word: Center, Deprel: obl, Head: transferred\n",
      "Word: a, Deprel: det, Head: facility\n",
      "Word: 150-bed, Deprel: amod, Head: facility\n",
      "Word: psychiatric, Deprel: amod, Head: treatment\n",
      "Word: treatment, Deprel: compound, Head: facility\n",
      "Word: facility, Deprel: obj, Head: transferred\n",
      "Word: in, Deprel: case, Head: Trenton\n",
      "Word: Trenton, Deprel: nmod, Head: facility\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Scientists believed Stardust trapped thousands of particles of dust'\n",
      "Word: Scientists, Deprel: nsubj, Head: believed\n",
      "Word: believed, Deprel: root, Head: ROOT\n",
      "Word: Stardust, Deprel: nsubj, Head: trapped\n",
      "Word: trapped, Deprel: ccomp, Head: believed\n",
      "Word: thousands, Deprel: obj, Head: trapped\n",
      "Word: of, Deprel: case, Head: particles\n",
      "Word: particles, Deprel: nmod, Head: thousands\n",
      "Word: of, Deprel: case, Head: dust\n",
      "Word: dust, Deprel: nmod, Head: particles\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Stardust was designed to gather thousands of dust particles streaming from Wild 2'\n",
      "Word: Stardust, Deprel: nsubj:pass, Head: designed\n",
      "Word: was, Deprel: aux:pass, Head: designed\n",
      "Word: designed, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: gather\n",
      "Word: gather, Deprel: advcl, Head: designed\n",
      "Word: thousands, Deprel: obj, Head: gather\n",
      "Word: of, Deprel: case, Head: particles\n",
      "Word: dust, Deprel: compound, Head: particles\n",
      "Word: particles, Deprel: nmod, Head: thousands\n",
      "Word: streaming, Deprel: acl, Head: particles\n",
      "Word: from, Deprel: case, Head: Wild\n",
      "Word: Wild, Deprel: obl, Head: streaming\n",
      "Word: 2, Deprel: nummod, Head: Wild\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Nine seconds later it broke the sound barrier and continued its steep powered ascent'\n",
      "Word: Nine, Deprel: nummod, Head: seconds\n",
      "Word: seconds, Deprel: obl:npmod, Head: later\n",
      "Word: later, Deprel: advmod, Head: broke\n",
      "Word: it, Deprel: nsubj, Head: broke\n",
      "Word: broke, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: barrier\n",
      "Word: sound, Deprel: compound, Head: barrier\n",
      "Word: barrier, Deprel: obj, Head: broke\n",
      "Word: and, Deprel: cc, Head: continued\n",
      "Word: continued, Deprel: conj, Head: broke\n",
      "Word: its, Deprel: nmod:poss, Head: ascent\n",
      "Word: steep, Deprel: amod, Head: ascent\n",
      "Word: powered, Deprel: amod, Head: ascent\n",
      "Word: ascent, Deprel: obj, Head: continued\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Nine seconds later SpaceShipOne broke the sound barrier the company said'\n",
      "Word: Nine, Deprel: nummod, Head: seconds\n",
      "Word: seconds, Deprel: obl:npmod, Head: later\n",
      "Word: later, Deprel: advmod, Head: broke\n",
      "Word: SpaceShipOne, Deprel: nsubj, Head: broke\n",
      "Word: broke, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: barrier\n",
      "Word: sound, Deprel: compound, Head: barrier\n",
      "Word: barrier, Deprel: obj, Head: broke\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: barrier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The report by the independent expert committee aims to dissipate any suspicion about the Hong Kong government s handling of the SARS crisis'\n",
      "Word: The, Deprel: det, Head: report\n",
      "Word: report, Deprel: nsubj, Head: aims\n",
      "Word: by, Deprel: case, Head: committee\n",
      "Word: the, Deprel: det, Head: committee\n",
      "Word: independent, Deprel: amod, Head: committee\n",
      "Word: expert, Deprel: compound, Head: committee\n",
      "Word: committee, Deprel: nmod, Head: report\n",
      "Word: aims, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: dissipate\n",
      "Word: dissipate, Deprel: xcomp, Head: aims\n",
      "Word: any, Deprel: det, Head: suspicion\n",
      "Word: suspicion, Deprel: obj, Head: dissipate\n",
      "Word: about, Deprel: case, Head: handling\n",
      "Word: the, Deprel: det, Head: government\n",
      "Word: Hong, Deprel: compound, Head: government\n",
      "Word: Kong, Deprel: compound, Head: government\n",
      "Word: government, Deprel: nmod:poss, Head: handling\n",
      "Word: s, Deprel: case, Head: government\n",
      "Word: handling, Deprel: nmod, Head: suspicion\n",
      "Word: of, Deprel: case, Head: crisis\n",
      "Word: the, Deprel: det, Head: crisis\n",
      "Word: SARS, Deprel: compound, Head: crisis\n",
      "Word: crisis, Deprel: nmod, Head: handling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A long awaited report on the Hong Kong government s handling of the SARS outbreak has been released'\n",
      "Word: A, Deprel: det, Head: report\n",
      "Word: long, Deprel: amod, Head: awaited\n",
      "Word: awaited, Deprel: amod, Head: report\n",
      "Word: report, Deprel: nsubj:pass, Head: released\n",
      "Word: on, Deprel: case, Head: handling\n",
      "Word: the, Deprel: det, Head: government\n",
      "Word: Hong, Deprel: compound, Head: government\n",
      "Word: Kong, Deprel: compound, Head: government\n",
      "Word: government, Deprel: nmod:poss, Head: handling\n",
      "Word: s, Deprel: case, Head: government\n",
      "Word: handling, Deprel: nmod, Head: report\n",
      "Word: of, Deprel: case, Head: outbreak\n",
      "Word: the, Deprel: det, Head: outbreak\n",
      "Word: SARS, Deprel: compound, Head: outbreak\n",
      "Word: outbreak, Deprel: nmod, Head: handling\n",
      "Word: has, Deprel: aux, Head: released\n",
      "Word: been, Deprel: aux:pass, Head: released\n",
      "Word: released, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The plane was estimated to be within 100 pounds of its maximum takeoff weight'\n",
      "Word: The, Deprel: det, Head: plane\n",
      "Word: plane, Deprel: nsubj:pass, Head: estimated\n",
      "Word: was, Deprel: aux:pass, Head: estimated\n",
      "Word: estimated, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: pounds\n",
      "Word: be, Deprel: cop, Head: pounds\n",
      "Word: within, Deprel: case, Head: pounds\n",
      "Word: 100, Deprel: nummod, Head: pounds\n",
      "Word: pounds, Deprel: xcomp, Head: estimated\n",
      "Word: of, Deprel: case, Head: weight\n",
      "Word: its, Deprel: nmod:poss, Head: weight\n",
      "Word: maximum, Deprel: amod, Head: weight\n",
      "Word: takeoff, Deprel: compound, Head: weight\n",
      "Word: weight, Deprel: nmod, Head: pounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'US Airways Flight 5481 which crashed Jan 8 was judged to be within 100 pounds of its maximum takeoff weight'\n",
      "Word: US, Deprel: compound, Head: Airways\n",
      "Word: Airways, Deprel: nsubj:pass, Head: judged\n",
      "Word: Flight, Deprel: flat, Head: Airways\n",
      "Word: 5481, Deprel: nummod, Head: Flight\n",
      "Word: which, Deprel: nsubj, Head: crashed\n",
      "Word: crashed, Deprel: acl:relcl, Head: Flight\n",
      "Word: Jan, Deprel: obj, Head: crashed\n",
      "Word: 8, Deprel: nummod, Head: Jan\n",
      "Word: was, Deprel: aux:pass, Head: judged\n",
      "Word: judged, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: pounds\n",
      "Word: be, Deprel: cop, Head: pounds\n",
      "Word: within, Deprel: case, Head: pounds\n",
      "Word: 100, Deprel: nummod, Head: pounds\n",
      "Word: pounds, Deprel: xcomp, Head: judged\n",
      "Word: of, Deprel: case, Head: weight\n",
      "Word: its, Deprel: nmod:poss, Head: weight\n",
      "Word: maximum, Deprel: amod, Head: weight\n",
      "Word: takeoff, Deprel: compound, Head: weight\n",
      "Word: weight, Deprel: nmod, Head: pounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Both devices implement the v1.2 standard s eSCO facility to provide the basis for new cordless telephony applications'\n",
      "Word: Both, Deprel: det, Head: devices\n",
      "Word: devices, Deprel: nsubj, Head: implement\n",
      "Word: implement, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: standard\n",
      "Word: v1.2, Deprel: compound, Head: standard\n",
      "Word: standard, Deprel: nmod:poss, Head: facility\n",
      "Word: s, Deprel: case, Head: standard\n",
      "Word: eSCO, Deprel: compound, Head: facility\n",
      "Word: facility, Deprel: obj, Head: implement\n",
      "Word: to, Deprel: mark, Head: provide\n",
      "Word: provide, Deprel: advcl, Head: implement\n",
      "Word: the, Deprel: det, Head: basis\n",
      "Word: basis, Deprel: obj, Head: provide\n",
      "Word: for, Deprel: case, Head: applications\n",
      "Word: new, Deprel: amod, Head: applications\n",
      "Word: cordless, Deprel: compound, Head: applications\n",
      "Word: telephony, Deprel: compound, Head: applications\n",
      "Word: applications, Deprel: nmod, Head: basis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'BlueCore3 also implements v1.2 s eSCO facility to provide the basis for advanced cordless telephony applications for Bluetooth transmission'\n",
      "Word: BlueCore3, Deprel: nsubj, Head: implements\n",
      "Word: also, Deprel: advmod, Head: implements\n",
      "Word: implements, Deprel: root, Head: ROOT\n",
      "Word: v1.2, Deprel: nmod:poss, Head: facility\n",
      "Word: s, Deprel: case, Head: v1.2\n",
      "Word: eSCO, Deprel: compound, Head: facility\n",
      "Word: facility, Deprel: obj, Head: implements\n",
      "Word: to, Deprel: mark, Head: provide\n",
      "Word: provide, Deprel: advcl, Head: implements\n",
      "Word: the, Deprel: det, Head: basis\n",
      "Word: basis, Deprel: obj, Head: provide\n",
      "Word: for, Deprel: case, Head: applications\n",
      "Word: advanced, Deprel: amod, Head: applications\n",
      "Word: cordless, Deprel: compound, Head: applications\n",
      "Word: telephony, Deprel: compound, Head: applications\n",
      "Word: applications, Deprel: nmod, Head: basis\n",
      "Word: for, Deprel: case, Head: transmission\n",
      "Word: Bluetooth, Deprel: compound, Head: transmission\n",
      "Word: transmission, Deprel: nmod, Head: applications\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Michael Bloomberg NYC Mayor I m gon na try march with a number of different groups'\n",
      "Word: Michael, Deprel: root, Head: ROOT\n",
      "Word: Bloomberg, Deprel: flat, Head: Michael\n",
      "Word: NYC, Deprel: compound, Head: Mayor\n",
      "Word: Mayor, Deprel: list, Head: Michael\n",
      "Word: I, Deprel: nsubj, Head: gon\n",
      "Word: m, Deprel: aux, Head: gon\n",
      "Word: gon, Deprel: parataxis, Head: Michael\n",
      "Word: na, Deprel: mark, Head: try\n",
      "Word: try, Deprel: xcomp, Head: gon\n",
      "Word: march, Deprel: obj, Head: try\n",
      "Word: with, Deprel: case, Head: number\n",
      "Word: a, Deprel: det, Head: number\n",
      "Word: number, Deprel: obl, Head: try\n",
      "Word: of, Deprel: case, Head: groups\n",
      "Word: different, Deprel: amod, Head: groups\n",
      "Word: groups, Deprel: nmod, Head: number\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I m going to try to march with a number of different groups Bloomberg said'\n",
      "Word: I, Deprel: nsubj, Head: going\n",
      "Word: m, Deprel: aux, Head: going\n",
      "Word: going, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: try\n",
      "Word: try, Deprel: xcomp, Head: going\n",
      "Word: to, Deprel: mark, Head: march\n",
      "Word: march, Deprel: xcomp, Head: try\n",
      "Word: with, Deprel: case, Head: number\n",
      "Word: a, Deprel: det, Head: number\n",
      "Word: number, Deprel: obl, Head: march\n",
      "Word: of, Deprel: case, Head: groups\n",
      "Word: different, Deprel: amod, Head: groups\n",
      "Word: groups, Deprel: nmod, Head: number\n",
      "Word: Bloomberg, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: groups\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The attack seemed similar to others staged near foreign compounds in Riyadh on May 12'\n",
      "Word: The, Deprel: det, Head: attack\n",
      "Word: attack, Deprel: nsubj, Head: seemed\n",
      "Word: seemed, Deprel: root, Head: ROOT\n",
      "Word: similar, Deprel: xcomp, Head: seemed\n",
      "Word: to, Deprel: case, Head: others\n",
      "Word: others, Deprel: obl, Head: similar\n",
      "Word: staged, Deprel: acl, Head: others\n",
      "Word: near, Deprel: case, Head: compounds\n",
      "Word: foreign, Deprel: amod, Head: compounds\n",
      "Word: compounds, Deprel: obl, Head: staged\n",
      "Word: in, Deprel: case, Head: Riyadh\n",
      "Word: Riyadh, Deprel: nmod, Head: compounds\n",
      "Word: on, Deprel: case, Head: 12\n",
      "Word: May, Deprel: compound, Head: 12\n",
      "Word: 12, Deprel: obl, Head: staged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The attack seemed similar to attacks staged near foreign compounds in Riyadh on May 12 for which officials have also blamed al-Qaida'\n",
      "Word: The, Deprel: det, Head: attack\n",
      "Word: attack, Deprel: nsubj, Head: seemed\n",
      "Word: seemed, Deprel: root, Head: ROOT\n",
      "Word: similar, Deprel: xcomp, Head: seemed\n",
      "Word: to, Deprel: case, Head: attacks\n",
      "Word: attacks, Deprel: obl, Head: similar\n",
      "Word: staged, Deprel: acl, Head: attacks\n",
      "Word: near, Deprel: case, Head: compounds\n",
      "Word: foreign, Deprel: amod, Head: compounds\n",
      "Word: compounds, Deprel: obl, Head: staged\n",
      "Word: in, Deprel: case, Head: Riyadh\n",
      "Word: Riyadh, Deprel: nmod, Head: compounds\n",
      "Word: on, Deprel: case, Head: May\n",
      "Word: May, Deprel: compound, Head: 12\n",
      "Word: 12, Deprel: obl, Head: staged\n",
      "Word: for, Deprel: case, Head: which\n",
      "Word: which, Deprel: obl, Head: blamed\n",
      "Word: officials, Deprel: nsubj, Head: blamed\n",
      "Word: have, Deprel: aux, Head: blamed\n",
      "Word: also, Deprel: advmod, Head: blamed\n",
      "Word: blamed, Deprel: acl:relcl, Head: attacks\n",
      "Word: al-Qaida, Deprel: obj, Head: blamed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The drop in core wholesale prices in April reflected falling prices for cars trucks men s and boy s clothes and cigarettes'\n",
      "Word: The, Deprel: det, Head: drop\n",
      "Word: drop, Deprel: nsubj, Head: reflected\n",
      "Word: in, Deprel: case, Head: prices\n",
      "Word: core, Deprel: compound, Head: prices\n",
      "Word: wholesale, Deprel: compound, Head: prices\n",
      "Word: prices, Deprel: nmod, Head: drop\n",
      "Word: in, Deprel: case, Head: April\n",
      "Word: April, Deprel: nmod, Head: drop\n",
      "Word: reflected, Deprel: root, Head: ROOT\n",
      "Word: falling, Deprel: amod, Head: prices\n",
      "Word: prices, Deprel: obj, Head: reflected\n",
      "Word: for, Deprel: case, Head: trucks\n",
      "Word: cars, Deprel: compound, Head: trucks\n",
      "Word: trucks, Deprel: compound, Head: men\n",
      "Word: men, Deprel: nmod:poss, Head: clothes\n",
      "Word: s, Deprel: case, Head: men\n",
      "Word: and, Deprel: cc, Head: boy\n",
      "Word: boy, Deprel: conj, Head: men\n",
      "Word: s, Deprel: case, Head: boy\n",
      "Word: clothes, Deprel: nmod, Head: prices\n",
      "Word: and, Deprel: cc, Head: cigarettes\n",
      "Word: cigarettes, Deprel: conj, Head: clothes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'That was the biggest drop since August 1993 and stemmed from falling prices for cars trucks men s and boys clothes and cigarettes'\n",
      "Word: That, Deprel: nsubj, Head: drop\n",
      "Word: was, Deprel: cop, Head: drop\n",
      "Word: the, Deprel: det, Head: drop\n",
      "Word: biggest, Deprel: amod, Head: drop\n",
      "Word: drop, Deprel: root, Head: ROOT\n",
      "Word: since, Deprel: case, Head: August\n",
      "Word: August, Deprel: nmod, Head: drop\n",
      "Word: 1993, Deprel: nummod, Head: August\n",
      "Word: and, Deprel: cc, Head: stemmed\n",
      "Word: stemmed, Deprel: conj, Head: drop\n",
      "Word: from, Deprel: case, Head: prices\n",
      "Word: falling, Deprel: amod, Head: prices\n",
      "Word: prices, Deprel: obl, Head: stemmed\n",
      "Word: for, Deprel: case, Head: cars\n",
      "Word: cars, Deprel: nmod, Head: prices\n",
      "Word: trucks, Deprel: compound, Head: men\n",
      "Word: men, Deprel: nmod:poss, Head: clothes\n",
      "Word: s, Deprel: case, Head: men\n",
      "Word: and, Deprel: cc, Head: boys\n",
      "Word: boys, Deprel: conj, Head: men\n",
      "Word: clothes, Deprel: nmod, Head: prices\n",
      "Word: and, Deprel: cc, Head: cigarettes\n",
      "Word: cigarettes, Deprel: conj, Head: clothes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Gainer said the two staff aides are very sorry this all happened and the security personnel had performed well within standards'\n",
      "Word: Gainer, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: aides\n",
      "Word: two, Deprel: nummod, Head: aides\n",
      "Word: staff, Deprel: compound, Head: aides\n",
      "Word: aides, Deprel: nsubj, Head: sorry\n",
      "Word: are, Deprel: cop, Head: sorry\n",
      "Word: very, Deprel: advmod, Head: sorry\n",
      "Word: sorry, Deprel: ccomp, Head: said\n",
      "Word: this, Deprel: nsubj, Head: happened\n",
      "Word: all, Deprel: nsubj, Head: happened\n",
      "Word: happened, Deprel: ccomp, Head: sorry\n",
      "Word: and, Deprel: cc, Head: performed\n",
      "Word: the, Deprel: det, Head: personnel\n",
      "Word: security, Deprel: compound, Head: personnel\n",
      "Word: personnel, Deprel: nsubj, Head: performed\n",
      "Word: had, Deprel: aux, Head: performed\n",
      "Word: performed, Deprel: conj, Head: sorry\n",
      "Word: well, Deprel: advmod, Head: performed\n",
      "Word: within, Deprel: case, Head: standards\n",
      "Word: standards, Deprel: obl, Head: performed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The security personnel performed well within standards and the two staff aides were very sorry all this happened Gainer said'\n",
      "Word: The, Deprel: det, Head: personnel\n",
      "Word: security, Deprel: compound, Head: personnel\n",
      "Word: personnel, Deprel: nsubj, Head: performed\n",
      "Word: performed, Deprel: root, Head: ROOT\n",
      "Word: well, Deprel: advmod, Head: performed\n",
      "Word: within, Deprel: case, Head: standards\n",
      "Word: standards, Deprel: obl, Head: performed\n",
      "Word: and, Deprel: cc, Head: sorry\n",
      "Word: the, Deprel: det, Head: aides\n",
      "Word: two, Deprel: nummod, Head: aides\n",
      "Word: staff, Deprel: compound, Head: aides\n",
      "Word: aides, Deprel: nsubj, Head: sorry\n",
      "Word: were, Deprel: cop, Head: sorry\n",
      "Word: very, Deprel: advmod, Head: sorry\n",
      "Word: sorry, Deprel: conj, Head: performed\n",
      "Word: all, Deprel: det:predet, Head: this\n",
      "Word: this, Deprel: nsubj, Head: happened\n",
      "Word: happened, Deprel: ccomp, Head: sorry\n",
      "Word: Gainer, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: ccomp, Head: happened\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We put a lot of effort and energy into improving our patching process probably later than we should have and now we re just gaining incredible speed'\n",
      "Word: We, Deprel: nsubj, Head: put\n",
      "Word: put, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: lot\n",
      "Word: lot, Deprel: obj, Head: put\n",
      "Word: of, Deprel: case, Head: effort\n",
      "Word: effort, Deprel: nmod, Head: lot\n",
      "Word: and, Deprel: cc, Head: energy\n",
      "Word: energy, Deprel: conj, Head: effort\n",
      "Word: into, Deprel: mark, Head: improving\n",
      "Word: improving, Deprel: advcl, Head: put\n",
      "Word: our, Deprel: nmod:poss, Head: process\n",
      "Word: patching, Deprel: compound, Head: process\n",
      "Word: process, Deprel: obj, Head: improving\n",
      "Word: probably, Deprel: advmod, Head: later\n",
      "Word: later, Deprel: advmod, Head: improving\n",
      "Word: than, Deprel: mark, Head: have\n",
      "Word: we, Deprel: nsubj, Head: have\n",
      "Word: should, Deprel: aux, Head: have\n",
      "Word: have, Deprel: advcl, Head: later\n",
      "Word: and, Deprel: cc, Head: gaining\n",
      "Word: now, Deprel: advmod, Head: gaining\n",
      "Word: we, Deprel: nsubj, Head: gaining\n",
      "Word: re, Deprel: aux, Head: gaining\n",
      "Word: just, Deprel: advmod, Head: gaining\n",
      "Word: gaining, Deprel: conj, Head: put\n",
      "Word: incredible, Deprel: amod, Head: speed\n",
      "Word: speed, Deprel: obj, Head: gaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We ve put a lot of effort and energy into improving our patching progress probably later than we should have'\n",
      "Word: We, Deprel: nsubj, Head: put\n",
      "Word: ve, Deprel: aux, Head: put\n",
      "Word: put, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: lot\n",
      "Word: lot, Deprel: obj, Head: put\n",
      "Word: of, Deprel: case, Head: effort\n",
      "Word: effort, Deprel: nmod, Head: lot\n",
      "Word: and, Deprel: cc, Head: energy\n",
      "Word: energy, Deprel: conj, Head: effort\n",
      "Word: into, Deprel: mark, Head: improving\n",
      "Word: improving, Deprel: advcl, Head: put\n",
      "Word: our, Deprel: nmod:poss, Head: progress\n",
      "Word: patching, Deprel: compound, Head: progress\n",
      "Word: progress, Deprel: obj, Head: improving\n",
      "Word: probably, Deprel: advmod, Head: later\n",
      "Word: later, Deprel: advmod, Head: improving\n",
      "Word: than, Deprel: mark, Head: have\n",
      "Word: we, Deprel: nsubj, Head: have\n",
      "Word: should, Deprel: aux, Head: have\n",
      "Word: have, Deprel: advcl, Head: later\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'International rescue workers are scouring flattened debris for survivors in Iran s shattered ancient Silk Road city of Bam after a violent earthquake killed more than 20,000 people'\n",
      "Word: International, Deprel: amod, Head: workers\n",
      "Word: rescue, Deprel: compound, Head: workers\n",
      "Word: workers, Deprel: nsubj, Head: scouring\n",
      "Word: are, Deprel: aux, Head: scouring\n",
      "Word: scouring, Deprel: root, Head: ROOT\n",
      "Word: flattened, Deprel: amod, Head: debris\n",
      "Word: debris, Deprel: obj, Head: scouring\n",
      "Word: for, Deprel: case, Head: survivors\n",
      "Word: survivors, Deprel: obl, Head: scouring\n",
      "Word: in, Deprel: case, Head: city\n",
      "Word: Iran, Deprel: nmod:poss, Head: city\n",
      "Word: s, Deprel: case, Head: Iran\n",
      "Word: shattered, Deprel: amod, Head: city\n",
      "Word: ancient, Deprel: amod, Head: city\n",
      "Word: Silk, Deprel: compound, Head: Road\n",
      "Word: Road, Deprel: compound, Head: city\n",
      "Word: city, Deprel: nmod, Head: survivors\n",
      "Word: of, Deprel: case, Head: Bam\n",
      "Word: Bam, Deprel: nmod, Head: city\n",
      "Word: after, Deprel: mark, Head: killed\n",
      "Word: a, Deprel: det, Head: earthquake\n",
      "Word: violent, Deprel: amod, Head: earthquake\n",
      "Word: earthquake, Deprel: nsubj, Head: killed\n",
      "Word: killed, Deprel: advcl, Head: scouring\n",
      "Word: more, Deprel: advmod, Head: 20,000\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 20,000, Deprel: nummod, Head: people\n",
      "Word: people, Deprel: obj, Head: killed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'International rescue workers hacked desperately through flattened debris for survivors and cemeteries overflowed in Iran s ancient Silk Road city of Bam yesterday'\n",
      "Word: International, Deprel: amod, Head: workers\n",
      "Word: rescue, Deprel: compound, Head: workers\n",
      "Word: workers, Deprel: nsubj, Head: hacked\n",
      "Word: hacked, Deprel: root, Head: ROOT\n",
      "Word: desperately, Deprel: advmod, Head: hacked\n",
      "Word: through, Deprel: case, Head: debris\n",
      "Word: flattened, Deprel: amod, Head: debris\n",
      "Word: debris, Deprel: obl, Head: hacked\n",
      "Word: for, Deprel: case, Head: survivors\n",
      "Word: survivors, Deprel: obl, Head: hacked\n",
      "Word: and, Deprel: cc, Head: cemeteries\n",
      "Word: cemeteries, Deprel: conj, Head: survivors\n",
      "Word: overflowed, Deprel: conj, Head: hacked\n",
      "Word: in, Deprel: case, Head: city\n",
      "Word: Iran, Deprel: nmod:poss, Head: city\n",
      "Word: s, Deprel: case, Head: Iran\n",
      "Word: ancient, Deprel: amod, Head: city\n",
      "Word: Silk, Deprel: compound, Head: Road\n",
      "Word: Road, Deprel: compound, Head: city\n",
      "Word: city, Deprel: obl, Head: overflowed\n",
      "Word: of, Deprel: case, Head: Bam\n",
      "Word: Bam, Deprel: nmod, Head: city\n",
      "Word: yesterday, Deprel: nmod:tmod, Head: city\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Griffith a Mount Airy native now lives on the North Carolina coast in Manteo'\n",
      "Word: Griffith, Deprel: nsubj, Head: lives\n",
      "Word: a, Deprel: det, Head: native\n",
      "Word: Mount, Deprel: compound, Head: native\n",
      "Word: Airy, Deprel: amod, Head: native\n",
      "Word: native, Deprel: appos, Head: Griffith\n",
      "Word: now, Deprel: advmod, Head: lives\n",
      "Word: lives, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: coast\n",
      "Word: the, Deprel: det, Head: coast\n",
      "Word: North, Deprel: compound, Head: Carolina\n",
      "Word: Carolina, Deprel: compound, Head: coast\n",
      "Word: coast, Deprel: obl, Head: lives\n",
      "Word: in, Deprel: case, Head: Manteo\n",
      "Word: Manteo, Deprel: obl, Head: lives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Griffith 77 grew up in Mount Airy and now lives in Manteo'\n",
      "Word: Griffith, Deprel: nsubj, Head: grew\n",
      "Word: 77, Deprel: flat, Head: Griffith\n",
      "Word: grew, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: grew\n",
      "Word: in, Deprel: case, Head: Mount\n",
      "Word: Mount, Deprel: obl, Head: grew\n",
      "Word: Airy, Deprel: flat, Head: Mount\n",
      "Word: and, Deprel: cc, Head: lives\n",
      "Word: now, Deprel: advmod, Head: lives\n",
      "Word: lives, Deprel: conj, Head: grew\n",
      "Word: in, Deprel: case, Head: Manteo\n",
      "Word: Manteo, Deprel: obl, Head: lives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He also said the academy will get its own internal report next week detailing the seriousness of the remaining problem'\n",
      "Word: He, Deprel: nsubj, Head: said\n",
      "Word: also, Deprel: advmod, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: academy\n",
      "Word: academy, Deprel: nsubj, Head: get\n",
      "Word: will, Deprel: aux, Head: get\n",
      "Word: get, Deprel: ccomp, Head: said\n",
      "Word: its, Deprel: nmod:poss, Head: report\n",
      "Word: own, Deprel: amod, Head: report\n",
      "Word: internal, Deprel: amod, Head: report\n",
      "Word: report, Deprel: obj, Head: get\n",
      "Word: next, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: get\n",
      "Word: detailing, Deprel: advcl, Head: get\n",
      "Word: the, Deprel: det, Head: seriousness\n",
      "Word: seriousness, Deprel: obj, Head: detailing\n",
      "Word: of, Deprel: case, Head: problem\n",
      "Word: the, Deprel: det, Head: problem\n",
      "Word: remaining, Deprel: amod, Head: problem\n",
      "Word: problem, Deprel: nmod, Head: seriousness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The academy will get its own internal report next week and it will be made public Rosa said'\n",
      "Word: The, Deprel: det, Head: academy\n",
      "Word: academy, Deprel: nsubj, Head: get\n",
      "Word: will, Deprel: aux, Head: get\n",
      "Word: get, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: report\n",
      "Word: own, Deprel: amod, Head: report\n",
      "Word: internal, Deprel: amod, Head: report\n",
      "Word: report, Deprel: obj, Head: get\n",
      "Word: next, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: get\n",
      "Word: and, Deprel: cc, Head: made\n",
      "Word: it, Deprel: nsubj:pass, Head: made\n",
      "Word: will, Deprel: aux, Head: made\n",
      "Word: be, Deprel: aux:pass, Head: made\n",
      "Word: made, Deprel: conj, Head: get\n",
      "Word: public, Deprel: xcomp, Head: made\n",
      "Word: Rosa, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: xcomp, Head: made\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The boy also sprayed the room full of retardant from fire extinguishers which made it hard to see the chief said'\n",
      "Word: The, Deprel: det, Head: boy\n",
      "Word: boy, Deprel: nsubj, Head: sprayed\n",
      "Word: also, Deprel: advmod, Head: sprayed\n",
      "Word: sprayed, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: room\n",
      "Word: room, Deprel: obj, Head: sprayed\n",
      "Word: full, Deprel: amod, Head: room\n",
      "Word: of, Deprel: case, Head: retardant\n",
      "Word: retardant, Deprel: obl, Head: full\n",
      "Word: from, Deprel: case, Head: extinguishers\n",
      "Word: fire, Deprel: compound, Head: extinguishers\n",
      "Word: extinguishers, Deprel: obl, Head: full\n",
      "Word: which, Deprel: nsubj, Head: made\n",
      "Word: made, Deprel: acl:relcl, Head: room\n",
      "Word: it, Deprel: obj, Head: made\n",
      "Word: hard, Deprel: xcomp, Head: made\n",
      "Word: to, Deprel: mark, Head: see\n",
      "Word: see, Deprel: xcomp, Head: hard\n",
      "Word: the, Deprel: det, Head: chief\n",
      "Word: chief, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: ccomp, Head: see\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The boy fired once into a wall and sprayed the room with fire extinguishers making it hard to see the chief said'\n",
      "Word: The, Deprel: det, Head: boy\n",
      "Word: boy, Deprel: nsubj, Head: fired\n",
      "Word: fired, Deprel: root, Head: ROOT\n",
      "Word: once, Deprel: advmod, Head: fired\n",
      "Word: into, Deprel: case, Head: wall\n",
      "Word: a, Deprel: det, Head: wall\n",
      "Word: wall, Deprel: obl, Head: fired\n",
      "Word: and, Deprel: cc, Head: sprayed\n",
      "Word: sprayed, Deprel: conj, Head: fired\n",
      "Word: the, Deprel: det, Head: room\n",
      "Word: room, Deprel: obj, Head: sprayed\n",
      "Word: with, Deprel: case, Head: extinguishers\n",
      "Word: fire, Deprel: compound, Head: extinguishers\n",
      "Word: extinguishers, Deprel: obl, Head: sprayed\n",
      "Word: making, Deprel: advcl, Head: sprayed\n",
      "Word: it, Deprel: obj, Head: making\n",
      "Word: hard, Deprel: xcomp, Head: making\n",
      "Word: to, Deprel: mark, Head: see\n",
      "Word: see, Deprel: advcl, Head: hard\n",
      "Word: the, Deprel: det, Head: chief\n",
      "Word: chief, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: ccomp, Head: see\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Conference Board reported its U.S Consumer Confidence Index slipped to 83.5 in June from 83.6 in May'\n",
      "Word: The, Deprel: det, Head: Board\n",
      "Word: Conference, Deprel: compound, Head: Board\n",
      "Word: Board, Deprel: nsubj, Head: reported\n",
      "Word: reported, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: Index\n",
      "Word: U.S, Deprel: compound, Head: Index\n",
      "Word: Consumer, Deprel: compound, Head: Confidence\n",
      "Word: Confidence, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: nsubj, Head: slipped\n",
      "Word: slipped, Deprel: ccomp, Head: reported\n",
      "Word: to, Deprel: case, Head: 83.5\n",
      "Word: 83.5, Deprel: obl, Head: slipped\n",
      "Word: in, Deprel: case, Head: June\n",
      "Word: June, Deprel: obl, Head: slipped\n",
      "Word: from, Deprel: case, Head: 83.6\n",
      "Word: 83.6, Deprel: obl, Head: slipped\n",
      "Word: in, Deprel: case, Head: May\n",
      "Word: May, Deprel: obl, Head: slipped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The consumer-confidence index came in at 83.5 in June down slightly from a revised 83.6 in May the Conference Board said'\n",
      "Word: The, Deprel: det, Head: index\n",
      "Word: consumer-confidence, Deprel: compound, Head: index\n",
      "Word: index, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: advmod, Head: came\n",
      "Word: at, Deprel: case, Head: 83.5\n",
      "Word: 83.5, Deprel: obl, Head: came\n",
      "Word: in, Deprel: case, Head: June\n",
      "Word: June, Deprel: nmod, Head: 83.5\n",
      "Word: down, Deprel: advmod, Head: came\n",
      "Word: slightly, Deprel: advmod, Head: down\n",
      "Word: from, Deprel: case, Head: 83.6\n",
      "Word: a, Deprel: det, Head: 83.6\n",
      "Word: revised, Deprel: amod, Head: 83.6\n",
      "Word: 83.6, Deprel: obl, Head: came\n",
      "Word: in, Deprel: case, Head: May\n",
      "Word: May, Deprel: nmod, Head: 83.6\n",
      "Word: the, Deprel: det, Head: Board\n",
      "Word: Conference, Deprel: compound, Head: Board\n",
      "Word: Board, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: came\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I notice a mood change in their priorities one politician said'\n",
      "Word: I, Deprel: nsubj, Head: notice\n",
      "Word: notice, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: change\n",
      "Word: mood, Deprel: compound, Head: change\n",
      "Word: change, Deprel: obj, Head: notice\n",
      "Word: in, Deprel: case, Head: priorities\n",
      "Word: their, Deprel: nmod:poss, Head: priorities\n",
      "Word: priorities, Deprel: nmod, Head: change\n",
      "Word: one, Deprel: nummod, Head: politician\n",
      "Word: politician, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: notice\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I notice a mood change in their priorities said one Iraqi politician after meeting with Mr Bremer'\n",
      "Word: I, Deprel: nsubj, Head: notice\n",
      "Word: notice, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: change\n",
      "Word: mood, Deprel: compound, Head: change\n",
      "Word: change, Deprel: nsubj, Head: said\n",
      "Word: in, Deprel: case, Head: priorities\n",
      "Word: their, Deprel: nmod:poss, Head: priorities\n",
      "Word: priorities, Deprel: nmod, Head: change\n",
      "Word: said, Deprel: ccomp, Head: notice\n",
      "Word: one, Deprel: nummod, Head: politician\n",
      "Word: Iraqi, Deprel: amod, Head: politician\n",
      "Word: politician, Deprel: obj, Head: said\n",
      "Word: after, Deprel: mark, Head: meeting\n",
      "Word: meeting, Deprel: advcl, Head: said\n",
      "Word: with, Deprel: case, Head: Bremer\n",
      "Word: Mr, Deprel: compound, Head: Bremer\n",
      "Word: Bremer, Deprel: obl, Head: meeting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But HRT should not be used to prevent heart disease or any other chronic condition'\n",
      "Word: But, Deprel: cc, Head: used\n",
      "Word: HRT, Deprel: nsubj:pass, Head: used\n",
      "Word: should, Deprel: aux, Head: used\n",
      "Word: not, Deprel: advmod, Head: used\n",
      "Word: be, Deprel: aux:pass, Head: used\n",
      "Word: used, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: prevent\n",
      "Word: prevent, Deprel: advcl, Head: used\n",
      "Word: heart, Deprel: compound, Head: disease\n",
      "Word: disease, Deprel: obj, Head: prevent\n",
      "Word: or, Deprel: cc, Head: condition\n",
      "Word: any, Deprel: det, Head: condition\n",
      "Word: other, Deprel: amod, Head: condition\n",
      "Word: chronic, Deprel: amod, Head: condition\n",
      "Word: condition, Deprel: conj, Head: disease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The clear message is it should not be used to prevent cardiovascular disease Manson said'\n",
      "Word: The, Deprel: det, Head: message\n",
      "Word: clear, Deprel: amod, Head: message\n",
      "Word: message, Deprel: nsubj:outer, Head: used\n",
      "Word: is, Deprel: cop, Head: used\n",
      "Word: it, Deprel: nsubj:pass, Head: used\n",
      "Word: should, Deprel: aux, Head: used\n",
      "Word: not, Deprel: advmod, Head: used\n",
      "Word: be, Deprel: aux:pass, Head: used\n",
      "Word: used, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: prevent\n",
      "Word: prevent, Deprel: advcl, Head: used\n",
      "Word: cardiovascular, Deprel: amod, Head: disease\n",
      "Word: disease, Deprel: obj, Head: prevent\n",
      "Word: Manson, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: disease\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Heather 35 who lost a leg in a road accident is thought to have steel plates fitted in her hips which would make natural childbirth impossible'\n",
      "Word: Heather, Deprel: nsubj:pass, Head: thought\n",
      "Word: 35, Deprel: dep, Head: Heather\n",
      "Word: who, Deprel: nsubj, Head: lost\n",
      "Word: lost, Deprel: acl:relcl, Head: Heather\n",
      "Word: a, Deprel: det, Head: leg\n",
      "Word: leg, Deprel: obj, Head: lost\n",
      "Word: in, Deprel: case, Head: accident\n",
      "Word: a, Deprel: det, Head: accident\n",
      "Word: road, Deprel: compound, Head: accident\n",
      "Word: accident, Deprel: obl, Head: lost\n",
      "Word: is, Deprel: aux:pass, Head: thought\n",
      "Word: thought, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: have\n",
      "Word: have, Deprel: xcomp, Head: thought\n",
      "Word: steel, Deprel: compound, Head: plates\n",
      "Word: plates, Deprel: obj, Head: have\n",
      "Word: fitted, Deprel: acl, Head: plates\n",
      "Word: in, Deprel: case, Head: hips\n",
      "Word: her, Deprel: nmod:poss, Head: hips\n",
      "Word: hips, Deprel: obl, Head: fitted\n",
      "Word: which, Deprel: nsubj, Head: make\n",
      "Word: would, Deprel: aux, Head: make\n",
      "Word: make, Deprel: acl:relcl, Head: plates\n",
      "Word: natural, Deprel: amod, Head: childbirth\n",
      "Word: childbirth, Deprel: obj, Head: make\n",
      "Word: impossible, Deprel: xcomp, Head: make\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Former model Lady McCartney lost a leg in a road accident in 1993 and is understood to have steel plates fitted in her hips which would make natural childbirth difficult'\n",
      "Word: Former, Deprel: amod, Head: model\n",
      "Word: model, Deprel: compound, Head: Lady\n",
      "Word: Lady, Deprel: nsubj, Head: lost\n",
      "Word: McCartney, Deprel: flat, Head: Lady\n",
      "Word: lost, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: leg\n",
      "Word: leg, Deprel: obj, Head: lost\n",
      "Word: in, Deprel: case, Head: accident\n",
      "Word: a, Deprel: det, Head: accident\n",
      "Word: road, Deprel: compound, Head: accident\n",
      "Word: accident, Deprel: obl, Head: lost\n",
      "Word: in, Deprel: case, Head: 1993\n",
      "Word: 1993, Deprel: obl, Head: lost\n",
      "Word: and, Deprel: cc, Head: understood\n",
      "Word: is, Deprel: aux:pass, Head: understood\n",
      "Word: understood, Deprel: conj, Head: lost\n",
      "Word: to, Deprel: mark, Head: have\n",
      "Word: have, Deprel: xcomp, Head: understood\n",
      "Word: steel, Deprel: compound, Head: plates\n",
      "Word: plates, Deprel: obj, Head: have\n",
      "Word: fitted, Deprel: acl, Head: plates\n",
      "Word: in, Deprel: case, Head: hips\n",
      "Word: her, Deprel: nmod:poss, Head: hips\n",
      "Word: hips, Deprel: obl, Head: fitted\n",
      "Word: which, Deprel: nsubj, Head: make\n",
      "Word: would, Deprel: aux, Head: make\n",
      "Word: make, Deprel: acl:relcl, Head: plates\n",
      "Word: natural, Deprel: amod, Head: childbirth\n",
      "Word: childbirth, Deprel: obj, Head: make\n",
      "Word: difficult, Deprel: xcomp, Head: make\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The network is also dropping its Friday night Dateline edition'\n",
      "Word: The, Deprel: det, Head: network\n",
      "Word: network, Deprel: nsubj, Head: dropping\n",
      "Word: is, Deprel: aux, Head: dropping\n",
      "Word: also, Deprel: advmod, Head: dropping\n",
      "Word: dropping, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: edition\n",
      "Word: Friday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: compound, Head: edition\n",
      "Word: Dateline, Deprel: compound, Head: edition\n",
      "Word: edition, Deprel: obj, Head: dropping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The network will drop one edition of Dateline its newsmagazine franchise'\n",
      "Word: The, Deprel: det, Head: network\n",
      "Word: network, Deprel: nsubj, Head: drop\n",
      "Word: will, Deprel: aux, Head: drop\n",
      "Word: drop, Deprel: root, Head: ROOT\n",
      "Word: one, Deprel: nummod, Head: edition\n",
      "Word: edition, Deprel: obj, Head: drop\n",
      "Word: of, Deprel: case, Head: Dateline\n",
      "Word: Dateline, Deprel: nmod, Head: edition\n",
      "Word: its, Deprel: nmod:poss, Head: franchise\n",
      "Word: newsmagazine, Deprel: compound, Head: franchise\n",
      "Word: franchise, Deprel: nmod, Head: edition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The meat poultry butter cheese and nuts were impounded a year ago at a LaGrou Cold Storage warehouse in Chicago'\n",
      "Word: The, Deprel: det, Head: cheese\n",
      "Word: meat, Deprel: compound, Head: butter\n",
      "Word: poultry, Deprel: compound, Head: butter\n",
      "Word: butter, Deprel: compound, Head: cheese\n",
      "Word: cheese, Deprel: nsubj:pass, Head: impounded\n",
      "Word: and, Deprel: cc, Head: nuts\n",
      "Word: nuts, Deprel: conj, Head: cheese\n",
      "Word: were, Deprel: aux:pass, Head: impounded\n",
      "Word: impounded, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:npmod, Head: ago\n",
      "Word: ago, Deprel: advmod, Head: impounded\n",
      "Word: at, Deprel: case, Head: warehouse\n",
      "Word: a, Deprel: det, Head: warehouse\n",
      "Word: LaGrou, Deprel: compound, Head: warehouse\n",
      "Word: Cold, Deprel: amod, Head: Storage\n",
      "Word: Storage, Deprel: compound, Head: warehouse\n",
      "Word: warehouse, Deprel: obl, Head: impounded\n",
      "Word: in, Deprel: case, Head: Chicago\n",
      "Word: Chicago, Deprel: nmod, Head: warehouse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The meat poultry butter cheese and nuts were being stored by more than 100 wholesalers in Chicago'\n",
      "Word: The, Deprel: det, Head: cheese\n",
      "Word: meat, Deprel: compound, Head: butter\n",
      "Word: poultry, Deprel: compound, Head: butter\n",
      "Word: butter, Deprel: compound, Head: cheese\n",
      "Word: cheese, Deprel: nsubj:pass, Head: stored\n",
      "Word: and, Deprel: cc, Head: nuts\n",
      "Word: nuts, Deprel: conj, Head: cheese\n",
      "Word: were, Deprel: aux, Head: stored\n",
      "Word: being, Deprel: aux:pass, Head: stored\n",
      "Word: stored, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: wholesalers\n",
      "Word: more, Deprel: advmod, Head: 100\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 100, Deprel: nummod, Head: wholesalers\n",
      "Word: wholesalers, Deprel: obl, Head: stored\n",
      "Word: in, Deprel: case, Head: Chicago\n",
      "Word: Chicago, Deprel: nmod, Head: wholesalers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The BlueCore3-Multimedia includes a 16-bit stereo audio CODEC with dual ADC and DAC for stereo audio'\n",
      "Word: The, Deprel: det, Head: BlueCore3-Multimedia\n",
      "Word: BlueCore3-Multimedia, Deprel: nsubj, Head: includes\n",
      "Word: includes, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: CODEC\n",
      "Word: 16-bit, Deprel: amod, Head: CODEC\n",
      "Word: stereo, Deprel: compound, Head: audio\n",
      "Word: audio, Deprel: compound, Head: CODEC\n",
      "Word: CODEC, Deprel: obj, Head: includes\n",
      "Word: with, Deprel: case, Head: ADC\n",
      "Word: dual, Deprel: amod, Head: ADC\n",
      "Word: ADC, Deprel: nmod, Head: CODEC\n",
      "Word: and, Deprel: cc, Head: DAC\n",
      "Word: DAC, Deprel: conj, Head: ADC\n",
      "Word: for, Deprel: case, Head: audio\n",
      "Word: stereo, Deprel: compound, Head: audio\n",
      "Word: audio, Deprel: nmod, Head: ADC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'BlueCore3-Multimedia contains an open platform DSP co-processor and also includes a 16-bit stereo audio codec with dual ADC and DAC for stereo audio'\n",
      "Word: BlueCore3-Multimedia, Deprel: nsubj, Head: contains\n",
      "Word: contains, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: co-processor\n",
      "Word: open, Deprel: amod, Head: platform\n",
      "Word: platform, Deprel: compound, Head: co-processor\n",
      "Word: DSP, Deprel: compound, Head: co-processor\n",
      "Word: co-processor, Deprel: obj, Head: contains\n",
      "Word: and, Deprel: cc, Head: includes\n",
      "Word: also, Deprel: advmod, Head: includes\n",
      "Word: includes, Deprel: conj, Head: contains\n",
      "Word: a, Deprel: det, Head: codec\n",
      "Word: 16-bit, Deprel: compound, Head: codec\n",
      "Word: stereo, Deprel: compound, Head: audio\n",
      "Word: audio, Deprel: compound, Head: codec\n",
      "Word: codec, Deprel: obj, Head: includes\n",
      "Word: with, Deprel: case, Head: ADC\n",
      "Word: dual, Deprel: amod, Head: ADC\n",
      "Word: ADC, Deprel: nmod, Head: codec\n",
      "Word: and, Deprel: cc, Head: DAC\n",
      "Word: DAC, Deprel: conj, Head: ADC\n",
      "Word: for, Deprel: case, Head: audio\n",
      "Word: stereo, Deprel: compound, Head: audio\n",
      "Word: audio, Deprel: nmod, Head: ADC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Vice President Dick Cheney and Mississippi Republican gubernatorial candidate Haley Barbour acknowledge the cheering crowd'\n",
      "Word: Vice, Deprel: compound, Head: President\n",
      "Word: President, Deprel: nsubj, Head: acknowledge\n",
      "Word: Dick, Deprel: flat, Head: President\n",
      "Word: Cheney, Deprel: flat, Head: President\n",
      "Word: and, Deprel: cc, Head: Haley\n",
      "Word: Mississippi, Deprel: compound, Head: Republican\n",
      "Word: Republican, Deprel: amod, Head: candidate\n",
      "Word: gubernatorial, Deprel: compound, Head: candidate\n",
      "Word: candidate, Deprel: compound, Head: Haley\n",
      "Word: Haley, Deprel: conj, Head: President\n",
      "Word: Barbour, Deprel: flat, Head: Haley\n",
      "Word: acknowledge, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: crowd\n",
      "Word: cheering, Deprel: amod, Head: crowd\n",
      "Word: crowd, Deprel: obj, Head: acknowledge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Vice President Dick Cheney says Mississippi Republican Haley Barbour would be a good governor because of his government and business savvy'\n",
      "Word: Vice, Deprel: compound, Head: President\n",
      "Word: President, Deprel: nsubj, Head: says\n",
      "Word: Dick, Deprel: flat, Head: President\n",
      "Word: Cheney, Deprel: flat, Head: President\n",
      "Word: says, Deprel: root, Head: ROOT\n",
      "Word: Mississippi, Deprel: compound, Head: Republican\n",
      "Word: Republican, Deprel: compound, Head: Haley\n",
      "Word: Haley, Deprel: nsubj, Head: governor\n",
      "Word: Barbour, Deprel: flat, Head: Haley\n",
      "Word: would, Deprel: aux, Head: governor\n",
      "Word: be, Deprel: cop, Head: governor\n",
      "Word: a, Deprel: det, Head: governor\n",
      "Word: good, Deprel: amod, Head: governor\n",
      "Word: governor, Deprel: ccomp, Head: says\n",
      "Word: because, Deprel: case, Head: government\n",
      "Word: of, Deprel: fixed, Head: because\n",
      "Word: his, Deprel: nmod:poss, Head: government\n",
      "Word: government, Deprel: obl, Head: governor\n",
      "Word: and, Deprel: cc, Head: savvy\n",
      "Word: business, Deprel: compound, Head: savvy\n",
      "Word: savvy, Deprel: conj, Head: government\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The 51-year-old nurse worked at North York General Hospital the epicentre of the latest outbreak'\n",
      "Word: The, Deprel: det, Head: nurse\n",
      "Word: 51-year-old, Deprel: amod, Head: nurse\n",
      "Word: nurse, Deprel: nsubj, Head: worked\n",
      "Word: worked, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: Hospital\n",
      "Word: North, Deprel: compound, Head: York\n",
      "Word: York, Deprel: compound, Head: Hospital\n",
      "Word: General, Deprel: amod, Head: Hospital\n",
      "Word: Hospital, Deprel: obl, Head: worked\n",
      "Word: the, Deprel: det, Head: epicentre\n",
      "Word: epicentre, Deprel: obj, Head: worked\n",
      "Word: of, Deprel: case, Head: outbreak\n",
      "Word: the, Deprel: det, Head: outbreak\n",
      "Word: latest, Deprel: amod, Head: outbreak\n",
      "Word: outbreak, Deprel: nmod, Head: epicentre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Emile Laroza 51 contracted SARS while working as a nurse at North York General Hospital the epicentre of the second SARS outbreak'\n",
      "Word: Emile, Deprel: nsubj, Head: contracted\n",
      "Word: Laroza, Deprel: flat, Head: Emile\n",
      "Word: 51, Deprel: nmod:npmod, Head: Emile\n",
      "Word: contracted, Deprel: root, Head: ROOT\n",
      "Word: SARS, Deprel: obj, Head: contracted\n",
      "Word: while, Deprel: mark, Head: working\n",
      "Word: working, Deprel: advcl, Head: contracted\n",
      "Word: as, Deprel: case, Head: nurse\n",
      "Word: a, Deprel: det, Head: nurse\n",
      "Word: nurse, Deprel: obl, Head: working\n",
      "Word: at, Deprel: case, Head: Hospital\n",
      "Word: North, Deprel: compound, Head: York\n",
      "Word: York, Deprel: compound, Head: Hospital\n",
      "Word: General, Deprel: amod, Head: Hospital\n",
      "Word: Hospital, Deprel: nmod, Head: nurse\n",
      "Word: the, Deprel: det, Head: epicentre\n",
      "Word: epicentre, Deprel: obj, Head: working\n",
      "Word: of, Deprel: case, Head: outbreak\n",
      "Word: the, Deprel: det, Head: outbreak\n",
      "Word: second, Deprel: amod, Head: outbreak\n",
      "Word: SARS, Deprel: compound, Head: outbreak\n",
      "Word: outbreak, Deprel: nmod, Head: epicentre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Rusch has also allowed five or more earned runs in each of his last three starts'\n",
      "Word: Rusch, Deprel: nsubj, Head: allowed\n",
      "Word: has, Deprel: aux, Head: allowed\n",
      "Word: also, Deprel: advmod, Head: allowed\n",
      "Word: allowed, Deprel: root, Head: ROOT\n",
      "Word: five, Deprel: nummod, Head: runs\n",
      "Word: or, Deprel: cc, Head: more\n",
      "Word: more, Deprel: conj, Head: five\n",
      "Word: earned, Deprel: amod, Head: runs\n",
      "Word: runs, Deprel: obj, Head: allowed\n",
      "Word: in, Deprel: case, Head: each\n",
      "Word: each, Deprel: obl, Head: allowed\n",
      "Word: of, Deprel: case, Head: starts\n",
      "Word: his, Deprel: nmod:poss, Head: starts\n",
      "Word: last, Deprel: amod, Head: starts\n",
      "Word: three, Deprel: nummod, Head: starts\n",
      "Word: starts, Deprel: nmod, Head: each\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Redman has allowed two earned runs or less in six of his nine starts'\n",
      "Word: Redman, Deprel: nsubj, Head: allowed\n",
      "Word: has, Deprel: aux, Head: allowed\n",
      "Word: allowed, Deprel: root, Head: ROOT\n",
      "Word: two, Deprel: nummod, Head: runs\n",
      "Word: earned, Deprel: amod, Head: runs\n",
      "Word: runs, Deprel: obj, Head: allowed\n",
      "Word: or, Deprel: cc, Head: less\n",
      "Word: less, Deprel: conj, Head: runs\n",
      "Word: in, Deprel: case, Head: six\n",
      "Word: six, Deprel: obl, Head: allowed\n",
      "Word: of, Deprel: case, Head: starts\n",
      "Word: his, Deprel: nmod:poss, Head: starts\n",
      "Word: nine, Deprel: nummod, Head: starts\n",
      "Word: starts, Deprel: nmod, Head: six\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Turner transferred about 10 million shares to a charitable trust before they were sold'\n",
      "Word: Mr, Deprel: nsubj, Head: transferred\n",
      "Word: Turner, Deprel: flat, Head: Mr\n",
      "Word: transferred, Deprel: root, Head: ROOT\n",
      "Word: about, Deprel: advmod, Head: million\n",
      "Word: 10, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: shares\n",
      "Word: shares, Deprel: obj, Head: transferred\n",
      "Word: to, Deprel: case, Head: trust\n",
      "Word: a, Deprel: det, Head: trust\n",
      "Word: charitable, Deprel: amod, Head: trust\n",
      "Word: trust, Deprel: obl, Head: transferred\n",
      "Word: before, Deprel: mark, Head: sold\n",
      "Word: they, Deprel: nsubj, Head: sold\n",
      "Word: were, Deprel: aux:pass, Head: sold\n",
      "Word: sold, Deprel: advcl, Head: transferred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The sales leave Mr Turner with about 45 million shares in AOL'\n",
      "Word: The, Deprel: det, Head: sales\n",
      "Word: sales, Deprel: nsubj, Head: leave\n",
      "Word: leave, Deprel: root, Head: ROOT\n",
      "Word: Mr, Deprel: obj, Head: leave\n",
      "Word: Turner, Deprel: flat, Head: Mr\n",
      "Word: with, Deprel: case, Head: shares\n",
      "Word: about, Deprel: advmod, Head: million\n",
      "Word: 45, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: shares\n",
      "Word: shares, Deprel: obl, Head: leave\n",
      "Word: in, Deprel: case, Head: AOL\n",
      "Word: AOL, Deprel: nmod, Head: shares\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He also recruited others to participate in the scheme by convincing them to receive fraudulently obtained merchandise he had ordered for himself'\n",
      "Word: He, Deprel: nsubj, Head: recruited\n",
      "Word: also, Deprel: advmod, Head: recruited\n",
      "Word: recruited, Deprel: root, Head: ROOT\n",
      "Word: others, Deprel: obj, Head: recruited\n",
      "Word: to, Deprel: mark, Head: participate\n",
      "Word: participate, Deprel: xcomp, Head: recruited\n",
      "Word: in, Deprel: case, Head: scheme\n",
      "Word: the, Deprel: det, Head: scheme\n",
      "Word: scheme, Deprel: obl, Head: participate\n",
      "Word: by, Deprel: mark, Head: convincing\n",
      "Word: convincing, Deprel: advcl, Head: participate\n",
      "Word: them, Deprel: iobj, Head: convincing\n",
      "Word: to, Deprel: mark, Head: receive\n",
      "Word: receive, Deprel: xcomp, Head: convincing\n",
      "Word: fraudulently, Deprel: advmod, Head: obtained\n",
      "Word: obtained, Deprel: amod, Head: merchandise\n",
      "Word: merchandise, Deprel: obj, Head: receive\n",
      "Word: he, Deprel: nsubj, Head: ordered\n",
      "Word: had, Deprel: aux, Head: ordered\n",
      "Word: ordered, Deprel: acl:relcl, Head: merchandise\n",
      "Word: for, Deprel: case, Head: himself\n",
      "Word: himself, Deprel: obl, Head: ordered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He also recruited other people to take delivery of fraudulently obtained merchandise he had ordered'\n",
      "Word: He, Deprel: nsubj, Head: recruited\n",
      "Word: also, Deprel: advmod, Head: recruited\n",
      "Word: recruited, Deprel: root, Head: ROOT\n",
      "Word: other, Deprel: amod, Head: people\n",
      "Word: people, Deprel: obj, Head: recruited\n",
      "Word: to, Deprel: mark, Head: take\n",
      "Word: take, Deprel: xcomp, Head: recruited\n",
      "Word: delivery, Deprel: obj, Head: take\n",
      "Word: of, Deprel: case, Head: merchandise\n",
      "Word: fraudulently, Deprel: advmod, Head: obtained\n",
      "Word: obtained, Deprel: amod, Head: merchandise\n",
      "Word: merchandise, Deprel: nmod, Head: delivery\n",
      "Word: he, Deprel: nsubj, Head: ordered\n",
      "Word: had, Deprel: aux, Head: ordered\n",
      "Word: ordered, Deprel: acl:relcl, Head: merchandise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Gartner s report said global WLAN equipment shipments reached 19.5 million last year a 120 percent increase over 2001 s 8.9 million units'\n",
      "Word: Gartner, Deprel: nmod:poss, Head: report\n",
      "Word: s, Deprel: case, Head: Gartner\n",
      "Word: report, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: global, Deprel: amod, Head: shipments\n",
      "Word: WLAN, Deprel: compound, Head: shipments\n",
      "Word: equipment, Deprel: compound, Head: shipments\n",
      "Word: shipments, Deprel: nsubj, Head: reached\n",
      "Word: reached, Deprel: ccomp, Head: said\n",
      "Word: 19.5, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: reached\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: reached\n",
      "Word: a, Deprel: det, Head: increase\n",
      "Word: 120, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: increase\n",
      "Word: increase, Deprel: obj, Head: reached\n",
      "Word: over, Deprel: case, Head: units\n",
      "Word: 2001, Deprel: nmod:poss, Head: units\n",
      "Word: s, Deprel: case, Head: 2001\n",
      "Word: 8.9, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: units\n",
      "Word: units, Deprel: obl, Head: reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Total shipments reached 19.5 million units last year compared with 8.9 million units in 2001'\n",
      "Word: Total, Deprel: amod, Head: shipments\n",
      "Word: shipments, Deprel: nsubj, Head: reached\n",
      "Word: reached, Deprel: root, Head: ROOT\n",
      "Word: 19.5, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: units\n",
      "Word: units, Deprel: obj, Head: reached\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: reached\n",
      "Word: compared, Deprel: advcl, Head: reached\n",
      "Word: with, Deprel: case, Head: units\n",
      "Word: 8.9, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: units\n",
      "Word: units, Deprel: obl, Head: reached\n",
      "Word: in, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: nmod, Head: units\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The New York Mets then selected outfielder Lastings Milledge from Lakewood Ranch High School in Florida'\n",
      "Word: The, Deprel: det, Head: Mets\n",
      "Word: New, Deprel: compound, Head: York\n",
      "Word: York, Deprel: compound, Head: Mets\n",
      "Word: Mets, Deprel: nsubj, Head: selected\n",
      "Word: then, Deprel: advmod, Head: selected\n",
      "Word: selected, Deprel: root, Head: ROOT\n",
      "Word: outfielder, Deprel: obj, Head: selected\n",
      "Word: Lastings, Deprel: flat, Head: outfielder\n",
      "Word: Milledge, Deprel: flat, Head: outfielder\n",
      "Word: from, Deprel: case, Head: School\n",
      "Word: Lakewood, Deprel: compound, Head: Ranch\n",
      "Word: Ranch, Deprel: compound, Head: School\n",
      "Word: High, Deprel: amod, Head: School\n",
      "Word: School, Deprel: obl, Head: selected\n",
      "Word: in, Deprel: case, Head: Florida\n",
      "Word: Florida, Deprel: nmod, Head: School\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Mets took Lastings Milledge an outfielder from Florida with the 12th pick'\n",
      "Word: The, Deprel: det, Head: Mets\n",
      "Word: Mets, Deprel: nsubj, Head: took\n",
      "Word: took, Deprel: root, Head: ROOT\n",
      "Word: Lastings, Deprel: obj, Head: took\n",
      "Word: Milledge, Deprel: flat, Head: Lastings\n",
      "Word: an, Deprel: det, Head: outfielder\n",
      "Word: outfielder, Deprel: obj, Head: took\n",
      "Word: from, Deprel: case, Head: Florida\n",
      "Word: Florida, Deprel: obl, Head: took\n",
      "Word: with, Deprel: case, Head: pick\n",
      "Word: the, Deprel: det, Head: pick\n",
      "Word: 12th, Deprel: amod, Head: pick\n",
      "Word: pick, Deprel: obl, Head: took\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Now with the agency s last three shuttles grounded in the wake of the Columbia disaster that wait could be even longer'\n",
      "Word: Now, Deprel: advmod, Head: longer\n",
      "Word: with, Deprel: case, Head: shuttles\n",
      "Word: the, Deprel: det, Head: agency\n",
      "Word: agency, Deprel: nmod:poss, Head: shuttles\n",
      "Word: s, Deprel: case, Head: agency\n",
      "Word: last, Deprel: amod, Head: shuttles\n",
      "Word: three, Deprel: nummod, Head: shuttles\n",
      "Word: shuttles, Deprel: obl, Head: longer\n",
      "Word: grounded, Deprel: acl, Head: shuttles\n",
      "Word: in, Deprel: case, Head: wake\n",
      "Word: the, Deprel: det, Head: wake\n",
      "Word: wake, Deprel: obl, Head: grounded\n",
      "Word: of, Deprel: case, Head: disaster\n",
      "Word: the, Deprel: det, Head: disaster\n",
      "Word: Columbia, Deprel: compound, Head: disaster\n",
      "Word: disaster, Deprel: nmod, Head: wake\n",
      "Word: that, Deprel: nsubj, Head: wait\n",
      "Word: wait, Deprel: nsubj, Head: longer\n",
      "Word: could, Deprel: aux, Head: longer\n",
      "Word: be, Deprel: cop, Head: longer\n",
      "Word: even, Deprel: advmod, Head: longer\n",
      "Word: longer, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'With the remaining three shuttles grounded in the wake of the Columbia accident the rookies will have to wait even longer'\n",
      "Word: With, Deprel: case, Head: shuttles\n",
      "Word: the, Deprel: det, Head: shuttles\n",
      "Word: remaining, Deprel: amod, Head: shuttles\n",
      "Word: three, Deprel: nummod, Head: shuttles\n",
      "Word: shuttles, Deprel: obl, Head: have\n",
      "Word: grounded, Deprel: acl, Head: shuttles\n",
      "Word: in, Deprel: case, Head: wake\n",
      "Word: the, Deprel: det, Head: wake\n",
      "Word: wake, Deprel: obl, Head: grounded\n",
      "Word: of, Deprel: case, Head: accident\n",
      "Word: the, Deprel: det, Head: accident\n",
      "Word: Columbia, Deprel: compound, Head: accident\n",
      "Word: accident, Deprel: nmod, Head: wake\n",
      "Word: the, Deprel: det, Head: rookies\n",
      "Word: rookies, Deprel: nsubj, Head: have\n",
      "Word: will, Deprel: aux, Head: have\n",
      "Word: have, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: wait\n",
      "Word: wait, Deprel: xcomp, Head: have\n",
      "Word: even, Deprel: advmod, Head: longer\n",
      "Word: longer, Deprel: advmod, Head: wait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bremer 61 is a onetime assistant to former Secretaries of State William P Rogers and Henry Kissinger and was ambassador-at-large for counterterrorism from 1986 to 1989'\n",
      "Word: Bremer, Deprel: nsubj, Head: assistant\n",
      "Word: 61, Deprel: nummod, Head: Bremer\n",
      "Word: is, Deprel: cop, Head: assistant\n",
      "Word: a, Deprel: det, Head: assistant\n",
      "Word: onetime, Deprel: amod, Head: assistant\n",
      "Word: assistant, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Secretaries\n",
      "Word: former, Deprel: amod, Head: Secretaries\n",
      "Word: Secretaries, Deprel: nmod, Head: assistant\n",
      "Word: of, Deprel: case, Head: State\n",
      "Word: State, Deprel: nmod, Head: Secretaries\n",
      "Word: William, Deprel: appos, Head: Secretaries\n",
      "Word: P, Deprel: flat, Head: William\n",
      "Word: Rogers, Deprel: flat, Head: William\n",
      "Word: and, Deprel: cc, Head: Henry\n",
      "Word: Henry, Deprel: conj, Head: William\n",
      "Word: Kissinger, Deprel: flat, Head: Henry\n",
      "Word: and, Deprel: cc, Head: ambassador-at-large\n",
      "Word: was, Deprel: cop, Head: ambassador-at-large\n",
      "Word: ambassador-at-large, Deprel: conj, Head: assistant\n",
      "Word: for, Deprel: case, Head: counterterrorism\n",
      "Word: counterterrorism, Deprel: obl, Head: ambassador-at-large\n",
      "Word: from, Deprel: case, Head: 1986\n",
      "Word: 1986, Deprel: obl, Head: ambassador-at-large\n",
      "Word: to, Deprel: case, Head: 1989\n",
      "Word: 1989, Deprel: obl, Head: ambassador-at-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bremer 61 is a former assistant to former Secretaries of State William P Rogers and Henry Kissinger'\n",
      "Word: Bremer, Deprel: nsubj, Head: assistant\n",
      "Word: 61, Deprel: nummod, Head: Bremer\n",
      "Word: is, Deprel: cop, Head: assistant\n",
      "Word: a, Deprel: det, Head: assistant\n",
      "Word: former, Deprel: amod, Head: assistant\n",
      "Word: assistant, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Secretaries\n",
      "Word: former, Deprel: amod, Head: Secretaries\n",
      "Word: Secretaries, Deprel: nmod, Head: assistant\n",
      "Word: of, Deprel: case, Head: State\n",
      "Word: State, Deprel: nmod, Head: Secretaries\n",
      "Word: William, Deprel: appos, Head: Secretaries\n",
      "Word: P, Deprel: flat, Head: William\n",
      "Word: Rogers, Deprel: flat, Head: William\n",
      "Word: and, Deprel: cc, Head: Henry\n",
      "Word: Henry, Deprel: conj, Head: William\n",
      "Word: Kissinger, Deprel: flat, Head: Henry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Roy Moore the suspended chief justice of the Alabama Supreme Court stood accused but unrepentant Wednesday in the same courtroom he recently presided over'\n",
      "Word: Roy, Deprel: nsubj, Head: stood\n",
      "Word: Moore, Deprel: flat, Head: Roy\n",
      "Word: the, Deprel: det, Head: justice\n",
      "Word: suspended, Deprel: amod, Head: justice\n",
      "Word: chief, Deprel: amod, Head: justice\n",
      "Word: justice, Deprel: appos, Head: Roy\n",
      "Word: of, Deprel: case, Head: Court\n",
      "Word: the, Deprel: det, Head: Court\n",
      "Word: Alabama, Deprel: compound, Head: Court\n",
      "Word: Supreme, Deprel: amod, Head: Court\n",
      "Word: Court, Deprel: nmod, Head: justice\n",
      "Word: stood, Deprel: root, Head: ROOT\n",
      "Word: accused, Deprel: xcomp, Head: stood\n",
      "Word: but, Deprel: cc, Head: unrepentant\n",
      "Word: unrepentant, Deprel: conj, Head: accused\n",
      "Word: Wednesday, Deprel: obl:tmod, Head: accused\n",
      "Word: in, Deprel: case, Head: courtroom\n",
      "Word: the, Deprel: det, Head: courtroom\n",
      "Word: same, Deprel: amod, Head: courtroom\n",
      "Word: courtroom, Deprel: obl, Head: accused\n",
      "Word: he, Deprel: nsubj, Head: presided\n",
      "Word: recently, Deprel: advmod, Head: presided\n",
      "Word: presided, Deprel: parataxis, Head: stood\n",
      "Word: over, Deprel: advmod, Head: presided\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Moore the suspended chief justice of the Alabama Supreme Court stands trial before the Alabama Court of the Judiciary'\n",
      "Word: Moore, Deprel: nsubj, Head: stands\n",
      "Word: the, Deprel: det, Head: justice\n",
      "Word: suspended, Deprel: amod, Head: justice\n",
      "Word: chief, Deprel: amod, Head: justice\n",
      "Word: justice, Deprel: nsubj, Head: stands\n",
      "Word: of, Deprel: case, Head: Court\n",
      "Word: the, Deprel: det, Head: Court\n",
      "Word: Alabama, Deprel: compound, Head: Court\n",
      "Word: Supreme, Deprel: amod, Head: Court\n",
      "Word: Court, Deprel: nmod, Head: justice\n",
      "Word: stands, Deprel: root, Head: ROOT\n",
      "Word: trial, Deprel: xcomp, Head: stands\n",
      "Word: before, Deprel: case, Head: Court\n",
      "Word: the, Deprel: det, Head: Court\n",
      "Word: Alabama, Deprel: compound, Head: Court\n",
      "Word: Court, Deprel: obl, Head: stands\n",
      "Word: of, Deprel: case, Head: Judiciary\n",
      "Word: the, Deprel: det, Head: Judiciary\n",
      "Word: Judiciary, Deprel: nmod, Head: Court\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The blue-chip Dow Jones industrial average DJI climbed 164 points or 1.91 percent to 8,765.38 brushing its highest levels since mid-January'\n",
      "Word: The, Deprel: det, Head: DJI\n",
      "Word: blue-chip, Deprel: compound, Head: average\n",
      "Word: Dow, Deprel: compound, Head: Jones\n",
      "Word: Jones, Deprel: compound, Head: average\n",
      "Word: industrial, Deprel: compound, Head: average\n",
      "Word: average, Deprel: compound, Head: DJI\n",
      "Word: DJI, Deprel: nsubj, Head: climbed\n",
      "Word: climbed, Deprel: root, Head: ROOT\n",
      "Word: 164, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: climbed\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.91, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 8,765.38\n",
      "Word: 8,765.38, Deprel: obl, Head: climbed\n",
      "Word: brushing, Deprel: advcl, Head: climbed\n",
      "Word: its, Deprel: nmod:poss, Head: levels\n",
      "Word: highest, Deprel: amod, Head: levels\n",
      "Word: levels, Deprel: obj, Head: brushing\n",
      "Word: since, Deprel: case, Head: mid-January\n",
      "Word: mid-January, Deprel: obl, Head: brushing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The blue-chip Dow Jones industrial average DJI tacked on 97 points or 1.14 percent to 8,699'\n",
      "Word: The, Deprel: det, Head: DJI\n",
      "Word: blue-chip, Deprel: compound, Head: average\n",
      "Word: Dow, Deprel: compound, Head: Jones\n",
      "Word: Jones, Deprel: compound, Head: average\n",
      "Word: industrial, Deprel: compound, Head: average\n",
      "Word: average, Deprel: compound, Head: DJI\n",
      "Word: DJI, Deprel: nsubj, Head: tacked\n",
      "Word: tacked, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: points\n",
      "Word: 97, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl, Head: tacked\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.14, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 8,699\n",
      "Word: 8,699, Deprel: obl, Head: tacked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'An arrest warrant claimed Bryant assaulted the woman June 30 at a hotel'\n",
      "Word: An, Deprel: det, Head: warrant\n",
      "Word: arrest, Deprel: compound, Head: warrant\n",
      "Word: warrant, Deprel: nsubj, Head: claimed\n",
      "Word: claimed, Deprel: root, Head: ROOT\n",
      "Word: Bryant, Deprel: nsubj, Head: assaulted\n",
      "Word: assaulted, Deprel: ccomp, Head: claimed\n",
      "Word: the, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: obj, Head: assaulted\n",
      "Word: June, Deprel: appos, Head: woman\n",
      "Word: 30, Deprel: nummod, Head: June\n",
      "Word: at, Deprel: case, Head: hotel\n",
      "Word: a, Deprel: det, Head: hotel\n",
      "Word: hotel, Deprel: obl, Head: assaulted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'According to an arrest warrant Bryant 24 attacked a woman on June 30'\n",
      "Word: According, Deprel: case, Head: warrant\n",
      "Word: to, Deprel: fixed, Head: According\n",
      "Word: an, Deprel: det, Head: warrant\n",
      "Word: arrest, Deprel: compound, Head: warrant\n",
      "Word: warrant, Deprel: obl, Head: attacked\n",
      "Word: Bryant, Deprel: nsubj, Head: attacked\n",
      "Word: 24, Deprel: flat, Head: Bryant\n",
      "Word: attacked, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: obj, Head: attacked\n",
      "Word: on, Deprel: case, Head: June\n",
      "Word: June, Deprel: obl, Head: attacked\n",
      "Word: 30, Deprel: nummod, Head: June\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Florida Sen Bob Graham was not identifiable by 61 percent of those polled'\n",
      "Word: Florida, Deprel: compound, Head: Sen\n",
      "Word: Sen, Deprel: compound, Head: Bob\n",
      "Word: Bob, Deprel: nsubj:pass, Head: identifiable\n",
      "Word: Graham, Deprel: flat, Head: Bob\n",
      "Word: was, Deprel: aux:pass, Head: identifiable\n",
      "Word: not, Deprel: advmod, Head: identifiable\n",
      "Word: identifiable, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: percent\n",
      "Word: 61, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: identifiable\n",
      "Word: of, Deprel: case, Head: those\n",
      "Word: those, Deprel: nmod, Head: percent\n",
      "Word: polled, Deprel: acl, Head: those\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Kerry was viewed favorably by 66 percent of those polled Dean at 57 percent'\n",
      "Word: Kerry, Deprel: nsubj:pass, Head: viewed\n",
      "Word: was, Deprel: aux:pass, Head: viewed\n",
      "Word: viewed, Deprel: root, Head: ROOT\n",
      "Word: favorably, Deprel: advmod, Head: viewed\n",
      "Word: by, Deprel: case, Head: percent\n",
      "Word: 66, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: viewed\n",
      "Word: of, Deprel: case, Head: those\n",
      "Word: those, Deprel: nmod, Head: percent\n",
      "Word: polled, Deprel: advcl, Head: viewed\n",
      "Word: Dean, Deprel: obj, Head: polled\n",
      "Word: at, Deprel: case, Head: percent\n",
      "Word: 57, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: polled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index SPX rose 3.47 points or 0.36 percent to 977.59'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broader, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: compound, Head: s\n",
      "Word: s, Deprel: compound, Head: SPX\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 3.47, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: rose\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.36, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 977.59\n",
      "Word: 977.59, Deprel: obl, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The tech-laden Nasdaq Composite Index IXIC shed 8 points or 0.45 percent to 1,645'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: tech-laden, Deprel: amod, Head: IXIC\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: shed\n",
      "Word: shed, Deprel: root, Head: ROOT\n",
      "Word: 8, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: shed\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.45, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,645\n",
      "Word: 1,645, Deprel: obl, Head: shed\n",
      "\n",
      "Dependencies for Sentence: 'As a result 24 players broke par in the first round'\n",
      "Word: As, Deprel: case, Head: result\n",
      "Word: a, Deprel: det, Head: result\n",
      "Word: result, Deprel: obl, Head: broke\n",
      "Word: 24, Deprel: nummod, Head: players\n",
      "Word: players, Deprel: nsubj, Head: broke\n",
      "Word: broke, Deprel: root, Head: ROOT\n",
      "Word: par, Deprel: obj, Head: broke\n",
      "Word: in, Deprel: case, Head: round\n",
      "Word: the, Deprel: det, Head: round\n",
      "Word: first, Deprel: amod, Head: round\n",
      "Word: round, Deprel: obl, Head: broke\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Twenty-four players broke par in the first round the third highest figure in U.S Open history'\n",
      "Word: Twenty-four, Deprel: nummod, Head: players\n",
      "Word: players, Deprel: nsubj, Head: broke\n",
      "Word: broke, Deprel: root, Head: ROOT\n",
      "Word: par, Deprel: obj, Head: broke\n",
      "Word: in, Deprel: case, Head: round\n",
      "Word: the, Deprel: det, Head: round\n",
      "Word: first, Deprel: amod, Head: round\n",
      "Word: round, Deprel: obl, Head: broke\n",
      "Word: the, Deprel: det, Head: figure\n",
      "Word: third, Deprel: amod, Head: figure\n",
      "Word: highest, Deprel: amod, Head: figure\n",
      "Word: figure, Deprel: obj, Head: broke\n",
      "Word: in, Deprel: case, Head: history\n",
      "Word: U.S, Deprel: compound, Head: history\n",
      "Word: Open, Deprel: compound, Head: history\n",
      "Word: history, Deprel: nmod, Head: figure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Those conversations had not taken place as of Tuesday night according to an Oracle spokeswoman'\n",
      "Word: Those, Deprel: det, Head: conversations\n",
      "Word: conversations, Deprel: nsubj, Head: taken\n",
      "Word: had, Deprel: aux, Head: taken\n",
      "Word: not, Deprel: advmod, Head: taken\n",
      "Word: taken, Deprel: root, Head: ROOT\n",
      "Word: place, Deprel: obj, Head: taken\n",
      "Word: as, Deprel: case, Head: night\n",
      "Word: of, Deprel: fixed, Head: as\n",
      "Word: Tuesday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl, Head: taken\n",
      "Word: according, Deprel: case, Head: spokeswoman\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: an, Deprel: det, Head: spokeswoman\n",
      "Word: Oracle, Deprel: compound, Head: spokeswoman\n",
      "Word: spokeswoman, Deprel: obl, Head: taken\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Those talks have not taken place according to an Oracle spokeswoman'\n",
      "Word: Those, Deprel: det, Head: talks\n",
      "Word: talks, Deprel: nsubj, Head: taken\n",
      "Word: have, Deprel: aux, Head: taken\n",
      "Word: not, Deprel: advmod, Head: taken\n",
      "Word: taken, Deprel: root, Head: ROOT\n",
      "Word: place, Deprel: obj, Head: taken\n",
      "Word: according, Deprel: case, Head: spokeswoman\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: an, Deprel: det, Head: spokeswoman\n",
      "Word: Oracle, Deprel: compound, Head: spokeswoman\n",
      "Word: spokeswoman, Deprel: obl, Head: taken\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'FRIENDS of Robert De Niro yesterday rallied around him after he was diagnosed with prostate cancer'\n",
      "Word: FRIENDS, Deprel: nsubj, Head: rallied\n",
      "Word: of, Deprel: case, Head: Robert\n",
      "Word: Robert, Deprel: nmod, Head: FRIENDS\n",
      "Word: De, Deprel: flat, Head: Robert\n",
      "Word: Niro, Deprel: flat, Head: Robert\n",
      "Word: yesterday, Deprel: obl:tmod, Head: rallied\n",
      "Word: rallied, Deprel: root, Head: ROOT\n",
      "Word: around, Deprel: case, Head: him\n",
      "Word: him, Deprel: obl, Head: rallied\n",
      "Word: after, Deprel: mark, Head: diagnosed\n",
      "Word: he, Deprel: nsubj:pass, Head: diagnosed\n",
      "Word: was, Deprel: aux:pass, Head: diagnosed\n",
      "Word: diagnosed, Deprel: advcl, Head: rallied\n",
      "Word: with, Deprel: case, Head: cancer\n",
      "Word: prostate, Deprel: compound, Head: cancer\n",
      "Word: cancer, Deprel: obl, Head: diagnosed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hollywood actor Robert De Niro has been diagnosed with prostate cancer his spokesman said today'\n",
      "Word: Hollywood, Deprel: compound, Head: actor\n",
      "Word: actor, Deprel: nsubj:pass, Head: diagnosed\n",
      "Word: Robert, Deprel: flat, Head: actor\n",
      "Word: De, Deprel: flat, Head: Robert\n",
      "Word: Niro, Deprel: flat, Head: Robert\n",
      "Word: has, Deprel: aux, Head: diagnosed\n",
      "Word: been, Deprel: aux:pass, Head: diagnosed\n",
      "Word: diagnosed, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: cancer\n",
      "Word: prostate, Deprel: compound, Head: cancer\n",
      "Word: cancer, Deprel: obl, Head: diagnosed\n",
      "Word: his, Deprel: nmod:poss, Head: spokesman\n",
      "Word: spokesman, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: cancer\n",
      "Word: today, Deprel: obl:tmod, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Albertsons and Kroger s Ralphs chain locked out their workers in response'\n",
      "Word: Albertsons, Deprel: nmod:poss, Head: chain\n",
      "Word: and, Deprel: cc, Head: Kroger\n",
      "Word: Kroger, Deprel: conj, Head: Albertsons\n",
      "Word: s, Deprel: case, Head: Kroger\n",
      "Word: Ralphs, Deprel: compound, Head: chain\n",
      "Word: chain, Deprel: nsubj, Head: locked\n",
      "Word: locked, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: compound:prt, Head: locked\n",
      "Word: their, Deprel: nmod:poss, Head: workers\n",
      "Word: workers, Deprel: obj, Head: locked\n",
      "Word: in, Deprel: case, Head: response\n",
      "Word: response, Deprel: obl, Head: locked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Kroger s Ralphs chain and Albertsons immediately locked out their grocery workers in a show of solidarity'\n",
      "Word: Kroger, Deprel: nmod:poss, Head: chain\n",
      "Word: s, Deprel: case, Head: Kroger\n",
      "Word: Ralphs, Deprel: compound, Head: chain\n",
      "Word: chain, Deprel: nsubj, Head: locked\n",
      "Word: and, Deprel: cc, Head: Albertsons\n",
      "Word: Albertsons, Deprel: conj, Head: chain\n",
      "Word: immediately, Deprel: advmod, Head: locked\n",
      "Word: locked, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: compound:prt, Head: locked\n",
      "Word: their, Deprel: nmod:poss, Head: workers\n",
      "Word: grocery, Deprel: compound, Head: workers\n",
      "Word: workers, Deprel: obj, Head: locked\n",
      "Word: in, Deprel: case, Head: show\n",
      "Word: a, Deprel: det, Head: show\n",
      "Word: show, Deprel: obl, Head: locked\n",
      "Word: of, Deprel: case, Head: solidarity\n",
      "Word: solidarity, Deprel: nmod, Head: show\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Taiwan has attempted to gain observer status to the United Nations-affiliated WHO for seven years but again was rebuffed March 19 at its annual conference in Geneva'\n",
      "Word: Taiwan, Deprel: nsubj, Head: attempted\n",
      "Word: has, Deprel: aux, Head: attempted\n",
      "Word: attempted, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: gain\n",
      "Word: gain, Deprel: xcomp, Head: attempted\n",
      "Word: observer, Deprel: compound, Head: status\n",
      "Word: status, Deprel: obj, Head: gain\n",
      "Word: to, Deprel: case, Head: WHO\n",
      "Word: the, Deprel: det, Head: WHO\n",
      "Word: United, Deprel: amod, Head: Nations-affiliated\n",
      "Word: Nations-affiliated, Deprel: compound, Head: WHO\n",
      "Word: WHO, Deprel: obl, Head: gain\n",
      "Word: for, Deprel: case, Head: years\n",
      "Word: seven, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl, Head: gain\n",
      "Word: but, Deprel: cc, Head: rebuffed\n",
      "Word: again, Deprel: advmod, Head: rebuffed\n",
      "Word: was, Deprel: aux:pass, Head: rebuffed\n",
      "Word: rebuffed, Deprel: conj, Head: attempted\n",
      "Word: March, Deprel: obl:tmod, Head: rebuffed\n",
      "Word: 19, Deprel: nummod, Head: March\n",
      "Word: at, Deprel: case, Head: conference\n",
      "Word: its, Deprel: nmod:poss, Head: conference\n",
      "Word: annual, Deprel: amod, Head: conference\n",
      "Word: conference, Deprel: obl, Head: rebuffed\n",
      "Word: in, Deprel: case, Head: Geneva\n",
      "Word: Geneva, Deprel: nmod, Head: conference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It has sought observer status for seven years but was again rebuffed May 19 at the annual WHO conference in Geneva'\n",
      "Word: It, Deprel: nsubj, Head: sought\n",
      "Word: has, Deprel: aux, Head: sought\n",
      "Word: sought, Deprel: root, Head: ROOT\n",
      "Word: observer, Deprel: compound, Head: status\n",
      "Word: status, Deprel: obj, Head: sought\n",
      "Word: for, Deprel: case, Head: years\n",
      "Word: seven, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl, Head: sought\n",
      "Word: but, Deprel: cc, Head: rebuffed\n",
      "Word: was, Deprel: aux:pass, Head: rebuffed\n",
      "Word: again, Deprel: advmod, Head: rebuffed\n",
      "Word: rebuffed, Deprel: conj, Head: sought\n",
      "Word: May, Deprel: obl:tmod, Head: rebuffed\n",
      "Word: 19, Deprel: nummod, Head: May\n",
      "Word: at, Deprel: case, Head: conference\n",
      "Word: the, Deprel: det, Head: conference\n",
      "Word: annual, Deprel: amod, Head: conference\n",
      "Word: WHO, Deprel: compound, Head: conference\n",
      "Word: conference, Deprel: obl, Head: rebuffed\n",
      "Word: in, Deprel: case, Head: Geneva\n",
      "Word: Geneva, Deprel: nmod, Head: conference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technology-packed Nasdaq Composite Index IXIC dropped 37.78 points or 1.94 percent to 1,912.36'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-packed, Deprel: amod, Head: IXIC\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: dropped\n",
      "Word: dropped, Deprel: root, Head: ROOT\n",
      "Word: 37.78, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: dropped\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.94, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,912.36\n",
      "Word: 1,912.36, Deprel: obl, Head: dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Nasdaq composite index fell 2.95 or 0.2 percent for the week to 1,912.36 after stumbling 37.78 yesterday'\n",
      "Word: The, Deprel: det, Head: index\n",
      "Word: Nasdaq, Deprel: compound, Head: index\n",
      "Word: composite, Deprel: compound, Head: index\n",
      "Word: index, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 2.95, Deprel: nummod, Head: percent\n",
      "Word: or, Deprel: cc, Head: 0.2\n",
      "Word: 0.2, Deprel: conj, Head: 2.95\n",
      "Word: percent, Deprel: obl:tmod, Head: fell\n",
      "Word: for, Deprel: case, Head: week\n",
      "Word: the, Deprel: det, Head: week\n",
      "Word: week, Deprel: obl, Head: fell\n",
      "Word: to, Deprel: case, Head: 1,912.36\n",
      "Word: 1,912.36, Deprel: obl, Head: fell\n",
      "Word: after, Deprel: mark, Head: stumbling\n",
      "Word: stumbling, Deprel: advcl, Head: fell\n",
      "Word: 37.78, Deprel: nummod, Head: yesterday\n",
      "Word: yesterday, Deprel: obl:tmod, Head: stumbling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of SCO closed at 10.93 down 28 cents in Monday trading on the Nasdaq Stock Market'\n",
      "Word: Shares, Deprel: nsubj, Head: closed\n",
      "Word: of, Deprel: case, Head: SCO\n",
      "Word: SCO, Deprel: nmod, Head: Shares\n",
      "Word: closed, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: 10.93\n",
      "Word: 10.93, Deprel: obl, Head: closed\n",
      "Word: down, Deprel: advmod, Head: closed\n",
      "Word: 28, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl, Head: closed\n",
      "Word: in, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: nmod, Head: cents\n",
      "Word: trading, Deprel: advcl, Head: closed\n",
      "Word: on, Deprel: case, Head: Market\n",
      "Word: the, Deprel: det, Head: Market\n",
      "Word: Nasdaq, Deprel: compound, Head: Market\n",
      "Word: Stock, Deprel: compound, Head: Market\n",
      "Word: Market, Deprel: obl, Head: trading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'IBM shares closed up 1.75 or 2.11 percent at 84.50 on the New York Stock Exchange'\n",
      "Word: IBM, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: closed\n",
      "Word: closed, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: advmod, Head: closed\n",
      "Word: 1.75, Deprel: nummod, Head: percent\n",
      "Word: or, Deprel: cc, Head: 2.11\n",
      "Word: 2.11, Deprel: conj, Head: 1.75\n",
      "Word: percent, Deprel: obl:tmod, Head: closed\n",
      "Word: at, Deprel: case, Head: 84.50\n",
      "Word: 84.50, Deprel: obl, Head: closed\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A Washington County man may have the countys first human case of West Nile virus the health department said Friday'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: Washington, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: man\n",
      "Word: man, Deprel: nsubj, Head: have\n",
      "Word: may, Deprel: aux, Head: have\n",
      "Word: have, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: countys\n",
      "Word: countys, Deprel: nmod:poss, Head: case\n",
      "Word: first, Deprel: amod, Head: case\n",
      "Word: human, Deprel: amod, Head: case\n",
      "Word: case, Deprel: obj, Head: have\n",
      "Word: of, Deprel: case, Head: virus\n",
      "Word: West, Deprel: compound, Head: Nile\n",
      "Word: Nile, Deprel: compound, Head: virus\n",
      "Word: virus, Deprel: nmod, Head: case\n",
      "Word: the, Deprel: det, Head: department\n",
      "Word: health, Deprel: compound, Head: department\n",
      "Word: department, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: case\n",
      "Word: Friday, Deprel: obl:tmod, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The countys first and only human case of West Nile this year was confirmed by health officials on Sept 8'\n",
      "Word: The, Deprel: det, Head: case\n",
      "Word: countys, Deprel: compound, Head: case\n",
      "Word: first, Deprel: amod, Head: case\n",
      "Word: and, Deprel: cc, Head: only\n",
      "Word: only, Deprel: conj, Head: first\n",
      "Word: human, Deprel: amod, Head: case\n",
      "Word: case, Deprel: nsubj:pass, Head: confirmed\n",
      "Word: of, Deprel: case, Head: Nile\n",
      "Word: West, Deprel: compound, Head: Nile\n",
      "Word: Nile, Deprel: nmod, Head: case\n",
      "Word: this, Deprel: det, Head: year\n",
      "Word: year, Deprel: nmod:tmod, Head: case\n",
      "Word: was, Deprel: aux:pass, Head: confirmed\n",
      "Word: confirmed, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: officials\n",
      "Word: health, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: obl, Head: confirmed\n",
      "Word: on, Deprel: case, Head: Sept\n",
      "Word: Sept, Deprel: obl, Head: confirmed\n",
      "Word: 8, Deprel: nummod, Head: Sept\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'National Breast Cancer Centre chief executive Professor Christine Ewan said it was too early to quantify the risk to women'\n",
      "Word: National, Deprel: amod, Head: Centre\n",
      "Word: Breast, Deprel: compound, Head: Cancer\n",
      "Word: Cancer, Deprel: compound, Head: Centre\n",
      "Word: Centre, Deprel: compound, Head: Professor\n",
      "Word: chief, Deprel: compound, Head: executive\n",
      "Word: executive, Deprel: compound, Head: Professor\n",
      "Word: Professor, Deprel: nsubj, Head: said\n",
      "Word: Christine, Deprel: flat, Head: Professor\n",
      "Word: Ewan, Deprel: flat, Head: Professor\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: expl, Head: early\n",
      "Word: was, Deprel: cop, Head: early\n",
      "Word: too, Deprel: advmod, Head: early\n",
      "Word: early, Deprel: ccomp, Head: said\n",
      "Word: to, Deprel: mark, Head: quantify\n",
      "Word: quantify, Deprel: csubj, Head: early\n",
      "Word: the, Deprel: det, Head: risk\n",
      "Word: risk, Deprel: obj, Head: quantify\n",
      "Word: to, Deprel: case, Head: women\n",
      "Word: women, Deprel: nmod, Head: risk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'National Breast Cancer Centre head Professor Christine Ewan said there was no need for panic'\n",
      "Word: National, Deprel: amod, Head: Cancer\n",
      "Word: Breast, Deprel: compound, Head: Cancer\n",
      "Word: Cancer, Deprel: compound, Head: Centre\n",
      "Word: Centre, Deprel: compound, Head: Professor\n",
      "Word: head, Deprel: compound, Head: Professor\n",
      "Word: Professor, Deprel: nsubj, Head: said\n",
      "Word: Christine, Deprel: flat, Head: Professor\n",
      "Word: Ewan, Deprel: flat, Head: Professor\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: there, Deprel: expl, Head: was\n",
      "Word: was, Deprel: ccomp, Head: said\n",
      "Word: no, Deprel: det, Head: need\n",
      "Word: need, Deprel: nsubj, Head: was\n",
      "Word: for, Deprel: case, Head: panic\n",
      "Word: panic, Deprel: nmod, Head: need\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Brendsel and chief financial officer Vaughn Clarke resigned June 9'\n",
      "Word: Brendsel, Deprel: nsubj, Head: resigned\n",
      "Word: and, Deprel: cc, Head: Vaughn\n",
      "Word: chief, Deprel: amod, Head: officer\n",
      "Word: financial, Deprel: amod, Head: officer\n",
      "Word: officer, Deprel: compound, Head: Vaughn\n",
      "Word: Vaughn, Deprel: conj, Head: Brendsel\n",
      "Word: Clarke, Deprel: flat, Head: Vaughn\n",
      "Word: resigned, Deprel: root, Head: ROOT\n",
      "Word: June, Deprel: obl:tmod, Head: resigned\n",
      "Word: 9, Deprel: obl:tmod, Head: resigned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The company s chief executive retired and chief financial officer resigned'\n",
      "Word: The, Deprel: det, Head: company\n",
      "Word: company, Deprel: nmod:poss, Head: executive\n",
      "Word: s, Deprel: case, Head: company\n",
      "Word: chief, Deprel: amod, Head: executive\n",
      "Word: executive, Deprel: nsubj, Head: retired\n",
      "Word: retired, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: officer\n",
      "Word: chief, Deprel: amod, Head: officer\n",
      "Word: financial, Deprel: amod, Head: officer\n",
      "Word: officer, Deprel: nsubj, Head: resigned\n",
      "Word: resigned, Deprel: conj, Head: retired\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On health care the NDP says there will be no privatization and no health-care premiums'\n",
      "Word: On, Deprel: case, Head: care\n",
      "Word: health, Deprel: compound, Head: care\n",
      "Word: care, Deprel: obl, Head: says\n",
      "Word: the, Deprel: det, Head: NDP\n",
      "Word: NDP, Deprel: nsubj, Head: says\n",
      "Word: says, Deprel: root, Head: ROOT\n",
      "Word: there, Deprel: expl, Head: privatization\n",
      "Word: will, Deprel: aux, Head: privatization\n",
      "Word: be, Deprel: cop, Head: privatization\n",
      "Word: no, Deprel: det, Head: privatization\n",
      "Word: privatization, Deprel: ccomp, Head: says\n",
      "Word: and, Deprel: cc, Head: premiums\n",
      "Word: no, Deprel: det, Head: premiums\n",
      "Word: health-care, Deprel: compound, Head: premiums\n",
      "Word: premiums, Deprel: conj, Head: privatization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The New Democrats also renewed their commitment to no health-care privatization and no premiums'\n",
      "Word: The, Deprel: det, Head: Democrats\n",
      "Word: New, Deprel: amod, Head: Democrats\n",
      "Word: Democrats, Deprel: nsubj, Head: renewed\n",
      "Word: also, Deprel: advmod, Head: renewed\n",
      "Word: renewed, Deprel: root, Head: ROOT\n",
      "Word: their, Deprel: nmod:poss, Head: commitment\n",
      "Word: commitment, Deprel: obj, Head: renewed\n",
      "Word: to, Deprel: case, Head: privatization\n",
      "Word: no, Deprel: det, Head: privatization\n",
      "Word: health-care, Deprel: compound, Head: privatization\n",
      "Word: privatization, Deprel: nmod, Head: commitment\n",
      "Word: and, Deprel: cc, Head: premiums\n",
      "Word: no, Deprel: det, Head: premiums\n",
      "Word: premiums, Deprel: conj, Head: privatization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But JT was careful to clarify that it was not certain about the outcome of the discussion at this moment'\n",
      "Word: But, Deprel: cc, Head: careful\n",
      "Word: JT, Deprel: nsubj, Head: careful\n",
      "Word: was, Deprel: cop, Head: careful\n",
      "Word: careful, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: clarify\n",
      "Word: clarify, Deprel: advcl, Head: careful\n",
      "Word: that, Deprel: mark, Head: certain\n",
      "Word: it, Deprel: nsubj, Head: certain\n",
      "Word: was, Deprel: cop, Head: certain\n",
      "Word: not, Deprel: advmod, Head: certain\n",
      "Word: certain, Deprel: ccomp, Head: clarify\n",
      "Word: about, Deprel: case, Head: outcome\n",
      "Word: the, Deprel: det, Head: outcome\n",
      "Word: outcome, Deprel: obl, Head: certain\n",
      "Word: of, Deprel: case, Head: discussion\n",
      "Word: the, Deprel: det, Head: discussion\n",
      "Word: discussion, Deprel: nmod, Head: outcome\n",
      "Word: at, Deprel: case, Head: moment\n",
      "Word: this, Deprel: det, Head: moment\n",
      "Word: moment, Deprel: nmod, Head: discussion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'However we are not certain about the outcome of the discussion at this moment'\n",
      "Word: However, Deprel: advmod, Head: certain\n",
      "Word: we, Deprel: nsubj, Head: certain\n",
      "Word: are, Deprel: cop, Head: certain\n",
      "Word: not, Deprel: advmod, Head: certain\n",
      "Word: certain, Deprel: root, Head: ROOT\n",
      "Word: about, Deprel: case, Head: outcome\n",
      "Word: the, Deprel: det, Head: outcome\n",
      "Word: outcome, Deprel: obl, Head: certain\n",
      "Word: of, Deprel: case, Head: discussion\n",
      "Word: the, Deprel: det, Head: discussion\n",
      "Word: discussion, Deprel: nmod, Head: outcome\n",
      "Word: at, Deprel: case, Head: moment\n",
      "Word: this, Deprel: det, Head: moment\n",
      "Word: moment, Deprel: nmod, Head: discussion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The House voted 425 to 2 to clear the bill the first of 13 that Congress must pass each year to fund the federal government'\n",
      "Word: The, Deprel: det, Head: House\n",
      "Word: House, Deprel: nsubj, Head: voted\n",
      "Word: voted, Deprel: root, Head: ROOT\n",
      "Word: 425, Deprel: obj, Head: voted\n",
      "Word: to, Deprel: case, Head: 2\n",
      "Word: 2, Deprel: nmod, Head: 425\n",
      "Word: to, Deprel: mark, Head: clear\n",
      "Word: clear, Deprel: advcl, Head: voted\n",
      "Word: the, Deprel: det, Head: bill\n",
      "Word: bill, Deprel: obj, Head: clear\n",
      "Word: the, Deprel: det, Head: first\n",
      "Word: first, Deprel: obl:npmod, Head: clear\n",
      "Word: of, Deprel: case, Head: 13\n",
      "Word: 13, Deprel: nmod, Head: first\n",
      "Word: that, Deprel: mark, Head: pass\n",
      "Word: Congress, Deprel: nsubj, Head: pass\n",
      "Word: must, Deprel: aux, Head: pass\n",
      "Word: pass, Deprel: acl, Head: bill\n",
      "Word: each, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: pass\n",
      "Word: to, Deprel: mark, Head: fund\n",
      "Word: fund, Deprel: advcl, Head: pass\n",
      "Word: the, Deprel: det, Head: government\n",
      "Word: federal, Deprel: amod, Head: government\n",
      "Word: government, Deprel: obj, Head: fund\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The bill is among the first of 13 that Congress must pass each year to fund the federal government'\n",
      "Word: The, Deprel: det, Head: bill\n",
      "Word: bill, Deprel: nsubj, Head: first\n",
      "Word: is, Deprel: cop, Head: first\n",
      "Word: among, Deprel: case, Head: first\n",
      "Word: the, Deprel: det, Head: first\n",
      "Word: first, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: 13\n",
      "Word: 13, Deprel: nmod, Head: first\n",
      "Word: that, Deprel: obj, Head: pass\n",
      "Word: Congress, Deprel: nsubj, Head: pass\n",
      "Word: must, Deprel: aux, Head: pass\n",
      "Word: pass, Deprel: acl:relcl, Head: first\n",
      "Word: each, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: pass\n",
      "Word: to, Deprel: mark, Head: fund\n",
      "Word: fund, Deprel: advcl, Head: pass\n",
      "Word: the, Deprel: det, Head: government\n",
      "Word: federal, Deprel: amod, Head: government\n",
      "Word: government, Deprel: obj, Head: fund\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Knight agreed to a two-year 2.38 million contract that included a 300,000 signing bonus'\n",
      "Word: Knight, Deprel: nsubj, Head: agreed\n",
      "Word: agreed, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: contract\n",
      "Word: a, Deprel: det, Head: contract\n",
      "Word: two-year, Deprel: amod, Head: contract\n",
      "Word: 2.38, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: contract\n",
      "Word: contract, Deprel: obl, Head: agreed\n",
      "Word: that, Deprel: nsubj, Head: included\n",
      "Word: included, Deprel: acl:relcl, Head: contract\n",
      "Word: a, Deprel: det, Head: bonus\n",
      "Word: 300,000, Deprel: nummod, Head: bonus\n",
      "Word: signing, Deprel: compound, Head: bonus\n",
      "Word: bonus, Deprel: obj, Head: included\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'ESPN reported that Knight s two-year deal is worth 2.38 million including a 300,000 signing bonus'\n",
      "Word: ESPN, Deprel: nsubj, Head: reported\n",
      "Word: reported, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: worth\n",
      "Word: Knight, Deprel: nmod:poss, Head: deal\n",
      "Word: s, Deprel: case, Head: Knight\n",
      "Word: two-year, Deprel: amod, Head: deal\n",
      "Word: deal, Deprel: nsubj, Head: worth\n",
      "Word: is, Deprel: cop, Head: worth\n",
      "Word: worth, Deprel: ccomp, Head: reported\n",
      "Word: 2.38, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: worth\n",
      "Word: including, Deprel: case, Head: bonus\n",
      "Word: a, Deprel: det, Head: bonus\n",
      "Word: 300,000, Deprel: nummod, Head: bonus\n",
      "Word: signing, Deprel: compound, Head: bonus\n",
      "Word: bonus, Deprel: obl, Head: worth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Against the Japanese currency the euro was at 135.92/6.04 yen against the late New York level of 136.03/14'\n",
      "Word: Against, Deprel: case, Head: currency\n",
      "Word: the, Deprel: det, Head: currency\n",
      "Word: Japanese, Deprel: amod, Head: currency\n",
      "Word: currency, Deprel: obl, Head: yen\n",
      "Word: the, Deprel: det, Head: euro\n",
      "Word: euro, Deprel: nsubj, Head: yen\n",
      "Word: was, Deprel: cop, Head: yen\n",
      "Word: at, Deprel: case, Head: yen\n",
      "Word: 135.92/6.04, Deprel: nummod, Head: yen\n",
      "Word: yen, Deprel: root, Head: ROOT\n",
      "Word: against, Deprel: case, Head: level\n",
      "Word: the, Deprel: det, Head: level\n",
      "Word: late, Deprel: amod, Head: level\n",
      "Word: New, Deprel: compound, Head: level\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: level, Deprel: nmod, Head: yen\n",
      "Word: of, Deprel: case, Head: 136.03/14\n",
      "Word: 136.03/14, Deprel: nmod, Head: level\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The dollar was at 117.85 yen against the Japanese currency up 0.1 percent'\n",
      "Word: The, Deprel: det, Head: dollar\n",
      "Word: dollar, Deprel: nsubj, Head: yen\n",
      "Word: was, Deprel: cop, Head: yen\n",
      "Word: at, Deprel: case, Head: yen\n",
      "Word: 117.85, Deprel: nummod, Head: yen\n",
      "Word: yen, Deprel: root, Head: ROOT\n",
      "Word: against, Deprel: case, Head: currency\n",
      "Word: the, Deprel: det, Head: currency\n",
      "Word: Japanese, Deprel: amod, Head: currency\n",
      "Word: currency, Deprel: nmod, Head: yen\n",
      "Word: up, Deprel: case, Head: percent\n",
      "Word: 0.1, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: yen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The procedure is generally performed in the second or third trimester'\n",
      "Word: The, Deprel: det, Head: procedure\n",
      "Word: procedure, Deprel: nsubj:pass, Head: performed\n",
      "Word: is, Deprel: aux:pass, Head: performed\n",
      "Word: generally, Deprel: advmod, Head: performed\n",
      "Word: performed, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: trimester\n",
      "Word: the, Deprel: det, Head: trimester\n",
      "Word: second, Deprel: amod, Head: trimester\n",
      "Word: or, Deprel: cc, Head: third\n",
      "Word: third, Deprel: conj, Head: second\n",
      "Word: trimester, Deprel: obl, Head: performed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technique is used during the second and occasionally third trimester of pregnancy'\n",
      "Word: The, Deprel: det, Head: technique\n",
      "Word: technique, Deprel: nsubj:pass, Head: used\n",
      "Word: is, Deprel: aux:pass, Head: used\n",
      "Word: used, Deprel: root, Head: ROOT\n",
      "Word: during, Deprel: case, Head: trimester\n",
      "Word: the, Deprel: det, Head: trimester\n",
      "Word: second, Deprel: amod, Head: trimester\n",
      "Word: and, Deprel: cc, Head: third\n",
      "Word: occasionally, Deprel: advmod, Head: third\n",
      "Word: third, Deprel: conj, Head: second\n",
      "Word: trimester, Deprel: obl, Head: used\n",
      "Word: of, Deprel: case, Head: pregnancy\n",
      "Word: pregnancy, Deprel: nmod, Head: trimester\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new companies will begin trading on Nasdaq today under the ticker symbols PLMO and PSRC'\n",
      "Word: The, Deprel: det, Head: companies\n",
      "Word: new, Deprel: amod, Head: companies\n",
      "Word: companies, Deprel: nsubj, Head: begin\n",
      "Word: will, Deprel: aux, Head: begin\n",
      "Word: begin, Deprel: root, Head: ROOT\n",
      "Word: trading, Deprel: xcomp, Head: begin\n",
      "Word: on, Deprel: case, Head: Nasdaq\n",
      "Word: Nasdaq, Deprel: obl, Head: trading\n",
      "Word: today, Deprel: obl:tmod, Head: begin\n",
      "Word: under, Deprel: case, Head: symbols\n",
      "Word: the, Deprel: det, Head: symbols\n",
      "Word: ticker, Deprel: compound, Head: symbols\n",
      "Word: symbols, Deprel: obl, Head: begin\n",
      "Word: PLMO, Deprel: appos, Head: symbols\n",
      "Word: and, Deprel: cc, Head: PSRC\n",
      "Word: PSRC, Deprel: conj, Head: PLMO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Also as part of the deal PalmSource stock will begin trading on the NASDAQ stock market Wednesday under the ticker symbol PSRC'\n",
      "Word: Also, Deprel: advmod, Head: begin\n",
      "Word: as, Deprel: case, Head: part\n",
      "Word: part, Deprel: obl, Head: begin\n",
      "Word: of, Deprel: case, Head: deal\n",
      "Word: the, Deprel: det, Head: stock\n",
      "Word: deal, Deprel: compound, Head: stock\n",
      "Word: PalmSource, Deprel: compound, Head: stock\n",
      "Word: stock, Deprel: nsubj, Head: begin\n",
      "Word: will, Deprel: aux, Head: begin\n",
      "Word: begin, Deprel: root, Head: ROOT\n",
      "Word: trading, Deprel: xcomp, Head: begin\n",
      "Word: on, Deprel: case, Head: market\n",
      "Word: the, Deprel: det, Head: market\n",
      "Word: NASDAQ, Deprel: compound, Head: market\n",
      "Word: stock, Deprel: compound, Head: market\n",
      "Word: market, Deprel: obl, Head: trading\n",
      "Word: Wednesday, Deprel: obl:tmod, Head: begin\n",
      "Word: under, Deprel: case, Head: symbol\n",
      "Word: the, Deprel: det, Head: symbol\n",
      "Word: ticker, Deprel: compound, Head: symbol\n",
      "Word: symbol, Deprel: obl, Head: begin\n",
      "Word: PSRC, Deprel: appos, Head: symbol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Kids adults booksellers and postal workers all are preparing for Harry Potter and the Order of the Phoenix'\n",
      "Word: Kids, Deprel: compound, Head: adults\n",
      "Word: adults, Deprel: compound, Head: booksellers\n",
      "Word: booksellers, Deprel: nsubj, Head: preparing\n",
      "Word: and, Deprel: cc, Head: workers\n",
      "Word: postal, Deprel: amod, Head: workers\n",
      "Word: workers, Deprel: conj, Head: booksellers\n",
      "Word: all, Deprel: det, Head: booksellers\n",
      "Word: are, Deprel: aux, Head: preparing\n",
      "Word: preparing, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: Harry\n",
      "Word: Harry, Deprel: obl, Head: preparing\n",
      "Word: Potter, Deprel: flat, Head: Harry\n",
      "Word: and, Deprel: cc, Head: Order\n",
      "Word: the, Deprel: det, Head: Order\n",
      "Word: Order, Deprel: conj, Head: Harry\n",
      "Word: of, Deprel: case, Head: Phoenix\n",
      "Word: the, Deprel: det, Head: Phoenix\n",
      "Word: Phoenix, Deprel: nmod, Head: Order\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The crates are full of hardback copies of Harry Potter and the Order of the Phoenix'\n",
      "Word: The, Deprel: det, Head: crates\n",
      "Word: crates, Deprel: nsubj, Head: full\n",
      "Word: are, Deprel: cop, Head: full\n",
      "Word: full, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: copies\n",
      "Word: hardback, Deprel: compound, Head: copies\n",
      "Word: copies, Deprel: obl, Head: full\n",
      "Word: of, Deprel: case, Head: Harry\n",
      "Word: Harry, Deprel: nmod, Head: copies\n",
      "Word: Potter, Deprel: flat, Head: Harry\n",
      "Word: and, Deprel: cc, Head: Order\n",
      "Word: the, Deprel: det, Head: Order\n",
      "Word: Order, Deprel: conj, Head: Harry\n",
      "Word: of, Deprel: case, Head: Phoenix\n",
      "Word: the, Deprel: det, Head: Phoenix\n",
      "Word: Phoenix, Deprel: nmod, Head: Order\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Besides Hampton and Newport News the grant funds water testing in Yorktown King George County Norfolk and Virginia Beach'\n",
      "Word: Besides, Deprel: case, Head: Hampton\n",
      "Word: Hampton, Deprel: obl, Head: funds\n",
      "Word: and, Deprel: cc, Head: Newport\n",
      "Word: Newport, Deprel: conj, Head: Hampton\n",
      "Word: News, Deprel: conj, Head: Hampton\n",
      "Word: the, Deprel: det, Head: grant\n",
      "Word: grant, Deprel: nsubj, Head: funds\n",
      "Word: funds, Deprel: root, Head: ROOT\n",
      "Word: water, Deprel: compound, Head: testing\n",
      "Word: testing, Deprel: obj, Head: funds\n",
      "Word: in, Deprel: case, Head: County\n",
      "Word: Yorktown, Deprel: compound, Head: County\n",
      "Word: King, Deprel: compound, Head: County\n",
      "Word: George, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: Norfolk\n",
      "Word: Norfolk, Deprel: nmod, Head: testing\n",
      "Word: and, Deprel: cc, Head: Beach\n",
      "Word: Virginia, Deprel: compound, Head: Beach\n",
      "Word: Beach, Deprel: conj, Head: Norfolk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The grant also funds beach testing in King George County Norfolk and Virginia Beach'\n",
      "Word: The, Deprel: det, Head: grant\n",
      "Word: grant, Deprel: nsubj, Head: funds\n",
      "Word: also, Deprel: advmod, Head: funds\n",
      "Word: funds, Deprel: root, Head: ROOT\n",
      "Word: beach, Deprel: compound, Head: testing\n",
      "Word: testing, Deprel: obj, Head: funds\n",
      "Word: in, Deprel: case, Head: Norfolk\n",
      "Word: King, Deprel: compound, Head: County\n",
      "Word: George, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: Norfolk\n",
      "Word: Norfolk, Deprel: nmod, Head: testing\n",
      "Word: and, Deprel: cc, Head: Beach\n",
      "Word: Virginia, Deprel: compound, Head: Beach\n",
      "Word: Beach, Deprel: conj, Head: Norfolk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of Halliburton fell 71 cents or 3 percent to close at 21.59 yesterday on the New York Stock Exchange'\n",
      "Word: Shares, Deprel: nsubj, Head: fell\n",
      "Word: of, Deprel: case, Head: Halliburton\n",
      "Word: Halliburton, Deprel: nmod, Head: Shares\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 71, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: fell\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 3, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: cents\n",
      "Word: to, Deprel: case, Head: close\n",
      "Word: close, Deprel: obl, Head: fell\n",
      "Word: at, Deprel: case, Head: 21.59\n",
      "Word: 21.59, Deprel: obl, Head: fell\n",
      "Word: yesterday, Deprel: obl:tmod, Head: fell\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: compound, Head: Exchange\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Halliburton shares fell 54 cents or 2.4 percent to 21.76 a share in midday New York Stock Exchange trade'\n",
      "Word: Halliburton, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 54, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: fell\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 2.4, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: cents\n",
      "Word: to, Deprel: case, Head: 21.76\n",
      "Word: 21.76, Deprel: obl, Head: fell\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: obl, Head: fell\n",
      "Word: in, Deprel: case, Head: trade\n",
      "Word: midday, Deprel: compound, Head: trade\n",
      "Word: New, Deprel: amod, Head: York\n",
      "Word: York, Deprel: compound, Head: Exchange\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: compound, Head: trade\n",
      "Word: trade, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He said the attackers left behind leaflets urging staff at the Ishtar Sheraton to stop working at the hotel and demanding U.S forces leave Iraq'\n",
      "Word: He, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: attackers\n",
      "Word: attackers, Deprel: nsubj, Head: left\n",
      "Word: left, Deprel: ccomp, Head: said\n",
      "Word: behind, Deprel: case, Head: leaflets\n",
      "Word: leaflets, Deprel: obl, Head: left\n",
      "Word: urging, Deprel: acl, Head: leaflets\n",
      "Word: staff, Deprel: iobj, Head: urging\n",
      "Word: at, Deprel: case, Head: Sheraton\n",
      "Word: the, Deprel: det, Head: Sheraton\n",
      "Word: Ishtar, Deprel: compound, Head: Sheraton\n",
      "Word: Sheraton, Deprel: obl, Head: urging\n",
      "Word: to, Deprel: mark, Head: stop\n",
      "Word: stop, Deprel: xcomp, Head: urging\n",
      "Word: working, Deprel: xcomp, Head: stop\n",
      "Word: at, Deprel: case, Head: hotel\n",
      "Word: the, Deprel: det, Head: hotel\n",
      "Word: hotel, Deprel: obl, Head: working\n",
      "Word: and, Deprel: cc, Head: demanding\n",
      "Word: demanding, Deprel: conj, Head: working\n",
      "Word: U.S, Deprel: compound, Head: forces\n",
      "Word: forces, Deprel: nsubj, Head: leave\n",
      "Word: leave, Deprel: ccomp, Head: demanding\n",
      "Word: Iraq, Deprel: obj, Head: leave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He said the attackers left behind leaflets urging workers at the Ishtar Sheraton to stop working at the hotel'\n",
      "Word: He, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: attackers\n",
      "Word: attackers, Deprel: nsubj, Head: left\n",
      "Word: left, Deprel: ccomp, Head: said\n",
      "Word: behind, Deprel: case, Head: leaflets\n",
      "Word: leaflets, Deprel: obl, Head: left\n",
      "Word: urging, Deprel: acl, Head: leaflets\n",
      "Word: workers, Deprel: iobj, Head: urging\n",
      "Word: at, Deprel: case, Head: Sheraton\n",
      "Word: the, Deprel: det, Head: Sheraton\n",
      "Word: Ishtar, Deprel: compound, Head: Sheraton\n",
      "Word: Sheraton, Deprel: obl, Head: urging\n",
      "Word: to, Deprel: mark, Head: stop\n",
      "Word: stop, Deprel: xcomp, Head: urging\n",
      "Word: working, Deprel: xcomp, Head: stop\n",
      "Word: at, Deprel: case, Head: hotel\n",
      "Word: the, Deprel: det, Head: hotel\n",
      "Word: hotel, Deprel: obl, Head: working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'With diplomacy heating up in the nearly 10-month-old nuclear crisis Chinese Foreign Minister Li Zhaoxing is slated to visit South Korea from August 13 to 15'\n",
      "Word: With, Deprel: mark, Head: heating\n",
      "Word: diplomacy, Deprel: obl, Head: slated\n",
      "Word: heating, Deprel: advcl, Head: slated\n",
      "Word: up, Deprel: compound:prt, Head: heating\n",
      "Word: in, Deprel: case, Head: crisis\n",
      "Word: the, Deprel: det, Head: crisis\n",
      "Word: nearly, Deprel: advmod, Head: 10-month-old\n",
      "Word: 10-month-old, Deprel: amod, Head: crisis\n",
      "Word: nuclear, Deprel: amod, Head: crisis\n",
      "Word: crisis, Deprel: obl, Head: heating\n",
      "Word: Chinese, Deprel: amod, Head: Minister\n",
      "Word: Foreign, Deprel: amod, Head: Minister\n",
      "Word: Minister, Deprel: nsubj:pass, Head: slated\n",
      "Word: Li, Deprel: flat, Head: Minister\n",
      "Word: Zhaoxing, Deprel: flat, Head: Minister\n",
      "Word: is, Deprel: aux:pass, Head: slated\n",
      "Word: slated, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: visit\n",
      "Word: visit, Deprel: xcomp, Head: slated\n",
      "Word: South, Deprel: compound, Head: Korea\n",
      "Word: Korea, Deprel: obj, Head: visit\n",
      "Word: from, Deprel: case, Head: 13\n",
      "Word: August, Deprel: compound, Head: 13\n",
      "Word: 13, Deprel: obl, Head: visit\n",
      "Word: to, Deprel: case, Head: 15\n",
      "Word: 15, Deprel: obl, Head: visit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'With diplomacy heating up in the nearly 10-month-old crisis Chinese Foreign Minister Li Zhaoxing flies to Japan on Sunday en route to South Korea on August 13'\n",
      "Word: With, Deprel: mark, Head: heating\n",
      "Word: diplomacy, Deprel: obl, Head: flies\n",
      "Word: heating, Deprel: acl, Head: diplomacy\n",
      "Word: up, Deprel: compound:prt, Head: heating\n",
      "Word: in, Deprel: case, Head: crisis\n",
      "Word: the, Deprel: det, Head: crisis\n",
      "Word: nearly, Deprel: advmod, Head: 10-month-old\n",
      "Word: 10-month-old, Deprel: amod, Head: crisis\n",
      "Word: crisis, Deprel: obl, Head: heating\n",
      "Word: Chinese, Deprel: amod, Head: Minister\n",
      "Word: Foreign, Deprel: amod, Head: Minister\n",
      "Word: Minister, Deprel: nsubj, Head: flies\n",
      "Word: Li, Deprel: flat, Head: Minister\n",
      "Word: Zhaoxing, Deprel: flat, Head: Minister\n",
      "Word: flies, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Japan\n",
      "Word: Japan, Deprel: obl, Head: flies\n",
      "Word: on, Deprel: case, Head: Sunday\n",
      "Word: Sunday, Deprel: obl, Head: flies\n",
      "Word: en, Deprel: case, Head: route\n",
      "Word: route, Deprel: obl, Head: flies\n",
      "Word: to, Deprel: case, Head: Korea\n",
      "Word: South, Deprel: compound, Head: Korea\n",
      "Word: Korea, Deprel: nmod, Head: route\n",
      "Word: on, Deprel: case, Head: 13\n",
      "Word: August, Deprel: compound, Head: 13\n",
      "Word: 13, Deprel: obl, Head: flies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Tail wagging Abbey trotted on stage with Conway before a crowd of more than 10,000 attendees at PeopleSoft s annual customer conference at the Anaheim Convention Center'\n",
      "Word: Tail, Deprel: compound, Head: wagging\n",
      "Word: wagging, Deprel: compound, Head: Abbey\n",
      "Word: Abbey, Deprel: nsubj, Head: trotted\n",
      "Word: trotted, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: stage\n",
      "Word: stage, Deprel: obl, Head: trotted\n",
      "Word: with, Deprel: case, Head: Conway\n",
      "Word: Conway, Deprel: obl, Head: trotted\n",
      "Word: before, Deprel: case, Head: crowd\n",
      "Word: a, Deprel: det, Head: crowd\n",
      "Word: crowd, Deprel: obl, Head: trotted\n",
      "Word: of, Deprel: case, Head: attendees\n",
      "Word: more, Deprel: advmod, Head: 10,000\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 10,000, Deprel: nummod, Head: attendees\n",
      "Word: attendees, Deprel: nmod, Head: crowd\n",
      "Word: at, Deprel: case, Head: conference\n",
      "Word: PeopleSoft, Deprel: nmod:poss, Head: conference\n",
      "Word: s, Deprel: case, Head: PeopleSoft\n",
      "Word: annual, Deprel: amod, Head: conference\n",
      "Word: customer, Deprel: compound, Head: conference\n",
      "Word: conference, Deprel: nmod, Head: attendees\n",
      "Word: at, Deprel: case, Head: Center\n",
      "Word: the, Deprel: det, Head: Center\n",
      "Word: Anaheim, Deprel: compound, Head: Center\n",
      "Word: Convention, Deprel: compound, Head: Center\n",
      "Word: Center, Deprel: nmod, Head: conference\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Monday Abbey trotted on stage tail wagging with Conway before a crowd of 10,000 attendees at PeopleSoft s annual customer conference'\n",
      "Word: On, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: trotted\n",
      "Word: Abbey, Deprel: nsubj, Head: trotted\n",
      "Word: trotted, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: tail\n",
      "Word: stage, Deprel: compound, Head: tail\n",
      "Word: tail, Deprel: obl, Head: trotted\n",
      "Word: wagging, Deprel: advcl, Head: trotted\n",
      "Word: with, Deprel: case, Head: Conway\n",
      "Word: Conway, Deprel: obl, Head: wagging\n",
      "Word: before, Deprel: case, Head: crowd\n",
      "Word: a, Deprel: det, Head: crowd\n",
      "Word: crowd, Deprel: obl, Head: wagging\n",
      "Word: of, Deprel: case, Head: attendees\n",
      "Word: 10,000, Deprel: nummod, Head: attendees\n",
      "Word: attendees, Deprel: nmod, Head: crowd\n",
      "Word: at, Deprel: case, Head: conference\n",
      "Word: PeopleSoft, Deprel: nmod:poss, Head: conference\n",
      "Word: s, Deprel: case, Head: PeopleSoft\n",
      "Word: annual, Deprel: amod, Head: conference\n",
      "Word: customer, Deprel: compound, Head: conference\n",
      "Word: conference, Deprel: nmod, Head: attendees\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bond bulls would like the Fed to recognize that risks are biased toward economic weakness'\n",
      "Word: Bond, Deprel: compound, Head: bulls\n",
      "Word: bulls, Deprel: nsubj, Head: like\n",
      "Word: would, Deprel: aux, Head: like\n",
      "Word: like, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: Fed\n",
      "Word: Fed, Deprel: obj, Head: like\n",
      "Word: to, Deprel: mark, Head: recognize\n",
      "Word: recognize, Deprel: xcomp, Head: like\n",
      "Word: that, Deprel: mark, Head: biased\n",
      "Word: risks, Deprel: nsubj, Head: biased\n",
      "Word: are, Deprel: cop, Head: biased\n",
      "Word: biased, Deprel: ccomp, Head: recognize\n",
      "Word: toward, Deprel: case, Head: weakness\n",
      "Word: economic, Deprel: amod, Head: weakness\n",
      "Word: weakness, Deprel: obl, Head: biased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Fed also said the risks to the economy were biased toward weakness'\n",
      "Word: The, Deprel: det, Head: Fed\n",
      "Word: Fed, Deprel: nsubj, Head: said\n",
      "Word: also, Deprel: advmod, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: risks\n",
      "Word: risks, Deprel: nsubj, Head: biased\n",
      "Word: to, Deprel: case, Head: economy\n",
      "Word: the, Deprel: det, Head: economy\n",
      "Word: economy, Deprel: nmod, Head: risks\n",
      "Word: were, Deprel: cop, Head: biased\n",
      "Word: biased, Deprel: ccomp, Head: said\n",
      "Word: toward, Deprel: case, Head: weakness\n",
      "Word: weakness, Deprel: obl, Head: biased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'There is the real potential for a secondary collapse Gov James McGreevey said'\n",
      "Word: There, Deprel: expl, Head: is\n",
      "Word: is, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: potential\n",
      "Word: real, Deprel: amod, Head: potential\n",
      "Word: potential, Deprel: nsubj, Head: is\n",
      "Word: for, Deprel: case, Head: collapse\n",
      "Word: a, Deprel: det, Head: collapse\n",
      "Word: secondary, Deprel: amod, Head: collapse\n",
      "Word: collapse, Deprel: nmod, Head: potential\n",
      "Word: Gov, Deprel: nsubj, Head: said\n",
      "Word: James, Deprel: flat, Head: Gov\n",
      "Word: McGreevey, Deprel: flat, Head: Gov\n",
      "Word: said, Deprel: acl:relcl, Head: collapse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The damaged area of the garage was not stable with the real potential for a secondary collapse McGreevey said'\n",
      "Word: The, Deprel: det, Head: area\n",
      "Word: damaged, Deprel: amod, Head: area\n",
      "Word: area, Deprel: nsubj, Head: stable\n",
      "Word: of, Deprel: case, Head: garage\n",
      "Word: the, Deprel: det, Head: garage\n",
      "Word: garage, Deprel: nmod, Head: area\n",
      "Word: was, Deprel: cop, Head: stable\n",
      "Word: not, Deprel: advmod, Head: stable\n",
      "Word: stable, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: potential\n",
      "Word: the, Deprel: det, Head: potential\n",
      "Word: real, Deprel: amod, Head: potential\n",
      "Word: potential, Deprel: obl, Head: stable\n",
      "Word: for, Deprel: case, Head: collapse\n",
      "Word: a, Deprel: det, Head: collapse\n",
      "Word: secondary, Deprel: amod, Head: collapse\n",
      "Word: collapse, Deprel: nmod, Head: potential\n",
      "Word: McGreevey, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: collapse\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'At midnight on Wednesday 68 percent of voters said no to the tax with 97 percent of the votes counted'\n",
      "Word: At, Deprel: case, Head: midnight\n",
      "Word: midnight, Deprel: obl, Head: said\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: nmod, Head: midnight\n",
      "Word: 68, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: nsubj, Head: said\n",
      "Word: of, Deprel: case, Head: voters\n",
      "Word: voters, Deprel: nmod, Head: percent\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: no, Deprel: obj, Head: said\n",
      "Word: to, Deprel: case, Head: tax\n",
      "Word: the, Deprel: det, Head: tax\n",
      "Word: tax, Deprel: nmod, Head: no\n",
      "Word: with, Deprel: case, Head: percent\n",
      "Word: 97, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: said\n",
      "Word: of, Deprel: case, Head: votes\n",
      "Word: the, Deprel: det, Head: votes\n",
      "Word: votes, Deprel: nmod, Head: percent\n",
      "Word: counted, Deprel: acl, Head: votes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'With 97 percent of precincts counted tonight 68 percent of voters opposed the tax'\n",
      "Word: With, Deprel: case, Head: percent\n",
      "Word: 97, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: nsubj, Head: counted\n",
      "Word: of, Deprel: case, Head: precincts\n",
      "Word: precincts, Deprel: nmod, Head: percent\n",
      "Word: counted, Deprel: advcl, Head: opposed\n",
      "Word: tonight, Deprel: obl:tmod, Head: counted\n",
      "Word: 68, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: nsubj, Head: opposed\n",
      "Word: of, Deprel: case, Head: voters\n",
      "Word: voters, Deprel: nmod, Head: percent\n",
      "Word: opposed, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: tax\n",
      "Word: tax, Deprel: obj, Head: opposed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The government did not identify the taikonauts — a term coined from ‘ ‘ taikong ’ ’ the Chinese word for space — who would travel on the second mission'\n",
      "Word: The, Deprel: det, Head: government\n",
      "Word: government, Deprel: nsubj, Head: identify\n",
      "Word: did, Deprel: aux, Head: identify\n",
      "Word: not, Deprel: advmod, Head: identify\n",
      "Word: identify, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: taikonauts\n",
      "Word: taikonauts, Deprel: obj, Head: identify\n",
      "Word: —, Deprel: punct, Head: term\n",
      "Word: a, Deprel: det, Head: term\n",
      "Word: term, Deprel: appos, Head: taikonauts\n",
      "Word: coined, Deprel: acl, Head: term\n",
      "Word: from, Deprel: case, Head: taikong\n",
      "Word: ‘, Deprel: punct, Head: from\n",
      "Word: ‘, Deprel: punct, Head: taikong\n",
      "Word: taikong, Deprel: obl, Head: coined\n",
      "Word: ’, Deprel: punct, Head: taikong\n",
      "Word: ’, Deprel: punct, Head: taikong\n",
      "Word: the, Deprel: det, Head: word\n",
      "Word: Chinese, Deprel: amod, Head: word\n",
      "Word: word, Deprel: obl, Head: coined\n",
      "Word: for, Deprel: case, Head: space\n",
      "Word: space, Deprel: nmod, Head: word\n",
      "Word: —, Deprel: punct, Head: travel\n",
      "Word: who, Deprel: nsubj, Head: travel\n",
      "Word: would, Deprel: aux, Head: travel\n",
      "Word: travel, Deprel: acl:relcl, Head: word\n",
      "Word: on, Deprel: case, Head: mission\n",
      "Word: the, Deprel: det, Head: mission\n",
      "Word: second, Deprel: amod, Head: mission\n",
      "Word: mission, Deprel: obl, Head: travel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The government did not identify the taikonauts a term coined from taikong the Chinese word for space'\n",
      "Word: The, Deprel: det, Head: government\n",
      "Word: government, Deprel: nsubj, Head: identify\n",
      "Word: did, Deprel: aux, Head: identify\n",
      "Word: not, Deprel: advmod, Head: identify\n",
      "Word: identify, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: taikonauts\n",
      "Word: taikonauts, Deprel: obj, Head: identify\n",
      "Word: a, Deprel: det, Head: term\n",
      "Word: term, Deprel: obj, Head: identify\n",
      "Word: coined, Deprel: acl, Head: term\n",
      "Word: from, Deprel: case, Head: taikong\n",
      "Word: taikong, Deprel: obl, Head: coined\n",
      "Word: the, Deprel: det, Head: word\n",
      "Word: Chinese, Deprel: amod, Head: word\n",
      "Word: word, Deprel: obl, Head: coined\n",
      "Word: for, Deprel: case, Head: space\n",
      "Word: space, Deprel: nmod, Head: word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'No 2 HP saw its Unix server sales dropped 3.6 percent to 1.36 billion'\n",
      "Word: No, Deprel: det, Head: HP\n",
      "Word: 2, Deprel: nummod, Head: HP\n",
      "Word: HP, Deprel: nsubj, Head: saw\n",
      "Word: saw, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: sales\n",
      "Word: Unix, Deprel: compound, Head: server\n",
      "Word: server, Deprel: compound, Head: sales\n",
      "Word: sales, Deprel: nsubj, Head: dropped\n",
      "Word: dropped, Deprel: ccomp, Head: saw\n",
      "Word: 3.6, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: dropped\n",
      "Word: to, Deprel: case, Head: billion\n",
      "Word: 1.36, Deprel: nummod, Head: billion\n",
      "Word: billion, Deprel: obl, Head: dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'HP fell to second place with server sales growing 0.4 percent to 2.9 billion'\n",
      "Word: HP, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: place\n",
      "Word: second, Deprel: amod, Head: place\n",
      "Word: place, Deprel: obl, Head: fell\n",
      "Word: with, Deprel: mark, Head: growing\n",
      "Word: server, Deprel: compound, Head: sales\n",
      "Word: sales, Deprel: nsubj, Head: growing\n",
      "Word: growing, Deprel: advcl, Head: fell\n",
      "Word: 0.4, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:npmod, Head: growing\n",
      "Word: to, Deprel: case, Head: billion\n",
      "Word: 2.9, Deprel: nummod, Head: billion\n",
      "Word: billion, Deprel: obl, Head: growing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Graham is expected to be nominated and elected to a second one-year term today and will deliver the presidential address'\n",
      "Word: Graham, Deprel: nsubj:pass, Head: expected\n",
      "Word: is, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: nominated\n",
      "Word: be, Deprel: aux:pass, Head: nominated\n",
      "Word: nominated, Deprel: xcomp, Head: expected\n",
      "Word: and, Deprel: cc, Head: elected\n",
      "Word: elected, Deprel: conj, Head: nominated\n",
      "Word: to, Deprel: case, Head: term\n",
      "Word: a, Deprel: det, Head: term\n",
      "Word: second, Deprel: amod, Head: term\n",
      "Word: one-year, Deprel: amod, Head: term\n",
      "Word: term, Deprel: obl, Head: elected\n",
      "Word: today, Deprel: obl:tmod, Head: elected\n",
      "Word: and, Deprel: cc, Head: deliver\n",
      "Word: will, Deprel: aux, Head: deliver\n",
      "Word: deliver, Deprel: conj, Head: expected\n",
      "Word: the, Deprel: det, Head: address\n",
      "Word: presidential, Deprel: amod, Head: address\n",
      "Word: address, Deprel: obj, Head: deliver\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Later Tuesday Graham was expected to be re-elected for a second one-year term'\n",
      "Word: Later, Deprel: advmod, Head: Tuesday\n",
      "Word: Tuesday, Deprel: obl:tmod, Head: expected\n",
      "Word: Graham, Deprel: nsubj:pass, Head: expected\n",
      "Word: was, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: re-elected\n",
      "Word: be, Deprel: aux:pass, Head: re-elected\n",
      "Word: re-elected, Deprel: xcomp, Head: expected\n",
      "Word: for, Deprel: case, Head: term\n",
      "Word: a, Deprel: det, Head: term\n",
      "Word: second, Deprel: amod, Head: term\n",
      "Word: one-year, Deprel: amod, Head: term\n",
      "Word: term, Deprel: obl, Head: re-elected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'These changes may affect a large number of existing Web pages the statement continued'\n",
      "Word: These, Deprel: det, Head: changes\n",
      "Word: changes, Deprel: nsubj, Head: affect\n",
      "Word: may, Deprel: aux, Head: affect\n",
      "Word: affect, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: number\n",
      "Word: large, Deprel: amod, Head: number\n",
      "Word: number, Deprel: obj, Head: affect\n",
      "Word: of, Deprel: case, Head: pages\n",
      "Word: existing, Deprel: amod, Head: pages\n",
      "Word: Web, Deprel: compound, Head: pages\n",
      "Word: pages, Deprel: nmod, Head: number\n",
      "Word: the, Deprel: det, Head: statement\n",
      "Word: statement, Deprel: nsubj, Head: continued\n",
      "Word: continued, Deprel: acl:relcl, Head: pages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Still changes to IE may affect a large number of existing Web pages according to the W3C s notice'\n",
      "Word: Still, Deprel: advmod, Head: affect\n",
      "Word: changes, Deprel: nsubj, Head: affect\n",
      "Word: to, Deprel: case, Head: IE\n",
      "Word: IE, Deprel: nmod, Head: changes\n",
      "Word: may, Deprel: aux, Head: affect\n",
      "Word: affect, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: number\n",
      "Word: large, Deprel: amod, Head: number\n",
      "Word: number, Deprel: obj, Head: affect\n",
      "Word: of, Deprel: case, Head: pages\n",
      "Word: existing, Deprel: amod, Head: pages\n",
      "Word: Web, Deprel: compound, Head: pages\n",
      "Word: pages, Deprel: nmod, Head: number\n",
      "Word: according, Deprel: case, Head: notice\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: the, Deprel: det, Head: W3C\n",
      "Word: W3C, Deprel: nmod:poss, Head: notice\n",
      "Word: s, Deprel: case, Head: W3C\n",
      "Word: notice, Deprel: obl, Head: affect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'People are obviously inconvenienced said Dr Jim Young Ontario s commissioner of public safety'\n",
      "Word: People, Deprel: nsubj, Head: inconvenienced\n",
      "Word: are, Deprel: cop, Head: inconvenienced\n",
      "Word: obviously, Deprel: advmod, Head: inconvenienced\n",
      "Word: inconvenienced, Deprel: root, Head: ROOT\n",
      "Word: said, Deprel: parataxis, Head: inconvenienced\n",
      "Word: Dr, Deprel: compound, Head: commissioner\n",
      "Word: Jim, Deprel: flat, Head: Dr\n",
      "Word: Young, Deprel: amod, Head: Ontario\n",
      "Word: Ontario, Deprel: nmod:poss, Head: commissioner\n",
      "Word: s, Deprel: case, Head: Ontario\n",
      "Word: commissioner, Deprel: obj, Head: said\n",
      "Word: of, Deprel: case, Head: safety\n",
      "Word: public, Deprel: amod, Head: safety\n",
      "Word: safety, Deprel: nmod, Head: commissioner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We re being hyper-vigilant said Dr James Young Ontario s commissioner of public safety'\n",
      "Word: We, Deprel: nsubj, Head: said\n",
      "Word: re, Deprel: aux, Head: hyper-vigilant\n",
      "Word: being, Deprel: cop, Head: hyper-vigilant\n",
      "Word: hyper-vigilant, Deprel: csubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Dr, Deprel: nmod:poss, Head: commissioner\n",
      "Word: James, Deprel: flat, Head: Dr\n",
      "Word: Young, Deprel: amod, Head: Ontario\n",
      "Word: Ontario, Deprel: nmod:poss, Head: commissioner\n",
      "Word: s, Deprel: case, Head: Ontario\n",
      "Word: commissioner, Deprel: obj, Head: said\n",
      "Word: of, Deprel: case, Head: safety\n",
      "Word: public, Deprel: amod, Head: safety\n",
      "Word: safety, Deprel: nmod, Head: commissioner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The others were given copies of Dr Atkins New Diet Revolution and told to follow it'\n",
      "Word: The, Deprel: det, Head: others\n",
      "Word: others, Deprel: nsubj:pass, Head: given\n",
      "Word: were, Deprel: aux:pass, Head: given\n",
      "Word: given, Deprel: root, Head: ROOT\n",
      "Word: copies, Deprel: obj, Head: given\n",
      "Word: of, Deprel: case, Head: Revolution\n",
      "Word: Dr, Deprel: compound, Head: Revolution\n",
      "Word: Atkins, Deprel: flat, Head: Dr\n",
      "Word: New, Deprel: amod, Head: Revolution\n",
      "Word: Diet, Deprel: compound, Head: Revolution\n",
      "Word: Revolution, Deprel: nmod, Head: copies\n",
      "Word: and, Deprel: cc, Head: told\n",
      "Word: told, Deprel: conj, Head: given\n",
      "Word: to, Deprel: mark, Head: follow\n",
      "Word: follow, Deprel: xcomp, Head: told\n",
      "Word: it, Deprel: obj, Head: follow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The researchers gave copies of Dr Atkins New Diet Revolution to the carb-cutters'\n",
      "Word: The, Deprel: det, Head: researchers\n",
      "Word: researchers, Deprel: nsubj, Head: gave\n",
      "Word: gave, Deprel: root, Head: ROOT\n",
      "Word: copies, Deprel: obj, Head: gave\n",
      "Word: of, Deprel: case, Head: Revolution\n",
      "Word: Dr, Deprel: compound, Head: Revolution\n",
      "Word: Atkins, Deprel: flat, Head: Dr\n",
      "Word: New, Deprel: amod, Head: Revolution\n",
      "Word: Diet, Deprel: compound, Head: Revolution\n",
      "Word: Revolution, Deprel: nmod, Head: copies\n",
      "Word: to, Deprel: case, Head: carb-cutters\n",
      "Word: the, Deprel: det, Head: carb-cutters\n",
      "Word: carb-cutters, Deprel: obl, Head: gave\n",
      "\n",
      "Dependencies for Sentence: 'Barbini said the union may reach a compromise with the United States but it wants a system for labeling such foods something the industry successfully fought here'\n",
      "Word: Barbini, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: union\n",
      "Word: union, Deprel: nsubj, Head: reach\n",
      "Word: may, Deprel: aux, Head: reach\n",
      "Word: reach, Deprel: ccomp, Head: said\n",
      "Word: a, Deprel: det, Head: compromise\n",
      "Word: compromise, Deprel: obj, Head: reach\n",
      "Word: with, Deprel: case, Head: States\n",
      "Word: the, Deprel: det, Head: States\n",
      "Word: United, Deprel: amod, Head: States\n",
      "Word: States, Deprel: nmod, Head: compromise\n",
      "Word: but, Deprel: cc, Head: wants\n",
      "Word: it, Deprel: nsubj, Head: wants\n",
      "Word: wants, Deprel: conj, Head: said\n",
      "Word: a, Deprel: det, Head: system\n",
      "Word: system, Deprel: obj, Head: wants\n",
      "Word: for, Deprel: mark, Head: labeling\n",
      "Word: labeling, Deprel: acl, Head: system\n",
      "Word: such, Deprel: amod, Head: foods\n",
      "Word: foods, Deprel: obj, Head: labeling\n",
      "Word: something, Deprel: obj, Head: labeling\n",
      "Word: the, Deprel: det, Head: industry\n",
      "Word: industry, Deprel: nsubj, Head: fought\n",
      "Word: successfully, Deprel: advmod, Head: fought\n",
      "Word: fought, Deprel: acl:relcl, Head: something\n",
      "Word: here, Deprel: advmod, Head: fought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Barbini said the EU may reach a compromise but it wants a system for labeling such foods something the industry has resisted'\n",
      "Word: Barbini, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: EU\n",
      "Word: EU, Deprel: nsubj, Head: reach\n",
      "Word: may, Deprel: aux, Head: reach\n",
      "Word: reach, Deprel: ccomp, Head: said\n",
      "Word: a, Deprel: det, Head: compromise\n",
      "Word: compromise, Deprel: obj, Head: reach\n",
      "Word: but, Deprel: cc, Head: wants\n",
      "Word: it, Deprel: nsubj, Head: wants\n",
      "Word: wants, Deprel: conj, Head: said\n",
      "Word: a, Deprel: det, Head: system\n",
      "Word: system, Deprel: obj, Head: wants\n",
      "Word: for, Deprel: mark, Head: labeling\n",
      "Word: labeling, Deprel: acl, Head: system\n",
      "Word: such, Deprel: amod, Head: foods\n",
      "Word: foods, Deprel: obj, Head: labeling\n",
      "Word: something, Deprel: obj, Head: labeling\n",
      "Word: the, Deprel: det, Head: industry\n",
      "Word: industry, Deprel: nsubj, Head: resisted\n",
      "Word: has, Deprel: aux, Head: resisted\n",
      "Word: resisted, Deprel: acl:relcl, Head: something\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The blaze then spread to several surrounding structures on the property and destroyed them'\n",
      "Word: The, Deprel: det, Head: blaze\n",
      "Word: blaze, Deprel: nsubj, Head: spread\n",
      "Word: then, Deprel: advmod, Head: spread\n",
      "Word: spread, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: structures\n",
      "Word: several, Deprel: amod, Head: structures\n",
      "Word: surrounding, Deprel: amod, Head: structures\n",
      "Word: structures, Deprel: obl, Head: spread\n",
      "Word: on, Deprel: case, Head: property\n",
      "Word: the, Deprel: det, Head: property\n",
      "Word: property, Deprel: nmod, Head: structures\n",
      "Word: and, Deprel: cc, Head: destroyed\n",
      "Word: destroyed, Deprel: conj, Head: spread\n",
      "Word: them, Deprel: obj, Head: destroyed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The fire spread to several surrounding structures on the property and destroyed them as deputies held back firefighters'\n",
      "Word: The, Deprel: det, Head: fire\n",
      "Word: fire, Deprel: nsubj, Head: spread\n",
      "Word: spread, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: structures\n",
      "Word: several, Deprel: amod, Head: structures\n",
      "Word: surrounding, Deprel: amod, Head: structures\n",
      "Word: structures, Deprel: obl, Head: spread\n",
      "Word: on, Deprel: case, Head: property\n",
      "Word: the, Deprel: det, Head: property\n",
      "Word: property, Deprel: nmod, Head: structures\n",
      "Word: and, Deprel: cc, Head: destroyed\n",
      "Word: destroyed, Deprel: conj, Head: spread\n",
      "Word: them, Deprel: obj, Head: destroyed\n",
      "Word: as, Deprel: mark, Head: held\n",
      "Word: deputies, Deprel: nsubj, Head: held\n",
      "Word: held, Deprel: advcl, Head: destroyed\n",
      "Word: back, Deprel: advmod, Head: held\n",
      "Word: firefighters, Deprel: obj, Head: held\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The rapper s lawyer Mark Gann did n't return calls for comment'\n",
      "Word: The, Deprel: det, Head: rapper\n",
      "Word: rapper, Deprel: nmod:poss, Head: lawyer\n",
      "Word: s, Deprel: case, Head: rapper\n",
      "Word: lawyer, Deprel: nsubj, Head: return\n",
      "Word: Mark, Deprel: appos, Head: lawyer\n",
      "Word: Gann, Deprel: flat, Head: Mark\n",
      "Word: did, Deprel: aux, Head: return\n",
      "Word: n't, Deprel: advmod, Head: return\n",
      "Word: return, Deprel: root, Head: ROOT\n",
      "Word: calls, Deprel: obj, Head: return\n",
      "Word: for, Deprel: case, Head: comment\n",
      "Word: comment, Deprel: nmod, Head: calls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The 27-year-old rapper s attorney in the civil matter Mark Gann did not return calls for comment'\n",
      "Word: The, Deprel: det, Head: rapper\n",
      "Word: 27-year-old, Deprel: amod, Head: rapper\n",
      "Word: rapper, Deprel: nmod:poss, Head: attorney\n",
      "Word: s, Deprel: case, Head: rapper\n",
      "Word: attorney, Deprel: nsubj, Head: return\n",
      "Word: in, Deprel: case, Head: matter\n",
      "Word: the, Deprel: det, Head: matter\n",
      "Word: civil, Deprel: amod, Head: matter\n",
      "Word: matter, Deprel: nmod, Head: attorney\n",
      "Word: Mark, Deprel: appos, Head: matter\n",
      "Word: Gann, Deprel: flat, Head: Mark\n",
      "Word: did, Deprel: aux, Head: return\n",
      "Word: not, Deprel: advmod, Head: return\n",
      "Word: return, Deprel: root, Head: ROOT\n",
      "Word: calls, Deprel: obj, Head: return\n",
      "Word: for, Deprel: case, Head: comment\n",
      "Word: comment, Deprel: obl, Head: return\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Sources say agents confiscated several documents he was carrying'\n",
      "Word: Sources, Deprel: nsubj, Head: say\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: agents, Deprel: nsubj, Head: confiscated\n",
      "Word: confiscated, Deprel: ccomp, Head: say\n",
      "Word: several, Deprel: amod, Head: documents\n",
      "Word: documents, Deprel: obj, Head: confiscated\n",
      "Word: he, Deprel: nsubj, Head: carrying\n",
      "Word: was, Deprel: aux, Head: carrying\n",
      "Word: carrying, Deprel: acl:relcl, Head: documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Agents confiscated several classified documents in his possession and interrogated him'\n",
      "Word: Agents, Deprel: nsubj, Head: confiscated\n",
      "Word: confiscated, Deprel: root, Head: ROOT\n",
      "Word: several, Deprel: amod, Head: documents\n",
      "Word: classified, Deprel: amod, Head: documents\n",
      "Word: documents, Deprel: obj, Head: confiscated\n",
      "Word: in, Deprel: case, Head: possession\n",
      "Word: his, Deprel: nmod:poss, Head: possession\n",
      "Word: possession, Deprel: obl, Head: confiscated\n",
      "Word: and, Deprel: cc, Head: interrogated\n",
      "Word: interrogated, Deprel: conj, Head: confiscated\n",
      "Word: him, Deprel: obj, Head: interrogated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Also weighing on the market was news that General Motors GM.N planned to issue 10 billion in debt in part to plug a hole in its pension plan'\n",
      "Word: Also, Deprel: advmod, Head: weighing\n",
      "Word: weighing, Deprel: csubj, Head: news\n",
      "Word: on, Deprel: case, Head: market\n",
      "Word: the, Deprel: det, Head: market\n",
      "Word: market, Deprel: obl, Head: weighing\n",
      "Word: was, Deprel: cop, Head: news\n",
      "Word: news, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: planned\n",
      "Word: General, Deprel: compound, Head: Motors\n",
      "Word: Motors, Deprel: compound, Head: GM.N\n",
      "Word: GM.N, Deprel: nsubj, Head: planned\n",
      "Word: planned, Deprel: acl, Head: news\n",
      "Word: to, Deprel: mark, Head: issue\n",
      "Word: issue, Deprel: xcomp, Head: planned\n",
      "Word: 10, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: nummod, Head: debt\n",
      "Word: in, Deprel: case, Head: debt\n",
      "Word: debt, Deprel: obj, Head: issue\n",
      "Word: in, Deprel: case, Head: part\n",
      "Word: part, Deprel: obl, Head: issue\n",
      "Word: to, Deprel: mark, Head: plug\n",
      "Word: plug, Deprel: advcl, Head: issue\n",
      "Word: a, Deprel: det, Head: hole\n",
      "Word: hole, Deprel: obj, Head: plug\n",
      "Word: in, Deprel: case, Head: plan\n",
      "Word: its, Deprel: nmod:poss, Head: plan\n",
      "Word: pension, Deprel: compound, Head: plan\n",
      "Word: plan, Deprel: obl, Head: plug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Also hurting was news General Motors GM.N was to issue 10 billion in debt in part to plug a hole in its pension plan'\n",
      "Word: Also, Deprel: advmod, Head: hurting\n",
      "Word: hurting, Deprel: csubj, Head: news\n",
      "Word: was, Deprel: cop, Head: hurting\n",
      "Word: news, Deprel: root, Head: ROOT\n",
      "Word: General, Deprel: amod, Head: Motors\n",
      "Word: Motors, Deprel: compound, Head: GM.N\n",
      "Word: GM.N, Deprel: nsubj, Head: issue\n",
      "Word: was, Deprel: aux, Head: issue\n",
      "Word: to, Deprel: mark, Head: issue\n",
      "Word: issue, Deprel: acl:relcl, Head: news\n",
      "Word: 10, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obj, Head: issue\n",
      "Word: in, Deprel: case, Head: debt\n",
      "Word: debt, Deprel: obj, Head: issue\n",
      "Word: in, Deprel: case, Head: part\n",
      "Word: part, Deprel: obl, Head: issue\n",
      "Word: to, Deprel: mark, Head: plug\n",
      "Word: plug, Deprel: advcl, Head: issue\n",
      "Word: a, Deprel: det, Head: hole\n",
      "Word: hole, Deprel: obj, Head: plug\n",
      "Word: in, Deprel: case, Head: plan\n",
      "Word: its, Deprel: nmod:poss, Head: plan\n",
      "Word: pension, Deprel: compound, Head: plan\n",
      "Word: plan, Deprel: obl, Head: plug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The helicopter burst into flames upon impact according to the Mohave County Sheriff s Office'\n",
      "Word: The, Deprel: det, Head: helicopter\n",
      "Word: helicopter, Deprel: nsubj, Head: burst\n",
      "Word: burst, Deprel: root, Head: ROOT\n",
      "Word: into, Deprel: case, Head: flames\n",
      "Word: flames, Deprel: obl, Head: burst\n",
      "Word: upon, Deprel: case, Head: impact\n",
      "Word: impact, Deprel: obl, Head: burst\n",
      "Word: according, Deprel: case, Head: Office\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: the, Deprel: det, Head: Sheriff\n",
      "Word: Mohave, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: Sheriff\n",
      "Word: Sheriff, Deprel: nmod:poss, Head: Office\n",
      "Word: s, Deprel: case, Head: Sheriff\n",
      "Word: Office, Deprel: obl, Head: burst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The helicopter was owned by Las Vegas-based Sundance Helicopters Inc according to the sheriff s office'\n",
      "Word: The, Deprel: det, Head: helicopter\n",
      "Word: helicopter, Deprel: nsubj:pass, Head: owned\n",
      "Word: was, Deprel: aux:pass, Head: owned\n",
      "Word: owned, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: Inc\n",
      "Word: Las, Deprel: compound, Head: Inc\n",
      "Word: Vegas-based, Deprel: flat, Head: Las\n",
      "Word: Sundance, Deprel: compound, Head: Helicopters\n",
      "Word: Helicopters, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: obl, Head: owned\n",
      "Word: according, Deprel: case, Head: office\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: the, Deprel: det, Head: sheriff\n",
      "Word: sheriff, Deprel: nmod:poss, Head: office\n",
      "Word: s, Deprel: case, Head: sheriff\n",
      "Word: office, Deprel: obl, Head: owned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I am advised that certain allegations of criminal conduct have been interposed against my counsel said Silver'\n",
      "Word: I, Deprel: nsubj:pass, Head: advised\n",
      "Word: am, Deprel: aux:pass, Head: advised\n",
      "Word: advised, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: interposed\n",
      "Word: certain, Deprel: amod, Head: allegations\n",
      "Word: allegations, Deprel: nsubj:pass, Head: interposed\n",
      "Word: of, Deprel: case, Head: conduct\n",
      "Word: criminal, Deprel: amod, Head: conduct\n",
      "Word: conduct, Deprel: nmod, Head: allegations\n",
      "Word: have, Deprel: aux, Head: interposed\n",
      "Word: been, Deprel: aux:pass, Head: interposed\n",
      "Word: interposed, Deprel: ccomp, Head: advised\n",
      "Word: against, Deprel: case, Head: counsel\n",
      "Word: my, Deprel: nmod:poss, Head: counsel\n",
      "Word: counsel, Deprel: obl, Head: interposed\n",
      "Word: said, Deprel: parataxis, Head: advised\n",
      "Word: Silver, Deprel: obj, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I am advised that certain allegations of criminal conduct have been interposed against my counsel J Michael Boxley the Silver statement said'\n",
      "Word: I, Deprel: nsubj:pass, Head: advised\n",
      "Word: am, Deprel: aux:pass, Head: advised\n",
      "Word: advised, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: interposed\n",
      "Word: certain, Deprel: amod, Head: allegations\n",
      "Word: allegations, Deprel: nsubj:pass, Head: interposed\n",
      "Word: of, Deprel: case, Head: conduct\n",
      "Word: criminal, Deprel: amod, Head: conduct\n",
      "Word: conduct, Deprel: nmod, Head: allegations\n",
      "Word: have, Deprel: aux, Head: interposed\n",
      "Word: been, Deprel: aux:pass, Head: interposed\n",
      "Word: interposed, Deprel: ccomp, Head: advised\n",
      "Word: against, Deprel: case, Head: counsel\n",
      "Word: my, Deprel: nmod:poss, Head: counsel\n",
      "Word: counsel, Deprel: obl, Head: interposed\n",
      "Word: J, Deprel: appos, Head: counsel\n",
      "Word: Michael, Deprel: flat, Head: J\n",
      "Word: Boxley, Deprel: flat, Head: J\n",
      "Word: the, Deprel: det, Head: statement\n",
      "Word: Silver, Deprel: amod, Head: statement\n",
      "Word: statement, Deprel: appos, Head: J\n",
      "Word: said, Deprel: advcl, Head: interposed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I think we made the right case and did the right thing'\n",
      "Word: I, Deprel: nsubj, Head: think\n",
      "Word: think, Deprel: root, Head: ROOT\n",
      "Word: we, Deprel: nsubj, Head: made\n",
      "Word: made, Deprel: ccomp, Head: think\n",
      "Word: the, Deprel: det, Head: case\n",
      "Word: right, Deprel: amod, Head: case\n",
      "Word: case, Deprel: obj, Head: made\n",
      "Word: and, Deprel: cc, Head: did\n",
      "Word: did, Deprel: conj, Head: made\n",
      "Word: the, Deprel: det, Head: thing\n",
      "Word: right, Deprel: amod, Head: thing\n",
      "Word: thing, Deprel: obj, Head: did\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Blair went on I think we did the right thing in relation to Iraq'\n",
      "Word: Mr, Deprel: compound, Head: Blair\n",
      "Word: Blair, Deprel: nsubj, Head: went\n",
      "Word: went, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: compound:prt, Head: went\n",
      "Word: I, Deprel: nsubj, Head: think\n",
      "Word: think, Deprel: parataxis, Head: went\n",
      "Word: we, Deprel: nsubj, Head: did\n",
      "Word: did, Deprel: ccomp, Head: think\n",
      "Word: the, Deprel: det, Head: thing\n",
      "Word: right, Deprel: amod, Head: thing\n",
      "Word: thing, Deprel: obj, Head: did\n",
      "Word: in, Deprel: case, Head: relation\n",
      "Word: relation, Deprel: obl, Head: did\n",
      "Word: to, Deprel: case, Head: Iraq\n",
      "Word: Iraq, Deprel: nmod, Head: relation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Russin did not comment his lawyer did not attend the hearing and did not return phone messages'\n",
      "Word: Russin, Deprel: nsubj, Head: comment\n",
      "Word: did, Deprel: aux, Head: comment\n",
      "Word: not, Deprel: advmod, Head: comment\n",
      "Word: comment, Deprel: root, Head: ROOT\n",
      "Word: his, Deprel: nmod:poss, Head: lawyer\n",
      "Word: lawyer, Deprel: nsubj, Head: attend\n",
      "Word: did, Deprel: aux, Head: attend\n",
      "Word: not, Deprel: advmod, Head: attend\n",
      "Word: attend, Deprel: ccomp, Head: comment\n",
      "Word: the, Deprel: det, Head: hearing\n",
      "Word: hearing, Deprel: obj, Head: attend\n",
      "Word: and, Deprel: cc, Head: return\n",
      "Word: did, Deprel: aux, Head: return\n",
      "Word: not, Deprel: advmod, Head: return\n",
      "Word: return, Deprel: conj, Head: comment\n",
      "Word: phone, Deprel: compound, Head: messages\n",
      "Word: messages, Deprel: obj, Head: return\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'His lawyer a cousin Basil Russin did not attend the hearing and did not return phone messages'\n",
      "Word: His, Deprel: nmod:poss, Head: lawyer\n",
      "Word: lawyer, Deprel: nsubj, Head: attend\n",
      "Word: a, Deprel: det, Head: cousin\n",
      "Word: cousin, Deprel: appos, Head: lawyer\n",
      "Word: Basil, Deprel: appos, Head: lawyer\n",
      "Word: Russin, Deprel: flat, Head: Basil\n",
      "Word: did, Deprel: aux, Head: attend\n",
      "Word: not, Deprel: advmod, Head: attend\n",
      "Word: attend, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: hearing\n",
      "Word: hearing, Deprel: obj, Head: attend\n",
      "Word: and, Deprel: cc, Head: return\n",
      "Word: did, Deprel: aux, Head: return\n",
      "Word: not, Deprel: advmod, Head: return\n",
      "Word: return, Deprel: conj, Head: attend\n",
      "Word: phone, Deprel: compound, Head: messages\n",
      "Word: messages, Deprel: obj, Head: return\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Licensing revenue slid 21 percent however to 107.6 million'\n",
      "Word: Licensing, Deprel: compound, Head: revenue\n",
      "Word: revenue, Deprel: nsubj, Head: slid\n",
      "Word: slid, Deprel: root, Head: ROOT\n",
      "Word: 21, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:npmod, Head: however\n",
      "Word: however, Deprel: advmod, Head: slid\n",
      "Word: to, Deprel: case, Head: million\n",
      "Word: 107.6, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: obl, Head: however\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'License sales a key measure of demand fell 21 percent to 107.6 million'\n",
      "Word: License, Deprel: compound, Head: sales\n",
      "Word: sales, Deprel: nsubj, Head: fell\n",
      "Word: a, Deprel: det, Head: measure\n",
      "Word: key, Deprel: amod, Head: measure\n",
      "Word: measure, Deprel: appos, Head: sales\n",
      "Word: of, Deprel: case, Head: demand\n",
      "Word: demand, Deprel: nmod, Head: measure\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 21, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: fell\n",
      "Word: to, Deprel: case, Head: million\n",
      "Word: 107.6, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hispanics the fastest growing ethnic group in the US have overtaken blacks to become the largest minority in the US according to newly released government figures'\n",
      "Word: Hispanics, Deprel: nsubj, Head: overtaken\n",
      "Word: the, Deprel: det, Head: group\n",
      "Word: fastest, Deprel: amod, Head: group\n",
      "Word: growing, Deprel: amod, Head: group\n",
      "Word: ethnic, Deprel: amod, Head: group\n",
      "Word: group, Deprel: appos, Head: Hispanics\n",
      "Word: in, Deprel: case, Head: US\n",
      "Word: the, Deprel: det, Head: US\n",
      "Word: US, Deprel: nmod, Head: group\n",
      "Word: have, Deprel: aux, Head: overtaken\n",
      "Word: overtaken, Deprel: root, Head: ROOT\n",
      "Word: blacks, Deprel: obj, Head: overtaken\n",
      "Word: to, Deprel: mark, Head: become\n",
      "Word: become, Deprel: xcomp, Head: overtaken\n",
      "Word: the, Deprel: det, Head: minority\n",
      "Word: largest, Deprel: amod, Head: minority\n",
      "Word: minority, Deprel: xcomp, Head: become\n",
      "Word: in, Deprel: case, Head: US\n",
      "Word: the, Deprel: det, Head: US\n",
      "Word: US, Deprel: nmod, Head: minority\n",
      "Word: according, Deprel: case, Head: figures\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: newly, Deprel: advmod, Head: released\n",
      "Word: released, Deprel: amod, Head: figures\n",
      "Word: government, Deprel: compound, Head: figures\n",
      "Word: figures, Deprel: obl, Head: become\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hispanics have officially overtaken African Americans as the largest minority group in the US according to a report released by the US Census Bureau'\n",
      "Word: Hispanics, Deprel: nsubj, Head: overtaken\n",
      "Word: have, Deprel: aux, Head: overtaken\n",
      "Word: officially, Deprel: advmod, Head: overtaken\n",
      "Word: overtaken, Deprel: root, Head: ROOT\n",
      "Word: African, Deprel: amod, Head: Americans\n",
      "Word: Americans, Deprel: obj, Head: overtaken\n",
      "Word: as, Deprel: case, Head: group\n",
      "Word: the, Deprel: det, Head: group\n",
      "Word: largest, Deprel: amod, Head: group\n",
      "Word: minority, Deprel: compound, Head: group\n",
      "Word: group, Deprel: obl, Head: overtaken\n",
      "Word: in, Deprel: case, Head: US\n",
      "Word: the, Deprel: det, Head: US\n",
      "Word: US, Deprel: nmod, Head: group\n",
      "Word: according, Deprel: case, Head: report\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: a, Deprel: det, Head: report\n",
      "Word: report, Deprel: obl, Head: overtaken\n",
      "Word: released, Deprel: acl, Head: report\n",
      "Word: by, Deprel: case, Head: Bureau\n",
      "Word: the, Deprel: det, Head: Bureau\n",
      "Word: US, Deprel: compound, Head: Bureau\n",
      "Word: Census, Deprel: compound, Head: Bureau\n",
      "Word: Bureau, Deprel: obl, Head: released\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Bishop of Armidale Peter Brain was forthright'\n",
      "Word: The, Deprel: det, Head: Bishop\n",
      "Word: Bishop, Deprel: nsubj, Head: forthright\n",
      "Word: of, Deprel: case, Head: Armidale\n",
      "Word: Armidale, Deprel: nmod, Head: Bishop\n",
      "Word: Peter, Deprel: flat, Head: Armidale\n",
      "Word: Brain, Deprel: flat, Head: Armidale\n",
      "Word: was, Deprel: cop, Head: forthright\n",
      "Word: forthright, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He has n't got much choice said the Bishop of Armidale Peter Brain'\n",
      "Word: He, Deprel: nsubj, Head: got\n",
      "Word: has, Deprel: aux, Head: got\n",
      "Word: n't, Deprel: advmod, Head: got\n",
      "Word: got, Deprel: root, Head: ROOT\n",
      "Word: much, Deprel: amod, Head: choice\n",
      "Word: choice, Deprel: obj, Head: got\n",
      "Word: said, Deprel: parataxis, Head: got\n",
      "Word: the, Deprel: det, Head: Bishop\n",
      "Word: Bishop, Deprel: obj, Head: said\n",
      "Word: of, Deprel: case, Head: Armidale\n",
      "Word: Armidale, Deprel: nmod, Head: Bishop\n",
      "Word: Peter, Deprel: flat, Head: Armidale\n",
      "Word: Brain, Deprel: flat, Head: Peter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'When fully operational the facility is expected to employ up to 1,000 people'\n",
      "Word: When, Deprel: advmod, Head: operational\n",
      "Word: fully, Deprel: advmod, Head: operational\n",
      "Word: operational, Deprel: advcl, Head: expected\n",
      "Word: the, Deprel: det, Head: facility\n",
      "Word: facility, Deprel: nsubj:pass, Head: expected\n",
      "Word: is, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: employ\n",
      "Word: employ, Deprel: xcomp, Head: expected\n",
      "Word: up, Deprel: advmod, Head: 1,000\n",
      "Word: to, Deprel: fixed, Head: up\n",
      "Word: 1,000, Deprel: nummod, Head: people\n",
      "Word: people, Deprel: obj, Head: employ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The plant would employ 1,000 people when fully built out the company said'\n",
      "Word: The, Deprel: det, Head: plant\n",
      "Word: plant, Deprel: nsubj, Head: employ\n",
      "Word: would, Deprel: aux, Head: employ\n",
      "Word: employ, Deprel: root, Head: ROOT\n",
      "Word: 1,000, Deprel: nummod, Head: people\n",
      "Word: people, Deprel: obj, Head: employ\n",
      "Word: when, Deprel: advmod, Head: built\n",
      "Word: fully, Deprel: advmod, Head: built\n",
      "Word: built, Deprel: advcl, Head: employ\n",
      "Word: out, Deprel: compound:prt, Head: built\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: employ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Kollar-Kotelly has scheduled another antitrust settlement compliance hearing for January'\n",
      "Word: Kollar-Kotelly, Deprel: nsubj, Head: scheduled\n",
      "Word: has, Deprel: aux, Head: scheduled\n",
      "Word: scheduled, Deprel: root, Head: ROOT\n",
      "Word: another, Deprel: det, Head: hearing\n",
      "Word: antitrust, Deprel: compound, Head: settlement\n",
      "Word: settlement, Deprel: compound, Head: hearing\n",
      "Word: compliance, Deprel: compound, Head: hearing\n",
      "Word: hearing, Deprel: obj, Head: scheduled\n",
      "Word: for, Deprel: case, Head: January\n",
      "Word: January, Deprel: nmod, Head: hearing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The judge scheduled another oversight hearing for late January'\n",
      "Word: The, Deprel: det, Head: judge\n",
      "Word: judge, Deprel: nsubj, Head: scheduled\n",
      "Word: scheduled, Deprel: root, Head: ROOT\n",
      "Word: another, Deprel: det, Head: hearing\n",
      "Word: oversight, Deprel: compound, Head: hearing\n",
      "Word: hearing, Deprel: obj, Head: scheduled\n",
      "Word: for, Deprel: case, Head: January\n",
      "Word: late, Deprel: amod, Head: January\n",
      "Word: January, Deprel: obl, Head: scheduled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The American Stock Exchange biotech index BTK surged 5 percent'\n",
      "Word: The, Deprel: det, Head: BTK\n",
      "Word: American, Deprel: amod, Head: Exchange\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: compound, Head: index\n",
      "Word: biotech, Deprel: compound, Head: index\n",
      "Word: index, Deprel: compound, Head: BTK\n",
      "Word: BTK, Deprel: nsubj, Head: surged\n",
      "Word: surged, Deprel: root, Head: ROOT\n",
      "Word: 5, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: surged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Philadelphia Stock Exchange s semiconductor index SOXX jumped 6.10 percent'\n",
      "Word: The, Deprel: det, Head: Exchange\n",
      "Word: Philadelphia, Deprel: compound, Head: Exchange\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: nmod:poss, Head: SOXX\n",
      "Word: s, Deprel: case, Head: Exchange\n",
      "Word: semiconductor, Deprel: compound, Head: index\n",
      "Word: index, Deprel: compound, Head: SOXX\n",
      "Word: SOXX, Deprel: nsubj, Head: jumped\n",
      "Word: jumped, Deprel: root, Head: ROOT\n",
      "Word: 6.10, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: jumped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Tomorrow at the Mission Inn I have the opportunity to congratulate the governor-elect of the great state of California'\n",
      "Word: Tomorrow, Deprel: obl:tmod, Head: have\n",
      "Word: at, Deprel: case, Head: Inn\n",
      "Word: the, Deprel: det, Head: Inn\n",
      "Word: Mission, Deprel: compound, Head: Inn\n",
      "Word: Inn, Deprel: nmod, Head: Tomorrow\n",
      "Word: I, Deprel: nsubj, Head: have\n",
      "Word: have, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: opportunity\n",
      "Word: opportunity, Deprel: obj, Head: have\n",
      "Word: to, Deprel: mark, Head: congratulate\n",
      "Word: congratulate, Deprel: acl, Head: opportunity\n",
      "Word: the, Deprel: det, Head: governor-elect\n",
      "Word: governor-elect, Deprel: obj, Head: congratulate\n",
      "Word: of, Deprel: case, Head: state\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: great, Deprel: amod, Head: state\n",
      "Word: state, Deprel: nmod, Head: governor-elect\n",
      "Word: of, Deprel: case, Head: California\n",
      "Word: California, Deprel: nmod, Head: state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I have the opportunity to congratulate the governor-elect of the great state of California and I m looking forward to it'\n",
      "Word: I, Deprel: nsubj, Head: have\n",
      "Word: have, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: opportunity\n",
      "Word: opportunity, Deprel: obj, Head: have\n",
      "Word: to, Deprel: mark, Head: congratulate\n",
      "Word: congratulate, Deprel: acl, Head: opportunity\n",
      "Word: the, Deprel: det, Head: governor-elect\n",
      "Word: governor-elect, Deprel: obj, Head: congratulate\n",
      "Word: of, Deprel: case, Head: state\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: great, Deprel: amod, Head: state\n",
      "Word: state, Deprel: nmod, Head: governor-elect\n",
      "Word: of, Deprel: case, Head: California\n",
      "Word: California, Deprel: nmod, Head: state\n",
      "Word: and, Deprel: cc, Head: looking\n",
      "Word: I, Deprel: nsubj, Head: looking\n",
      "Word: m, Deprel: aux, Head: looking\n",
      "Word: looking, Deprel: conj, Head: have\n",
      "Word: forward, Deprel: advmod, Head: looking\n",
      "Word: to, Deprel: case, Head: it\n",
      "Word: it, Deprel: obl, Head: looking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I really liked him and I still do Cohen Alon told the Herald yesterday'\n",
      "Word: I, Deprel: nsubj, Head: liked\n",
      "Word: really, Deprel: advmod, Head: liked\n",
      "Word: liked, Deprel: root, Head: ROOT\n",
      "Word: him, Deprel: obj, Head: liked\n",
      "Word: and, Deprel: cc, Head: do\n",
      "Word: I, Deprel: nsubj, Head: do\n",
      "Word: still, Deprel: advmod, Head: do\n",
      "Word: do, Deprel: conj, Head: liked\n",
      "Word: Cohen, Deprel: nsubj, Head: told\n",
      "Word: Alon, Deprel: flat, Head: Cohen\n",
      "Word: told, Deprel: parataxis, Head: liked\n",
      "Word: the, Deprel: det, Head: Herald\n",
      "Word: Herald, Deprel: iobj, Head: told\n",
      "Word: yesterday, Deprel: obl:tmod, Head: told\n",
      "\n",
      "Dependencies for Sentence: 'And I really liked him and I still do'\n",
      "Word: And, Deprel: cc, Head: liked\n",
      "Word: I, Deprel: nsubj, Head: liked\n",
      "Word: really, Deprel: advmod, Head: liked\n",
      "Word: liked, Deprel: root, Head: ROOT\n",
      "Word: him, Deprel: obj, Head: liked\n",
      "Word: and, Deprel: cc, Head: do\n",
      "Word: I, Deprel: nsubj, Head: do\n",
      "Word: still, Deprel: advmod, Head: do\n",
      "Word: do, Deprel: conj, Head: liked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'For the full 12-month period ending June 30 2003 advanced services lines for ADSL increased by 37 percent and cable modem connections increased by 75 percent'\n",
      "Word: For, Deprel: case, Head: period\n",
      "Word: the, Deprel: det, Head: period\n",
      "Word: full, Deprel: amod, Head: period\n",
      "Word: 12-month, Deprel: compound, Head: period\n",
      "Word: period, Deprel: obl, Head: increased\n",
      "Word: ending, Deprel: acl, Head: period\n",
      "Word: June, Deprel: obl:tmod, Head: ending\n",
      "Word: 30, Deprel: nummod, Head: June\n",
      "Word: 2003, Deprel: nummod, Head: June\n",
      "Word: advanced, Deprel: amod, Head: lines\n",
      "Word: services, Deprel: compound, Head: lines\n",
      "Word: lines, Deprel: nsubj, Head: increased\n",
      "Word: for, Deprel: case, Head: ADSL\n",
      "Word: ADSL, Deprel: nmod, Head: lines\n",
      "Word: increased, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: percent\n",
      "Word: 37, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: increased\n",
      "Word: and, Deprel: cc, Head: increased\n",
      "Word: cable, Deprel: compound, Head: modem\n",
      "Word: modem, Deprel: compound, Head: connections\n",
      "Word: connections, Deprel: nsubj, Head: increased\n",
      "Word: increased, Deprel: conj, Head: increased\n",
      "Word: by, Deprel: case, Head: percent\n",
      "Word: 75, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: increased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'For the 12-month period ending June 30 high-speed lines installed in homes and businesses increased by 45 percent'\n",
      "Word: For, Deprel: case, Head: period\n",
      "Word: the, Deprel: det, Head: period\n",
      "Word: 12-month, Deprel: amod, Head: period\n",
      "Word: period, Deprel: obl, Head: increased\n",
      "Word: ending, Deprel: acl, Head: period\n",
      "Word: June, Deprel: compound, Head: lines\n",
      "Word: 30, Deprel: nummod, Head: June\n",
      "Word: high-speed, Deprel: compound, Head: lines\n",
      "Word: lines, Deprel: nsubj, Head: increased\n",
      "Word: installed, Deprel: acl, Head: lines\n",
      "Word: in, Deprel: case, Head: homes\n",
      "Word: homes, Deprel: obl, Head: installed\n",
      "Word: and, Deprel: cc, Head: businesses\n",
      "Word: businesses, Deprel: conj, Head: homes\n",
      "Word: increased, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: percent\n",
      "Word: 45, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: increased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new research will be published soon in the Proceedings of the National Academy of Sciences'\n",
      "Word: The, Deprel: det, Head: research\n",
      "Word: new, Deprel: amod, Head: research\n",
      "Word: research, Deprel: nsubj:pass, Head: published\n",
      "Word: will, Deprel: aux, Head: published\n",
      "Word: be, Deprel: aux:pass, Head: published\n",
      "Word: published, Deprel: root, Head: ROOT\n",
      "Word: soon, Deprel: advmod, Head: published\n",
      "Word: in, Deprel: case, Head: Proceedings\n",
      "Word: the, Deprel: det, Head: Proceedings\n",
      "Word: Proceedings, Deprel: obl, Head: published\n",
      "Word: of, Deprel: case, Head: Academy\n",
      "Word: the, Deprel: det, Head: Academy\n",
      "Word: National, Deprel: amod, Head: Academy\n",
      "Word: Academy, Deprel: nmod, Head: Proceedings\n",
      "Word: of, Deprel: case, Head: Sciences\n",
      "Word: Sciences, Deprel: nmod, Head: Academy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It will appear in the next few weeks on the Web site of the Proceedings of the National Academy of Sciences'\n",
      "Word: It, Deprel: nsubj, Head: appear\n",
      "Word: will, Deprel: aux, Head: appear\n",
      "Word: appear, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: weeks\n",
      "Word: the, Deprel: det, Head: weeks\n",
      "Word: next, Deprel: amod, Head: weeks\n",
      "Word: few, Deprel: amod, Head: weeks\n",
      "Word: weeks, Deprel: obl, Head: appear\n",
      "Word: on, Deprel: case, Head: site\n",
      "Word: the, Deprel: det, Head: site\n",
      "Word: Web, Deprel: compound, Head: site\n",
      "Word: site, Deprel: obl, Head: appear\n",
      "Word: of, Deprel: case, Head: Proceedings\n",
      "Word: the, Deprel: det, Head: Proceedings\n",
      "Word: Proceedings, Deprel: nmod, Head: site\n",
      "Word: of, Deprel: case, Head: Academy\n",
      "Word: the, Deprel: det, Head: Academy\n",
      "Word: National, Deprel: amod, Head: Academy\n",
      "Word: Academy, Deprel: nmod, Head: Proceedings\n",
      "Word: of, Deprel: case, Head: Sciences\n",
      "Word: Sciences, Deprel: nmod, Head: Academy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I expect Japan to keep conducting intervention but the volume is likely to fall sharply said Junya Tanase forex strategist at JP Morgan Chase'\n",
      "Word: I, Deprel: nsubj, Head: expect\n",
      "Word: expect, Deprel: root, Head: ROOT\n",
      "Word: Japan, Deprel: obj, Head: expect\n",
      "Word: to, Deprel: mark, Head: keep\n",
      "Word: keep, Deprel: xcomp, Head: expect\n",
      "Word: conducting, Deprel: xcomp, Head: keep\n",
      "Word: intervention, Deprel: obj, Head: conducting\n",
      "Word: but, Deprel: cc, Head: likely\n",
      "Word: the, Deprel: det, Head: volume\n",
      "Word: volume, Deprel: nsubj, Head: likely\n",
      "Word: is, Deprel: cop, Head: likely\n",
      "Word: likely, Deprel: conj, Head: expect\n",
      "Word: to, Deprel: mark, Head: fall\n",
      "Word: fall, Deprel: xcomp, Head: likely\n",
      "Word: sharply, Deprel: advmod, Head: fall\n",
      "Word: said, Deprel: parataxis, Head: expect\n",
      "Word: Junya, Deprel: compound, Head: strategist\n",
      "Word: Tanase, Deprel: flat, Head: Junya\n",
      "Word: forex, Deprel: compound, Head: strategist\n",
      "Word: strategist, Deprel: obj, Head: said\n",
      "Word: at, Deprel: case, Head: Chase\n",
      "Word: JP, Deprel: compound, Head: Chase\n",
      "Word: Morgan, Deprel: compound, Head: Chase\n",
      "Word: Chase, Deprel: nmod, Head: strategist\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Junya Tanase forex strategist at JP Morgan Chase said I expect Japan to keep conducting intervention but the volume is likely to fall sharply'\n",
      "Word: Junya, Deprel: nsubj, Head: said\n",
      "Word: Tanase, Deprel: flat, Head: Junya\n",
      "Word: forex, Deprel: compound, Head: strategist\n",
      "Word: strategist, Deprel: appos, Head: Junya\n",
      "Word: at, Deprel: case, Head: Chase\n",
      "Word: JP, Deprel: compound, Head: Chase\n",
      "Word: Morgan, Deprel: compound, Head: Chase\n",
      "Word: Chase, Deprel: nmod, Head: strategist\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: I, Deprel: nsubj, Head: expect\n",
      "Word: expect, Deprel: ccomp, Head: said\n",
      "Word: Japan, Deprel: obj, Head: expect\n",
      "Word: to, Deprel: mark, Head: keep\n",
      "Word: keep, Deprel: xcomp, Head: expect\n",
      "Word: conducting, Deprel: xcomp, Head: keep\n",
      "Word: intervention, Deprel: obj, Head: conducting\n",
      "Word: but, Deprel: cc, Head: likely\n",
      "Word: the, Deprel: det, Head: volume\n",
      "Word: volume, Deprel: nsubj, Head: likely\n",
      "Word: is, Deprel: cop, Head: likely\n",
      "Word: likely, Deprel: conj, Head: said\n",
      "Word: to, Deprel: mark, Head: fall\n",
      "Word: fall, Deprel: xcomp, Head: likely\n",
      "Word: sharply, Deprel: advmod, Head: fall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Sunshine Group LTD represented the developers The Related Companies and Apollo Real Estate Advisors LP on the deal'\n",
      "Word: The, Deprel: det, Head: LTD\n",
      "Word: Sunshine, Deprel: compound, Head: Group\n",
      "Word: Group, Deprel: compound, Head: LTD\n",
      "Word: LTD, Deprel: nsubj, Head: represented\n",
      "Word: represented, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: developers\n",
      "Word: developers, Deprel: obj, Head: represented\n",
      "Word: The, Deprel: det, Head: Companies\n",
      "Word: Related, Deprel: amod, Head: Companies\n",
      "Word: Companies, Deprel: appos, Head: developers\n",
      "Word: and, Deprel: cc, Head: LP\n",
      "Word: Apollo, Deprel: compound, Head: LP\n",
      "Word: Real, Deprel: amod, Head: Estate\n",
      "Word: Estate, Deprel: compound, Head: Advisors\n",
      "Word: Advisors, Deprel: compound, Head: LP\n",
      "Word: LP, Deprel: conj, Head: Companies\n",
      "Word: on, Deprel: case, Head: deal\n",
      "Word: the, Deprel: det, Head: deal\n",
      "Word: deal, Deprel: obl, Head: represented\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The developers The Related Cos and Apollo Real Estate Advisors hope sales top 1 billion'\n",
      "Word: The, Deprel: det, Head: developers\n",
      "Word: developers, Deprel: nsubj, Head: hope\n",
      "Word: The, Deprel: det, Head: Cos\n",
      "Word: Related, Deprel: amod, Head: Cos\n",
      "Word: Cos, Deprel: appos, Head: developers\n",
      "Word: and, Deprel: cc, Head: Advisors\n",
      "Word: Apollo, Deprel: compound, Head: Advisors\n",
      "Word: Real, Deprel: amod, Head: Estate\n",
      "Word: Estate, Deprel: compound, Head: Advisors\n",
      "Word: Advisors, Deprel: conj, Head: Cos\n",
      "Word: hope, Deprel: root, Head: ROOT\n",
      "Word: sales, Deprel: nsubj, Head: top\n",
      "Word: top, Deprel: ccomp, Head: hope\n",
      "Word: 1, Deprel: nummod, Head: billion\n",
      "Word: billion, Deprel: obj, Head: top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'State Education Commissioner Kent King said Wednesday that the scores on the Missouri Assessment Program tests disappointed him'\n",
      "Word: State, Deprel: compound, Head: Education\n",
      "Word: Education, Deprel: compound, Head: Commissioner\n",
      "Word: Commissioner, Deprel: nsubj, Head: said\n",
      "Word: Kent, Deprel: flat, Head: Commissioner\n",
      "Word: King, Deprel: flat, Head: Kent\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Wednesday, Deprel: obl:tmod, Head: said\n",
      "Word: that, Deprel: mark, Head: disappointed\n",
      "Word: the, Deprel: det, Head: scores\n",
      "Word: scores, Deprel: nsubj, Head: disappointed\n",
      "Word: on, Deprel: case, Head: tests\n",
      "Word: the, Deprel: det, Head: tests\n",
      "Word: Missouri, Deprel: compound, Head: Program\n",
      "Word: Assessment, Deprel: compound, Head: Program\n",
      "Word: Program, Deprel: compound, Head: tests\n",
      "Word: tests, Deprel: nmod, Head: scores\n",
      "Word: disappointed, Deprel: ccomp, Head: said\n",
      "Word: him, Deprel: obj, Head: disappointed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Missouri Education Commissioner Kent King said he was disappointed by the scores'\n",
      "Word: Missouri, Deprel: compound, Head: Commissioner\n",
      "Word: Education, Deprel: compound, Head: Commissioner\n",
      "Word: Commissioner, Deprel: nsubj, Head: said\n",
      "Word: Kent, Deprel: flat, Head: Commissioner\n",
      "Word: King, Deprel: flat, Head: Commissioner\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj:pass, Head: disappointed\n",
      "Word: was, Deprel: aux:pass, Head: disappointed\n",
      "Word: disappointed, Deprel: ccomp, Head: said\n",
      "Word: by, Deprel: case, Head: scores\n",
      "Word: the, Deprel: det, Head: scores\n",
      "Word: scores, Deprel: obl:agent, Head: disappointed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Agents found more than 1,000 credit cards and credit card duplicating machines during a search of Ragin s address'\n",
      "Word: Agents, Deprel: nsubj, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: more, Deprel: advmod, Head: 1,000\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 1,000, Deprel: nummod, Head: cards\n",
      "Word: credit, Deprel: compound, Head: cards\n",
      "Word: cards, Deprel: obj, Head: found\n",
      "Word: and, Deprel: cc, Head: machines\n",
      "Word: credit, Deprel: compound, Head: card\n",
      "Word: card, Deprel: compound, Head: machines\n",
      "Word: duplicating, Deprel: compound, Head: machines\n",
      "Word: machines, Deprel: conj, Head: cards\n",
      "Word: during, Deprel: case, Head: search\n",
      "Word: a, Deprel: det, Head: search\n",
      "Word: search, Deprel: obl, Head: found\n",
      "Word: of, Deprel: case, Head: address\n",
      "Word: Ragin, Deprel: nmod:poss, Head: address\n",
      "Word: s, Deprel: case, Head: Ragin\n",
      "Word: address, Deprel: nmod, Head: search\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'When Ragin s address was raided authorities found more than 1,000 credit cards and duplicating machines'\n",
      "Word: When, Deprel: advmod, Head: raided\n",
      "Word: Ragin, Deprel: nmod:poss, Head: address\n",
      "Word: s, Deprel: case, Head: Ragin\n",
      "Word: address, Deprel: nsubj:pass, Head: raided\n",
      "Word: was, Deprel: aux:pass, Head: raided\n",
      "Word: raided, Deprel: advcl, Head: found\n",
      "Word: authorities, Deprel: nsubj, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: more, Deprel: advmod, Head: 1,000\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 1,000, Deprel: nummod, Head: cards\n",
      "Word: credit, Deprel: compound, Head: cards\n",
      "Word: cards, Deprel: obj, Head: found\n",
      "Word: and, Deprel: cc, Head: machines\n",
      "Word: duplicating, Deprel: amod, Head: machines\n",
      "Word: machines, Deprel: conj, Head: cards\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Lowe s with about half as many stores reported a 33 percent increase in third-quarter profit behind a 12 percent jump in same-store sales'\n",
      "Word: Lowe, Deprel: root, Head: ROOT\n",
      "Word: s, Deprel: case, Head: Lowe\n",
      "Word: with, Deprel: case, Head: half\n",
      "Word: about, Deprel: advmod, Head: half\n",
      "Word: half, Deprel: nmod, Head: Lowe\n",
      "Word: as, Deprel: mark, Head: reported\n",
      "Word: many, Deprel: amod, Head: stores\n",
      "Word: stores, Deprel: nsubj, Head: reported\n",
      "Word: reported, Deprel: advcl, Head: Lowe\n",
      "Word: a, Deprel: det, Head: increase\n",
      "Word: 33, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: increase\n",
      "Word: increase, Deprel: obj, Head: reported\n",
      "Word: in, Deprel: case, Head: profit\n",
      "Word: third-quarter, Deprel: amod, Head: profit\n",
      "Word: profit, Deprel: nmod, Head: increase\n",
      "Word: behind, Deprel: case, Head: jump\n",
      "Word: a, Deprel: det, Head: jump\n",
      "Word: 12, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: jump\n",
      "Word: jump, Deprel: obl, Head: reported\n",
      "Word: in, Deprel: case, Head: sales\n",
      "Word: same-store, Deprel: compound, Head: sales\n",
      "Word: sales, Deprel: nmod, Head: jump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Home Depot reported a 22 percent jump in third-quarter profit behind a nearly 8 percent rise in same-store sales'\n",
      "Word: Home, Deprel: compound, Head: Depot\n",
      "Word: Depot, Deprel: nsubj, Head: reported\n",
      "Word: reported, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: jump\n",
      "Word: 22, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: jump\n",
      "Word: jump, Deprel: obj, Head: reported\n",
      "Word: in, Deprel: case, Head: profit\n",
      "Word: third-quarter, Deprel: amod, Head: profit\n",
      "Word: profit, Deprel: nmod, Head: jump\n",
      "Word: behind, Deprel: case, Head: rise\n",
      "Word: a, Deprel: det, Head: rise\n",
      "Word: nearly, Deprel: advmod, Head: percent\n",
      "Word: 8, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: rise\n",
      "Word: rise, Deprel: obl, Head: reported\n",
      "Word: in, Deprel: case, Head: sales\n",
      "Word: same-store, Deprel: compound, Head: sales\n",
      "Word: sales, Deprel: nmod, Head: rise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Caldera acquired the Unix server software of the original SCO and changed its name to the SCO Group'\n",
      "Word: Caldera, Deprel: nsubj, Head: acquired\n",
      "Word: acquired, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: software\n",
      "Word: Unix, Deprel: compound, Head: server\n",
      "Word: server, Deprel: compound, Head: software\n",
      "Word: software, Deprel: obj, Head: acquired\n",
      "Word: of, Deprel: case, Head: SCO\n",
      "Word: the, Deprel: det, Head: SCO\n",
      "Word: original, Deprel: amod, Head: SCO\n",
      "Word: SCO, Deprel: nmod, Head: software\n",
      "Word: and, Deprel: cc, Head: changed\n",
      "Word: changed, Deprel: conj, Head: acquired\n",
      "Word: its, Deprel: nmod:poss, Head: name\n",
      "Word: name, Deprel: obj, Head: changed\n",
      "Word: to, Deprel: case, Head: Group\n",
      "Word: the, Deprel: det, Head: Group\n",
      "Word: SCO, Deprel: compound, Head: Group\n",
      "Word: Group, Deprel: obl, Head: changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'SCO changed its name to Tarantella and Caldera later changed its name to the SCO Group'\n",
      "Word: SCO, Deprel: nsubj, Head: changed\n",
      "Word: changed, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: name\n",
      "Word: name, Deprel: obj, Head: changed\n",
      "Word: to, Deprel: case, Head: Tarantella\n",
      "Word: Tarantella, Deprel: obl, Head: changed\n",
      "Word: and, Deprel: cc, Head: changed\n",
      "Word: Caldera, Deprel: nsubj, Head: changed\n",
      "Word: later, Deprel: advmod, Head: changed\n",
      "Word: changed, Deprel: conj, Head: changed\n",
      "Word: its, Deprel: nmod:poss, Head: name\n",
      "Word: name, Deprel: obj, Head: changed\n",
      "Word: to, Deprel: case, Head: Group\n",
      "Word: the, Deprel: det, Head: Group\n",
      "Word: SCO, Deprel: compound, Head: Group\n",
      "Word: Group, Deprel: obl, Head: changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Two convicted killers and another inmate escaped from a state prison on a busy street Wednesday by cutting through a fence a Corrections Department official said'\n",
      "Word: Two, Deprel: nummod, Head: killers\n",
      "Word: convicted, Deprel: amod, Head: killers\n",
      "Word: killers, Deprel: nsubj, Head: escaped\n",
      "Word: and, Deprel: cc, Head: inmate\n",
      "Word: another, Deprel: det, Head: inmate\n",
      "Word: inmate, Deprel: conj, Head: killers\n",
      "Word: escaped, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: prison\n",
      "Word: a, Deprel: det, Head: prison\n",
      "Word: state, Deprel: compound, Head: prison\n",
      "Word: prison, Deprel: obl, Head: escaped\n",
      "Word: on, Deprel: case, Head: street\n",
      "Word: a, Deprel: det, Head: street\n",
      "Word: busy, Deprel: amod, Head: street\n",
      "Word: street, Deprel: obl, Head: escaped\n",
      "Word: Wednesday, Deprel: obl:tmod, Head: escaped\n",
      "Word: by, Deprel: mark, Head: cutting\n",
      "Word: cutting, Deprel: advcl, Head: escaped\n",
      "Word: through, Deprel: case, Head: fence\n",
      "Word: a, Deprel: det, Head: fence\n",
      "Word: fence, Deprel: obl, Head: cutting\n",
      "Word: a, Deprel: det, Head: official\n",
      "Word: Corrections, Deprel: compound, Head: Department\n",
      "Word: Department, Deprel: compound, Head: official\n",
      "Word: official, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: fence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A convicted killer and two other inmates cut through two fences topped with razor wire and escaped from a state prison on a busy street'\n",
      "Word: A, Deprel: det, Head: killer\n",
      "Word: convicted, Deprel: amod, Head: killer\n",
      "Word: killer, Deprel: nsubj, Head: cut\n",
      "Word: and, Deprel: cc, Head: inmates\n",
      "Word: two, Deprel: nummod, Head: inmates\n",
      "Word: other, Deprel: amod, Head: inmates\n",
      "Word: inmates, Deprel: conj, Head: killer\n",
      "Word: cut, Deprel: root, Head: ROOT\n",
      "Word: through, Deprel: case, Head: fences\n",
      "Word: two, Deprel: nummod, Head: fences\n",
      "Word: fences, Deprel: obl, Head: cut\n",
      "Word: topped, Deprel: advcl, Head: cut\n",
      "Word: with, Deprel: case, Head: wire\n",
      "Word: razor, Deprel: compound, Head: wire\n",
      "Word: wire, Deprel: obl, Head: topped\n",
      "Word: and, Deprel: cc, Head: escaped\n",
      "Word: escaped, Deprel: conj, Head: cut\n",
      "Word: from, Deprel: case, Head: prison\n",
      "Word: a, Deprel: det, Head: prison\n",
      "Word: state, Deprel: compound, Head: prison\n",
      "Word: prison, Deprel: obl, Head: escaped\n",
      "Word: on, Deprel: case, Head: street\n",
      "Word: a, Deprel: det, Head: street\n",
      "Word: busy, Deprel: amod, Head: street\n",
      "Word: street, Deprel: obl, Head: escaped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It is about a third of what I owe in the world he told reporters'\n",
      "Word: It, Deprel: nsubj, Head: third\n",
      "Word: is, Deprel: cop, Head: third\n",
      "Word: about, Deprel: advmod, Head: third\n",
      "Word: a, Deprel: det, Head: third\n",
      "Word: third, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: what\n",
      "Word: what, Deprel: nmod, Head: third\n",
      "Word: I, Deprel: nsubj, Head: owe\n",
      "Word: owe, Deprel: acl:relcl, Head: what\n",
      "Word: in, Deprel: case, Head: world\n",
      "Word: the, Deprel: det, Head: world\n",
      "Word: world, Deprel: obl, Head: owe\n",
      "Word: he, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: parataxis, Head: third\n",
      "Word: reporters, Deprel: iobj, Head: told\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It ai n't coming to me but it s only about a third of what I owe in the world'\n",
      "Word: It, Deprel: nsubj, Head: coming\n",
      "Word: ai, Deprel: aux, Head: coming\n",
      "Word: n't, Deprel: advmod, Head: coming\n",
      "Word: coming, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: me\n",
      "Word: me, Deprel: obl, Head: coming\n",
      "Word: but, Deprel: cc, Head: third\n",
      "Word: it, Deprel: nsubj, Head: third\n",
      "Word: s, Deprel: cop, Head: third\n",
      "Word: only, Deprel: advmod, Head: third\n",
      "Word: about, Deprel: advmod, Head: third\n",
      "Word: a, Deprel: det, Head: third\n",
      "Word: third, Deprel: conj, Head: coming\n",
      "Word: of, Deprel: case, Head: what\n",
      "Word: what, Deprel: nmod, Head: third\n",
      "Word: I, Deprel: nsubj, Head: owe\n",
      "Word: owe, Deprel: acl:relcl, Head: what\n",
      "Word: in, Deprel: case, Head: world\n",
      "Word: the, Deprel: det, Head: world\n",
      "Word: world, Deprel: obl, Head: owe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Officers threw him to the ground and handcuffed him and Reyna dropped a knee into his back according to testimony'\n",
      "Word: Officers, Deprel: nsubj, Head: threw\n",
      "Word: threw, Deprel: root, Head: ROOT\n",
      "Word: him, Deprel: obj, Head: threw\n",
      "Word: to, Deprel: case, Head: ground\n",
      "Word: the, Deprel: det, Head: ground\n",
      "Word: ground, Deprel: obl, Head: threw\n",
      "Word: and, Deprel: cc, Head: handcuffed\n",
      "Word: handcuffed, Deprel: conj, Head: threw\n",
      "Word: him, Deprel: obj, Head: handcuffed\n",
      "Word: and, Deprel: cc, Head: dropped\n",
      "Word: Reyna, Deprel: nsubj, Head: dropped\n",
      "Word: dropped, Deprel: conj, Head: threw\n",
      "Word: a, Deprel: det, Head: knee\n",
      "Word: knee, Deprel: obj, Head: dropped\n",
      "Word: into, Deprel: case, Head: back\n",
      "Word: his, Deprel: nmod:poss, Head: back\n",
      "Word: back, Deprel: obl, Head: dropped\n",
      "Word: according, Deprel: case, Head: testimony\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: testimony, Deprel: obl, Head: dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'That s when officers threw him to the ground and handcuffed him according to testimony'\n",
      "Word: That, Deprel: nsubj, Head: s\n",
      "Word: s, Deprel: root, Head: ROOT\n",
      "Word: when, Deprel: advmod, Head: threw\n",
      "Word: officers, Deprel: nsubj, Head: threw\n",
      "Word: threw, Deprel: advcl, Head: s\n",
      "Word: him, Deprel: obj, Head: threw\n",
      "Word: to, Deprel: case, Head: ground\n",
      "Word: the, Deprel: det, Head: ground\n",
      "Word: ground, Deprel: obl, Head: threw\n",
      "Word: and, Deprel: cc, Head: handcuffed\n",
      "Word: handcuffed, Deprel: conj, Head: threw\n",
      "Word: him, Deprel: obj, Head: handcuffed\n",
      "Word: according, Deprel: case, Head: testimony\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: testimony, Deprel: obl, Head: handcuffed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The best-performing stock was Altria Group Inc which rose more than 27 percent to close at 42.31 a share'\n",
      "Word: The, Deprel: det, Head: stock\n",
      "Word: best-performing, Deprel: amod, Head: stock\n",
      "Word: stock, Deprel: nsubj, Head: Inc\n",
      "Word: was, Deprel: cop, Head: Inc\n",
      "Word: Altria, Deprel: compound, Head: Inc\n",
      "Word: Group, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: root, Head: ROOT\n",
      "Word: which, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: acl:relcl, Head: Inc\n",
      "Word: more, Deprel: advmod, Head: 27\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 27, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: rose\n",
      "Word: to, Deprel: mark, Head: close\n",
      "Word: close, Deprel: advcl, Head: rose\n",
      "Word: at, Deprel: case, Head: 42.31\n",
      "Word: 42.31, Deprel: obl, Head: close\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: obl, Head: close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Altria Group Inc MO.N fell 50 cents or 1.2 percent to 41.81'\n",
      "Word: Altria, Deprel: compound, Head: Group\n",
      "Word: Group, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: compound, Head: MO.N\n",
      "Word: MO.N, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 50, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: fell\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.2, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: cents\n",
      "Word: to, Deprel: case, Head: 41.81\n",
      "Word: 41.81, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Officials are trying to retrieve the bodies from the water police officer J.D Tambe told Reuters adding 26 of the dead were women'\n",
      "Word: Officials, Deprel: nsubj, Head: trying\n",
      "Word: are, Deprel: aux, Head: trying\n",
      "Word: trying, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: retrieve\n",
      "Word: retrieve, Deprel: xcomp, Head: trying\n",
      "Word: the, Deprel: det, Head: bodies\n",
      "Word: bodies, Deprel: obj, Head: retrieve\n",
      "Word: from, Deprel: case, Head: officer\n",
      "Word: the, Deprel: det, Head: officer\n",
      "Word: water, Deprel: compound, Head: police\n",
      "Word: police, Deprel: compound, Head: officer\n",
      "Word: officer, Deprel: nmod, Head: bodies\n",
      "Word: J.D, Deprel: appos, Head: officer\n",
      "Word: Tambe, Deprel: flat, Head: J.D\n",
      "Word: told, Deprel: acl:relcl, Head: bodies\n",
      "Word: Reuters, Deprel: iobj, Head: told\n",
      "Word: adding, Deprel: advcl, Head: told\n",
      "Word: 26, Deprel: nsubj, Head: women\n",
      "Word: of, Deprel: case, Head: dead\n",
      "Word: the, Deprel: det, Head: dead\n",
      "Word: dead, Deprel: nmod, Head: 26\n",
      "Word: were, Deprel: cop, Head: women\n",
      "Word: women, Deprel: ccomp, Head: adding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Officials are trying to retrieve the bodies from the water police official J.D Tambe told Reuters'\n",
      "Word: Officials, Deprel: nsubj, Head: trying\n",
      "Word: are, Deprel: aux, Head: trying\n",
      "Word: trying, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: retrieve\n",
      "Word: retrieve, Deprel: xcomp, Head: trying\n",
      "Word: the, Deprel: det, Head: bodies\n",
      "Word: bodies, Deprel: obj, Head: retrieve\n",
      "Word: from, Deprel: case, Head: official\n",
      "Word: the, Deprel: det, Head: official\n",
      "Word: water, Deprel: compound, Head: police\n",
      "Word: police, Deprel: compound, Head: official\n",
      "Word: official, Deprel: compound, Head: J.D\n",
      "Word: J.D, Deprel: nsubj, Head: told\n",
      "Word: Tambe, Deprel: flat, Head: J.D\n",
      "Word: told, Deprel: parataxis, Head: trying\n",
      "Word: Reuters, Deprel: iobj, Head: told\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'According to market research from The NPD Group the number of people downloading music dropped from 14.5 million in April to 10.4 million in June'\n",
      "Word: According, Deprel: case, Head: research\n",
      "Word: to, Deprel: fixed, Head: According\n",
      "Word: market, Deprel: compound, Head: research\n",
      "Word: research, Deprel: obl, Head: dropped\n",
      "Word: from, Deprel: case, Head: Group\n",
      "Word: The, Deprel: det, Head: Group\n",
      "Word: NPD, Deprel: compound, Head: Group\n",
      "Word: Group, Deprel: nmod, Head: research\n",
      "Word: the, Deprel: det, Head: number\n",
      "Word: number, Deprel: nsubj, Head: dropped\n",
      "Word: of, Deprel: case, Head: people\n",
      "Word: people, Deprel: nmod, Head: number\n",
      "Word: downloading, Deprel: acl, Head: people\n",
      "Word: music, Deprel: obj, Head: downloading\n",
      "Word: dropped, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: million\n",
      "Word: 14.5, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obl, Head: dropped\n",
      "Word: in, Deprel: case, Head: April\n",
      "Word: April, Deprel: obl, Head: dropped\n",
      "Word: to, Deprel: case, Head: million\n",
      "Word: 10.4, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: obl, Head: dropped\n",
      "Word: in, Deprel: case, Head: June\n",
      "Word: June, Deprel: nmod, Head: million\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The number of households acquiring music fell from a high of 14.5 million in April to 12.7 million in May and 10.4 million in June according to NPD'\n",
      "Word: The, Deprel: det, Head: number\n",
      "Word: number, Deprel: nsubj, Head: fell\n",
      "Word: of, Deprel: case, Head: households\n",
      "Word: households, Deprel: nmod, Head: number\n",
      "Word: acquiring, Deprel: acl, Head: households\n",
      "Word: music, Deprel: obj, Head: acquiring\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: high\n",
      "Word: a, Deprel: det, Head: high\n",
      "Word: high, Deprel: obl, Head: fell\n",
      "Word: of, Deprel: case, Head: million\n",
      "Word: 14.5, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nmod, Head: high\n",
      "Word: in, Deprel: case, Head: April\n",
      "Word: April, Deprel: obl, Head: fell\n",
      "Word: to, Deprel: case, Head: million\n",
      "Word: 12.7, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: obl, Head: fell\n",
      "Word: in, Deprel: case, Head: May\n",
      "Word: May, Deprel: obl, Head: fell\n",
      "Word: and, Deprel: cc, Head: million\n",
      "Word: 10.4, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: conj, Head: fell\n",
      "Word: in, Deprel: case, Head: June\n",
      "Word: June, Deprel: nmod, Head: million\n",
      "Word: according, Deprel: case, Head: NPD\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: NPD, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This is an easy case in my view and wholly without merit both factually and legally'\n",
      "Word: This, Deprel: nsubj, Head: case\n",
      "Word: is, Deprel: cop, Head: case\n",
      "Word: an, Deprel: det, Head: case\n",
      "Word: easy, Deprel: amod, Head: case\n",
      "Word: case, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: view\n",
      "Word: my, Deprel: nmod:poss, Head: view\n",
      "Word: view, Deprel: nmod, Head: case\n",
      "Word: and, Deprel: cc, Head: merit\n",
      "Word: wholly, Deprel: advmod, Head: merit\n",
      "Word: without, Deprel: case, Head: merit\n",
      "Word: merit, Deprel: conj, Head: case\n",
      "Word: both, Deprel: cc:preconj, Head: factually\n",
      "Word: factually, Deprel: advmod, Head: merit\n",
      "Word: and, Deprel: cc, Head: legally\n",
      "Word: legally, Deprel: conj, Head: factually\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This case is wholly without merit both factually and legally Judge Denny Chin scoffed'\n",
      "Word: This, Deprel: det, Head: case\n",
      "Word: case, Deprel: nsubj, Head: merit\n",
      "Word: is, Deprel: cop, Head: merit\n",
      "Word: wholly, Deprel: advmod, Head: merit\n",
      "Word: without, Deprel: case, Head: merit\n",
      "Word: merit, Deprel: root, Head: ROOT\n",
      "Word: both, Deprel: cc:preconj, Head: factually\n",
      "Word: factually, Deprel: advmod, Head: merit\n",
      "Word: and, Deprel: cc, Head: scoffed\n",
      "Word: legally, Deprel: conj, Head: factually\n",
      "Word: Judge, Deprel: nsubj, Head: scoffed\n",
      "Word: Denny, Deprel: flat, Head: Judge\n",
      "Word: Chin, Deprel: flat, Head: Judge\n",
      "Word: scoffed, Deprel: conj, Head: merit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The tech-laced Nasdaq Composite Index gained 2.90 points or 0.18 percent to 1,606.87'\n",
      "Word: The, Deprel: det, Head: Index\n",
      "Word: tech-laced, Deprel: amod, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: nsubj, Head: gained\n",
      "Word: gained, Deprel: root, Head: ROOT\n",
      "Word: 2.90, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: gained\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.18, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,606.87\n",
      "Word: 1,606.87, Deprel: obl, Head: gained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'At 12:10 p.m EDT Canada s benchmark S P/TSX composite index was up 6.87 points or 0.1 per cent to 6,979.29'\n",
      "Word: At, Deprel: case, Head: p.m\n",
      "Word: 12:10, Deprel: nummod, Head: p.m\n",
      "Word: p.m, Deprel: obl, Head: up\n",
      "Word: EDT, Deprel: compound, Head: Canada\n",
      "Word: Canada, Deprel: nmod:poss, Head: index\n",
      "Word: s, Deprel: case, Head: Canada\n",
      "Word: benchmark, Deprel: compound, Head: S\n",
      "Word: S, Deprel: compound, Head: index\n",
      "Word: P/TSX, Deprel: compound, Head: composite\n",
      "Word: composite, Deprel: compound, Head: index\n",
      "Word: index, Deprel: nsubj, Head: up\n",
      "Word: was, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: 6.87, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: up\n",
      "Word: or, Deprel: cc, Head: cent\n",
      "Word: 0.1, Deprel: nummod, Head: cent\n",
      "Word: per, Deprel: compound, Head: cent\n",
      "Word: cent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 6,979.29\n",
      "Word: 6,979.29, Deprel: obl, Head: up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The weather service reported maximum sustained winds of nearly 105 miles an hour with stronger gusts'\n",
      "Word: The, Deprel: det, Head: service\n",
      "Word: weather, Deprel: compound, Head: service\n",
      "Word: service, Deprel: nsubj, Head: reported\n",
      "Word: reported, Deprel: root, Head: ROOT\n",
      "Word: maximum, Deprel: amod, Head: winds\n",
      "Word: sustained, Deprel: amod, Head: winds\n",
      "Word: winds, Deprel: obj, Head: reported\n",
      "Word: of, Deprel: case, Head: miles\n",
      "Word: nearly, Deprel: advmod, Head: 105\n",
      "Word: 105, Deprel: nummod, Head: miles\n",
      "Word: miles, Deprel: nmod, Head: winds\n",
      "Word: an, Deprel: det, Head: hour\n",
      "Word: hour, Deprel: nmod:tmod, Head: miles\n",
      "Word: with, Deprel: case, Head: gusts\n",
      "Word: stronger, Deprel: amod, Head: gusts\n",
      "Word: gusts, Deprel: obl, Head: reported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Maximum sustained winds were around 40 mph with stronger gusts'\n",
      "Word: Maximum, Deprel: amod, Head: winds\n",
      "Word: sustained, Deprel: amod, Head: winds\n",
      "Word: winds, Deprel: nsubj, Head: mph\n",
      "Word: were, Deprel: cop, Head: mph\n",
      "Word: around, Deprel: advmod, Head: 40\n",
      "Word: 40, Deprel: nummod, Head: mph\n",
      "Word: mph, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: gusts\n",
      "Word: stronger, Deprel: amod, Head: gusts\n",
      "Word: gusts, Deprel: nmod, Head: mph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The WiFi potties were to be unveiled this summer at music festivals in Britain'\n",
      "Word: The, Deprel: det, Head: potties\n",
      "Word: WiFi, Deprel: compound, Head: potties\n",
      "Word: potties, Deprel: nsubj:pass, Head: unveiled\n",
      "Word: were, Deprel: aux, Head: unveiled\n",
      "Word: to, Deprel: mark, Head: unveiled\n",
      "Word: be, Deprel: aux:pass, Head: unveiled\n",
      "Word: unveiled, Deprel: root, Head: ROOT\n",
      "Word: this, Deprel: det, Head: summer\n",
      "Word: summer, Deprel: obl:tmod, Head: unveiled\n",
      "Word: at, Deprel: case, Head: festivals\n",
      "Word: music, Deprel: compound, Head: festivals\n",
      "Word: festivals, Deprel: obl, Head: unveiled\n",
      "Word: in, Deprel: case, Head: Britain\n",
      "Word: Britain, Deprel: nmod, Head: festivals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The world s first portal potty was soon to be rolled out at summer festivals in Great Britain'\n",
      "Word: The, Deprel: det, Head: world\n",
      "Word: world, Deprel: nmod:poss, Head: potty\n",
      "Word: s, Deprel: case, Head: world\n",
      "Word: first, Deprel: amod, Head: portal\n",
      "Word: portal, Deprel: compound, Head: potty\n",
      "Word: potty, Deprel: nsubj:pass, Head: rolled\n",
      "Word: was, Deprel: aux, Head: rolled\n",
      "Word: soon, Deprel: advmod, Head: rolled\n",
      "Word: to, Deprel: mark, Head: rolled\n",
      "Word: be, Deprel: aux:pass, Head: rolled\n",
      "Word: rolled, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: compound:prt, Head: rolled\n",
      "Word: at, Deprel: case, Head: festivals\n",
      "Word: summer, Deprel: compound, Head: festivals\n",
      "Word: festivals, Deprel: obl, Head: rolled\n",
      "Word: in, Deprel: case, Head: Britain\n",
      "Word: Great, Deprel: amod, Head: Britain\n",
      "Word: Britain, Deprel: nmod, Head: festivals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The benchmark 10-year Treasury note yield US10YT=RR dipped below 4.20 percent on Tuesday'\n",
      "Word: The, Deprel: det, Head: US10YT=RR\n",
      "Word: benchmark, Deprel: compound, Head: 10-year\n",
      "Word: 10-year, Deprel: compound, Head: note\n",
      "Word: Treasury, Deprel: compound, Head: note\n",
      "Word: note, Deprel: compound, Head: US10YT=RR\n",
      "Word: yield, Deprel: compound, Head: US10YT=RR\n",
      "Word: US10YT=RR, Deprel: nsubj, Head: dipped\n",
      "Word: dipped, Deprel: root, Head: ROOT\n",
      "Word: below, Deprel: case, Head: percent\n",
      "Word: 4.20, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: dipped\n",
      "Word: on, Deprel: case, Head: Tuesday\n",
      "Word: Tuesday, Deprel: obl, Head: dipped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Prices for Treasury securities also rose with the yield on the benchmark 10-year note falling to 4.19 percent'\n",
      "Word: Prices, Deprel: nsubj, Head: rose\n",
      "Word: for, Deprel: case, Head: securities\n",
      "Word: Treasury, Deprel: compound, Head: securities\n",
      "Word: securities, Deprel: nmod, Head: Prices\n",
      "Word: also, Deprel: advmod, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: mark, Head: falling\n",
      "Word: the, Deprel: det, Head: yield\n",
      "Word: yield, Deprel: nsubj, Head: falling\n",
      "Word: on, Deprel: case, Head: note\n",
      "Word: the, Deprel: det, Head: note\n",
      "Word: benchmark, Deprel: compound, Head: note\n",
      "Word: 10-year, Deprel: amod, Head: note\n",
      "Word: note, Deprel: nmod, Head: yield\n",
      "Word: falling, Deprel: advcl, Head: rose\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 4.19, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: falling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'MEN who drink tea particularly green tea can greatly reduce their risk of prostate cancer a landmark WA study has found'\n",
      "Word: MEN, Deprel: nsubj, Head: reduce\n",
      "Word: who, Deprel: nsubj, Head: drink\n",
      "Word: drink, Deprel: acl:relcl, Head: MEN\n",
      "Word: tea, Deprel: obj, Head: drink\n",
      "Word: particularly, Deprel: advmod, Head: green\n",
      "Word: green, Deprel: amod, Head: tea\n",
      "Word: tea, Deprel: obj, Head: drink\n",
      "Word: can, Deprel: aux, Head: reduce\n",
      "Word: greatly, Deprel: advmod, Head: reduce\n",
      "Word: reduce, Deprel: root, Head: ROOT\n",
      "Word: their, Deprel: nmod:poss, Head: risk\n",
      "Word: risk, Deprel: obj, Head: reduce\n",
      "Word: of, Deprel: case, Head: cancer\n",
      "Word: prostate, Deprel: compound, Head: cancer\n",
      "Word: cancer, Deprel: nmod, Head: risk\n",
      "Word: a, Deprel: det, Head: study\n",
      "Word: landmark, Deprel: compound, Head: study\n",
      "Word: WA, Deprel: compound, Head: study\n",
      "Word: study, Deprel: nsubj, Head: found\n",
      "Word: has, Deprel: aux, Head: found\n",
      "Word: found, Deprel: parataxis, Head: reduce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'DRINKING green tea can dramatically reduce the risk of men contracting prostate cancer a study by Australian researchers has discovered'\n",
      "Word: DRINKING, Deprel: compound, Head: tea\n",
      "Word: green, Deprel: amod, Head: tea\n",
      "Word: tea, Deprel: nsubj, Head: reduce\n",
      "Word: can, Deprel: aux, Head: reduce\n",
      "Word: dramatically, Deprel: advmod, Head: reduce\n",
      "Word: reduce, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: risk\n",
      "Word: risk, Deprel: obj, Head: reduce\n",
      "Word: of, Deprel: case, Head: men\n",
      "Word: men, Deprel: nmod, Head: risk\n",
      "Word: contracting, Deprel: acl, Head: men\n",
      "Word: prostate, Deprel: compound, Head: cancer\n",
      "Word: cancer, Deprel: obj, Head: contracting\n",
      "Word: a, Deprel: det, Head: study\n",
      "Word: study, Deprel: nsubj, Head: discovered\n",
      "Word: by, Deprel: case, Head: researchers\n",
      "Word: Australian, Deprel: amod, Head: researchers\n",
      "Word: researchers, Deprel: nmod, Head: study\n",
      "Word: has, Deprel: aux, Head: discovered\n",
      "Word: discovered, Deprel: parataxis, Head: reduce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'So was Edie Falco the critically praised co-star of Frankie and Johnny'\n",
      "Word: So, Deprel: advmod, Head: was\n",
      "Word: was, Deprel: root, Head: ROOT\n",
      "Word: Edie, Deprel: nsubj, Head: was\n",
      "Word: Falco, Deprel: flat, Head: Edie\n",
      "Word: the, Deprel: det, Head: co-star\n",
      "Word: critically, Deprel: advmod, Head: praised\n",
      "Word: praised, Deprel: amod, Head: co-star\n",
      "Word: co-star, Deprel: appos, Head: Edie\n",
      "Word: of, Deprel: case, Head: Frankie\n",
      "Word: Frankie, Deprel: nmod, Head: co-star\n",
      "Word: and, Deprel: cc, Head: Johnny\n",
      "Word: Johnny, Deprel: conj, Head: Frankie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Edie Falco was not nominated for Frankie and Johnny'\n",
      "Word: Edie, Deprel: nsubj:pass, Head: nominated\n",
      "Word: Falco, Deprel: flat, Head: Edie\n",
      "Word: was, Deprel: aux:pass, Head: nominated\n",
      "Word: not, Deprel: advmod, Head: nominated\n",
      "Word: nominated, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: Frankie\n",
      "Word: Frankie, Deprel: obl, Head: nominated\n",
      "Word: and, Deprel: cc, Head: Johnny\n",
      "Word: Johnny, Deprel: conj, Head: Frankie\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'John Hickenlooper had 65 percent of the vote to 35 percent for City Auditor Don Mares'\n",
      "Word: John, Deprel: nsubj, Head: had\n",
      "Word: Hickenlooper, Deprel: flat, Head: John\n",
      "Word: had, Deprel: root, Head: ROOT\n",
      "Word: 65, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: had\n",
      "Word: of, Deprel: case, Head: vote\n",
      "Word: the, Deprel: det, Head: vote\n",
      "Word: vote, Deprel: nmod, Head: percent\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 35, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: had\n",
      "Word: for, Deprel: case, Head: Don\n",
      "Word: City, Deprel: compound, Head: Auditor\n",
      "Word: Auditor, Deprel: compound, Head: Don\n",
      "Word: Don, Deprel: obl, Head: had\n",
      "Word: Mares, Deprel: flat, Head: Don\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hickenlooper clobbered city Auditor Don Mares 46 in the Tuesday runoff'\n",
      "Word: Hickenlooper, Deprel: nsubj, Head: clobbered\n",
      "Word: clobbered, Deprel: root, Head: ROOT\n",
      "Word: city, Deprel: compound, Head: Auditor\n",
      "Word: Auditor, Deprel: obj, Head: clobbered\n",
      "Word: Don, Deprel: flat, Head: Auditor\n",
      "Word: Mares, Deprel: flat, Head: Auditor\n",
      "Word: 46, Deprel: nummod, Head: Auditor\n",
      "Word: in, Deprel: case, Head: runoff\n",
      "Word: the, Deprel: det, Head: runoff\n",
      "Word: Tuesday, Deprel: compound, Head: runoff\n",
      "Word: runoff, Deprel: obl, Head: clobbered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Forecasters said warnings might go up for Cuba later Thursday'\n",
      "Word: Forecasters, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: warnings, Deprel: nsubj, Head: go\n",
      "Word: might, Deprel: aux, Head: go\n",
      "Word: go, Deprel: ccomp, Head: said\n",
      "Word: up, Deprel: compound:prt, Head: go\n",
      "Word: for, Deprel: case, Head: Cuba\n",
      "Word: Cuba, Deprel: obl, Head: go\n",
      "Word: later, Deprel: advmod, Head: Thursday\n",
      "Word: Thursday, Deprel: obl:tmod, Head: go\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Watches or warnings could be issued for eastern Cuba later on Thursday'\n",
      "Word: Watches, Deprel: nsubj:pass, Head: issued\n",
      "Word: or, Deprel: cc, Head: warnings\n",
      "Word: warnings, Deprel: conj, Head: Watches\n",
      "Word: could, Deprel: aux, Head: issued\n",
      "Word: be, Deprel: aux:pass, Head: issued\n",
      "Word: issued, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: Cuba\n",
      "Word: eastern, Deprel: amod, Head: Cuba\n",
      "Word: Cuba, Deprel: obl, Head: issued\n",
      "Word: later, Deprel: advmod, Head: issued\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: issued\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shiites make up 20 percent of the country s population'\n",
      "Word: Shiites, Deprel: nsubj, Head: make\n",
      "Word: make, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: make\n",
      "Word: 20, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: make\n",
      "Word: of, Deprel: case, Head: population\n",
      "Word: the, Deprel: det, Head: country\n",
      "Word: country, Deprel: nmod:poss, Head: population\n",
      "Word: s, Deprel: case, Head: country\n",
      "Word: population, Deprel: nmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Sunnis make up 77 percent of Pakistan s population Shiites 20 percent'\n",
      "Word: Sunnis, Deprel: nsubj, Head: make\n",
      "Word: make, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: make\n",
      "Word: 77, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: make\n",
      "Word: of, Deprel: case, Head: Shiites\n",
      "Word: Pakistan, Deprel: nmod:poss, Head: Shiites\n",
      "Word: s, Deprel: case, Head: Pakistan\n",
      "Word: population, Deprel: compound, Head: Shiites\n",
      "Word: Shiites, Deprel: nmod, Head: percent\n",
      "Word: 20, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: make\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The CWA which represents more than 2,300 Comcast employees called that excessive when a typical union employee makes about 27,000 a year'\n",
      "Word: The, Deprel: det, Head: CWA\n",
      "Word: CWA, Deprel: nsubj, Head: called\n",
      "Word: which, Deprel: nsubj, Head: represents\n",
      "Word: represents, Deprel: acl:relcl, Head: CWA\n",
      "Word: more, Deprel: advmod, Head: 2,300\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 2,300, Deprel: nummod, Head: employees\n",
      "Word: Comcast, Deprel: compound, Head: employees\n",
      "Word: employees, Deprel: obj, Head: represents\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: det, Head: excessive\n",
      "Word: excessive, Deprel: xcomp, Head: called\n",
      "Word: when, Deprel: advmod, Head: makes\n",
      "Word: a, Deprel: det, Head: employee\n",
      "Word: typical, Deprel: amod, Head: employee\n",
      "Word: union, Deprel: compound, Head: employee\n",
      "Word: employee, Deprel: nsubj, Head: makes\n",
      "Word: makes, Deprel: advcl, Head: called\n",
      "Word: about, Deprel: advmod, Head: 27,000\n",
      "Word: 27,000, Deprel: obj, Head: makes\n",
      "Word: a, Deprel: det, Head: year\n",
      "Word: year, Deprel: nmod:tmod, Head: 27,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Communications Workers Union which represents more than 2,300 Comcast employees called the executive pay package excessive when a typical union employee makes about 27,000 annually'\n",
      "Word: The, Deprel: det, Head: Union\n",
      "Word: Communications, Deprel: compound, Head: Workers\n",
      "Word: Workers, Deprel: compound, Head: Union\n",
      "Word: Union, Deprel: nsubj, Head: called\n",
      "Word: which, Deprel: nsubj, Head: represents\n",
      "Word: represents, Deprel: acl:relcl, Head: Union\n",
      "Word: more, Deprel: advmod, Head: 2,300\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 2,300, Deprel: nummod, Head: employees\n",
      "Word: Comcast, Deprel: compound, Head: employees\n",
      "Word: employees, Deprel: obj, Head: represents\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: package\n",
      "Word: executive, Deprel: amod, Head: package\n",
      "Word: pay, Deprel: compound, Head: package\n",
      "Word: package, Deprel: obj, Head: called\n",
      "Word: excessive, Deprel: xcomp, Head: called\n",
      "Word: when, Deprel: advmod, Head: makes\n",
      "Word: a, Deprel: det, Head: employee\n",
      "Word: typical, Deprel: amod, Head: employee\n",
      "Word: union, Deprel: compound, Head: employee\n",
      "Word: employee, Deprel: nsubj, Head: makes\n",
      "Word: makes, Deprel: advcl, Head: called\n",
      "Word: about, Deprel: advmod, Head: 27,000\n",
      "Word: 27,000, Deprel: obj, Head: makes\n",
      "Word: annually, Deprel: advmod, Head: makes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The consumer group generated 4.47 billion of profit and 20 billion of revenue from January to June 53 of Citigroup s profit and revenue'\n",
      "Word: The, Deprel: det, Head: group\n",
      "Word: consumer, Deprel: compound, Head: group\n",
      "Word: group, Deprel: nsubj, Head: generated\n",
      "Word: generated, Deprel: root, Head: ROOT\n",
      "Word: 4.47, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obj, Head: generated\n",
      "Word: of, Deprel: case, Head: profit\n",
      "Word: profit, Deprel: nmod, Head: billion\n",
      "Word: and, Deprel: cc, Head: billion\n",
      "Word: 20, Deprel: nummod, Head: billion\n",
      "Word: billion, Deprel: conj, Head: billion\n",
      "Word: of, Deprel: case, Head: revenue\n",
      "Word: revenue, Deprel: nmod, Head: billion\n",
      "Word: from, Deprel: case, Head: January\n",
      "Word: January, Deprel: obl, Head: generated\n",
      "Word: to, Deprel: case, Head: June\n",
      "Word: June, Deprel: obl, Head: generated\n",
      "Word: 53, Deprel: nummod, Head: June\n",
      "Word: of, Deprel: case, Head: profit\n",
      "Word: Citigroup, Deprel: nmod:poss, Head: profit\n",
      "Word: s, Deprel: case, Head: Citigroup\n",
      "Word: profit, Deprel: nmod, Head: June\n",
      "Word: and, Deprel: cc, Head: revenue\n",
      "Word: revenue, Deprel: conj, Head: profit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It generated 4.47 billion of profit and 20 billion of revenue in the year s first half 53 percent of Citigroup s totals'\n",
      "Word: It, Deprel: nsubj, Head: generated\n",
      "Word: generated, Deprel: root, Head: ROOT\n",
      "Word: 4.47, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obj, Head: generated\n",
      "Word: of, Deprel: case, Head: profit\n",
      "Word: profit, Deprel: nmod, Head: billion\n",
      "Word: and, Deprel: cc, Head: billion\n",
      "Word: 20, Deprel: nummod, Head: billion\n",
      "Word: billion, Deprel: conj, Head: billion\n",
      "Word: of, Deprel: case, Head: revenue\n",
      "Word: revenue, Deprel: nmod, Head: billion\n",
      "Word: in, Deprel: case, Head: half\n",
      "Word: the, Deprel: det, Head: year\n",
      "Word: year, Deprel: nmod:poss, Head: half\n",
      "Word: s, Deprel: case, Head: year\n",
      "Word: first, Deprel: amod, Head: half\n",
      "Word: half, Deprel: obl, Head: generated\n",
      "Word: 53, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: appos, Head: half\n",
      "Word: of, Deprel: case, Head: totals\n",
      "Word: Citigroup, Deprel: nmod:poss, Head: totals\n",
      "Word: s, Deprel: case, Head: Citigroup\n",
      "Word: totals, Deprel: nmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'GALLOWAY TOWNSHIP N.J Annika Sorenstam drew the crowds Michelle Wie got the publicity but Angela Stanford took her first LPGA victory'\n",
      "Word: GALLOWAY, Deprel: compound, Head: TOWNSHIP\n",
      "Word: TOWNSHIP, Deprel: compound, Head: N.J\n",
      "Word: N.J, Deprel: compound, Head: Sorenstam\n",
      "Word: Annika, Deprel: compound, Head: Sorenstam\n",
      "Word: Sorenstam, Deprel: nsubj, Head: drew\n",
      "Word: drew, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: crowds\n",
      "Word: crowds, Deprel: obj, Head: drew\n",
      "Word: Michelle, Deprel: nsubj, Head: got\n",
      "Word: Wie, Deprel: flat, Head: Michelle\n",
      "Word: got, Deprel: acl:relcl, Head: crowds\n",
      "Word: the, Deprel: det, Head: publicity\n",
      "Word: publicity, Deprel: obj, Head: got\n",
      "Word: but, Deprel: cc, Head: took\n",
      "Word: Angela, Deprel: nsubj, Head: took\n",
      "Word: Stanford, Deprel: flat, Head: Angela\n",
      "Word: took, Deprel: conj, Head: drew\n",
      "Word: her, Deprel: nmod:poss, Head: victory\n",
      "Word: first, Deprel: amod, Head: victory\n",
      "Word: LPGA, Deprel: compound, Head: victory\n",
      "Word: victory, Deprel: obj, Head: took\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'GALLOWAY TOWNSHIP N.J Annika Sorenstam and Michelle Wie drew the crowds but Angela Stanford took her first LPGA victory'\n",
      "Word: GALLOWAY, Deprel: compound, Head: TOWNSHIP\n",
      "Word: TOWNSHIP, Deprel: compound, Head: N.J\n",
      "Word: N.J, Deprel: compound, Head: Annika\n",
      "Word: Annika, Deprel: nsubj, Head: drew\n",
      "Word: Sorenstam, Deprel: flat, Head: Annika\n",
      "Word: and, Deprel: cc, Head: Michelle\n",
      "Word: Michelle, Deprel: conj, Head: Annika\n",
      "Word: Wie, Deprel: flat, Head: Michelle\n",
      "Word: drew, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: crowds\n",
      "Word: crowds, Deprel: obj, Head: drew\n",
      "Word: but, Deprel: cc, Head: took\n",
      "Word: Angela, Deprel: nsubj, Head: took\n",
      "Word: Stanford, Deprel: flat, Head: Angela\n",
      "Word: took, Deprel: conj, Head: drew\n",
      "Word: her, Deprel: nmod:poss, Head: victory\n",
      "Word: first, Deprel: amod, Head: victory\n",
      "Word: LPGA, Deprel: compound, Head: victory\n",
      "Word: victory, Deprel: obj, Head: took\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Saddam is gone but we want the U.S occupation to end said Hit resident Abu Qasim'\n",
      "Word: Saddam, Deprel: nsubj, Head: gone\n",
      "Word: is, Deprel: cop, Head: gone\n",
      "Word: gone, Deprel: root, Head: ROOT\n",
      "Word: but, Deprel: cc, Head: want\n",
      "Word: we, Deprel: nsubj, Head: want\n",
      "Word: want, Deprel: conj, Head: gone\n",
      "Word: the, Deprel: det, Head: occupation\n",
      "Word: U.S, Deprel: compound, Head: occupation\n",
      "Word: occupation, Deprel: obj, Head: want\n",
      "Word: to, Deprel: mark, Head: end\n",
      "Word: end, Deprel: acl, Head: occupation\n",
      "Word: said, Deprel: advcl, Head: want\n",
      "Word: Hit, Deprel: compound, Head: resident\n",
      "Word: resident, Deprel: compound, Head: Abu\n",
      "Word: Abu, Deprel: obj, Head: said\n",
      "Word: Qasim, Deprel: flat, Head: Abu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Saddam is gone but we want the U.S occupation to end'\n",
      "Word: Saddam, Deprel: nsubj, Head: gone\n",
      "Word: is, Deprel: cop, Head: gone\n",
      "Word: gone, Deprel: root, Head: ROOT\n",
      "Word: but, Deprel: cc, Head: want\n",
      "Word: we, Deprel: nsubj, Head: want\n",
      "Word: want, Deprel: conj, Head: gone\n",
      "Word: the, Deprel: det, Head: occupation\n",
      "Word: U.S, Deprel: compound, Head: occupation\n",
      "Word: occupation, Deprel: obj, Head: want\n",
      "Word: to, Deprel: mark, Head: end\n",
      "Word: end, Deprel: acl, Head: occupation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Young has 28 days to file a response and ask the NASD for a hearing'\n",
      "Word: Young, Deprel: nsubj, Head: has\n",
      "Word: has, Deprel: root, Head: ROOT\n",
      "Word: 28, Deprel: nummod, Head: days\n",
      "Word: days, Deprel: obj, Head: has\n",
      "Word: to, Deprel: mark, Head: file\n",
      "Word: file, Deprel: advcl, Head: has\n",
      "Word: a, Deprel: det, Head: response\n",
      "Word: response, Deprel: obj, Head: file\n",
      "Word: and, Deprel: cc, Head: ask\n",
      "Word: ask, Deprel: conj, Head: file\n",
      "Word: the, Deprel: det, Head: NASD\n",
      "Word: NASD, Deprel: iobj, Head: ask\n",
      "Word: for, Deprel: case, Head: hearing\n",
      "Word: a, Deprel: det, Head: hearing\n",
      "Word: hearing, Deprel: obl, Head: ask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Under NASD regulations Mr Young can file a response and request a hearing before an NASD panel'\n",
      "Word: Under, Deprel: case, Head: regulations\n",
      "Word: NASD, Deprel: compound, Head: regulations\n",
      "Word: regulations, Deprel: obl, Head: file\n",
      "Word: Mr, Deprel: nsubj, Head: file\n",
      "Word: Young, Deprel: flat, Head: Mr\n",
      "Word: can, Deprel: aux, Head: file\n",
      "Word: file, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: response\n",
      "Word: response, Deprel: obj, Head: file\n",
      "Word: and, Deprel: cc, Head: request\n",
      "Word: request, Deprel: conj, Head: file\n",
      "Word: a, Deprel: det, Head: hearing\n",
      "Word: hearing, Deprel: obj, Head: request\n",
      "Word: before, Deprel: case, Head: panel\n",
      "Word: an, Deprel: det, Head: panel\n",
      "Word: NASD, Deprel: compound, Head: panel\n",
      "Word: panel, Deprel: nmod, Head: hearing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'British Airways New York-to-London runs will end in October'\n",
      "Word: British, Deprel: amod, Head: Airways\n",
      "Word: Airways, Deprel: compound, Head: runs\n",
      "Word: New, Deprel: amod, Head: York-to-London\n",
      "Word: York-to-London, Deprel: compound, Head: runs\n",
      "Word: runs, Deprel: nsubj, Head: end\n",
      "Word: will, Deprel: aux, Head: end\n",
      "Word: end, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: October\n",
      "Word: October, Deprel: obl, Head: end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'British Airways plans to retire its seven Concordes at the end of October'\n",
      "Word: British, Deprel: amod, Head: Airways\n",
      "Word: Airways, Deprel: nsubj, Head: plans\n",
      "Word: plans, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: retire\n",
      "Word: retire, Deprel: xcomp, Head: plans\n",
      "Word: its, Deprel: nmod:poss, Head: Concordes\n",
      "Word: seven, Deprel: nummod, Head: Concordes\n",
      "Word: Concordes, Deprel: obj, Head: retire\n",
      "Word: at, Deprel: case, Head: end\n",
      "Word: the, Deprel: det, Head: end\n",
      "Word: end, Deprel: obl, Head: retire\n",
      "Word: of, Deprel: case, Head: October\n",
      "Word: October, Deprel: nmod, Head: end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new policy gives greatest weight to grades test scores and a student s high school curriculum'\n",
      "Word: The, Deprel: det, Head: policy\n",
      "Word: new, Deprel: amod, Head: policy\n",
      "Word: policy, Deprel: nsubj, Head: gives\n",
      "Word: gives, Deprel: root, Head: ROOT\n",
      "Word: greatest, Deprel: amod, Head: weight\n",
      "Word: weight, Deprel: obj, Head: gives\n",
      "Word: to, Deprel: case, Head: scores\n",
      "Word: grades, Deprel: compound, Head: scores\n",
      "Word: test, Deprel: compound, Head: scores\n",
      "Word: scores, Deprel: obl, Head: gives\n",
      "Word: and, Deprel: cc, Head: curriculum\n",
      "Word: a, Deprel: det, Head: student\n",
      "Word: student, Deprel: nmod:poss, Head: curriculum\n",
      "Word: s, Deprel: case, Head: student\n",
      "Word: high, Deprel: amod, Head: school\n",
      "Word: school, Deprel: compound, Head: curriculum\n",
      "Word: curriculum, Deprel: conj, Head: scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Academic achievement including grades test scores and high school curriculum are given the highest priority'\n",
      "Word: Academic, Deprel: amod, Head: achievement\n",
      "Word: achievement, Deprel: nsubj:pass, Head: given\n",
      "Word: including, Deprel: case, Head: scores\n",
      "Word: grades, Deprel: compound, Head: scores\n",
      "Word: test, Deprel: compound, Head: scores\n",
      "Word: scores, Deprel: nmod, Head: achievement\n",
      "Word: and, Deprel: cc, Head: curriculum\n",
      "Word: high, Deprel: amod, Head: school\n",
      "Word: school, Deprel: compound, Head: curriculum\n",
      "Word: curriculum, Deprel: conj, Head: scores\n",
      "Word: are, Deprel: aux:pass, Head: given\n",
      "Word: given, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: priority\n",
      "Word: highest, Deprel: amod, Head: priority\n",
      "Word: priority, Deprel: obj, Head: given\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new version W32/Sobig.C-mm had already reached a high level outbreak status by Monday according to security analysts'\n",
      "Word: The, Deprel: det, Head: W32/Sobig.C-mm\n",
      "Word: new, Deprel: amod, Head: W32/Sobig.C-mm\n",
      "Word: version, Deprel: compound, Head: W32/Sobig.C-mm\n",
      "Word: W32/Sobig.C-mm, Deprel: nsubj, Head: reached\n",
      "Word: had, Deprel: aux, Head: reached\n",
      "Word: already, Deprel: advmod, Head: reached\n",
      "Word: reached, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: status\n",
      "Word: high, Deprel: amod, Head: level\n",
      "Word: level, Deprel: compound, Head: status\n",
      "Word: outbreak, Deprel: compound, Head: status\n",
      "Word: status, Deprel: obj, Head: reached\n",
      "Word: by, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: reached\n",
      "Word: according, Deprel: case, Head: analysts\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: security, Deprel: compound, Head: analysts\n",
      "Word: analysts, Deprel: obl, Head: reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Security analysts said the new version W32/Sobig.C-mm had already reached a high level outbreak status by mid-afternoon on Monday'\n",
      "Word: Security, Deprel: compound, Head: analysts\n",
      "Word: analysts, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: version\n",
      "Word: new, Deprel: amod, Head: version\n",
      "Word: version, Deprel: nsubj, Head: reached\n",
      "Word: W32/Sobig.C-mm, Deprel: appos, Head: version\n",
      "Word: had, Deprel: aux, Head: reached\n",
      "Word: already, Deprel: advmod, Head: reached\n",
      "Word: reached, Deprel: ccomp, Head: said\n",
      "Word: a, Deprel: det, Head: status\n",
      "Word: high, Deprel: amod, Head: level\n",
      "Word: level, Deprel: compound, Head: status\n",
      "Word: outbreak, Deprel: compound, Head: status\n",
      "Word: status, Deprel: obj, Head: reached\n",
      "Word: by, Deprel: case, Head: mid-afternoon\n",
      "Word: mid-afternoon, Deprel: obl, Head: reached\n",
      "Word: on, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: nmod, Head: mid-afternoon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The only other person who had not been accounted for Sunday was a man from Fort Worth Texas'\n",
      "Word: The, Deprel: det, Head: person\n",
      "Word: only, Deprel: amod, Head: person\n",
      "Word: other, Deprel: amod, Head: person\n",
      "Word: person, Deprel: nsubj, Head: man\n",
      "Word: who, Deprel: nsubj:pass, Head: accounted\n",
      "Word: had, Deprel: aux, Head: accounted\n",
      "Word: not, Deprel: advmod, Head: accounted\n",
      "Word: been, Deprel: aux:pass, Head: accounted\n",
      "Word: accounted, Deprel: acl:relcl, Head: person\n",
      "Word: for, Deprel: case, Head: Sunday\n",
      "Word: Sunday, Deprel: obl:tmod, Head: accounted\n",
      "Word: was, Deprel: cop, Head: man\n",
      "Word: a, Deprel: det, Head: man\n",
      "Word: man, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: Texas\n",
      "Word: Fort, Deprel: compound, Head: Worth\n",
      "Word: Worth, Deprel: compound, Head: Texas\n",
      "Word: Texas, Deprel: nmod, Head: man\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Another person a man from Fort Worth Texas also was missing'\n",
      "Word: Another, Deprel: det, Head: person\n",
      "Word: person, Deprel: nsubj, Head: missing\n",
      "Word: a, Deprel: det, Head: man\n",
      "Word: man, Deprel: appos, Head: person\n",
      "Word: from, Deprel: case, Head: Texas\n",
      "Word: Fort, Deprel: nmod, Head: man\n",
      "Word: Worth, Deprel: flat, Head: Fort\n",
      "Word: Texas, Deprel: flat, Head: Fort\n",
      "Word: also, Deprel: advmod, Head: missing\n",
      "Word: was, Deprel: cop, Head: missing\n",
      "Word: missing, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Stocks dipped lower Tuesday as investors opted to cash in profits from Monday s big rally despite a trio of reports suggesting modest improvement in the economy'\n",
      "Word: Stocks, Deprel: nsubj, Head: dipped\n",
      "Word: dipped, Deprel: root, Head: ROOT\n",
      "Word: lower, Deprel: xcomp, Head: dipped\n",
      "Word: Tuesday, Deprel: obl:tmod, Head: dipped\n",
      "Word: as, Deprel: mark, Head: opted\n",
      "Word: investors, Deprel: nsubj, Head: opted\n",
      "Word: opted, Deprel: advcl, Head: dipped\n",
      "Word: to, Deprel: mark, Head: cash\n",
      "Word: cash, Deprel: xcomp, Head: opted\n",
      "Word: in, Deprel: compound:prt, Head: cash\n",
      "Word: profits, Deprel: obj, Head: cash\n",
      "Word: from, Deprel: case, Head: rally\n",
      "Word: Monday, Deprel: nmod:poss, Head: rally\n",
      "Word: s, Deprel: case, Head: Monday\n",
      "Word: big, Deprel: amod, Head: rally\n",
      "Word: rally, Deprel: obl, Head: cash\n",
      "Word: despite, Deprel: case, Head: trio\n",
      "Word: a, Deprel: det, Head: trio\n",
      "Word: trio, Deprel: obl, Head: cash\n",
      "Word: of, Deprel: case, Head: reports\n",
      "Word: reports, Deprel: nmod, Head: trio\n",
      "Word: suggesting, Deprel: acl, Head: reports\n",
      "Word: modest, Deprel: amod, Head: improvement\n",
      "Word: improvement, Deprel: obj, Head: suggesting\n",
      "Word: in, Deprel: case, Head: economy\n",
      "Word: the, Deprel: det, Head: economy\n",
      "Word: economy, Deprel: nmod, Head: improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Wall Street moved tentatively higher Tuesday as investors weighed a trio of reports showing modest economic improvement against an urge to cash in profits from Monday s big rally'\n",
      "Word: Wall, Deprel: compound, Head: Street\n",
      "Word: Street, Deprel: nsubj, Head: moved\n",
      "Word: moved, Deprel: root, Head: ROOT\n",
      "Word: tentatively, Deprel: advmod, Head: moved\n",
      "Word: higher, Deprel: advmod, Head: moved\n",
      "Word: Tuesday, Deprel: obl:tmod, Head: moved\n",
      "Word: as, Deprel: mark, Head: weighed\n",
      "Word: investors, Deprel: nsubj, Head: weighed\n",
      "Word: weighed, Deprel: advcl, Head: moved\n",
      "Word: a, Deprel: det, Head: trio\n",
      "Word: trio, Deprel: obj, Head: weighed\n",
      "Word: of, Deprel: case, Head: reports\n",
      "Word: reports, Deprel: nmod, Head: trio\n",
      "Word: showing, Deprel: acl, Head: reports\n",
      "Word: modest, Deprel: amod, Head: improvement\n",
      "Word: economic, Deprel: amod, Head: improvement\n",
      "Word: improvement, Deprel: obj, Head: showing\n",
      "Word: against, Deprel: case, Head: urge\n",
      "Word: an, Deprel: det, Head: urge\n",
      "Word: urge, Deprel: obl, Head: showing\n",
      "Word: to, Deprel: mark, Head: cash\n",
      "Word: cash, Deprel: acl, Head: urge\n",
      "Word: in, Deprel: compound:prt, Head: cash\n",
      "Word: profits, Deprel: obj, Head: cash\n",
      "Word: from, Deprel: case, Head: rally\n",
      "Word: Monday, Deprel: nmod:poss, Head: rally\n",
      "Word: s, Deprel: case, Head: Monday\n",
      "Word: big, Deprel: amod, Head: rally\n",
      "Word: rally, Deprel: obl, Head: cash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'From the start however the United States declared goal was not just to topple Saddam but to stabilize Iraq and install a friendly government'\n",
      "Word: From, Deprel: case, Head: start\n",
      "Word: the, Deprel: det, Head: start\n",
      "Word: start, Deprel: obl, Head: topple\n",
      "Word: however, Deprel: advmod, Head: topple\n",
      "Word: the, Deprel: det, Head: States\n",
      "Word: United, Deprel: amod, Head: States\n",
      "Word: States, Deprel: nsubj, Head: declared\n",
      "Word: declared, Deprel: csubj:outer, Head: topple\n",
      "Word: goal, Deprel: nsubj:outer, Head: topple\n",
      "Word: was, Deprel: cop, Head: topple\n",
      "Word: not, Deprel: advmod, Head: topple\n",
      "Word: just, Deprel: advmod, Head: topple\n",
      "Word: to, Deprel: mark, Head: topple\n",
      "Word: topple, Deprel: root, Head: ROOT\n",
      "Word: Saddam, Deprel: obj, Head: topple\n",
      "Word: but, Deprel: cc, Head: stabilize\n",
      "Word: to, Deprel: mark, Head: stabilize\n",
      "Word: stabilize, Deprel: conj, Head: topple\n",
      "Word: Iraq, Deprel: obj, Head: stabilize\n",
      "Word: and, Deprel: cc, Head: install\n",
      "Word: install, Deprel: conj, Head: stabilize\n",
      "Word: a, Deprel: det, Head: government\n",
      "Word: friendly, Deprel: amod, Head: government\n",
      "Word: government, Deprel: obj, Head: install\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But the United States ultimate goal was not just to topple Mr Hussein but to stabilize the country and install a friendly government'\n",
      "Word: But, Deprel: cc, Head: topple\n",
      "Word: the, Deprel: det, Head: goal\n",
      "Word: United, Deprel: amod, Head: States\n",
      "Word: States, Deprel: compound, Head: goal\n",
      "Word: ultimate, Deprel: amod, Head: goal\n",
      "Word: goal, Deprel: nsubj:outer, Head: topple\n",
      "Word: was, Deprel: cop, Head: topple\n",
      "Word: not, Deprel: advmod, Head: topple\n",
      "Word: just, Deprel: advmod, Head: topple\n",
      "Word: to, Deprel: mark, Head: topple\n",
      "Word: topple, Deprel: root, Head: ROOT\n",
      "Word: Mr, Deprel: obj, Head: topple\n",
      "Word: Hussein, Deprel: flat, Head: Mr\n",
      "Word: but, Deprel: cc, Head: stabilize\n",
      "Word: to, Deprel: mark, Head: stabilize\n",
      "Word: stabilize, Deprel: conj, Head: topple\n",
      "Word: the, Deprel: det, Head: country\n",
      "Word: country, Deprel: obj, Head: stabilize\n",
      "Word: and, Deprel: cc, Head: install\n",
      "Word: install, Deprel: conj, Head: stabilize\n",
      "Word: a, Deprel: det, Head: government\n",
      "Word: friendly, Deprel: amod, Head: government\n",
      "Word: government, Deprel: obj, Head: install\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index SPX gave up 11.91 points or 1.19 percent at 986.60'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broader, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: amod, Head: s\n",
      "Word: s, Deprel: compound, Head: SPX\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: gave\n",
      "Word: gave, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: gave\n",
      "Word: 11.91, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: gave\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.19, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 986.60\n",
      "Word: 986.60, Deprel: obl, Head: gave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index IXIC declined 16.68 points or 1.01 percent at 1,636.94'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-laced, Deprel: amod, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: declined\n",
      "Word: declined, Deprel: root, Head: ROOT\n",
      "Word: 16.68, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: declined\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.01, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 1,636.94\n",
      "Word: 1,636.94, Deprel: obl, Head: declined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'AFTRA members approved the merger by a vote of 75.88 to 24.12'\n",
      "Word: AFTRA, Deprel: compound, Head: members\n",
      "Word: members, Deprel: nsubj, Head: approved\n",
      "Word: approved, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: merger\n",
      "Word: merger, Deprel: obj, Head: approved\n",
      "Word: by, Deprel: case, Head: vote\n",
      "Word: a, Deprel: det, Head: vote\n",
      "Word: vote, Deprel: obl, Head: approved\n",
      "Word: of, Deprel: case, Head: 75.88\n",
      "Word: 75.88, Deprel: nmod, Head: vote\n",
      "Word: to, Deprel: case, Head: 24.12\n",
      "Word: 24.12, Deprel: nmod, Head: 75.88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'AFTRA on the other hand approved the merger by a whopping 75 percent'\n",
      "Word: AFTRA, Deprel: nsubj, Head: approved\n",
      "Word: on, Deprel: case, Head: hand\n",
      "Word: the, Deprel: det, Head: hand\n",
      "Word: other, Deprel: amod, Head: hand\n",
      "Word: hand, Deprel: obl, Head: approved\n",
      "Word: approved, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: merger\n",
      "Word: merger, Deprel: obj, Head: approved\n",
      "Word: by, Deprel: case, Head: percent\n",
      "Word: a, Deprel: det, Head: percent\n",
      "Word: whopping, Deprel: amod, Head: percent\n",
      "Word: 75, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: approved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The currency briefly weakened slightly on Monday to trade at 55.34/39 not far from its record low of 55.75'\n",
      "Word: The, Deprel: det, Head: currency\n",
      "Word: currency, Deprel: nsubj, Head: weakened\n",
      "Word: briefly, Deprel: advmod, Head: weakened\n",
      "Word: weakened, Deprel: root, Head: ROOT\n",
      "Word: slightly, Deprel: advmod, Head: weakened\n",
      "Word: on, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: weakened\n",
      "Word: to, Deprel: mark, Head: trade\n",
      "Word: trade, Deprel: advcl, Head: weakened\n",
      "Word: at, Deprel: case, Head: 55.34/39\n",
      "Word: 55.34/39, Deprel: obl, Head: trade\n",
      "Word: not, Deprel: advmod, Head: far\n",
      "Word: far, Deprel: advmod, Head: trade\n",
      "Word: from, Deprel: case, Head: low\n",
      "Word: its, Deprel: nmod:poss, Head: low\n",
      "Word: record, Deprel: compound, Head: low\n",
      "Word: low, Deprel: obl, Head: far\n",
      "Word: of, Deprel: case, Head: 55.75\n",
      "Word: 55.75, Deprel: nmod, Head: low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The currency briefly weakened on Monday morning but rebounded to trade at 55.25/29 little changed from Friday'\n",
      "Word: The, Deprel: det, Head: currency\n",
      "Word: currency, Deprel: nsubj, Head: weakened\n",
      "Word: briefly, Deprel: advmod, Head: weakened\n",
      "Word: weakened, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: morning\n",
      "Word: Monday, Deprel: compound, Head: morning\n",
      "Word: morning, Deprel: obl, Head: weakened\n",
      "Word: but, Deprel: cc, Head: rebounded\n",
      "Word: rebounded, Deprel: conj, Head: weakened\n",
      "Word: to, Deprel: case, Head: trade\n",
      "Word: trade, Deprel: obl, Head: rebounded\n",
      "Word: at, Deprel: case, Head: 55.25/29\n",
      "Word: 55.25/29, Deprel: nummod, Head: little\n",
      "Word: little, Deprel: advmod, Head: changed\n",
      "Word: changed, Deprel: advcl, Head: rebounded\n",
      "Word: from, Deprel: case, Head: Friday\n",
      "Word: Friday, Deprel: obl, Head: changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'While some other parts of Africa have been used as staging grounds for the terror group Malawi previously had not been a major focus of investigations into al-Qaida'\n",
      "Word: While, Deprel: mark, Head: used\n",
      "Word: some, Deprel: det, Head: parts\n",
      "Word: other, Deprel: amod, Head: parts\n",
      "Word: parts, Deprel: nsubj:pass, Head: used\n",
      "Word: of, Deprel: case, Head: Africa\n",
      "Word: Africa, Deprel: nmod, Head: parts\n",
      "Word: have, Deprel: aux, Head: used\n",
      "Word: been, Deprel: aux:pass, Head: used\n",
      "Word: used, Deprel: advcl, Head: focus\n",
      "Word: as, Deprel: case, Head: grounds\n",
      "Word: staging, Deprel: compound, Head: grounds\n",
      "Word: grounds, Deprel: obl, Head: used\n",
      "Word: for, Deprel: case, Head: group\n",
      "Word: the, Deprel: det, Head: group\n",
      "Word: terror, Deprel: compound, Head: group\n",
      "Word: group, Deprel: nmod, Head: grounds\n",
      "Word: Malawi, Deprel: nsubj, Head: focus\n",
      "Word: previously, Deprel: advmod, Head: focus\n",
      "Word: had, Deprel: aux, Head: focus\n",
      "Word: not, Deprel: advmod, Head: focus\n",
      "Word: been, Deprel: cop, Head: focus\n",
      "Word: a, Deprel: det, Head: focus\n",
      "Word: major, Deprel: amod, Head: focus\n",
      "Word: focus, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: investigations\n",
      "Word: investigations, Deprel: nmod, Head: focus\n",
      "Word: into, Deprel: case, Head: al-Qaida\n",
      "Word: al-Qaida, Deprel: nmod, Head: investigations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'While some other parts of Africa have been used as Al Qaeda staging grounds Malawi had previously not been a major focus of investigations into the group'\n",
      "Word: While, Deprel: mark, Head: used\n",
      "Word: some, Deprel: det, Head: parts\n",
      "Word: other, Deprel: amod, Head: parts\n",
      "Word: parts, Deprel: nsubj:pass, Head: used\n",
      "Word: of, Deprel: case, Head: Africa\n",
      "Word: Africa, Deprel: nmod, Head: parts\n",
      "Word: have, Deprel: aux, Head: used\n",
      "Word: been, Deprel: aux:pass, Head: used\n",
      "Word: used, Deprel: advcl, Head: focus\n",
      "Word: as, Deprel: case, Head: Malawi\n",
      "Word: Al, Deprel: compound, Head: Qaeda\n",
      "Word: Qaeda, Deprel: compound, Head: grounds\n",
      "Word: staging, Deprel: compound, Head: grounds\n",
      "Word: grounds, Deprel: compound, Head: Malawi\n",
      "Word: Malawi, Deprel: nsubj, Head: focus\n",
      "Word: had, Deprel: aux, Head: focus\n",
      "Word: previously, Deprel: advmod, Head: focus\n",
      "Word: not, Deprel: advmod, Head: focus\n",
      "Word: been, Deprel: cop, Head: focus\n",
      "Word: a, Deprel: det, Head: focus\n",
      "Word: major, Deprel: amod, Head: focus\n",
      "Word: focus, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: investigations\n",
      "Word: investigations, Deprel: nmod, Head: focus\n",
      "Word: into, Deprel: case, Head: group\n",
      "Word: the, Deprel: det, Head: group\n",
      "Word: group, Deprel: nmod, Head: investigations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Sunday a U.S soldier was killed and another injured in southern Iraq when a munitions dump exploded'\n",
      "Word: On, Deprel: case, Head: Sunday\n",
      "Word: Sunday, Deprel: obl, Head: killed\n",
      "Word: a, Deprel: det, Head: soldier\n",
      "Word: U.S, Deprel: compound, Head: soldier\n",
      "Word: soldier, Deprel: nsubj:pass, Head: killed\n",
      "Word: was, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: another\n",
      "Word: another, Deprel: nsubj:pass, Head: injured\n",
      "Word: injured, Deprel: conj, Head: killed\n",
      "Word: in, Deprel: case, Head: Iraq\n",
      "Word: southern, Deprel: amod, Head: Iraq\n",
      "Word: Iraq, Deprel: obl, Head: injured\n",
      "Word: when, Deprel: advmod, Head: exploded\n",
      "Word: a, Deprel: det, Head: dump\n",
      "Word: munitions, Deprel: compound, Head: dump\n",
      "Word: dump, Deprel: nsubj, Head: exploded\n",
      "Word: exploded, Deprel: advcl, Head: injured\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Sunday a U.S soldier was killed and another injured when a munitions dump they were guarding exploded in southern Iraq'\n",
      "Word: On, Deprel: case, Head: Sunday\n",
      "Word: Sunday, Deprel: obl, Head: killed\n",
      "Word: a, Deprel: det, Head: soldier\n",
      "Word: U.S, Deprel: compound, Head: soldier\n",
      "Word: soldier, Deprel: nsubj:pass, Head: killed\n",
      "Word: was, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: injured\n",
      "Word: another, Deprel: nsubj, Head: injured\n",
      "Word: injured, Deprel: conj, Head: killed\n",
      "Word: when, Deprel: advmod, Head: exploded\n",
      "Word: a, Deprel: det, Head: dump\n",
      "Word: munitions, Deprel: compound, Head: dump\n",
      "Word: dump, Deprel: nsubj, Head: exploded\n",
      "Word: they, Deprel: nsubj, Head: guarding\n",
      "Word: were, Deprel: aux, Head: guarding\n",
      "Word: guarding, Deprel: acl:relcl, Head: dump\n",
      "Word: exploded, Deprel: advcl, Head: killed\n",
      "Word: in, Deprel: case, Head: Iraq\n",
      "Word: southern, Deprel: amod, Head: Iraq\n",
      "Word: Iraq, Deprel: obl, Head: exploded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I m real excited to be a Cleveland Cavalier James said'\n",
      "Word: I, Deprel: nsubj, Head: excited\n",
      "Word: m, Deprel: cop, Head: excited\n",
      "Word: real, Deprel: advmod, Head: excited\n",
      "Word: excited, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: Cavalier\n",
      "Word: be, Deprel: cop, Head: Cavalier\n",
      "Word: a, Deprel: det, Head: Cavalier\n",
      "Word: Cleveland, Deprel: compound, Head: Cavalier\n",
      "Word: Cavalier, Deprel: xcomp, Head: excited\n",
      "Word: James, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: Cavalier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I m really excited about going to Cleveland James told ESPN.com'\n",
      "Word: I, Deprel: nsubj, Head: excited\n",
      "Word: m, Deprel: cop, Head: excited\n",
      "Word: really, Deprel: advmod, Head: excited\n",
      "Word: excited, Deprel: root, Head: ROOT\n",
      "Word: about, Deprel: mark, Head: going\n",
      "Word: going, Deprel: advcl, Head: excited\n",
      "Word: to, Deprel: case, Head: Cleveland\n",
      "Word: Cleveland, Deprel: obl, Head: going\n",
      "Word: James, Deprel: flat, Head: Cleveland\n",
      "Word: told, Deprel: parataxis, Head: excited\n",
      "Word: ESPN.com, Deprel: iobj, Head: told\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'According to law enforcement officials the person arrested was a known sophisticated hacker'\n",
      "Word: According, Deprel: case, Head: officials\n",
      "Word: to, Deprel: fixed, Head: According\n",
      "Word: law, Deprel: compound, Head: enforcement\n",
      "Word: enforcement, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: obl, Head: hacker\n",
      "Word: the, Deprel: det, Head: person\n",
      "Word: person, Deprel: nsubj, Head: hacker\n",
      "Word: arrested, Deprel: acl, Head: person\n",
      "Word: was, Deprel: cop, Head: hacker\n",
      "Word: a, Deprel: det, Head: hacker\n",
      "Word: known, Deprel: amod, Head: hacker\n",
      "Word: sophisticated, Deprel: amod, Head: hacker\n",
      "Word: hacker, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'According to law enforcement officials the individual decrypted passwords on the server'\n",
      "Word: According, Deprel: case, Head: officials\n",
      "Word: to, Deprel: fixed, Head: According\n",
      "Word: law, Deprel: compound, Head: enforcement\n",
      "Word: enforcement, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: obl, Head: decrypted\n",
      "Word: the, Deprel: det, Head: individual\n",
      "Word: individual, Deprel: nsubj, Head: decrypted\n",
      "Word: decrypted, Deprel: root, Head: ROOT\n",
      "Word: passwords, Deprel: obj, Head: decrypted\n",
      "Word: on, Deprel: case, Head: server\n",
      "Word: the, Deprel: det, Head: server\n",
      "Word: server, Deprel: obl, Head: decrypted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Excluding litigation charges RIM s loss narrowed even further to 1 cent a share'\n",
      "Word: Excluding, Deprel: case, Head: charges\n",
      "Word: litigation, Deprel: compound, Head: charges\n",
      "Word: charges, Deprel: obl, Head: narrowed\n",
      "Word: RIM, Deprel: nmod:poss, Head: loss\n",
      "Word: s, Deprel: case, Head: RIM\n",
      "Word: loss, Deprel: nsubj, Head: narrowed\n",
      "Word: narrowed, Deprel: root, Head: ROOT\n",
      "Word: even, Deprel: advmod, Head: further\n",
      "Word: further, Deprel: advmod, Head: narrowed\n",
      "Word: to, Deprel: case, Head: cent\n",
      "Word: 1, Deprel: nummod, Head: cent\n",
      "Word: cent, Deprel: obl, Head: narrowed\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:npmod, Head: cent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Excluding patent litigation RIM s loss for the quarter was 700,000 or 1 cent per share'\n",
      "Word: Excluding, Deprel: case, Head: loss\n",
      "Word: patent, Deprel: compound, Head: litigation\n",
      "Word: litigation, Deprel: compound, Head: RIM\n",
      "Word: RIM, Deprel: nmod:poss, Head: loss\n",
      "Word: s, Deprel: case, Head: RIM\n",
      "Word: loss, Deprel: nsubj, Head: 700,000\n",
      "Word: for, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: quarter, Deprel: nmod, Head: loss\n",
      "Word: was, Deprel: cop, Head: 700,000\n",
      "Word: 700,000, Deprel: root, Head: ROOT\n",
      "Word: or, Deprel: cc, Head: 1\n",
      "Word: 1, Deprel: nummod, Head: cent\n",
      "Word: cent, Deprel: conj, Head: 700,000\n",
      "Word: per, Deprel: case, Head: share\n",
      "Word: share, Deprel: nmod, Head: cent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broad Standard Poor s 500 Index SPX gained 19.72 points or 1.98 percent to 1,015.69'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broad, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: s\n",
      "Word: Poor, Deprel: amod, Head: s\n",
      "Word: s, Deprel: compound, Head: SPX\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: gained\n",
      "Word: gained, Deprel: root, Head: ROOT\n",
      "Word: 19.72, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: gained\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.98, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,015.69\n",
      "Word: 1,015.69, Deprel: obl, Head: gained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Dow Jones industrial average DJI jumped 2.09 percent while the Standard Poor s 500 Index SPX leapt 2.23 percent'\n",
      "Word: The, Deprel: det, Head: DJI\n",
      "Word: Dow, Deprel: compound, Head: average\n",
      "Word: Jones, Deprel: flat, Head: Dow\n",
      "Word: industrial, Deprel: compound, Head: average\n",
      "Word: average, Deprel: compound, Head: DJI\n",
      "Word: DJI, Deprel: nsubj, Head: jumped\n",
      "Word: jumped, Deprel: root, Head: ROOT\n",
      "Word: 2.09, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: jumped\n",
      "Word: while, Deprel: mark, Head: leapt\n",
      "Word: the, Deprel: det, Head: Poor\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: nmod:poss, Head: SPX\n",
      "Word: s, Deprel: case, Head: Poor\n",
      "Word: 500, Deprel: nummod, Head: Index\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: leapt\n",
      "Word: leapt, Deprel: advcl, Head: jumped\n",
      "Word: 2.23, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: leapt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It will also help reform the Royal Solomon Islands Police strengthen the courts and prisons system and protect key institutions such as the Finance Ministry from intimidation'\n",
      "Word: It, Deprel: nsubj, Head: help\n",
      "Word: will, Deprel: aux, Head: help\n",
      "Word: also, Deprel: advmod, Head: help\n",
      "Word: help, Deprel: root, Head: ROOT\n",
      "Word: reform, Deprel: xcomp, Head: help\n",
      "Word: the, Deprel: det, Head: Police\n",
      "Word: Royal, Deprel: amod, Head: Police\n",
      "Word: Solomon, Deprel: compound, Head: Islands\n",
      "Word: Islands, Deprel: compound, Head: Police\n",
      "Word: Police, Deprel: obj, Head: reform\n",
      "Word: strengthen, Deprel: xcomp, Head: reform\n",
      "Word: the, Deprel: det, Head: system\n",
      "Word: courts, Deprel: compound, Head: system\n",
      "Word: and, Deprel: cc, Head: prisons\n",
      "Word: prisons, Deprel: conj, Head: courts\n",
      "Word: system, Deprel: obj, Head: strengthen\n",
      "Word: and, Deprel: cc, Head: protect\n",
      "Word: protect, Deprel: conj, Head: strengthen\n",
      "Word: key, Deprel: amod, Head: institutions\n",
      "Word: institutions, Deprel: obj, Head: protect\n",
      "Word: such, Deprel: case, Head: Ministry\n",
      "Word: as, Deprel: fixed, Head: such\n",
      "Word: the, Deprel: det, Head: Ministry\n",
      "Word: Finance, Deprel: compound, Head: Ministry\n",
      "Word: Ministry, Deprel: nmod, Head: institutions\n",
      "Word: from, Deprel: case, Head: intimidation\n",
      "Word: intimidation, Deprel: obl, Head: protect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The intervention force will confiscate weapons reform the police strengthen the courts and prison system and protect key institutions such as the Finance Ministry'\n",
      "Word: The, Deprel: det, Head: force\n",
      "Word: intervention, Deprel: compound, Head: force\n",
      "Word: force, Deprel: nsubj, Head: confiscate\n",
      "Word: will, Deprel: aux, Head: confiscate\n",
      "Word: confiscate, Deprel: root, Head: ROOT\n",
      "Word: weapons, Deprel: compound, Head: reform\n",
      "Word: reform, Deprel: obj, Head: confiscate\n",
      "Word: the, Deprel: det, Head: police\n",
      "Word: police, Deprel: nsubj, Head: strengthen\n",
      "Word: strengthen, Deprel: acl:relcl, Head: reform\n",
      "Word: the, Deprel: det, Head: courts\n",
      "Word: courts, Deprel: obj, Head: strengthen\n",
      "Word: and, Deprel: cc, Head: system\n",
      "Word: prison, Deprel: compound, Head: system\n",
      "Word: system, Deprel: conj, Head: courts\n",
      "Word: and, Deprel: cc, Head: protect\n",
      "Word: protect, Deprel: conj, Head: strengthen\n",
      "Word: key, Deprel: amod, Head: institutions\n",
      "Word: institutions, Deprel: obj, Head: protect\n",
      "Word: such, Deprel: case, Head: Ministry\n",
      "Word: as, Deprel: fixed, Head: such\n",
      "Word: the, Deprel: det, Head: Ministry\n",
      "Word: Finance, Deprel: compound, Head: Ministry\n",
      "Word: Ministry, Deprel: nmod, Head: institutions\n",
      "\n",
      "Dependencies for Sentence: 'Mr Alibek said Our outcomes are very encouraging'\n",
      "Word: Mr, Deprel: nsubj, Head: said\n",
      "Word: Alibek, Deprel: flat, Head: Mr\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Our, Deprel: nmod:poss, Head: outcomes\n",
      "Word: outcomes, Deprel: nsubj, Head: encouraging\n",
      "Word: are, Deprel: cop, Head: encouraging\n",
      "Word: very, Deprel: advmod, Head: encouraging\n",
      "Word: encouraging, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Our outcomes are very encouraging George Mason researcher Ken Alibek said'\n",
      "Word: Our, Deprel: nmod:poss, Head: outcomes\n",
      "Word: outcomes, Deprel: nsubj, Head: encouraging\n",
      "Word: are, Deprel: cop, Head: encouraging\n",
      "Word: very, Deprel: advmod, Head: encouraging\n",
      "Word: encouraging, Deprel: root, Head: ROOT\n",
      "Word: George, Deprel: compound, Head: researcher\n",
      "Word: Mason, Deprel: flat, Head: George\n",
      "Word: researcher, Deprel: compound, Head: Ken\n",
      "Word: Ken, Deprel: nsubj, Head: said\n",
      "Word: Alibek, Deprel: flat, Head: Ken\n",
      "Word: said, Deprel: ccomp, Head: encouraging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Selenski descended down the wall and used the mattress to climb over razor wire'\n",
      "Word: Selenski, Deprel: nsubj, Head: descended\n",
      "Word: descended, Deprel: root, Head: ROOT\n",
      "Word: down, Deprel: case, Head: wall\n",
      "Word: the, Deprel: det, Head: wall\n",
      "Word: wall, Deprel: obl, Head: descended\n",
      "Word: and, Deprel: cc, Head: used\n",
      "Word: used, Deprel: conj, Head: descended\n",
      "Word: the, Deprel: det, Head: mattress\n",
      "Word: mattress, Deprel: obj, Head: used\n",
      "Word: to, Deprel: mark, Head: climb\n",
      "Word: climb, Deprel: advcl, Head: used\n",
      "Word: over, Deprel: case, Head: wire\n",
      "Word: razor, Deprel: compound, Head: wire\n",
      "Word: wire, Deprel: obl, Head: climb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Selenski used the mattress to scale a 10-foot razor wire Fischi said'\n",
      "Word: Selenski, Deprel: nsubj, Head: used\n",
      "Word: used, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: mattress\n",
      "Word: mattress, Deprel: obj, Head: used\n",
      "Word: to, Deprel: mark, Head: scale\n",
      "Word: scale, Deprel: advcl, Head: used\n",
      "Word: a, Deprel: det, Head: wire\n",
      "Word: 10-foot, Deprel: amod, Head: wire\n",
      "Word: razor, Deprel: compound, Head: wire\n",
      "Word: wire, Deprel: obj, Head: scale\n",
      "Word: Fischi, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: wire\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A jury convicted rapper C-Murder also known as Corey Miller of second-degree murder Tuesday night in the shooting death of a 16-year-old in a Jefferson Parish nightclub'\n",
      "Word: A, Deprel: det, Head: jury\n",
      "Word: jury, Deprel: nsubj, Head: convicted\n",
      "Word: convicted, Deprel: root, Head: ROOT\n",
      "Word: rapper, Deprel: obj, Head: convicted\n",
      "Word: C-Murder, Deprel: flat, Head: rapper\n",
      "Word: also, Deprel: advmod, Head: known\n",
      "Word: known, Deprel: acl, Head: rapper\n",
      "Word: as, Deprel: case, Head: Corey\n",
      "Word: Corey, Deprel: obl, Head: known\n",
      "Word: Miller, Deprel: flat, Head: Corey\n",
      "Word: of, Deprel: case, Head: murder\n",
      "Word: second-degree, Deprel: amod, Head: murder\n",
      "Word: murder, Deprel: obl, Head: known\n",
      "Word: Tuesday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: known\n",
      "Word: in, Deprel: case, Head: death\n",
      "Word: the, Deprel: det, Head: death\n",
      "Word: shooting, Deprel: compound, Head: death\n",
      "Word: death, Deprel: obl, Head: known\n",
      "Word: of, Deprel: case, Head: 16-year-old\n",
      "Word: a, Deprel: det, Head: 16-year-old\n",
      "Word: 16-year-old, Deprel: nmod, Head: death\n",
      "Word: in, Deprel: case, Head: nightclub\n",
      "Word: a, Deprel: det, Head: nightclub\n",
      "Word: Jefferson, Deprel: compound, Head: nightclub\n",
      "Word: Parish, Deprel: compound, Head: nightclub\n",
      "Word: nightclub, Deprel: nmod, Head: 16-year-old\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Rapper C-Murder has been convicted of second-degree murder a crime that carries an automatic life sentence in the shooting death of a 16-year-old inside a Jefferson Parish nightclub'\n",
      "Word: Rapper, Deprel: compound, Head: C-Murder\n",
      "Word: C-Murder, Deprel: nsubj:pass, Head: convicted\n",
      "Word: has, Deprel: aux, Head: convicted\n",
      "Word: been, Deprel: aux:pass, Head: convicted\n",
      "Word: convicted, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: murder\n",
      "Word: second-degree, Deprel: amod, Head: murder\n",
      "Word: murder, Deprel: obl, Head: convicted\n",
      "Word: a, Deprel: det, Head: crime\n",
      "Word: crime, Deprel: obj, Head: convicted\n",
      "Word: that, Deprel: nsubj, Head: carries\n",
      "Word: carries, Deprel: acl:relcl, Head: crime\n",
      "Word: an, Deprel: det, Head: sentence\n",
      "Word: automatic, Deprel: amod, Head: sentence\n",
      "Word: life, Deprel: compound, Head: sentence\n",
      "Word: sentence, Deprel: obj, Head: carries\n",
      "Word: in, Deprel: case, Head: death\n",
      "Word: the, Deprel: det, Head: death\n",
      "Word: shooting, Deprel: compound, Head: death\n",
      "Word: death, Deprel: obl, Head: carries\n",
      "Word: of, Deprel: case, Head: 16-year-old\n",
      "Word: a, Deprel: det, Head: 16-year-old\n",
      "Word: 16-year-old, Deprel: nmod, Head: death\n",
      "Word: inside, Deprel: case, Head: nightclub\n",
      "Word: a, Deprel: det, Head: nightclub\n",
      "Word: Jefferson, Deprel: compound, Head: nightclub\n",
      "Word: Parish, Deprel: compound, Head: nightclub\n",
      "Word: nightclub, Deprel: nmod, Head: 16-year-old\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Joe Kernan who had been lieutenant governor for the past seven years was sworn in as governor after O'Bannon died Saturday'\n",
      "Word: Joe, Deprel: nsubj:pass, Head: sworn\n",
      "Word: Kernan, Deprel: flat, Head: Joe\n",
      "Word: who, Deprel: nsubj, Head: governor\n",
      "Word: had, Deprel: aux, Head: governor\n",
      "Word: been, Deprel: cop, Head: governor\n",
      "Word: lieutenant, Deprel: compound, Head: governor\n",
      "Word: governor, Deprel: acl:relcl, Head: Joe\n",
      "Word: for, Deprel: case, Head: years\n",
      "Word: the, Deprel: det, Head: years\n",
      "Word: past, Deprel: amod, Head: years\n",
      "Word: seven, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl, Head: governor\n",
      "Word: was, Deprel: aux:pass, Head: sworn\n",
      "Word: sworn, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: compound:prt, Head: sworn\n",
      "Word: as, Deprel: case, Head: governor\n",
      "Word: governor, Deprel: obl, Head: sworn\n",
      "Word: after, Deprel: mark, Head: died\n",
      "Word: O'Bannon, Deprel: nsubj, Head: died\n",
      "Word: died, Deprel: advcl, Head: sworn\n",
      "Word: Saturday, Deprel: obj, Head: died\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Kernan who was O'Bannon s lieutenant governor friend and political partner was sworn in six hours after O'Bannon died Saturday'\n",
      "Word: Kernan, Deprel: nsubj:pass, Head: sworn\n",
      "Word: who, Deprel: nsubj, Head: friend\n",
      "Word: was, Deprel: cop, Head: friend\n",
      "Word: O'Bannon, Deprel: nmod:poss, Head: friend\n",
      "Word: s, Deprel: case, Head: O'Bannon\n",
      "Word: lieutenant, Deprel: compound, Head: governor\n",
      "Word: governor, Deprel: compound, Head: friend\n",
      "Word: friend, Deprel: acl:relcl, Head: Kernan\n",
      "Word: and, Deprel: cc, Head: partner\n",
      "Word: political, Deprel: amod, Head: partner\n",
      "Word: partner, Deprel: conj, Head: friend\n",
      "Word: was, Deprel: aux:pass, Head: sworn\n",
      "Word: sworn, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: compound:prt, Head: sworn\n",
      "Word: six, Deprel: nummod, Head: hours\n",
      "Word: hours, Deprel: obl:npmod, Head: died\n",
      "Word: after, Deprel: mark, Head: died\n",
      "Word: O'Bannon, Deprel: nsubj, Head: died\n",
      "Word: died, Deprel: advcl, Head: sworn\n",
      "Word: Saturday, Deprel: obj, Head: died\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Wells ’ other series include NBC ’ s ER and Third Watch'\n",
      "Word: Wells, Deprel: nmod:poss, Head: series\n",
      "Word: ’, Deprel: case, Head: Wells\n",
      "Word: other, Deprel: amod, Head: series\n",
      "Word: series, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: NBC, Deprel: nmod:poss, Head: ER\n",
      "Word: ’, Deprel: case, Head: NBC\n",
      "Word: s, Deprel: case, Head: NBC\n",
      "Word: ER, Deprel: obj, Head: include\n",
      "Word: and, Deprel: cc, Head: Watch\n",
      "Word: Third, Deprel: amod, Head: Watch\n",
      "Word: Watch, Deprel: conj, Head: ER\n",
      "\n",
      "Dependencies for Sentence: 'Wells other series include NBC s ER and Third Watch'\n",
      "Word: Wells, Deprel: compound, Head: series\n",
      "Word: other, Deprel: amod, Head: series\n",
      "Word: series, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: NBC, Deprel: nmod:poss, Head: ER\n",
      "Word: s, Deprel: case, Head: NBC\n",
      "Word: ER, Deprel: obj, Head: include\n",
      "Word: and, Deprel: cc, Head: Watch\n",
      "Word: Third, Deprel: amod, Head: Watch\n",
      "Word: Watch, Deprel: conj, Head: ER\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Thirty-three of the 42 men had been arrested by Wednesday evening said Daniel Bogden U.S attorney in Nevada'\n",
      "Word: Thirty-three, Deprel: nsubj:pass, Head: arrested\n",
      "Word: of, Deprel: case, Head: men\n",
      "Word: the, Deprel: det, Head: men\n",
      "Word: 42, Deprel: nummod, Head: men\n",
      "Word: men, Deprel: nmod, Head: Thirty-three\n",
      "Word: had, Deprel: aux, Head: arrested\n",
      "Word: been, Deprel: aux:pass, Head: arrested\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: evening\n",
      "Word: Wednesday, Deprel: compound, Head: evening\n",
      "Word: evening, Deprel: obl, Head: arrested\n",
      "Word: said, Deprel: parataxis, Head: arrested\n",
      "Word: Daniel, Deprel: compound, Head: attorney\n",
      "Word: Bogden, Deprel: flat, Head: Daniel\n",
      "Word: U.S, Deprel: compound, Head: attorney\n",
      "Word: attorney, Deprel: obj, Head: said\n",
      "Word: in, Deprel: case, Head: Nevada\n",
      "Word: Nevada, Deprel: nmod, Head: attorney\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Thirty-four of the men have been arrested and the others are being sought US Attorney Daniel Bogden said yesterday'\n",
      "Word: Thirty-four, Deprel: nsubj:pass, Head: arrested\n",
      "Word: of, Deprel: case, Head: men\n",
      "Word: the, Deprel: det, Head: men\n",
      "Word: men, Deprel: nmod, Head: Thirty-four\n",
      "Word: have, Deprel: aux, Head: arrested\n",
      "Word: been, Deprel: aux:pass, Head: arrested\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: sought\n",
      "Word: the, Deprel: det, Head: others\n",
      "Word: others, Deprel: nsubj:pass, Head: sought\n",
      "Word: are, Deprel: aux, Head: sought\n",
      "Word: being, Deprel: aux:pass, Head: sought\n",
      "Word: sought, Deprel: conj, Head: arrested\n",
      "Word: US, Deprel: compound, Head: Attorney\n",
      "Word: Attorney, Deprel: compound, Head: Daniel\n",
      "Word: Daniel, Deprel: nsubj, Head: said\n",
      "Word: Bogden, Deprel: flat, Head: Daniel\n",
      "Word: said, Deprel: parataxis, Head: arrested\n",
      "Word: yesterday, Deprel: obl:tmod, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Advanced Micro Devices said Fujitsu Siemens Computers is offering a high-end workstation based on AMD s Opteron 200 Series'\n",
      "Word: Advanced, Deprel: amod, Head: Devices\n",
      "Word: Micro, Deprel: compound, Head: Devices\n",
      "Word: Devices, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Fujitsu, Deprel: compound, Head: Computers\n",
      "Word: Siemens, Deprel: compound, Head: Computers\n",
      "Word: Computers, Deprel: nsubj, Head: offering\n",
      "Word: is, Deprel: aux, Head: offering\n",
      "Word: offering, Deprel: ccomp, Head: said\n",
      "Word: a, Deprel: det, Head: workstation\n",
      "Word: high-end, Deprel: amod, Head: workstation\n",
      "Word: workstation, Deprel: obj, Head: offering\n",
      "Word: based, Deprel: acl, Head: workstation\n",
      "Word: on, Deprel: case, Head: Series\n",
      "Word: AMD, Deprel: nmod:poss, Head: Series\n",
      "Word: s, Deprel: case, Head: AMD\n",
      "Word: Opteron, Deprel: compound, Head: Series\n",
      "Word: 200, Deprel: nummod, Head: Series\n",
      "Word: Series, Deprel: obl, Head: based\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Fujitsu Siemens Computers on Tuesday made good on a promise to offer a workstation based on Advanced Micro Devices Opteron processor'\n",
      "Word: Fujitsu, Deprel: compound, Head: Computers\n",
      "Word: Siemens, Deprel: compound, Head: Computers\n",
      "Word: Computers, Deprel: nsubj, Head: made\n",
      "Word: on, Deprel: case, Head: Tuesday\n",
      "Word: Tuesday, Deprel: nmod, Head: Computers\n",
      "Word: made, Deprel: root, Head: ROOT\n",
      "Word: good, Deprel: xcomp, Head: made\n",
      "Word: on, Deprel: case, Head: promise\n",
      "Word: a, Deprel: det, Head: promise\n",
      "Word: promise, Deprel: obl, Head: made\n",
      "Word: to, Deprel: mark, Head: offer\n",
      "Word: offer, Deprel: acl, Head: promise\n",
      "Word: a, Deprel: det, Head: workstation\n",
      "Word: workstation, Deprel: obj, Head: offer\n",
      "Word: based, Deprel: acl, Head: workstation\n",
      "Word: on, Deprel: case, Head: processor\n",
      "Word: Advanced, Deprel: amod, Head: Devices\n",
      "Word: Micro, Deprel: compound, Head: Devices\n",
      "Word: Devices, Deprel: compound, Head: processor\n",
      "Word: Opteron, Deprel: compound, Head: processor\n",
      "Word: processor, Deprel: obl, Head: based\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Five-time Tour de France winner and cancer survivor Lance Armstrong had a few words of advice for other cancer survivors in Denver on Friday'\n",
      "Word: Five-time, Deprel: amod, Head: winner\n",
      "Word: Tour, Deprel: compound, Head: winner\n",
      "Word: de, Deprel: compound, Head: France\n",
      "Word: France, Deprel: compound, Head: winner\n",
      "Word: winner, Deprel: nsubj, Head: had\n",
      "Word: and, Deprel: cc, Head: survivor\n",
      "Word: cancer, Deprel: compound, Head: survivor\n",
      "Word: survivor, Deprel: compound, Head: Lance\n",
      "Word: Lance, Deprel: conj, Head: winner\n",
      "Word: Armstrong, Deprel: flat, Head: Lance\n",
      "Word: had, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: words\n",
      "Word: few, Deprel: amod, Head: words\n",
      "Word: words, Deprel: obj, Head: had\n",
      "Word: of, Deprel: case, Head: advice\n",
      "Word: advice, Deprel: nmod, Head: words\n",
      "Word: for, Deprel: case, Head: survivors\n",
      "Word: other, Deprel: amod, Head: survivors\n",
      "Word: cancer, Deprel: compound, Head: survivors\n",
      "Word: survivors, Deprel: nmod, Head: words\n",
      "Word: in, Deprel: case, Head: Denver\n",
      "Word: Denver, Deprel: nmod, Head: survivors\n",
      "Word: on, Deprel: case, Head: Friday\n",
      "Word: Friday, Deprel: nmod, Head: survivors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Five-time Tour de France winner Lance Armstrong is in Denver today for a meeting about surviving cancer'\n",
      "Word: Five-time, Deprel: amod, Head: winner\n",
      "Word: Tour, Deprel: compound, Head: winner\n",
      "Word: de, Deprel: compound, Head: France\n",
      "Word: France, Deprel: compound, Head: winner\n",
      "Word: winner, Deprel: nsubj, Head: Denver\n",
      "Word: Lance, Deprel: flat, Head: winner\n",
      "Word: Armstrong, Deprel: flat, Head: Lance\n",
      "Word: is, Deprel: cop, Head: Denver\n",
      "Word: in, Deprel: case, Head: Denver\n",
      "Word: Denver, Deprel: root, Head: ROOT\n",
      "Word: today, Deprel: obl:tmod, Head: Denver\n",
      "Word: for, Deprel: case, Head: meeting\n",
      "Word: a, Deprel: det, Head: meeting\n",
      "Word: meeting, Deprel: obl, Head: Denver\n",
      "Word: about, Deprel: mark, Head: surviving\n",
      "Word: surviving, Deprel: acl, Head: meeting\n",
      "Word: cancer, Deprel: obj, Head: surviving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'She survives him as do their four children sons Anthony and Kelly daughters Linda Hope and Nora Somers and four grandchildren'\n",
      "Word: She, Deprel: nsubj, Head: survives\n",
      "Word: survives, Deprel: root, Head: ROOT\n",
      "Word: him, Deprel: obj, Head: survives\n",
      "Word: as, Deprel: mark, Head: do\n",
      "Word: do, Deprel: advcl, Head: survives\n",
      "Word: their, Deprel: nmod:poss, Head: children\n",
      "Word: four, Deprel: nummod, Head: children\n",
      "Word: children, Deprel: obj, Head: do\n",
      "Word: sons, Deprel: appos, Head: children\n",
      "Word: Anthony, Deprel: appos, Head: sons\n",
      "Word: and, Deprel: cc, Head: daughters\n",
      "Word: Kelly, Deprel: conj, Head: Anthony\n",
      "Word: daughters, Deprel: conj, Head: Anthony\n",
      "Word: Linda, Deprel: appos, Head: daughters\n",
      "Word: Hope, Deprel: flat, Head: Linda\n",
      "Word: and, Deprel: cc, Head: Nora\n",
      "Word: Nora, Deprel: conj, Head: Linda\n",
      "Word: Somers, Deprel: flat, Head: Nora\n",
      "Word: and, Deprel: cc, Head: grandchildren\n",
      "Word: four, Deprel: nummod, Head: grandchildren\n",
      "Word: grandchildren, Deprel: conj, Head: children\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hope is survived by his wife sons Anthony and Kelly daughters Linda and Nora Somers and four grandchildren'\n",
      "Word: Hope, Deprel: nsubj:pass, Head: survived\n",
      "Word: is, Deprel: aux:pass, Head: survived\n",
      "Word: survived, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: wife\n",
      "Word: his, Deprel: nmod:poss, Head: wife\n",
      "Word: wife, Deprel: obl:agent, Head: survived\n",
      "Word: sons, Deprel: appos, Head: wife\n",
      "Word: Anthony, Deprel: appos, Head: wife\n",
      "Word: and, Deprel: cc, Head: Kelly\n",
      "Word: Kelly, Deprel: conj, Head: Anthony\n",
      "Word: daughters, Deprel: conj, Head: Anthony\n",
      "Word: Linda, Deprel: flat, Head: daughters\n",
      "Word: and, Deprel: cc, Head: Nora\n",
      "Word: Nora, Deprel: conj, Head: Anthony\n",
      "Word: Somers, Deprel: flat, Head: Nora\n",
      "Word: and, Deprel: cc, Head: grandchildren\n",
      "Word: four, Deprel: nummod, Head: grandchildren\n",
      "Word: grandchildren, Deprel: conj, Head: wife\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Police using pepper spray arrested 12 people Monday night at a march and rally by about 400 activists protesting an annual training seminar of the Law Enforcement Intelligence Unit'\n",
      "Word: Police, Deprel: nsubj, Head: arrested\n",
      "Word: using, Deprel: acl, Head: Police\n",
      "Word: pepper, Deprel: compound, Head: spray\n",
      "Word: spray, Deprel: obj, Head: using\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: 12, Deprel: nummod, Head: people\n",
      "Word: people, Deprel: obj, Head: arrested\n",
      "Word: Monday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: arrested\n",
      "Word: at, Deprel: case, Head: march\n",
      "Word: a, Deprel: det, Head: march\n",
      "Word: march, Deprel: obl, Head: arrested\n",
      "Word: and, Deprel: cc, Head: rally\n",
      "Word: rally, Deprel: conj, Head: march\n",
      "Word: by, Deprel: case, Head: activists\n",
      "Word: about, Deprel: advmod, Head: 400\n",
      "Word: 400, Deprel: nummod, Head: activists\n",
      "Word: activists, Deprel: obl, Head: arrested\n",
      "Word: protesting, Deprel: acl, Head: activists\n",
      "Word: an, Deprel: det, Head: seminar\n",
      "Word: annual, Deprel: amod, Head: seminar\n",
      "Word: training, Deprel: compound, Head: seminar\n",
      "Word: seminar, Deprel: obj, Head: protesting\n",
      "Word: of, Deprel: case, Head: Unit\n",
      "Word: the, Deprel: det, Head: Unit\n",
      "Word: Law, Deprel: compound, Head: Enforcement\n",
      "Word: Enforcement, Deprel: compound, Head: Unit\n",
      "Word: Intelligence, Deprel: compound, Head: Unit\n",
      "Word: Unit, Deprel: nmod, Head: seminar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Police used pepper spray and rubber bullets to disperse a downtown march and rally last night by activists protesting an annual police intelligence-training seminar'\n",
      "Word: Police, Deprel: nsubj, Head: used\n",
      "Word: used, Deprel: root, Head: ROOT\n",
      "Word: pepper, Deprel: compound, Head: spray\n",
      "Word: spray, Deprel: obj, Head: used\n",
      "Word: and, Deprel: cc, Head: bullets\n",
      "Word: rubber, Deprel: compound, Head: bullets\n",
      "Word: bullets, Deprel: conj, Head: spray\n",
      "Word: to, Deprel: mark, Head: disperse\n",
      "Word: disperse, Deprel: advcl, Head: used\n",
      "Word: a, Deprel: det, Head: march\n",
      "Word: downtown, Deprel: amod, Head: march\n",
      "Word: march, Deprel: obj, Head: disperse\n",
      "Word: and, Deprel: cc, Head: rally\n",
      "Word: rally, Deprel: conj, Head: march\n",
      "Word: last, Deprel: amod, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: disperse\n",
      "Word: by, Deprel: case, Head: activists\n",
      "Word: activists, Deprel: obl, Head: disperse\n",
      "Word: protesting, Deprel: acl, Head: activists\n",
      "Word: an, Deprel: det, Head: seminar\n",
      "Word: annual, Deprel: amod, Head: seminar\n",
      "Word: police, Deprel: compound, Head: seminar\n",
      "Word: intelligence-training, Deprel: compound, Head: seminar\n",
      "Word: seminar, Deprel: obj, Head: protesting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Common side effects include nasal congestion runny nose sore throat and cough the FDA said'\n",
      "Word: Common, Deprel: amod, Head: effects\n",
      "Word: side, Deprel: compound, Head: effects\n",
      "Word: effects, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: nasal, Deprel: amod, Head: congestion\n",
      "Word: congestion, Deprel: compound, Head: nose\n",
      "Word: runny, Deprel: amod, Head: nose\n",
      "Word: nose, Deprel: compound, Head: throat\n",
      "Word: sore, Deprel: amod, Head: throat\n",
      "Word: throat, Deprel: obj, Head: include\n",
      "Word: and, Deprel: cc, Head: cough\n",
      "Word: cough, Deprel: conj, Head: throat\n",
      "Word: the, Deprel: det, Head: FDA\n",
      "Word: FDA, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: throat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The most common side effects after getting the nasal spray were nasal congestion runny nose sore throat and cough'\n",
      "Word: The, Deprel: det, Head: effects\n",
      "Word: most, Deprel: advmod, Head: common\n",
      "Word: common, Deprel: amod, Head: effects\n",
      "Word: side, Deprel: compound, Head: effects\n",
      "Word: effects, Deprel: nsubj, Head: throat\n",
      "Word: after, Deprel: mark, Head: getting\n",
      "Word: getting, Deprel: acl, Head: effects\n",
      "Word: the, Deprel: det, Head: spray\n",
      "Word: nasal, Deprel: amod, Head: spray\n",
      "Word: spray, Deprel: obj, Head: getting\n",
      "Word: were, Deprel: cop, Head: throat\n",
      "Word: nasal, Deprel: amod, Head: congestion\n",
      "Word: congestion, Deprel: compound, Head: throat\n",
      "Word: runny, Deprel: amod, Head: throat\n",
      "Word: nose, Deprel: compound, Head: throat\n",
      "Word: sore, Deprel: amod, Head: throat\n",
      "Word: throat, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: cough\n",
      "Word: cough, Deprel: conj, Head: throat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The department ordered an 18.2 percent reduction for Allstate Texas Lloyds and a 12 percent reduction for State Farm Lloyds'\n",
      "Word: The, Deprel: det, Head: department\n",
      "Word: department, Deprel: nsubj, Head: ordered\n",
      "Word: ordered, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: reduction\n",
      "Word: 18.2, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: reduction\n",
      "Word: reduction, Deprel: obj, Head: ordered\n",
      "Word: for, Deprel: case, Head: Lloyds\n",
      "Word: Allstate, Deprel: compound, Head: Lloyds\n",
      "Word: Texas, Deprel: compound, Head: Lloyds\n",
      "Word: Lloyds, Deprel: nmod, Head: reduction\n",
      "Word: and, Deprel: cc, Head: reduction\n",
      "Word: a, Deprel: det, Head: reduction\n",
      "Word: 12, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: reduction\n",
      "Word: reduction, Deprel: conj, Head: reduction\n",
      "Word: for, Deprel: case, Head: Lloyds\n",
      "Word: State, Deprel: compound, Head: Farm\n",
      "Word: Farm, Deprel: compound, Head: Lloyds\n",
      "Word: Lloyds, Deprel: nmod, Head: reduction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The department ordered a 12 percent reduction for State Farm Lloyds the state s largest insurer and an 18.2 percent reduction for Allstate Texas Lloyds the third-largest'\n",
      "Word: The, Deprel: det, Head: department\n",
      "Word: department, Deprel: nsubj, Head: ordered\n",
      "Word: ordered, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: reduction\n",
      "Word: 12, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: reduction\n",
      "Word: reduction, Deprel: obj, Head: ordered\n",
      "Word: for, Deprel: case, Head: Lloyds\n",
      "Word: State, Deprel: compound, Head: Lloyds\n",
      "Word: Farm, Deprel: compound, Head: Lloyds\n",
      "Word: Lloyds, Deprel: nmod, Head: reduction\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: state, Deprel: nmod:poss, Head: insurer\n",
      "Word: s, Deprel: case, Head: state\n",
      "Word: largest, Deprel: amod, Head: insurer\n",
      "Word: insurer, Deprel: appos, Head: reduction\n",
      "Word: and, Deprel: cc, Head: reduction\n",
      "Word: an, Deprel: det, Head: reduction\n",
      "Word: 18.2, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: reduction\n",
      "Word: reduction, Deprel: conj, Head: reduction\n",
      "Word: for, Deprel: case, Head: Lloyds\n",
      "Word: Allstate, Deprel: compound, Head: Lloyds\n",
      "Word: Texas, Deprel: compound, Head: Lloyds\n",
      "Word: Lloyds, Deprel: nmod, Head: reduction\n",
      "Word: the, Deprel: det, Head: third-largest\n",
      "Word: third-largest, Deprel: nmod:npmod, Head: reduction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Kodak expects earnings of 5 cents to 25 cents a share in the quarter'\n",
      "Word: Kodak, Deprel: nsubj, Head: expects\n",
      "Word: expects, Deprel: root, Head: ROOT\n",
      "Word: earnings, Deprel: obj, Head: expects\n",
      "Word: of, Deprel: case, Head: cents\n",
      "Word: 5, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: nmod, Head: earnings\n",
      "Word: to, Deprel: case, Head: cents\n",
      "Word: 25, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl, Head: expects\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:tmod, Head: cents\n",
      "Word: in, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: expects\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Analysts surveyed by Thomson First Call had expected Kodak to earn 68 cents a share for the quarter'\n",
      "Word: Analysts, Deprel: nsubj, Head: expected\n",
      "Word: surveyed, Deprel: acl, Head: Analysts\n",
      "Word: by, Deprel: case, Head: Call\n",
      "Word: Thomson, Deprel: compound, Head: Call\n",
      "Word: First, Deprel: amod, Head: Call\n",
      "Word: Call, Deprel: obl, Head: surveyed\n",
      "Word: had, Deprel: aux, Head: expected\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: Kodak, Deprel: obj, Head: expected\n",
      "Word: to, Deprel: mark, Head: earn\n",
      "Word: earn, Deprel: xcomp, Head: expected\n",
      "Word: 68, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obj, Head: earn\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:tmod, Head: cents\n",
      "Word: for, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: earn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Colgate shares closed Monday at 56.30 on the New York Stock Exchange'\n",
      "Word: Colgate, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: closed\n",
      "Word: closed, Deprel: root, Head: ROOT\n",
      "Word: Monday, Deprel: obl:tmod, Head: closed\n",
      "Word: at, Deprel: case, Head: 56.30\n",
      "Word: 56.30, Deprel: obl, Head: closed\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Colgate shares were down 30 cents at 56 in morning trade on the New York Stock Exchange'\n",
      "Word: Colgate, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: down\n",
      "Word: were, Deprel: cop, Head: down\n",
      "Word: down, Deprel: root, Head: ROOT\n",
      "Word: 30, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: down\n",
      "Word: at, Deprel: case, Head: 56\n",
      "Word: 56, Deprel: obl, Head: down\n",
      "Word: in, Deprel: case, Head: trade\n",
      "Word: morning, Deprel: compound, Head: trade\n",
      "Word: trade, Deprel: obl, Head: down\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: nmod, Head: trade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Several shots rang out in the darkness but only one gator had been killed by 11 p.m'\n",
      "Word: Several, Deprel: amod, Head: shots\n",
      "Word: shots, Deprel: nsubj, Head: rang\n",
      "Word: rang, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: compound:prt, Head: rang\n",
      "Word: in, Deprel: case, Head: darkness\n",
      "Word: the, Deprel: det, Head: darkness\n",
      "Word: darkness, Deprel: obl, Head: rang\n",
      "Word: but, Deprel: cc, Head: killed\n",
      "Word: only, Deprel: advmod, Head: one\n",
      "Word: one, Deprel: nummod, Head: gator\n",
      "Word: gator, Deprel: nsubj:pass, Head: killed\n",
      "Word: had, Deprel: aux, Head: killed\n",
      "Word: been, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: conj, Head: rang\n",
      "Word: by, Deprel: case, Head: p.m\n",
      "Word: 11, Deprel: nummod, Head: p.m\n",
      "Word: p.m, Deprel: obl, Head: killed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Several shots rang out Wednesday night but no gators were killed then'\n",
      "Word: Several, Deprel: amod, Head: shots\n",
      "Word: shots, Deprel: nsubj, Head: rang\n",
      "Word: rang, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: compound:prt, Head: rang\n",
      "Word: Wednesday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: rang\n",
      "Word: but, Deprel: cc, Head: killed\n",
      "Word: no, Deprel: det, Head: gators\n",
      "Word: gators, Deprel: nsubj:pass, Head: killed\n",
      "Word: were, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: conj, Head: rang\n",
      "Word: then, Deprel: advmod, Head: killed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of Corixa fell 12 cents to 6.88 on the Nasdaq stock market'\n",
      "Word: Shares, Deprel: nsubj, Head: fell\n",
      "Word: of, Deprel: case, Head: Corixa\n",
      "Word: Corixa, Deprel: nmod, Head: Shares\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 12, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: fell\n",
      "Word: to, Deprel: case, Head: 6.88\n",
      "Word: 6.88, Deprel: obl, Head: fell\n",
      "Word: on, Deprel: case, Head: market\n",
      "Word: the, Deprel: det, Head: market\n",
      "Word: Nasdaq, Deprel: compound, Head: market\n",
      "Word: stock, Deprel: compound, Head: market\n",
      "Word: market, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Corixa s stock barely flinched on the news dipping 12 cents to close at 6.88'\n",
      "Word: Corixa, Deprel: nmod:poss, Head: stock\n",
      "Word: s, Deprel: case, Head: Corixa\n",
      "Word: stock, Deprel: nsubj, Head: flinched\n",
      "Word: barely, Deprel: advmod, Head: flinched\n",
      "Word: flinched, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: news\n",
      "Word: the, Deprel: det, Head: news\n",
      "Word: news, Deprel: obl, Head: flinched\n",
      "Word: dipping, Deprel: acl, Head: news\n",
      "Word: 12, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obj, Head: dipping\n",
      "Word: to, Deprel: mark, Head: close\n",
      "Word: close, Deprel: advcl, Head: dipping\n",
      "Word: at, Deprel: case, Head: 6.88\n",
      "Word: 6.88, Deprel: obl, Head: close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index SPX was 0.46 points lower or 0.05 percent at 997.02'\n",
      "Word: The, Deprel: det, Head: Poor\n",
      "Word: broader, Deprel: amod, Head: Poor\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: nmod:poss, Head: SPX\n",
      "Word: s, Deprel: case, Head: Poor\n",
      "Word: 500, Deprel: nummod, Head: Index\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: lower\n",
      "Word: was, Deprel: cop, Head: lower\n",
      "Word: 0.46, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: lower\n",
      "Word: lower, Deprel: root, Head: ROOT\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.05, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: lower\n",
      "Word: at, Deprel: case, Head: 997.02\n",
      "Word: 997.02, Deprel: obl, Head: lower\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index IXIC was up 7.42 points or 0.45 percent at 1,653.44'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-laced, Deprel: amod, Head: IXIC\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: up\n",
      "Word: was, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: 7.42, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: up\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.45, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 1,653.44\n",
      "Word: 1,653.44, Deprel: obl, Head: up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Announcing the selection Kmart CEO Julian Day said Grey will help the retailer find creative ways to communicate the unique strengths of Kmart to the new America consumer'\n",
      "Word: Announcing, Deprel: advcl, Head: said\n",
      "Word: the, Deprel: det, Head: selection\n",
      "Word: selection, Deprel: obj, Head: Announcing\n",
      "Word: Kmart, Deprel: compound, Head: CEO\n",
      "Word: CEO, Deprel: compound, Head: Julian\n",
      "Word: Julian, Deprel: nsubj, Head: said\n",
      "Word: Day, Deprel: flat, Head: Julian\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Grey, Deprel: nsubj, Head: help\n",
      "Word: will, Deprel: aux, Head: help\n",
      "Word: help, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: retailer\n",
      "Word: retailer, Deprel: obj, Head: help\n",
      "Word: find, Deprel: xcomp, Head: help\n",
      "Word: creative, Deprel: amod, Head: ways\n",
      "Word: ways, Deprel: obj, Head: find\n",
      "Word: to, Deprel: mark, Head: communicate\n",
      "Word: communicate, Deprel: acl, Head: ways\n",
      "Word: the, Deprel: det, Head: strengths\n",
      "Word: unique, Deprel: amod, Head: strengths\n",
      "Word: strengths, Deprel: obj, Head: communicate\n",
      "Word: of, Deprel: case, Head: Kmart\n",
      "Word: Kmart, Deprel: nmod, Head: strengths\n",
      "Word: to, Deprel: case, Head: consumer\n",
      "Word: the, Deprel: det, Head: consumer\n",
      "Word: new, Deprel: amod, Head: consumer\n",
      "Word: America, Deprel: compound, Head: consumer\n",
      "Word: consumer, Deprel: obl, Head: communicate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Together we will find creative ways to communicate the unique strengths of Kmart to the new America consumer'\n",
      "Word: Together, Deprel: advmod, Head: find\n",
      "Word: we, Deprel: nsubj, Head: find\n",
      "Word: will, Deprel: aux, Head: find\n",
      "Word: find, Deprel: root, Head: ROOT\n",
      "Word: creative, Deprel: amod, Head: ways\n",
      "Word: ways, Deprel: obj, Head: find\n",
      "Word: to, Deprel: mark, Head: communicate\n",
      "Word: communicate, Deprel: acl, Head: ways\n",
      "Word: the, Deprel: det, Head: strengths\n",
      "Word: unique, Deprel: amod, Head: strengths\n",
      "Word: strengths, Deprel: obj, Head: communicate\n",
      "Word: of, Deprel: case, Head: Kmart\n",
      "Word: Kmart, Deprel: nmod, Head: strengths\n",
      "Word: to, Deprel: case, Head: consumer\n",
      "Word: the, Deprel: det, Head: consumer\n",
      "Word: new, Deprel: amod, Head: consumer\n",
      "Word: America, Deprel: compound, Head: consumer\n",
      "Word: consumer, Deprel: obl, Head: communicate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Republicans had pledged to complete a Medicare drug package by August then extended the deadline to Oct 17 and they are still working on it'\n",
      "Word: Republicans, Deprel: nsubj, Head: pledged\n",
      "Word: had, Deprel: aux, Head: pledged\n",
      "Word: pledged, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: complete\n",
      "Word: complete, Deprel: xcomp, Head: pledged\n",
      "Word: a, Deprel: det, Head: package\n",
      "Word: Medicare, Deprel: compound, Head: package\n",
      "Word: drug, Deprel: compound, Head: package\n",
      "Word: package, Deprel: obj, Head: complete\n",
      "Word: by, Deprel: case, Head: August\n",
      "Word: August, Deprel: obl, Head: complete\n",
      "Word: then, Deprel: advmod, Head: extended\n",
      "Word: extended, Deprel: parataxis, Head: pledged\n",
      "Word: the, Deprel: det, Head: deadline\n",
      "Word: deadline, Deprel: obj, Head: extended\n",
      "Word: to, Deprel: case, Head: Oct\n",
      "Word: Oct, Deprel: obl, Head: extended\n",
      "Word: 17, Deprel: nummod, Head: Oct\n",
      "Word: and, Deprel: cc, Head: working\n",
      "Word: they, Deprel: nsubj, Head: working\n",
      "Word: are, Deprel: aux, Head: working\n",
      "Word: still, Deprel: advmod, Head: working\n",
      "Word: working, Deprel: conj, Head: pledged\n",
      "Word: on, Deprel: case, Head: it\n",
      "Word: it, Deprel: obl, Head: working\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Republicans had pledged to complete a Medicare drug package by August then extended it to Oct 17'\n",
      "Word: Republicans, Deprel: nsubj, Head: pledged\n",
      "Word: had, Deprel: aux, Head: pledged\n",
      "Word: pledged, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: complete\n",
      "Word: complete, Deprel: xcomp, Head: pledged\n",
      "Word: a, Deprel: det, Head: package\n",
      "Word: Medicare, Deprel: compound, Head: package\n",
      "Word: drug, Deprel: compound, Head: package\n",
      "Word: package, Deprel: obj, Head: complete\n",
      "Word: by, Deprel: case, Head: August\n",
      "Word: August, Deprel: obl, Head: complete\n",
      "Word: then, Deprel: advmod, Head: extended\n",
      "Word: extended, Deprel: parataxis, Head: pledged\n",
      "Word: it, Deprel: obj, Head: extended\n",
      "Word: to, Deprel: case, Head: Oct\n",
      "Word: Oct, Deprel: obl, Head: extended\n",
      "Word: 17, Deprel: nummod, Head: Oct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Supermarket chains facing a possible grocery clerk strike this week accused union leaders Monday of breaking off contract talks prematurely over the weekend'\n",
      "Word: Supermarket, Deprel: compound, Head: chains\n",
      "Word: chains, Deprel: nsubj, Head: accused\n",
      "Word: facing, Deprel: acl, Head: chains\n",
      "Word: a, Deprel: det, Head: strike\n",
      "Word: possible, Deprel: amod, Head: strike\n",
      "Word: grocery, Deprel: compound, Head: clerk\n",
      "Word: clerk, Deprel: compound, Head: strike\n",
      "Word: strike, Deprel: obj, Head: facing\n",
      "Word: this, Deprel: det, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: facing\n",
      "Word: accused, Deprel: root, Head: ROOT\n",
      "Word: union, Deprel: compound, Head: leaders\n",
      "Word: leaders, Deprel: obj, Head: accused\n",
      "Word: Monday, Deprel: obl:tmod, Head: accused\n",
      "Word: of, Deprel: mark, Head: breaking\n",
      "Word: breaking, Deprel: advcl, Head: accused\n",
      "Word: off, Deprel: compound:prt, Head: breaking\n",
      "Word: contract, Deprel: compound, Head: talks\n",
      "Word: talks, Deprel: obj, Head: breaking\n",
      "Word: prematurely, Deprel: advmod, Head: breaking\n",
      "Word: over, Deprel: case, Head: weekend\n",
      "Word: the, Deprel: det, Head: weekend\n",
      "Word: weekend, Deprel: obl, Head: breaking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Supermarket chains are accusing union leaders of breaking off contract talks prematurely over the weekend as grocery clerks gear up for a possible strike'\n",
      "Word: Supermarket, Deprel: compound, Head: chains\n",
      "Word: chains, Deprel: nsubj, Head: accusing\n",
      "Word: are, Deprel: aux, Head: accusing\n",
      "Word: accusing, Deprel: root, Head: ROOT\n",
      "Word: union, Deprel: compound, Head: leaders\n",
      "Word: leaders, Deprel: obj, Head: accusing\n",
      "Word: of, Deprel: mark, Head: breaking\n",
      "Word: breaking, Deprel: advcl, Head: accusing\n",
      "Word: off, Deprel: compound:prt, Head: breaking\n",
      "Word: contract, Deprel: compound, Head: talks\n",
      "Word: talks, Deprel: obj, Head: breaking\n",
      "Word: prematurely, Deprel: advmod, Head: breaking\n",
      "Word: over, Deprel: case, Head: weekend\n",
      "Word: the, Deprel: det, Head: weekend\n",
      "Word: weekend, Deprel: obl, Head: breaking\n",
      "Word: as, Deprel: mark, Head: gear\n",
      "Word: grocery, Deprel: compound, Head: clerks\n",
      "Word: clerks, Deprel: nsubj, Head: gear\n",
      "Word: gear, Deprel: advcl, Head: breaking\n",
      "Word: up, Deprel: compound:prt, Head: gear\n",
      "Word: for, Deprel: case, Head: strike\n",
      "Word: a, Deprel: det, Head: strike\n",
      "Word: possible, Deprel: amod, Head: strike\n",
      "Word: strike, Deprel: obl, Head: gear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He was referring to John S Reed the former Citicorp chief executive who became interim chairman and chief executive of the exchange last Sunday'\n",
      "Word: He, Deprel: nsubj, Head: referring\n",
      "Word: was, Deprel: aux, Head: referring\n",
      "Word: referring, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: John\n",
      "Word: John, Deprel: obl, Head: referring\n",
      "Word: S, Deprel: flat, Head: John\n",
      "Word: Reed, Deprel: flat, Head: John\n",
      "Word: the, Deprel: det, Head: executive\n",
      "Word: former, Deprel: amod, Head: executive\n",
      "Word: Citicorp, Deprel: compound, Head: executive\n",
      "Word: chief, Deprel: compound, Head: executive\n",
      "Word: executive, Deprel: appos, Head: John\n",
      "Word: who, Deprel: nsubj, Head: became\n",
      "Word: became, Deprel: acl:relcl, Head: executive\n",
      "Word: interim, Deprel: amod, Head: chairman\n",
      "Word: chairman, Deprel: xcomp, Head: became\n",
      "Word: and, Deprel: cc, Head: executive\n",
      "Word: chief, Deprel: amod, Head: executive\n",
      "Word: executive, Deprel: conj, Head: chairman\n",
      "Word: of, Deprel: case, Head: exchange\n",
      "Word: the, Deprel: det, Head: exchange\n",
      "Word: exchange, Deprel: nmod, Head: executive\n",
      "Word: last, Deprel: amod, Head: Sunday\n",
      "Word: Sunday, Deprel: nmod:tmod, Head: chairman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Next week John S Reed the former Citicorp chief executive who Sunday became interim chairman and chief executive of the exchange will take up his position'\n",
      "Word: Next, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: take\n",
      "Word: John, Deprel: nsubj, Head: take\n",
      "Word: S, Deprel: flat, Head: John\n",
      "Word: Reed, Deprel: flat, Head: John\n",
      "Word: the, Deprel: det, Head: executive\n",
      "Word: former, Deprel: amod, Head: executive\n",
      "Word: Citicorp, Deprel: compound, Head: executive\n",
      "Word: chief, Deprel: amod, Head: executive\n",
      "Word: executive, Deprel: appos, Head: John\n",
      "Word: who, Deprel: nsubj, Head: became\n",
      "Word: Sunday, Deprel: nsubj, Head: became\n",
      "Word: became, Deprel: acl:relcl, Head: executive\n",
      "Word: interim, Deprel: amod, Head: chairman\n",
      "Word: chairman, Deprel: xcomp, Head: became\n",
      "Word: and, Deprel: cc, Head: executive\n",
      "Word: chief, Deprel: amod, Head: executive\n",
      "Word: executive, Deprel: conj, Head: chairman\n",
      "Word: of, Deprel: case, Head: exchange\n",
      "Word: the, Deprel: det, Head: exchange\n",
      "Word: exchange, Deprel: nmod, Head: executive\n",
      "Word: will, Deprel: aux, Head: take\n",
      "Word: take, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: take\n",
      "Word: his, Deprel: nmod:poss, Head: position\n",
      "Word: position, Deprel: obj, Head: take\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The index which measures activity in the service sector climbed to 50.7 last month from 47.9 in March'\n",
      "Word: The, Deprel: det, Head: index\n",
      "Word: index, Deprel: nsubj, Head: climbed\n",
      "Word: which, Deprel: nsubj, Head: measures\n",
      "Word: measures, Deprel: acl:relcl, Head: index\n",
      "Word: activity, Deprel: obj, Head: measures\n",
      "Word: in, Deprel: case, Head: sector\n",
      "Word: the, Deprel: det, Head: sector\n",
      "Word: service, Deprel: compound, Head: sector\n",
      "Word: sector, Deprel: nmod, Head: activity\n",
      "Word: climbed, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: 50.7\n",
      "Word: 50.7, Deprel: obl, Head: climbed\n",
      "Word: last, Deprel: amod, Head: month\n",
      "Word: month, Deprel: obl:tmod, Head: climbed\n",
      "Word: from, Deprel: case, Head: 47.9\n",
      "Word: 47.9, Deprel: obl, Head: climbed\n",
      "Word: in, Deprel: case, Head: March\n",
      "Word: March, Deprel: nmod, Head: 47.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Arizona-based ISM reported Monday that its non-manufacturing index rose to 50.7 last month from 47.9 in March'\n",
      "Word: The, Deprel: det, Head: ISM\n",
      "Word: Arizona-based, Deprel: amod, Head: ISM\n",
      "Word: ISM, Deprel: nsubj, Head: reported\n",
      "Word: reported, Deprel: root, Head: ROOT\n",
      "Word: Monday, Deprel: obl:tmod, Head: reported\n",
      "Word: that, Deprel: mark, Head: rose\n",
      "Word: its, Deprel: nmod:poss, Head: index\n",
      "Word: non-manufacturing, Deprel: compound, Head: index\n",
      "Word: index, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: ccomp, Head: reported\n",
      "Word: to, Deprel: case, Head: 50.7\n",
      "Word: 50.7, Deprel: obl, Head: rose\n",
      "Word: last, Deprel: amod, Head: month\n",
      "Word: month, Deprel: obl:tmod, Head: rose\n",
      "Word: from, Deprel: case, Head: 47.9\n",
      "Word: 47.9, Deprel: obl, Head: rose\n",
      "Word: in, Deprel: case, Head: March\n",
      "Word: March, Deprel: obl, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bush plans to meet with Israeli Prime Minister Ariel Sharon and the new Palestinian prime minister Mahmoud Abbas in the Jordanian port of Aqaba on Wednesday'\n",
      "Word: Bush, Deprel: nsubj, Head: plans\n",
      "Word: plans, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: meet\n",
      "Word: meet, Deprel: xcomp, Head: plans\n",
      "Word: with, Deprel: case, Head: Minister\n",
      "Word: Israeli, Deprel: amod, Head: Minister\n",
      "Word: Prime, Deprel: amod, Head: Minister\n",
      "Word: Minister, Deprel: obl, Head: meet\n",
      "Word: Ariel, Deprel: flat, Head: Minister\n",
      "Word: Sharon, Deprel: flat, Head: Minister\n",
      "Word: and, Deprel: cc, Head: minister\n",
      "Word: the, Deprel: det, Head: minister\n",
      "Word: new, Deprel: amod, Head: minister\n",
      "Word: Palestinian, Deprel: amod, Head: minister\n",
      "Word: prime, Deprel: amod, Head: minister\n",
      "Word: minister, Deprel: conj, Head: Minister\n",
      "Word: Mahmoud, Deprel: appos, Head: minister\n",
      "Word: Abbas, Deprel: flat, Head: Mahmoud\n",
      "Word: in, Deprel: case, Head: port\n",
      "Word: the, Deprel: det, Head: port\n",
      "Word: Jordanian, Deprel: amod, Head: port\n",
      "Word: port, Deprel: obl, Head: meet\n",
      "Word: of, Deprel: case, Head: Aqaba\n",
      "Word: Aqaba, Deprel: nmod, Head: port\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: nmod, Head: port\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Wednesday next week Mr Bush will meet Israeli Prime Minister Ariel Sharon and new Palestinian leader Mahmoud Abbas in Aqaba Jordan'\n",
      "Word: On, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: meet\n",
      "Word: next, Deprel: amod, Head: week\n",
      "Word: week, Deprel: nmod:tmod, Head: Wednesday\n",
      "Word: Mr, Deprel: nsubj, Head: meet\n",
      "Word: Bush, Deprel: flat, Head: Mr\n",
      "Word: will, Deprel: aux, Head: meet\n",
      "Word: meet, Deprel: root, Head: ROOT\n",
      "Word: Israeli, Deprel: amod, Head: Minister\n",
      "Word: Prime, Deprel: amod, Head: Minister\n",
      "Word: Minister, Deprel: obj, Head: meet\n",
      "Word: Ariel, Deprel: flat, Head: Minister\n",
      "Word: Sharon, Deprel: flat, Head: Minister\n",
      "Word: and, Deprel: cc, Head: Mahmoud\n",
      "Word: new, Deprel: amod, Head: Mahmoud\n",
      "Word: Palestinian, Deprel: amod, Head: leader\n",
      "Word: leader, Deprel: compound, Head: Mahmoud\n",
      "Word: Mahmoud, Deprel: conj, Head: Minister\n",
      "Word: Abbas, Deprel: flat, Head: Mahmoud\n",
      "Word: in, Deprel: case, Head: Aqaba\n",
      "Word: Aqaba, Deprel: obl, Head: meet\n",
      "Word: Jordan, Deprel: flat, Head: Aqaba\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Unlike many early-stage Internet firms Google is believed to be profitable'\n",
      "Word: Unlike, Deprel: case, Head: firms\n",
      "Word: many, Deprel: amod, Head: firms\n",
      "Word: early-stage, Deprel: amod, Head: firms\n",
      "Word: Internet, Deprel: compound, Head: firms\n",
      "Word: firms, Deprel: obl, Head: believed\n",
      "Word: Google, Deprel: nsubj:pass, Head: believed\n",
      "Word: is, Deprel: aux:pass, Head: believed\n",
      "Word: believed, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: profitable\n",
      "Word: be, Deprel: cop, Head: profitable\n",
      "Word: profitable, Deprel: xcomp, Head: believed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The privately held Google is believed to be profitable'\n",
      "Word: The, Deprel: det, Head: Google\n",
      "Word: privately, Deprel: advmod, Head: held\n",
      "Word: held, Deprel: amod, Head: Google\n",
      "Word: Google, Deprel: nsubj:pass, Head: believed\n",
      "Word: is, Deprel: aux:pass, Head: believed\n",
      "Word: believed, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: profitable\n",
      "Word: be, Deprel: cop, Head: profitable\n",
      "Word: profitable, Deprel: xcomp, Head: believed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It is safe to assume the Senate is prepared to pass some form of cap King said'\n",
      "Word: It, Deprel: expl, Head: safe\n",
      "Word: is, Deprel: cop, Head: safe\n",
      "Word: safe, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: assume\n",
      "Word: assume, Deprel: csubj, Head: safe\n",
      "Word: the, Deprel: det, Head: Senate\n",
      "Word: Senate, Deprel: nsubj, Head: prepared\n",
      "Word: is, Deprel: cop, Head: prepared\n",
      "Word: prepared, Deprel: ccomp, Head: assume\n",
      "Word: to, Deprel: mark, Head: pass\n",
      "Word: pass, Deprel: xcomp, Head: prepared\n",
      "Word: some, Deprel: det, Head: form\n",
      "Word: form, Deprel: obj, Head: pass\n",
      "Word: of, Deprel: case, Head: King\n",
      "Word: cap, Deprel: compound, Head: King\n",
      "Word: King, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl, Head: form\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Its safe to assume the Senate is prepared to pass some form of a cap The level of it is to be debated'\n",
      "Word: Its, Deprel: nmod:poss, Head: safe\n",
      "Word: safe, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: assume\n",
      "Word: assume, Deprel: csubj, Head: safe\n",
      "Word: the, Deprel: det, Head: Senate\n",
      "Word: Senate, Deprel: nsubj, Head: prepared\n",
      "Word: is, Deprel: cop, Head: prepared\n",
      "Word: prepared, Deprel: ccomp, Head: assume\n",
      "Word: to, Deprel: mark, Head: pass\n",
      "Word: pass, Deprel: xcomp, Head: prepared\n",
      "Word: some, Deprel: det, Head: form\n",
      "Word: form, Deprel: obj, Head: pass\n",
      "Word: of, Deprel: case, Head: cap\n",
      "Word: a, Deprel: det, Head: cap\n",
      "Word: cap, Deprel: nmod, Head: form\n",
      "Word: The, Deprel: det, Head: level\n",
      "Word: level, Deprel: nsubj, Head: is\n",
      "Word: of, Deprel: case, Head: it\n",
      "Word: it, Deprel: nmod, Head: level\n",
      "Word: is, Deprel: acl:relcl, Head: cap\n",
      "Word: to, Deprel: mark, Head: debated\n",
      "Word: be, Deprel: aux:pass, Head: debated\n",
      "Word: debated, Deprel: xcomp, Head: is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'And when asked if he felt regret or guilt about the attack his answer was an adamant no'\n",
      "Word: And, Deprel: cc, Head: adamant\n",
      "Word: when, Deprel: advmod, Head: asked\n",
      "Word: asked, Deprel: advcl, Head: adamant\n",
      "Word: if, Deprel: mark, Head: felt\n",
      "Word: he, Deprel: nsubj, Head: felt\n",
      "Word: felt, Deprel: ccomp, Head: asked\n",
      "Word: regret, Deprel: obj, Head: felt\n",
      "Word: or, Deprel: cc, Head: guilt\n",
      "Word: guilt, Deprel: conj, Head: regret\n",
      "Word: about, Deprel: case, Head: attack\n",
      "Word: the, Deprel: det, Head: attack\n",
      "Word: attack, Deprel: nmod, Head: regret\n",
      "Word: his, Deprel: nmod:poss, Head: answer\n",
      "Word: answer, Deprel: nsubj, Head: adamant\n",
      "Word: was, Deprel: cop, Head: adamant\n",
      "Word: an, Deprel: det, Head: adamant\n",
      "Word: adamant, Deprel: root, Head: ROOT\n",
      "Word: no, Deprel: discourse, Head: adamant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Asked if he felt any regret about theOctober 12 attack the answer was an adamant no'\n",
      "Word: Asked, Deprel: advcl, Head: adamant\n",
      "Word: if, Deprel: mark, Head: felt\n",
      "Word: he, Deprel: nsubj, Head: felt\n",
      "Word: felt, Deprel: ccomp, Head: Asked\n",
      "Word: any, Deprel: det, Head: regret\n",
      "Word: regret, Deprel: obj, Head: felt\n",
      "Word: about, Deprel: case, Head: attack\n",
      "Word: theOctober, Deprel: compound, Head: attack\n",
      "Word: 12, Deprel: nummod, Head: attack\n",
      "Word: attack, Deprel: nmod, Head: regret\n",
      "Word: the, Deprel: det, Head: answer\n",
      "Word: answer, Deprel: nsubj, Head: adamant\n",
      "Word: was, Deprel: cop, Head: adamant\n",
      "Word: an, Deprel: det, Head: adamant\n",
      "Word: adamant, Deprel: root, Head: ROOT\n",
      "Word: no, Deprel: discourse, Head: adamant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Another big gainer was Rambus Inc nasdaq RMBS news people which shot 32 percent higher'\n",
      "Word: Another, Deprel: det, Head: gainer\n",
      "Word: big, Deprel: amod, Head: gainer\n",
      "Word: gainer, Deprel: nsubj, Head: people\n",
      "Word: was, Deprel: cop, Head: people\n",
      "Word: Rambus, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: compound, Head: people\n",
      "Word: nasdaq, Deprel: compound, Head: people\n",
      "Word: RMBS, Deprel: compound, Head: people\n",
      "Word: news, Deprel: compound, Head: people\n",
      "Word: people, Deprel: root, Head: ROOT\n",
      "Word: which, Deprel: nsubj, Head: shot\n",
      "Word: shot, Deprel: acl:relcl, Head: people\n",
      "Word: 32, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:npmod, Head: higher\n",
      "Word: higher, Deprel: advmod, Head: shot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Rambus Inc nasdaq RMBS news people shot up 38 percent making it the biggest percentage gainer on the Nasdaq'\n",
      "Word: Rambus, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: compound, Head: people\n",
      "Word: nasdaq, Deprel: compound, Head: people\n",
      "Word: RMBS, Deprel: compound, Head: people\n",
      "Word: news, Deprel: compound, Head: people\n",
      "Word: people, Deprel: nsubj, Head: shot\n",
      "Word: shot, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: advmod, Head: shot\n",
      "Word: 38, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: shot\n",
      "Word: making, Deprel: advcl, Head: shot\n",
      "Word: it, Deprel: obj, Head: making\n",
      "Word: the, Deprel: det, Head: gainer\n",
      "Word: biggest, Deprel: amod, Head: gainer\n",
      "Word: percentage, Deprel: compound, Head: gainer\n",
      "Word: gainer, Deprel: xcomp, Head: making\n",
      "Word: on, Deprel: case, Head: Nasdaq\n",
      "Word: the, Deprel: det, Head: Nasdaq\n",
      "Word: Nasdaq, Deprel: nmod, Head: gainer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Russ Britt is the Los Angeles Bureau Chief for CBS.MarketWatch.com'\n",
      "Word: Russ, Deprel: nsubj, Head: Chief\n",
      "Word: Britt, Deprel: flat, Head: Russ\n",
      "Word: is, Deprel: cop, Head: Chief\n",
      "Word: the, Deprel: det, Head: Chief\n",
      "Word: Los, Deprel: compound, Head: Chief\n",
      "Word: Angeles, Deprel: flat, Head: Los\n",
      "Word: Bureau, Deprel: compound, Head: Chief\n",
      "Word: Chief, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: CBS.MarketWatch.com\n",
      "Word: CBS.MarketWatch.com, Deprel: nmod, Head: Chief\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Emily Church is London bureau chief of CBS.MarketWatch.com'\n",
      "Word: Emily, Deprel: nsubj, Head: chief\n",
      "Word: Church, Deprel: flat, Head: Emily\n",
      "Word: is, Deprel: cop, Head: chief\n",
      "Word: London, Deprel: compound, Head: chief\n",
      "Word: bureau, Deprel: compound, Head: chief\n",
      "Word: chief, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: CBS.MarketWatch.com\n",
      "Word: CBS.MarketWatch.com, Deprel: nmod, Head: chief\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'If you pass this bill Big Brother will be watching you said Rep John Mabry D-Waco'\n",
      "Word: If, Deprel: mark, Head: pass\n",
      "Word: you, Deprel: nsubj, Head: pass\n",
      "Word: pass, Deprel: advcl, Head: watching\n",
      "Word: this, Deprel: det, Head: bill\n",
      "Word: bill, Deprel: obj, Head: pass\n",
      "Word: Big, Deprel: amod, Head: Brother\n",
      "Word: Brother, Deprel: nsubj, Head: watching\n",
      "Word: will, Deprel: aux, Head: watching\n",
      "Word: be, Deprel: aux, Head: watching\n",
      "Word: watching, Deprel: root, Head: ROOT\n",
      "Word: you, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: ccomp, Head: watching\n",
      "Word: Rep, Deprel: obj, Head: said\n",
      "Word: John, Deprel: flat, Head: Rep\n",
      "Word: Mabry, Deprel: flat, Head: Rep\n",
      "Word: D-Waco, Deprel: flat, Head: Rep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'If you pass this bill Rep John Mabry Jr D-Waco told colleagues Big Brother will be watching you'\n",
      "Word: If, Deprel: mark, Head: pass\n",
      "Word: you, Deprel: nsubj, Head: pass\n",
      "Word: pass, Deprel: advcl, Head: told\n",
      "Word: this, Deprel: det, Head: bill\n",
      "Word: bill, Deprel: obj, Head: pass\n",
      "Word: Rep, Deprel: nsubj, Head: told\n",
      "Word: John, Deprel: flat, Head: Rep\n",
      "Word: Mabry, Deprel: flat, Head: Rep\n",
      "Word: Jr, Deprel: flat, Head: Rep\n",
      "Word: D-Waco, Deprel: flat, Head: Rep\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: colleagues, Deprel: iobj, Head: told\n",
      "Word: Big, Deprel: amod, Head: Brother\n",
      "Word: Brother, Deprel: nsubj, Head: watching\n",
      "Word: will, Deprel: aux, Head: watching\n",
      "Word: be, Deprel: aux, Head: watching\n",
      "Word: watching, Deprel: ccomp, Head: told\n",
      "Word: you, Deprel: obj, Head: watching\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Douglas Robinson a senior vice president of finance will take over as chief financial officer on an interim basis'\n",
      "Word: Douglas, Deprel: nsubj, Head: take\n",
      "Word: Robinson, Deprel: flat, Head: Douglas\n",
      "Word: a, Deprel: det, Head: president\n",
      "Word: senior, Deprel: amod, Head: president\n",
      "Word: vice, Deprel: compound, Head: president\n",
      "Word: president, Deprel: appos, Head: Douglas\n",
      "Word: of, Deprel: case, Head: finance\n",
      "Word: finance, Deprel: nmod, Head: president\n",
      "Word: will, Deprel: aux, Head: take\n",
      "Word: take, Deprel: root, Head: ROOT\n",
      "Word: over, Deprel: compound:prt, Head: take\n",
      "Word: as, Deprel: case, Head: officer\n",
      "Word: chief, Deprel: amod, Head: officer\n",
      "Word: financial, Deprel: amod, Head: officer\n",
      "Word: officer, Deprel: obl, Head: take\n",
      "Word: on, Deprel: case, Head: basis\n",
      "Word: an, Deprel: det, Head: basis\n",
      "Word: interim, Deprel: amod, Head: basis\n",
      "Word: basis, Deprel: obl, Head: take\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Douglas Robinson CA senior vice president finance will fill the position in the interim'\n",
      "Word: Douglas, Deprel: nsubj, Head: fill\n",
      "Word: Robinson, Deprel: flat, Head: Douglas\n",
      "Word: CA, Deprel: flat, Head: Douglas\n",
      "Word: senior, Deprel: amod, Head: finance\n",
      "Word: vice, Deprel: compound, Head: president\n",
      "Word: president, Deprel: compound, Head: finance\n",
      "Word: finance, Deprel: nsubj, Head: fill\n",
      "Word: will, Deprel: aux, Head: fill\n",
      "Word: fill, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: position\n",
      "Word: position, Deprel: obj, Head: fill\n",
      "Word: in, Deprel: case, Head: interim\n",
      "Word: the, Deprel: det, Head: interim\n",
      "Word: interim, Deprel: obl, Head: fill\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'INTEL TODAY disclosed details of its next-generation XScale processor for mobile phones and handheld devices here in San Jose'\n",
      "Word: INTEL, Deprel: nsubj, Head: disclosed\n",
      "Word: TODAY, Deprel: flat, Head: INTEL\n",
      "Word: disclosed, Deprel: root, Head: ROOT\n",
      "Word: details, Deprel: obj, Head: disclosed\n",
      "Word: of, Deprel: case, Head: processor\n",
      "Word: its, Deprel: nmod:poss, Head: processor\n",
      "Word: next-generation, Deprel: amod, Head: processor\n",
      "Word: XScale, Deprel: compound, Head: processor\n",
      "Word: processor, Deprel: nmod, Head: details\n",
      "Word: for, Deprel: case, Head: phones\n",
      "Word: mobile, Deprel: amod, Head: phones\n",
      "Word: phones, Deprel: nmod, Head: processor\n",
      "Word: and, Deprel: cc, Head: devices\n",
      "Word: handheld, Deprel: compound, Head: devices\n",
      "Word: devices, Deprel: conj, Head: phones\n",
      "Word: here, Deprel: advmod, Head: disclosed\n",
      "Word: in, Deprel: case, Head: San\n",
      "Word: San, Deprel: obl, Head: disclosed\n",
      "Word: Jose, Deprel: flat, Head: San\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Intel on Wednesday unveiled its next-generation processor for cell phones PDAs and other wireless devices'\n",
      "Word: Intel, Deprel: nsubj, Head: unveiled\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: nmod, Head: Intel\n",
      "Word: unveiled, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: processor\n",
      "Word: next-generation, Deprel: amod, Head: processor\n",
      "Word: processor, Deprel: obj, Head: unveiled\n",
      "Word: for, Deprel: case, Head: phones\n",
      "Word: cell, Deprel: compound, Head: phones\n",
      "Word: phones, Deprel: nmod, Head: processor\n",
      "Word: PDAs, Deprel: nmod, Head: processor\n",
      "Word: and, Deprel: cc, Head: devices\n",
      "Word: other, Deprel: amod, Head: devices\n",
      "Word: wireless, Deprel: amod, Head: devices\n",
      "Word: devices, Deprel: conj, Head: PDAs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Several states and the federal government later passed similar or more strict bans'\n",
      "Word: Several, Deprel: amod, Head: states\n",
      "Word: states, Deprel: nsubj, Head: passed\n",
      "Word: and, Deprel: cc, Head: government\n",
      "Word: the, Deprel: det, Head: government\n",
      "Word: federal, Deprel: amod, Head: government\n",
      "Word: government, Deprel: conj, Head: states\n",
      "Word: later, Deprel: advmod, Head: passed\n",
      "Word: passed, Deprel: root, Head: ROOT\n",
      "Word: similar, Deprel: amod, Head: bans\n",
      "Word: or, Deprel: cc, Head: strict\n",
      "Word: more, Deprel: advmod, Head: strict\n",
      "Word: strict, Deprel: conj, Head: similar\n",
      "Word: bans, Deprel: obj, Head: passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Following California s lead several states and the federal government passed similar or tougher bans'\n",
      "Word: Following, Deprel: case, Head: lead\n",
      "Word: California, Deprel: nmod:poss, Head: lead\n",
      "Word: s, Deprel: case, Head: California\n",
      "Word: lead, Deprel: obl, Head: passed\n",
      "Word: several, Deprel: amod, Head: states\n",
      "Word: states, Deprel: nsubj, Head: passed\n",
      "Word: and, Deprel: cc, Head: government\n",
      "Word: the, Deprel: det, Head: government\n",
      "Word: federal, Deprel: amod, Head: government\n",
      "Word: government, Deprel: conj, Head: states\n",
      "Word: passed, Deprel: root, Head: ROOT\n",
      "Word: similar, Deprel: amod, Head: bans\n",
      "Word: or, Deprel: cc, Head: tougher\n",
      "Word: tougher, Deprel: conj, Head: similar\n",
      "Word: bans, Deprel: obj, Head: passed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Still he noted Miami must decide whether to seek ACC membership for the next school year by June 30 to adhere to Big East guidelines'\n",
      "Word: Still, Deprel: advmod, Head: noted\n",
      "Word: he, Deprel: nsubj, Head: noted\n",
      "Word: noted, Deprel: root, Head: ROOT\n",
      "Word: Miami, Deprel: nsubj, Head: decide\n",
      "Word: must, Deprel: aux, Head: decide\n",
      "Word: decide, Deprel: ccomp, Head: noted\n",
      "Word: whether, Deprel: mark, Head: seek\n",
      "Word: to, Deprel: mark, Head: seek\n",
      "Word: seek, Deprel: xcomp, Head: decide\n",
      "Word: ACC, Deprel: compound, Head: membership\n",
      "Word: membership, Deprel: obj, Head: seek\n",
      "Word: for, Deprel: case, Head: year\n",
      "Word: the, Deprel: det, Head: year\n",
      "Word: next, Deprel: amod, Head: year\n",
      "Word: school, Deprel: compound, Head: year\n",
      "Word: year, Deprel: obl, Head: seek\n",
      "Word: by, Deprel: case, Head: June\n",
      "Word: June, Deprel: obl, Head: seek\n",
      "Word: 30, Deprel: nummod, Head: June\n",
      "Word: to, Deprel: mark, Head: adhere\n",
      "Word: adhere, Deprel: advcl, Head: seek\n",
      "Word: to, Deprel: case, Head: guidelines\n",
      "Word: Big, Deprel: amod, Head: East\n",
      "Word: East, Deprel: compound, Head: guidelines\n",
      "Word: guidelines, Deprel: obl, Head: adhere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Still he noted that Miami must decide whether to seek A.C.C membership by June 30 to adhere to Big East guidelines'\n",
      "Word: Still, Deprel: advmod, Head: noted\n",
      "Word: he, Deprel: nsubj, Head: noted\n",
      "Word: noted, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: decide\n",
      "Word: Miami, Deprel: nsubj, Head: decide\n",
      "Word: must, Deprel: aux, Head: decide\n",
      "Word: decide, Deprel: ccomp, Head: noted\n",
      "Word: whether, Deprel: mark, Head: seek\n",
      "Word: to, Deprel: mark, Head: seek\n",
      "Word: seek, Deprel: xcomp, Head: decide\n",
      "Word: A.C.C, Deprel: compound, Head: membership\n",
      "Word: membership, Deprel: obj, Head: seek\n",
      "Word: by, Deprel: case, Head: June\n",
      "Word: June, Deprel: obl, Head: seek\n",
      "Word: 30, Deprel: nummod, Head: June\n",
      "Word: to, Deprel: mark, Head: adhere\n",
      "Word: adhere, Deprel: advcl, Head: seek\n",
      "Word: to, Deprel: case, Head: guidelines\n",
      "Word: Big, Deprel: amod, Head: East\n",
      "Word: East, Deprel: compound, Head: guidelines\n",
      "Word: guidelines, Deprel: obl, Head: adhere\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He refused to reveal what percentage of flights carried sky marshals or whether they would be increased'\n",
      "Word: He, Deprel: nsubj, Head: refused\n",
      "Word: refused, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: reveal\n",
      "Word: reveal, Deprel: xcomp, Head: refused\n",
      "Word: what, Deprel: det, Head: percentage\n",
      "Word: percentage, Deprel: nsubj, Head: carried\n",
      "Word: of, Deprel: case, Head: flights\n",
      "Word: flights, Deprel: nmod, Head: percentage\n",
      "Word: carried, Deprel: ccomp, Head: reveal\n",
      "Word: sky, Deprel: compound, Head: marshals\n",
      "Word: marshals, Deprel: obj, Head: carried\n",
      "Word: or, Deprel: cc, Head: increased\n",
      "Word: whether, Deprel: mark, Head: increased\n",
      "Word: they, Deprel: nsubj, Head: increased\n",
      "Word: would, Deprel: aux, Head: increased\n",
      "Word: be, Deprel: aux:pass, Head: increased\n",
      "Word: increased, Deprel: conj, Head: carried\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He refused to say what percentage of domestic flights had security officers on board'\n",
      "Word: He, Deprel: nsubj, Head: refused\n",
      "Word: refused, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: say\n",
      "Word: say, Deprel: xcomp, Head: refused\n",
      "Word: what, Deprel: det, Head: percentage\n",
      "Word: percentage, Deprel: nsubj, Head: had\n",
      "Word: of, Deprel: case, Head: flights\n",
      "Word: domestic, Deprel: amod, Head: flights\n",
      "Word: flights, Deprel: nmod, Head: percentage\n",
      "Word: had, Deprel: ccomp, Head: say\n",
      "Word: security, Deprel: compound, Head: officers\n",
      "Word: officers, Deprel: obj, Head: had\n",
      "Word: on, Deprel: case, Head: board\n",
      "Word: board, Deprel: obl, Head: had\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Revenues for The Hulk came in well below those of last month s Marvel Comics adaptation X2 X-Men United which grossed 85.6 million in its opening weekend'\n",
      "Word: Revenues, Deprel: nsubj, Head: came\n",
      "Word: for, Deprel: case, Head: Hulk\n",
      "Word: The, Deprel: det, Head: Hulk\n",
      "Word: Hulk, Deprel: nmod, Head: Revenues\n",
      "Word: came, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: advmod, Head: came\n",
      "Word: well, Deprel: advmod, Head: those\n",
      "Word: below, Deprel: case, Head: those\n",
      "Word: those, Deprel: obl, Head: came\n",
      "Word: of, Deprel: case, Head: X2\n",
      "Word: last, Deprel: amod, Head: month\n",
      "Word: month, Deprel: nmod:poss, Head: X2\n",
      "Word: s, Deprel: case, Head: month\n",
      "Word: Marvel, Deprel: compound, Head: Comics\n",
      "Word: Comics, Deprel: compound, Head: adaptation\n",
      "Word: adaptation, Deprel: compound, Head: X2\n",
      "Word: X2, Deprel: nmod, Head: those\n",
      "Word: X-Men, Deprel: compound, Head: United\n",
      "Word: United, Deprel: appos, Head: X2\n",
      "Word: which, Deprel: nsubj, Head: grossed\n",
      "Word: grossed, Deprel: acl:relcl, Head: X2\n",
      "Word: 85.6, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: obj, Head: grossed\n",
      "Word: in, Deprel: case, Head: weekend\n",
      "Word: its, Deprel: nmod:poss, Head: weekend\n",
      "Word: opening, Deprel: amod, Head: weekend\n",
      "Word: weekend, Deprel: obl, Head: grossed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Hulk trailed last month s Marvel Comics adaptation X2 X-Men United which grossed 85.6-million in its opening weekend'\n",
      "Word: The, Deprel: det, Head: Hulk\n",
      "Word: Hulk, Deprel: nsubj, Head: trailed\n",
      "Word: trailed, Deprel: root, Head: ROOT\n",
      "Word: last, Deprel: amod, Head: month\n",
      "Word: month, Deprel: nmod:poss, Head: X2\n",
      "Word: s, Deprel: case, Head: month\n",
      "Word: Marvel, Deprel: compound, Head: Comics\n",
      "Word: Comics, Deprel: compound, Head: adaptation\n",
      "Word: adaptation, Deprel: compound, Head: X2\n",
      "Word: X2, Deprel: obj, Head: trailed\n",
      "Word: X-Men, Deprel: compound, Head: United\n",
      "Word: United, Deprel: appos, Head: X2\n",
      "Word: which, Deprel: nsubj, Head: grossed\n",
      "Word: grossed, Deprel: acl:relcl, Head: X2\n",
      "Word: 85.6-million, Deprel: obj, Head: grossed\n",
      "Word: in, Deprel: case, Head: weekend\n",
      "Word: its, Deprel: nmod:poss, Head: weekend\n",
      "Word: opening, Deprel: amod, Head: weekend\n",
      "Word: weekend, Deprel: obl, Head: grossed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of Littleton Colorado-based EchoStar rose 1.63 or 5.3 percent to 32.26 at 10:55 a.m'\n",
      "Word: Shares, Deprel: nsubj, Head: rose\n",
      "Word: of, Deprel: case, Head: EchoStar\n",
      "Word: Littleton, Deprel: compound, Head: EchoStar\n",
      "Word: Colorado-based, Deprel: compound, Head: EchoStar\n",
      "Word: EchoStar, Deprel: nmod, Head: Shares\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 1.63, Deprel: nummod, Head: percent\n",
      "Word: or, Deprel: cc, Head: 5.3\n",
      "Word: 5.3, Deprel: conj, Head: 1.63\n",
      "Word: percent, Deprel: obl:tmod, Head: rose\n",
      "Word: to, Deprel: case, Head: 32.26\n",
      "Word: 32.26, Deprel: obl, Head: rose\n",
      "Word: at, Deprel: case, Head: a.m\n",
      "Word: 10:55, Deprel: nummod, Head: a.m\n",
      "Word: a.m, Deprel: obl, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Monday EchoStar DISH news chart profile shares shrank 1.40 or 4.4 percent to 30.63'\n",
      "Word: On, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: shrank\n",
      "Word: EchoStar, Deprel: compound, Head: DISH\n",
      "Word: DISH, Deprel: compound, Head: news\n",
      "Word: news, Deprel: compound, Head: shares\n",
      "Word: chart, Deprel: compound, Head: profile\n",
      "Word: profile, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: shrank\n",
      "Word: shrank, Deprel: root, Head: ROOT\n",
      "Word: 1.40, Deprel: nummod, Head: percent\n",
      "Word: or, Deprel: cc, Head: 4.4\n",
      "Word: 4.4, Deprel: conj, Head: 1.40\n",
      "Word: percent, Deprel: obl:tmod, Head: shrank\n",
      "Word: to, Deprel: case, Head: 30.63\n",
      "Word: 30.63, Deprel: obl, Head: shrank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The valid signatures of 897,158 registered California voters must be collected and turned in to county election officials by Sept 2'\n",
      "Word: The, Deprel: det, Head: signatures\n",
      "Word: valid, Deprel: amod, Head: signatures\n",
      "Word: signatures, Deprel: nsubj:pass, Head: collected\n",
      "Word: of, Deprel: case, Head: voters\n",
      "Word: 897,158, Deprel: nummod, Head: voters\n",
      "Word: registered, Deprel: amod, Head: voters\n",
      "Word: California, Deprel: compound, Head: voters\n",
      "Word: voters, Deprel: nmod, Head: signatures\n",
      "Word: must, Deprel: aux, Head: collected\n",
      "Word: be, Deprel: aux:pass, Head: collected\n",
      "Word: collected, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: turned\n",
      "Word: turned, Deprel: conj, Head: collected\n",
      "Word: in, Deprel: compound:prt, Head: turned\n",
      "Word: to, Deprel: case, Head: officials\n",
      "Word: county, Deprel: compound, Head: officials\n",
      "Word: election, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: obl, Head: turned\n",
      "Word: by, Deprel: case, Head: Sept\n",
      "Word: Sept, Deprel: obl, Head: turned\n",
      "Word: 2, Deprel: nummod, Head: Sept\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'To force a recall election of Davis the valid signatures of 897,158 registered California voters must be turned in to election officials'\n",
      "Word: To, Deprel: mark, Head: force\n",
      "Word: force, Deprel: advcl, Head: turned\n",
      "Word: a, Deprel: det, Head: election\n",
      "Word: recall, Deprel: compound, Head: election\n",
      "Word: election, Deprel: obj, Head: force\n",
      "Word: of, Deprel: case, Head: Davis\n",
      "Word: Davis, Deprel: nmod, Head: election\n",
      "Word: the, Deprel: det, Head: signatures\n",
      "Word: valid, Deprel: amod, Head: signatures\n",
      "Word: signatures, Deprel: nsubj:pass, Head: turned\n",
      "Word: of, Deprel: case, Head: voters\n",
      "Word: 897,158, Deprel: nummod, Head: voters\n",
      "Word: registered, Deprel: amod, Head: voters\n",
      "Word: California, Deprel: compound, Head: voters\n",
      "Word: voters, Deprel: nmod, Head: signatures\n",
      "Word: must, Deprel: aux, Head: turned\n",
      "Word: be, Deprel: aux:pass, Head: turned\n",
      "Word: turned, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: compound:prt, Head: turned\n",
      "Word: to, Deprel: case, Head: officials\n",
      "Word: election, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: obl, Head: turned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The benchmark 10-year note US10YT=RR lost 11/32 in price taking its yield to 3.21 percent from 3.17 percent late on Monday'\n",
      "Word: The, Deprel: det, Head: note\n",
      "Word: benchmark, Deprel: compound, Head: note\n",
      "Word: 10-year, Deprel: compound, Head: note\n",
      "Word: note, Deprel: compound, Head: US10YT=RR\n",
      "Word: US10YT=RR, Deprel: nsubj, Head: lost\n",
      "Word: lost, Deprel: root, Head: ROOT\n",
      "Word: 11/32, Deprel: obj, Head: lost\n",
      "Word: in, Deprel: case, Head: price\n",
      "Word: price, Deprel: nmod, Head: 11/32\n",
      "Word: taking, Deprel: advcl, Head: lost\n",
      "Word: its, Deprel: nmod:poss, Head: yield\n",
      "Word: yield, Deprel: obj, Head: taking\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 3.21, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n",
      "Word: from, Deprel: case, Head: percent\n",
      "Word: 3.17, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n",
      "Word: late, Deprel: advmod, Head: Monday\n",
      "Word: on, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: taking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Further out the curve the benchmark 10-year note US10YT=RR shed 18/32 in price taking its yield to 3.24 percent from 3.17 percent'\n",
      "Word: Further, Deprel: advmod, Head: shed\n",
      "Word: out, Deprel: advmod, Head: Further\n",
      "Word: the, Deprel: det, Head: curve\n",
      "Word: curve, Deprel: obl, Head: shed\n",
      "Word: the, Deprel: det, Head: US10YT=RR\n",
      "Word: benchmark, Deprel: compound, Head: note\n",
      "Word: 10-year, Deprel: compound, Head: note\n",
      "Word: note, Deprel: compound, Head: US10YT=RR\n",
      "Word: US10YT=RR, Deprel: nsubj, Head: shed\n",
      "Word: shed, Deprel: root, Head: ROOT\n",
      "Word: 18/32, Deprel: obj, Head: shed\n",
      "Word: in, Deprel: case, Head: price\n",
      "Word: price, Deprel: nmod, Head: 18/32\n",
      "Word: taking, Deprel: advcl, Head: shed\n",
      "Word: its, Deprel: nmod:poss, Head: yield\n",
      "Word: yield, Deprel: obj, Head: taking\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 3.24, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n",
      "Word: from, Deprel: case, Head: percent\n",
      "Word: 3.17, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The MDC called the strike to force Mr Mugabe to either resign or negotiate a settlement of the Zimbabwe crisis'\n",
      "Word: The, Deprel: det, Head: MDC\n",
      "Word: MDC, Deprel: nsubj, Head: called\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: strike\n",
      "Word: strike, Deprel: obj, Head: called\n",
      "Word: to, Deprel: mark, Head: force\n",
      "Word: force, Deprel: advcl, Head: called\n",
      "Word: Mr, Deprel: obj, Head: force\n",
      "Word: Mugabe, Deprel: flat, Head: Mr\n",
      "Word: to, Deprel: mark, Head: resign\n",
      "Word: either, Deprel: cc:preconj, Head: resign\n",
      "Word: resign, Deprel: xcomp, Head: force\n",
      "Word: or, Deprel: cc, Head: negotiate\n",
      "Word: negotiate, Deprel: conj, Head: resign\n",
      "Word: a, Deprel: det, Head: settlement\n",
      "Word: settlement, Deprel: obj, Head: resign\n",
      "Word: of, Deprel: case, Head: crisis\n",
      "Word: the, Deprel: det, Head: crisis\n",
      "Word: Zimbabwe, Deprel: compound, Head: crisis\n",
      "Word: crisis, Deprel: nmod, Head: settlement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The MDC called the week-long protest to urge Mugabe either to resign or to negotiate a settlement of the crisis gripping the country'\n",
      "Word: The, Deprel: det, Head: MDC\n",
      "Word: MDC, Deprel: nsubj, Head: called\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: protest\n",
      "Word: week-long, Deprel: amod, Head: protest\n",
      "Word: protest, Deprel: obj, Head: called\n",
      "Word: to, Deprel: mark, Head: urge\n",
      "Word: urge, Deprel: advcl, Head: called\n",
      "Word: Mugabe, Deprel: iobj, Head: urge\n",
      "Word: either, Deprel: cc:preconj, Head: resign\n",
      "Word: to, Deprel: mark, Head: resign\n",
      "Word: resign, Deprel: xcomp, Head: urge\n",
      "Word: or, Deprel: cc, Head: negotiate\n",
      "Word: to, Deprel: mark, Head: negotiate\n",
      "Word: negotiate, Deprel: conj, Head: resign\n",
      "Word: a, Deprel: det, Head: settlement\n",
      "Word: settlement, Deprel: obj, Head: negotiate\n",
      "Word: of, Deprel: case, Head: crisis\n",
      "Word: the, Deprel: det, Head: crisis\n",
      "Word: crisis, Deprel: nmod, Head: settlement\n",
      "Word: gripping, Deprel: acl, Head: crisis\n",
      "Word: the, Deprel: det, Head: country\n",
      "Word: country, Deprel: obj, Head: gripping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The 6th U.S Circuit Court of Appeals on Wednesday ruled that an Ohio law banning a controversial late-term abortion method passes constitutional muster and the state can enforce it'\n",
      "Word: The, Deprel: det, Head: Court\n",
      "Word: 6th, Deprel: amod, Head: Court\n",
      "Word: U.S, Deprel: compound, Head: Circuit\n",
      "Word: Circuit, Deprel: compound, Head: Court\n",
      "Word: Court, Deprel: nsubj, Head: ruled\n",
      "Word: of, Deprel: case, Head: Appeals\n",
      "Word: Appeals, Deprel: nmod, Head: Court\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: nmod, Head: Court\n",
      "Word: ruled, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: passes\n",
      "Word: an, Deprel: det, Head: law\n",
      "Word: Ohio, Deprel: compound, Head: law\n",
      "Word: law, Deprel: nsubj, Head: passes\n",
      "Word: banning, Deprel: acl, Head: law\n",
      "Word: a, Deprel: det, Head: method\n",
      "Word: controversial, Deprel: amod, Head: method\n",
      "Word: late-term, Deprel: amod, Head: method\n",
      "Word: abortion, Deprel: compound, Head: method\n",
      "Word: method, Deprel: obj, Head: banning\n",
      "Word: passes, Deprel: ccomp, Head: ruled\n",
      "Word: constitutional, Deprel: amod, Head: muster\n",
      "Word: muster, Deprel: obj, Head: passes\n",
      "Word: and, Deprel: cc, Head: enforce\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: state, Deprel: nsubj, Head: enforce\n",
      "Word: can, Deprel: aux, Head: enforce\n",
      "Word: enforce, Deprel: conj, Head: passes\n",
      "Word: it, Deprel: obj, Head: enforce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'An Ohio law that bans a controversial late-term abortion procedure is constitutionally acceptable and the state can enforce it a federal appeals court ruled yesterday'\n",
      "Word: An, Deprel: det, Head: law\n",
      "Word: Ohio, Deprel: compound, Head: law\n",
      "Word: law, Deprel: nsubj, Head: acceptable\n",
      "Word: that, Deprel: nsubj, Head: bans\n",
      "Word: bans, Deprel: acl:relcl, Head: law\n",
      "Word: a, Deprel: det, Head: procedure\n",
      "Word: controversial, Deprel: amod, Head: procedure\n",
      "Word: late-term, Deprel: amod, Head: procedure\n",
      "Word: abortion, Deprel: compound, Head: procedure\n",
      "Word: procedure, Deprel: obj, Head: bans\n",
      "Word: is, Deprel: cop, Head: acceptable\n",
      "Word: constitutionally, Deprel: advmod, Head: acceptable\n",
      "Word: acceptable, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: enforce\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: state, Deprel: nsubj, Head: enforce\n",
      "Word: can, Deprel: aux, Head: enforce\n",
      "Word: enforce, Deprel: conj, Head: acceptable\n",
      "Word: it, Deprel: obj, Head: enforce\n",
      "Word: a, Deprel: det, Head: court\n",
      "Word: federal, Deprel: amod, Head: court\n",
      "Word: appeals, Deprel: compound, Head: court\n",
      "Word: court, Deprel: nsubj:pass, Head: ruled\n",
      "Word: ruled, Deprel: advcl, Head: enforce\n",
      "Word: yesterday, Deprel: obl:tmod, Head: ruled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Nasdaq composite index advanced 20.59 or 1.3 percent to 1,616.50 after gaining 5.7 percent last week'\n",
      "Word: The, Deprel: det, Head: index\n",
      "Word: Nasdaq, Deprel: compound, Head: composite\n",
      "Word: composite, Deprel: compound, Head: index\n",
      "Word: index, Deprel: nsubj, Head: advanced\n",
      "Word: advanced, Deprel: root, Head: ROOT\n",
      "Word: 20.59, Deprel: nummod, Head: percent\n",
      "Word: or, Deprel: cc, Head: 1.3\n",
      "Word: 1.3, Deprel: conj, Head: 20.59\n",
      "Word: percent, Deprel: obj, Head: advanced\n",
      "Word: to, Deprel: case, Head: 1,616.50\n",
      "Word: 1,616.50, Deprel: obl, Head: advanced\n",
      "Word: after, Deprel: mark, Head: gaining\n",
      "Word: gaining, Deprel: advcl, Head: advanced\n",
      "Word: 5.7, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: gaining\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: gaining\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index IXIC climbed 19.11 points or 1.2 percent to 1,615.02'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-laced, Deprel: amod, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: climbed\n",
      "Word: climbed, Deprel: root, Head: ROOT\n",
      "Word: 19.11, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: climbed\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.2, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,615.02\n",
      "Word: 1,615.02, Deprel: obl, Head: climbed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Revenue rose 3.9 percent to 1.63 billion from 1.57 billion'\n",
      "Word: Revenue, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 3.9, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: rose\n",
      "Word: to, Deprel: case, Head: billion\n",
      "Word: 1.63, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obl, Head: rose\n",
      "Word: from, Deprel: case, Head: billion\n",
      "Word: 1.57, Deprel: nummod, Head: billion\n",
      "Word: billion, Deprel: obl, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The McLean Virginia-based company said newspaper revenue increased 5 percent to 1.46 billion'\n",
      "Word: The, Deprel: det, Head: company\n",
      "Word: McLean, Deprel: compound, Head: company\n",
      "Word: Virginia-based, Deprel: amod, Head: company\n",
      "Word: company, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: newspaper, Deprel: compound, Head: revenue\n",
      "Word: revenue, Deprel: nsubj, Head: increased\n",
      "Word: increased, Deprel: ccomp, Head: said\n",
      "Word: 5, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: increased\n",
      "Word: to, Deprel: case, Head: billion\n",
      "Word: 1.46, Deprel: nummod, Head: billion\n",
      "Word: billion, Deprel: obl, Head: increased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In January 2000 notebooks represented less than 25 percent of sales volume'\n",
      "Word: In, Deprel: case, Head: January\n",
      "Word: January, Deprel: obl, Head: represented\n",
      "Word: 2000, Deprel: nummod, Head: January\n",
      "Word: notebooks, Deprel: nsubj, Head: represented\n",
      "Word: represented, Deprel: root, Head: ROOT\n",
      "Word: less, Deprel: advmod, Head: 25\n",
      "Word: than, Deprel: fixed, Head: less\n",
      "Word: 25, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: represented\n",
      "Word: of, Deprel: case, Head: volume\n",
      "Word: sales, Deprel: compound, Head: volume\n",
      "Word: volume, Deprel: nmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'That compares with January 2000 when laptops represented less than 25 percent of sales volume NPD said'\n",
      "Word: That, Deprel: nsubj, Head: compares\n",
      "Word: compares, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: January\n",
      "Word: January, Deprel: obl, Head: compares\n",
      "Word: 2000, Deprel: nummod, Head: January\n",
      "Word: when, Deprel: advmod, Head: represented\n",
      "Word: laptops, Deprel: nsubj, Head: represented\n",
      "Word: represented, Deprel: advcl, Head: compares\n",
      "Word: less, Deprel: advmod, Head: 25\n",
      "Word: than, Deprel: fixed, Head: less\n",
      "Word: 25, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: represented\n",
      "Word: of, Deprel: case, Head: volume\n",
      "Word: sales, Deprel: compound, Head: volume\n",
      "Word: volume, Deprel: nmod, Head: percent\n",
      "Word: NPD, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Argentine Guillermo Coria and Netherlander Martin Verkerk are in the other half'\n",
      "Word: Argentine, Deprel: amod, Head: Guillermo\n",
      "Word: Guillermo, Deprel: nsubj, Head: half\n",
      "Word: Coria, Deprel: flat, Head: Guillermo\n",
      "Word: and, Deprel: cc, Head: Netherlander\n",
      "Word: Netherlander, Deprel: conj, Head: Guillermo\n",
      "Word: Martin, Deprel: flat, Head: Netherlander\n",
      "Word: Verkerk, Deprel: flat, Head: Netherlander\n",
      "Word: are, Deprel: cop, Head: half\n",
      "Word: in, Deprel: case, Head: half\n",
      "Word: the, Deprel: det, Head: half\n",
      "Word: other, Deprel: amod, Head: half\n",
      "Word: half, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The other semifinal between Guillermo Coria of Argentina and Martin Verkerk of the Netherlands is also compelling'\n",
      "Word: The, Deprel: det, Head: semifinal\n",
      "Word: other, Deprel: amod, Head: semifinal\n",
      "Word: semifinal, Deprel: nsubj, Head: compelling\n",
      "Word: between, Deprel: case, Head: Guillermo\n",
      "Word: Guillermo, Deprel: nmod, Head: semifinal\n",
      "Word: Coria, Deprel: flat, Head: Guillermo\n",
      "Word: of, Deprel: case, Head: Argentina\n",
      "Word: Argentina, Deprel: nmod, Head: Guillermo\n",
      "Word: and, Deprel: cc, Head: Martin\n",
      "Word: Martin, Deprel: conj, Head: Guillermo\n",
      "Word: Verkerk, Deprel: flat, Head: Martin\n",
      "Word: of, Deprel: case, Head: Netherlands\n",
      "Word: the, Deprel: det, Head: Netherlands\n",
      "Word: Netherlands, Deprel: nmod, Head: Martin\n",
      "Word: is, Deprel: cop, Head: compelling\n",
      "Word: also, Deprel: advmod, Head: compelling\n",
      "Word: compelling, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Nasdaq Composite Index rose 19.67 or 1.3 percent to 1523.71 its highest since June 18'\n",
      "Word: The, Deprel: det, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 19.67, Deprel: obj, Head: rose\n",
      "Word: or, Deprel: cc, Head: 1.3\n",
      "Word: 1.3, Deprel: conj, Head: 19.67\n",
      "Word: percent, Deprel: obj, Head: rose\n",
      "Word: to, Deprel: case, Head: 1523.71\n",
      "Word: 1523.71, Deprel: obl, Head: rose\n",
      "Word: its, Deprel: cc, Head: highest\n",
      "Word: highest, Deprel: conj, Head: rose\n",
      "Word: since, Deprel: case, Head: June\n",
      "Word: June, Deprel: obl, Head: highest\n",
      "Word: 18, Deprel: nummod, Head: June\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The S P 500 had climbed 16 percent since its March low and yesterday closed at its highest since Dec 2'\n",
      "Word: The, Deprel: det, Head: 500\n",
      "Word: S, Deprel: compound, Head: P\n",
      "Word: P, Deprel: compound, Head: 500\n",
      "Word: 500, Deprel: nsubj, Head: climbed\n",
      "Word: had, Deprel: aux, Head: climbed\n",
      "Word: climbed, Deprel: root, Head: ROOT\n",
      "Word: 16, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: climbed\n",
      "Word: since, Deprel: case, Head: low\n",
      "Word: its, Deprel: nmod:poss, Head: low\n",
      "Word: March, Deprel: compound, Head: low\n",
      "Word: low, Deprel: obl, Head: climbed\n",
      "Word: and, Deprel: cc, Head: closed\n",
      "Word: yesterday, Deprel: obl:tmod, Head: closed\n",
      "Word: closed, Deprel: conj, Head: climbed\n",
      "Word: at, Deprel: case, Head: highest\n",
      "Word: its, Deprel: nmod:poss, Head: highest\n",
      "Word: highest, Deprel: obl, Head: closed\n",
      "Word: since, Deprel: case, Head: Dec\n",
      "Word: Dec, Deprel: obl, Head: closed\n",
      "Word: 2, Deprel: nummod, Head: Dec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'What can I say to you he told a crowd at a cemetery with a thousand headstones many of them marking the graves of entire families'\n",
      "Word: What, Deprel: obj, Head: say\n",
      "Word: can, Deprel: aux, Head: say\n",
      "Word: I, Deprel: nsubj, Head: say\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: you\n",
      "Word: you, Deprel: obl, Head: say\n",
      "Word: he, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: ccomp, Head: say\n",
      "Word: a, Deprel: det, Head: crowd\n",
      "Word: crowd, Deprel: iobj, Head: told\n",
      "Word: at, Deprel: case, Head: cemetery\n",
      "Word: a, Deprel: det, Head: cemetery\n",
      "Word: cemetery, Deprel: obl, Head: told\n",
      "Word: with, Deprel: case, Head: headstones\n",
      "Word: a, Deprel: det, Head: thousand\n",
      "Word: thousand, Deprel: nummod, Head: headstones\n",
      "Word: headstones, Deprel: obl, Head: told\n",
      "Word: many, Deprel: nsubj, Head: marking\n",
      "Word: of, Deprel: case, Head: them\n",
      "Word: them, Deprel: nmod, Head: many\n",
      "Word: marking, Deprel: acl:relcl, Head: headstones\n",
      "Word: the, Deprel: det, Head: graves\n",
      "Word: graves, Deprel: obj, Head: marking\n",
      "Word: of, Deprel: case, Head: families\n",
      "Word: entire, Deprel: amod, Head: families\n",
      "Word: families, Deprel: nmod, Head: graves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Powell told a crowd at a cemetery with a thousand headstones many of them marking the graves of entire families'\n",
      "Word: Mr, Deprel: nsubj, Head: told\n",
      "Word: Powell, Deprel: flat, Head: Mr\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: crowd\n",
      "Word: crowd, Deprel: iobj, Head: told\n",
      "Word: at, Deprel: case, Head: cemetery\n",
      "Word: a, Deprel: det, Head: cemetery\n",
      "Word: cemetery, Deprel: nmod, Head: crowd\n",
      "Word: with, Deprel: case, Head: headstones\n",
      "Word: a, Deprel: det, Head: thousand\n",
      "Word: thousand, Deprel: nummod, Head: headstones\n",
      "Word: headstones, Deprel: obl, Head: told\n",
      "Word: many, Deprel: nsubj, Head: marking\n",
      "Word: of, Deprel: case, Head: them\n",
      "Word: them, Deprel: nmod, Head: many\n",
      "Word: marking, Deprel: acl:relcl, Head: headstones\n",
      "Word: the, Deprel: det, Head: graves\n",
      "Word: graves, Deprel: obj, Head: marking\n",
      "Word: of, Deprel: case, Head: families\n",
      "Word: entire, Deprel: amod, Head: families\n",
      "Word: families, Deprel: nmod, Head: graves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'They said they had concluded that the film failed to present a balanced portrayal of the Reagans'\n",
      "Word: They, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: they, Deprel: nsubj, Head: concluded\n",
      "Word: had, Deprel: aux, Head: concluded\n",
      "Word: concluded, Deprel: ccomp, Head: said\n",
      "Word: that, Deprel: mark, Head: failed\n",
      "Word: the, Deprel: det, Head: film\n",
      "Word: film, Deprel: nsubj, Head: failed\n",
      "Word: failed, Deprel: ccomp, Head: concluded\n",
      "Word: to, Deprel: mark, Head: present\n",
      "Word: present, Deprel: xcomp, Head: failed\n",
      "Word: a, Deprel: det, Head: portrayal\n",
      "Word: balanced, Deprel: amod, Head: portrayal\n",
      "Word: portrayal, Deprel: obj, Head: present\n",
      "Word: of, Deprel: case, Head: Reagans\n",
      "Word: the, Deprel: det, Head: Reagans\n",
      "Word: Reagans, Deprel: nmod, Head: portrayal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'CBS said the show does not present a balanced portrayal of the Reagans for CBS and its audience'\n",
      "Word: CBS, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: show\n",
      "Word: show, Deprel: nsubj, Head: present\n",
      "Word: does, Deprel: aux, Head: present\n",
      "Word: not, Deprel: advmod, Head: present\n",
      "Word: present, Deprel: ccomp, Head: said\n",
      "Word: a, Deprel: det, Head: portrayal\n",
      "Word: balanced, Deprel: amod, Head: portrayal\n",
      "Word: portrayal, Deprel: obj, Head: present\n",
      "Word: of, Deprel: case, Head: Reagans\n",
      "Word: the, Deprel: det, Head: Reagans\n",
      "Word: Reagans, Deprel: nmod, Head: portrayal\n",
      "Word: for, Deprel: case, Head: CBS\n",
      "Word: CBS, Deprel: nmod, Head: Reagans\n",
      "Word: and, Deprel: cc, Head: audience\n",
      "Word: its, Deprel: nmod:poss, Head: audience\n",
      "Word: audience, Deprel: conj, Head: CBS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We re going to do everything in our power to get money back to ratepayers as quickly as possible Kennedy said'\n",
      "Word: We, Deprel: nsubj, Head: going\n",
      "Word: re, Deprel: aux, Head: going\n",
      "Word: going, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: do\n",
      "Word: do, Deprel: xcomp, Head: going\n",
      "Word: everything, Deprel: obj, Head: do\n",
      "Word: in, Deprel: case, Head: power\n",
      "Word: our, Deprel: nmod:poss, Head: power\n",
      "Word: power, Deprel: nmod, Head: everything\n",
      "Word: to, Deprel: mark, Head: get\n",
      "Word: get, Deprel: advcl, Head: do\n",
      "Word: money, Deprel: obj, Head: get\n",
      "Word: back, Deprel: advmod, Head: get\n",
      "Word: to, Deprel: case, Head: ratepayers\n",
      "Word: ratepayers, Deprel: obl, Head: get\n",
      "Word: as, Deprel: advmod, Head: quickly\n",
      "Word: quickly, Deprel: advmod, Head: get\n",
      "Word: as, Deprel: mark, Head: possible\n",
      "Word: possible, Deprel: advcl, Head: quickly\n",
      "Word: Kennedy, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: going\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'There s very strong interest in getting money back to the ratepayers as quickly as possible Commissioner Susan Kennedy said'\n",
      "Word: There, Deprel: expl, Head: s\n",
      "Word: s, Deprel: root, Head: ROOT\n",
      "Word: very, Deprel: advmod, Head: strong\n",
      "Word: strong, Deprel: amod, Head: interest\n",
      "Word: interest, Deprel: nsubj, Head: s\n",
      "Word: in, Deprel: mark, Head: getting\n",
      "Word: getting, Deprel: acl, Head: interest\n",
      "Word: money, Deprel: obj, Head: getting\n",
      "Word: back, Deprel: advmod, Head: getting\n",
      "Word: to, Deprel: case, Head: ratepayers\n",
      "Word: the, Deprel: det, Head: ratepayers\n",
      "Word: ratepayers, Deprel: obl, Head: getting\n",
      "Word: as, Deprel: advmod, Head: quickly\n",
      "Word: quickly, Deprel: advmod, Head: getting\n",
      "Word: as, Deprel: mark, Head: said\n",
      "Word: possible, Deprel: amod, Head: Commissioner\n",
      "Word: Commissioner, Deprel: compound, Head: Susan\n",
      "Word: Susan, Deprel: nsubj, Head: said\n",
      "Word: Kennedy, Deprel: flat, Head: Susan\n",
      "Word: said, Deprel: parataxis, Head: s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'She had only a single condition that the book not be published until her death'\n",
      "Word: She, Deprel: nsubj, Head: had\n",
      "Word: had, Deprel: root, Head: ROOT\n",
      "Word: only, Deprel: advmod, Head: condition\n",
      "Word: a, Deprel: det, Head: condition\n",
      "Word: single, Deprel: amod, Head: condition\n",
      "Word: condition, Deprel: obj, Head: had\n",
      "Word: that, Deprel: mark, Head: published\n",
      "Word: the, Deprel: det, Head: book\n",
      "Word: book, Deprel: nsubj:pass, Head: published\n",
      "Word: not, Deprel: advmod, Head: published\n",
      "Word: be, Deprel: aux:pass, Head: published\n",
      "Word: published, Deprel: acl:relcl, Head: condition\n",
      "Word: until, Deprel: case, Head: death\n",
      "Word: her, Deprel: nmod:poss, Head: death\n",
      "Word: death, Deprel: obl, Head: published\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'She insisted though that it not be published until after her death'\n",
      "Word: She, Deprel: nsubj, Head: insisted\n",
      "Word: insisted, Deprel: root, Head: ROOT\n",
      "Word: though, Deprel: advmod, Head: insisted\n",
      "Word: that, Deprel: mark, Head: published\n",
      "Word: it, Deprel: nsubj:pass, Head: published\n",
      "Word: not, Deprel: advmod, Head: published\n",
      "Word: be, Deprel: aux:pass, Head: published\n",
      "Word: published, Deprel: ccomp, Head: insisted\n",
      "Word: until, Deprel: case, Head: death\n",
      "Word: after, Deprel: case, Head: death\n",
      "Word: her, Deprel: nmod:poss, Head: death\n",
      "Word: death, Deprel: obl, Head: published\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The findings are published in the November 6 edition of the journal Nature'\n",
      "Word: The, Deprel: det, Head: findings\n",
      "Word: findings, Deprel: nsubj:pass, Head: published\n",
      "Word: are, Deprel: aux:pass, Head: published\n",
      "Word: published, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: edition\n",
      "Word: the, Deprel: det, Head: edition\n",
      "Word: November, Deprel: compound, Head: edition\n",
      "Word: 6, Deprel: nummod, Head: November\n",
      "Word: edition, Deprel: obl, Head: published\n",
      "Word: of, Deprel: case, Head: journal\n",
      "Word: the, Deprel: det, Head: journal\n",
      "Word: journal, Deprel: nmod, Head: edition\n",
      "Word: Nature, Deprel: appos, Head: journal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Both studies are published on Thursday in Nature the British weekly science journal'\n",
      "Word: Both, Deprel: det, Head: studies\n",
      "Word: studies, Deprel: nsubj:pass, Head: published\n",
      "Word: are, Deprel: aux:pass, Head: published\n",
      "Word: published, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: published\n",
      "Word: in, Deprel: case, Head: Nature\n",
      "Word: Nature, Deprel: obl, Head: published\n",
      "Word: the, Deprel: det, Head: journal\n",
      "Word: British, Deprel: amod, Head: journal\n",
      "Word: weekly, Deprel: amod, Head: journal\n",
      "Word: science, Deprel: compound, Head: journal\n",
      "Word: journal, Deprel: obj, Head: published\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Median household income declined 1.1 percent between 2001 and 2002 to 42,409 after accounting for inflation'\n",
      "Word: Median, Deprel: amod, Head: income\n",
      "Word: household, Deprel: compound, Head: income\n",
      "Word: income, Deprel: nsubj, Head: declined\n",
      "Word: declined, Deprel: root, Head: ROOT\n",
      "Word: 1.1, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: declined\n",
      "Word: between, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: declined\n",
      "Word: and, Deprel: cc, Head: 2002\n",
      "Word: 2002, Deprel: conj, Head: 2001\n",
      "Word: to, Deprel: case, Head: 42,409\n",
      "Word: 42,409, Deprel: obl, Head: declined\n",
      "Word: after, Deprel: mark, Head: accounting\n",
      "Word: accounting, Deprel: advcl, Head: declined\n",
      "Word: for, Deprel: case, Head: inflation\n",
      "Word: inflation, Deprel: obl, Head: accounting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The same survey found the median household income rose by 51 when accounting for inflation to 43,057'\n",
      "Word: The, Deprel: det, Head: survey\n",
      "Word: same, Deprel: amod, Head: survey\n",
      "Word: survey, Deprel: nsubj, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: income\n",
      "Word: median, Deprel: amod, Head: income\n",
      "Word: household, Deprel: compound, Head: income\n",
      "Word: income, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: ccomp, Head: found\n",
      "Word: by, Deprel: case, Head: 51\n",
      "Word: 51, Deprel: obl, Head: rose\n",
      "Word: when, Deprel: advmod, Head: accounting\n",
      "Word: accounting, Deprel: advcl, Head: rose\n",
      "Word: for, Deprel: case, Head: inflation\n",
      "Word: inflation, Deprel: obl, Head: accounting\n",
      "Word: to, Deprel: case, Head: 43,057\n",
      "Word: 43,057, Deprel: obl, Head: accounting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'U.S and European leaders pledged on Wednesday to work together to keep Iran from developing nuclear weapons presenting a united front after months of bitter acrimony over Iraq'\n",
      "Word: U.S, Deprel: compound, Head: leaders\n",
      "Word: and, Deprel: cc, Head: European\n",
      "Word: European, Deprel: conj, Head: U.S\n",
      "Word: leaders, Deprel: nsubj, Head: pledged\n",
      "Word: pledged, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: pledged\n",
      "Word: to, Deprel: mark, Head: work\n",
      "Word: work, Deprel: xcomp, Head: pledged\n",
      "Word: together, Deprel: advmod, Head: work\n",
      "Word: to, Deprel: mark, Head: keep\n",
      "Word: keep, Deprel: advcl, Head: work\n",
      "Word: Iran, Deprel: obj, Head: keep\n",
      "Word: from, Deprel: mark, Head: developing\n",
      "Word: developing, Deprel: advcl, Head: keep\n",
      "Word: nuclear, Deprel: amod, Head: weapons\n",
      "Word: weapons, Deprel: obj, Head: developing\n",
      "Word: presenting, Deprel: advcl, Head: developing\n",
      "Word: a, Deprel: det, Head: front\n",
      "Word: united, Deprel: amod, Head: front\n",
      "Word: front, Deprel: obj, Head: presenting\n",
      "Word: after, Deprel: case, Head: months\n",
      "Word: months, Deprel: obl, Head: presenting\n",
      "Word: of, Deprel: case, Head: acrimony\n",
      "Word: bitter, Deprel: amod, Head: acrimony\n",
      "Word: acrimony, Deprel: nmod, Head: months\n",
      "Word: over, Deprel: case, Head: Iraq\n",
      "Word: Iraq, Deprel: nmod, Head: acrimony\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bush said U.S and European Union leaders at an annual Washington summit agreed on the need to keep Iran from developing nuclear weapons'\n",
      "Word: Bush, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: U.S, Deprel: compound, Head: leaders\n",
      "Word: and, Deprel: cc, Head: Union\n",
      "Word: European, Deprel: amod, Head: Union\n",
      "Word: Union, Deprel: conj, Head: U.S\n",
      "Word: leaders, Deprel: nsubj, Head: agreed\n",
      "Word: at, Deprel: case, Head: summit\n",
      "Word: an, Deprel: det, Head: summit\n",
      "Word: annual, Deprel: amod, Head: summit\n",
      "Word: Washington, Deprel: compound, Head: summit\n",
      "Word: summit, Deprel: nmod, Head: leaders\n",
      "Word: agreed, Deprel: ccomp, Head: said\n",
      "Word: on, Deprel: case, Head: need\n",
      "Word: the, Deprel: det, Head: need\n",
      "Word: need, Deprel: obl, Head: agreed\n",
      "Word: to, Deprel: mark, Head: keep\n",
      "Word: keep, Deprel: acl, Head: need\n",
      "Word: Iran, Deprel: obj, Head: keep\n",
      "Word: from, Deprel: mark, Head: developing\n",
      "Word: developing, Deprel: advcl, Head: keep\n",
      "Word: nuclear, Deprel: amod, Head: weapons\n",
      "Word: weapons, Deprel: obj, Head: developing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The company said it would cut the wholesale price of most top-line CDs to 9.09 from 12.02'\n",
      "Word: The, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: cut\n",
      "Word: would, Deprel: aux, Head: cut\n",
      "Word: cut, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: price\n",
      "Word: wholesale, Deprel: amod, Head: price\n",
      "Word: price, Deprel: obj, Head: cut\n",
      "Word: of, Deprel: case, Head: CDs\n",
      "Word: most, Deprel: amod, Head: CDs\n",
      "Word: top-line, Deprel: amod, Head: CDs\n",
      "Word: CDs, Deprel: nmod, Head: price\n",
      "Word: to, Deprel: case, Head: 9.09\n",
      "Word: 9.09, Deprel: obl, Head: cut\n",
      "Word: from, Deprel: case, Head: 12.02\n",
      "Word: 12.02, Deprel: nmod, Head: 9.09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The company also said it would cut wholesale prices on cassettes and change the suggested retail price to 8.98'\n",
      "Word: The, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: said\n",
      "Word: also, Deprel: advmod, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: cut\n",
      "Word: would, Deprel: aux, Head: cut\n",
      "Word: cut, Deprel: ccomp, Head: said\n",
      "Word: wholesale, Deprel: compound, Head: prices\n",
      "Word: prices, Deprel: obj, Head: cut\n",
      "Word: on, Deprel: case, Head: cassettes\n",
      "Word: cassettes, Deprel: obl, Head: cut\n",
      "Word: and, Deprel: cc, Head: change\n",
      "Word: change, Deprel: conj, Head: cut\n",
      "Word: the, Deprel: det, Head: price\n",
      "Word: suggested, Deprel: amod, Head: price\n",
      "Word: retail, Deprel: compound, Head: price\n",
      "Word: price, Deprel: obj, Head: change\n",
      "Word: to, Deprel: case, Head: 8.98\n",
      "Word: 8.98, Deprel: obl, Head: change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He left the army for Syria where he received religious training'\n",
      "Word: He, Deprel: nsubj, Head: left\n",
      "Word: left, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: army\n",
      "Word: army, Deprel: obj, Head: left\n",
      "Word: for, Deprel: case, Head: Syria\n",
      "Word: Syria, Deprel: obl, Head: left\n",
      "Word: where, Deprel: advmod, Head: received\n",
      "Word: he, Deprel: nsubj, Head: received\n",
      "Word: received, Deprel: advcl, Head: left\n",
      "Word: religious, Deprel: amod, Head: training\n",
      "Word: training, Deprel: obj, Head: received\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He moved to Syria where he underwent further religious training in traditional Islamic beliefs'\n",
      "Word: He, Deprel: nsubj, Head: moved\n",
      "Word: moved, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Syria\n",
      "Word: Syria, Deprel: obl, Head: moved\n",
      "Word: where, Deprel: advmod, Head: underwent\n",
      "Word: he, Deprel: nsubj, Head: underwent\n",
      "Word: underwent, Deprel: advcl, Head: moved\n",
      "Word: further, Deprel: amod, Head: training\n",
      "Word: religious, Deprel: amod, Head: training\n",
      "Word: training, Deprel: obj, Head: underwent\n",
      "Word: in, Deprel: case, Head: beliefs\n",
      "Word: traditional, Deprel: amod, Head: beliefs\n",
      "Word: Islamic, Deprel: amod, Head: beliefs\n",
      "Word: beliefs, Deprel: obl, Head: underwent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The meeting was scheduled to end Wednesday night with attendees approving resolutions that express the denomination s view on issues but that are not binding on churches'\n",
      "Word: The, Deprel: det, Head: meeting\n",
      "Word: meeting, Deprel: nsubj:pass, Head: scheduled\n",
      "Word: was, Deprel: aux:pass, Head: scheduled\n",
      "Word: scheduled, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: end\n",
      "Word: end, Deprel: xcomp, Head: scheduled\n",
      "Word: Wednesday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: end\n",
      "Word: with, Deprel: case, Head: attendees\n",
      "Word: attendees, Deprel: obl, Head: end\n",
      "Word: approving, Deprel: acl, Head: attendees\n",
      "Word: resolutions, Deprel: obj, Head: approving\n",
      "Word: that, Deprel: nsubj, Head: express\n",
      "Word: express, Deprel: acl:relcl, Head: resolutions\n",
      "Word: the, Deprel: det, Head: denomination\n",
      "Word: denomination, Deprel: nmod:poss, Head: view\n",
      "Word: s, Deprel: case, Head: denomination\n",
      "Word: view, Deprel: obj, Head: express\n",
      "Word: on, Deprel: case, Head: issues\n",
      "Word: issues, Deprel: nmod, Head: view\n",
      "Word: but, Deprel: cc, Head: binding\n",
      "Word: that, Deprel: nsubj, Head: binding\n",
      "Word: are, Deprel: cop, Head: binding\n",
      "Word: not, Deprel: advmod, Head: binding\n",
      "Word: binding, Deprel: conj, Head: express\n",
      "Word: on, Deprel: case, Head: churches\n",
      "Word: churches, Deprel: obl, Head: binding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Wednesday attendees will vote on resolutions that express the Southern Baptist view on issues but are not binding on individual churches'\n",
      "Word: On, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: vote\n",
      "Word: attendees, Deprel: nsubj, Head: vote\n",
      "Word: will, Deprel: aux, Head: vote\n",
      "Word: vote, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: resolutions\n",
      "Word: resolutions, Deprel: obl, Head: vote\n",
      "Word: that, Deprel: nsubj, Head: express\n",
      "Word: express, Deprel: acl:relcl, Head: resolutions\n",
      "Word: the, Deprel: det, Head: view\n",
      "Word: Southern, Deprel: amod, Head: Baptist\n",
      "Word: Baptist, Deprel: compound, Head: view\n",
      "Word: view, Deprel: obj, Head: express\n",
      "Word: on, Deprel: case, Head: issues\n",
      "Word: issues, Deprel: obl, Head: express\n",
      "Word: but, Deprel: cc, Head: binding\n",
      "Word: are, Deprel: cop, Head: binding\n",
      "Word: not, Deprel: advmod, Head: binding\n",
      "Word: binding, Deprel: conj, Head: express\n",
      "Word: on, Deprel: case, Head: churches\n",
      "Word: individual, Deprel: amod, Head: churches\n",
      "Word: churches, Deprel: obl, Head: binding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But the inadequate performance of students in various subgroups tagged the state as deficient under the federal No Child Left Behind act'\n",
      "Word: But, Deprel: cc, Head: tagged\n",
      "Word: the, Deprel: det, Head: performance\n",
      "Word: inadequate, Deprel: amod, Head: performance\n",
      "Word: performance, Deprel: nsubj, Head: tagged\n",
      "Word: of, Deprel: case, Head: students\n",
      "Word: students, Deprel: nmod, Head: performance\n",
      "Word: in, Deprel: case, Head: subgroups\n",
      "Word: various, Deprel: amod, Head: subgroups\n",
      "Word: subgroups, Deprel: nmod, Head: students\n",
      "Word: tagged, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: state, Deprel: obj, Head: tagged\n",
      "Word: as, Deprel: case, Head: deficient\n",
      "Word: deficient, Deprel: obl, Head: tagged\n",
      "Word: under, Deprel: case, Head: act\n",
      "Word: the, Deprel: det, Head: act\n",
      "Word: federal, Deprel: amod, Head: act\n",
      "Word: No, Deprel: det, Head: Child\n",
      "Word: Child, Deprel: compound, Head: Behind\n",
      "Word: Left, Deprel: compound, Head: Behind\n",
      "Word: Behind, Deprel: compound, Head: act\n",
      "Word: act, Deprel: obl, Head: tagged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But the inadequate performance of students in various subgroups such as race pushed the state onto the needs-improvement list under the federal No Child Left Behind Act'\n",
      "Word: But, Deprel: cc, Head: pushed\n",
      "Word: the, Deprel: det, Head: performance\n",
      "Word: inadequate, Deprel: amod, Head: performance\n",
      "Word: performance, Deprel: nsubj, Head: pushed\n",
      "Word: of, Deprel: case, Head: students\n",
      "Word: students, Deprel: nmod, Head: performance\n",
      "Word: in, Deprel: case, Head: subgroups\n",
      "Word: various, Deprel: amod, Head: subgroups\n",
      "Word: subgroups, Deprel: nmod, Head: performance\n",
      "Word: such, Deprel: case, Head: race\n",
      "Word: as, Deprel: fixed, Head: such\n",
      "Word: race, Deprel: nmod, Head: subgroups\n",
      "Word: pushed, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: state, Deprel: obj, Head: pushed\n",
      "Word: onto, Deprel: case, Head: list\n",
      "Word: the, Deprel: det, Head: list\n",
      "Word: needs-improvement, Deprel: compound, Head: list\n",
      "Word: list, Deprel: obl, Head: pushed\n",
      "Word: under, Deprel: case, Head: Act\n",
      "Word: the, Deprel: det, Head: Act\n",
      "Word: federal, Deprel: amod, Head: Act\n",
      "Word: No, Deprel: det, Head: Act\n",
      "Word: Child, Deprel: compound, Head: Left\n",
      "Word: Left, Deprel: compound, Head: Behind\n",
      "Word: Behind, Deprel: compound, Head: Act\n",
      "Word: Act, Deprel: obl, Head: pushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This led to the recovery of the 270-kilogram Cancuen altar announced on Wednesday by the Vanderbilt University in Nashville and the National Geographic Society'\n",
      "Word: This, Deprel: nsubj, Head: led\n",
      "Word: led, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: recovery\n",
      "Word: the, Deprel: det, Head: recovery\n",
      "Word: recovery, Deprel: obl, Head: led\n",
      "Word: of, Deprel: case, Head: altar\n",
      "Word: the, Deprel: det, Head: altar\n",
      "Word: 270-kilogram, Deprel: compound, Head: altar\n",
      "Word: Cancuen, Deprel: compound, Head: altar\n",
      "Word: altar, Deprel: nmod, Head: recovery\n",
      "Word: announced, Deprel: acl, Head: altar\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: announced\n",
      "Word: by, Deprel: case, Head: University\n",
      "Word: the, Deprel: det, Head: University\n",
      "Word: Vanderbilt, Deprel: compound, Head: University\n",
      "Word: University, Deprel: obl, Head: announced\n",
      "Word: in, Deprel: case, Head: Nashville\n",
      "Word: Nashville, Deprel: nmod, Head: University\n",
      "Word: and, Deprel: cc, Head: Society\n",
      "Word: the, Deprel: det, Head: Society\n",
      "Word: National, Deprel: amod, Head: Society\n",
      "Word: Geographic, Deprel: amod, Head: Society\n",
      "Word: Society, Deprel: conj, Head: University\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This led last month to the recovery of the 600-pound Cancun altar Vanderbilt University in Nashville and the National Geographic Society announced Wednesday'\n",
      "Word: This, Deprel: nsubj, Head: led\n",
      "Word: led, Deprel: root, Head: ROOT\n",
      "Word: last, Deprel: amod, Head: month\n",
      "Word: month, Deprel: obl:tmod, Head: led\n",
      "Word: to, Deprel: case, Head: recovery\n",
      "Word: the, Deprel: det, Head: recovery\n",
      "Word: recovery, Deprel: obl, Head: led\n",
      "Word: of, Deprel: case, Head: University\n",
      "Word: the, Deprel: det, Head: University\n",
      "Word: 600-pound, Deprel: amod, Head: University\n",
      "Word: Cancun, Deprel: compound, Head: altar\n",
      "Word: altar, Deprel: compound, Head: University\n",
      "Word: Vanderbilt, Deprel: compound, Head: University\n",
      "Word: University, Deprel: nmod, Head: recovery\n",
      "Word: in, Deprel: case, Head: Nashville\n",
      "Word: Nashville, Deprel: nmod, Head: University\n",
      "Word: and, Deprel: cc, Head: announced\n",
      "Word: the, Deprel: det, Head: Society\n",
      "Word: National, Deprel: amod, Head: Society\n",
      "Word: Geographic, Deprel: amod, Head: Society\n",
      "Word: Society, Deprel: nsubj, Head: announced\n",
      "Word: announced, Deprel: conj, Head: led\n",
      "Word: Wednesday, Deprel: obj, Head: announced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of Allergan fell 14 cents to close at 78.12 on the New York Stock Exchange news web sites'\n",
      "Word: Shares, Deprel: nsubj, Head: fell\n",
      "Word: of, Deprel: case, Head: Allergan\n",
      "Word: Allergan, Deprel: nmod, Head: Shares\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 14, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: fell\n",
      "Word: to, Deprel: mark, Head: close\n",
      "Word: close, Deprel: advcl, Head: fell\n",
      "Word: at, Deprel: case, Head: 78.12\n",
      "Word: 78.12, Deprel: obl, Head: close\n",
      "Word: on, Deprel: case, Head: sites\n",
      "Word: the, Deprel: det, Head: sites\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: compound, Head: sites\n",
      "Word: news, Deprel: compound, Head: sites\n",
      "Word: web, Deprel: compound, Head: sites\n",
      "Word: sites, Deprel: obl, Head: close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of Allergan were up 14 cents at 78.40 in late trading on the New York Stock Exchange'\n",
      "Word: Shares, Deprel: nsubj, Head: up\n",
      "Word: of, Deprel: case, Head: Allergan\n",
      "Word: Allergan, Deprel: nmod, Head: Shares\n",
      "Word: were, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: 14, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: up\n",
      "Word: at, Deprel: case, Head: 78.40\n",
      "Word: 78.40, Deprel: obl, Head: up\n",
      "Word: in, Deprel: case, Head: trading\n",
      "Word: late, Deprel: amod, Head: trading\n",
      "Word: trading, Deprel: obl, Head: up\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The upcoming second-quarter earnings season will be particularly important in offering investors guidance they say'\n",
      "Word: The, Deprel: det, Head: season\n",
      "Word: upcoming, Deprel: amod, Head: season\n",
      "Word: second-quarter, Deprel: amod, Head: earnings\n",
      "Word: earnings, Deprel: compound, Head: season\n",
      "Word: season, Deprel: nsubj, Head: important\n",
      "Word: will, Deprel: aux, Head: important\n",
      "Word: be, Deprel: cop, Head: important\n",
      "Word: particularly, Deprel: advmod, Head: important\n",
      "Word: important, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: mark, Head: offering\n",
      "Word: offering, Deprel: advcl, Head: important\n",
      "Word: investors, Deprel: iobj, Head: offering\n",
      "Word: guidance, Deprel: obj, Head: offering\n",
      "Word: they, Deprel: nsubj, Head: say\n",
      "Word: say, Deprel: acl:relcl, Head: guidance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'They say second-quarter earnings reports will be key in giving investors that guidance'\n",
      "Word: They, Deprel: nsubj, Head: say\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: second-quarter, Deprel: amod, Head: reports\n",
      "Word: earnings, Deprel: compound, Head: reports\n",
      "Word: reports, Deprel: nsubj, Head: key\n",
      "Word: will, Deprel: aux, Head: key\n",
      "Word: be, Deprel: cop, Head: key\n",
      "Word: key, Deprel: ccomp, Head: say\n",
      "Word: in, Deprel: mark, Head: giving\n",
      "Word: giving, Deprel: advcl, Head: key\n",
      "Word: investors, Deprel: iobj, Head: giving\n",
      "Word: that, Deprel: det, Head: guidance\n",
      "Word: guidance, Deprel: obj, Head: giving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In a not-too-subtle swipe at Dean he predicted Americans would not elect a Democrat who sounds an uncertain trumpet in these dangerous times'\n",
      "Word: In, Deprel: case, Head: swipe\n",
      "Word: a, Deprel: det, Head: swipe\n",
      "Word: not-too-subtle, Deprel: amod, Head: swipe\n",
      "Word: swipe, Deprel: obl, Head: predicted\n",
      "Word: at, Deprel: case, Head: Dean\n",
      "Word: Dean, Deprel: nmod, Head: swipe\n",
      "Word: he, Deprel: nsubj, Head: predicted\n",
      "Word: predicted, Deprel: root, Head: ROOT\n",
      "Word: Americans, Deprel: nsubj, Head: elect\n",
      "Word: would, Deprel: aux, Head: elect\n",
      "Word: not, Deprel: advmod, Head: elect\n",
      "Word: elect, Deprel: ccomp, Head: predicted\n",
      "Word: a, Deprel: det, Head: Democrat\n",
      "Word: Democrat, Deprel: obj, Head: elect\n",
      "Word: who, Deprel: nsubj, Head: sounds\n",
      "Word: sounds, Deprel: acl:relcl, Head: Democrat\n",
      "Word: an, Deprel: det, Head: trumpet\n",
      "Word: uncertain, Deprel: amod, Head: trumpet\n",
      "Word: trumpet, Deprel: xcomp, Head: sounds\n",
      "Word: in, Deprel: case, Head: times\n",
      "Word: these, Deprel: det, Head: times\n",
      "Word: dangerous, Deprel: amod, Head: times\n",
      "Word: times, Deprel: nmod, Head: trumpet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'They will not elect as president a Democrat who sounds an uncertain trumpet in these dangerous times'\n",
      "Word: They, Deprel: nsubj, Head: elect\n",
      "Word: will, Deprel: aux, Head: elect\n",
      "Word: not, Deprel: advmod, Head: elect\n",
      "Word: elect, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: case, Head: president\n",
      "Word: president, Deprel: obl, Head: elect\n",
      "Word: a, Deprel: det, Head: Democrat\n",
      "Word: Democrat, Deprel: obj, Head: elect\n",
      "Word: who, Deprel: nsubj, Head: sounds\n",
      "Word: sounds, Deprel: acl:relcl, Head: Democrat\n",
      "Word: an, Deprel: det, Head: trumpet\n",
      "Word: uncertain, Deprel: amod, Head: trumpet\n",
      "Word: trumpet, Deprel: xcomp, Head: sounds\n",
      "Word: in, Deprel: case, Head: times\n",
      "Word: these, Deprel: det, Head: times\n",
      "Word: dangerous, Deprel: amod, Head: times\n",
      "Word: times, Deprel: nmod, Head: trumpet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'That took the benchmark 10-year note US10YT=RR down 9/32 its yield rising to 3.37 percent from 3.34 percent late on Thursday'\n",
      "Word: That, Deprel: nsubj, Head: took\n",
      "Word: took, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: US10YT=RR\n",
      "Word: benchmark, Deprel: compound, Head: note\n",
      "Word: 10-year, Deprel: amod, Head: US10YT=RR\n",
      "Word: note, Deprel: compound, Head: US10YT=RR\n",
      "Word: US10YT=RR, Deprel: obj, Head: took\n",
      "Word: down, Deprel: case, Head: 9/32\n",
      "Word: 9/32, Deprel: obl, Head: took\n",
      "Word: its, Deprel: nmod:poss, Head: yield\n",
      "Word: yield, Deprel: obl:tmod, Head: took\n",
      "Word: rising, Deprel: advcl, Head: took\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 3.37, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: rising\n",
      "Word: from, Deprel: case, Head: percent\n",
      "Word: 3.34, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: rising\n",
      "Word: late, Deprel: advmod, Head: Thursday\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: rising\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'That saw the benchmark 10-year note US10YT=RR slip 5/32 in price taking its yield to 3.36 percent from 3.34 percent late on Thursday'\n",
      "Word: That, Deprel: nsubj, Head: saw\n",
      "Word: saw, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: note\n",
      "Word: benchmark, Deprel: compound, Head: note\n",
      "Word: 10-year, Deprel: compound, Head: note\n",
      "Word: note, Deprel: obj, Head: saw\n",
      "Word: US10YT=RR, Deprel: compound, Head: slip\n",
      "Word: slip, Deprel: appos, Head: note\n",
      "Word: 5/32, Deprel: nummod, Head: slip\n",
      "Word: in, Deprel: case, Head: price\n",
      "Word: price, Deprel: nmod, Head: 5/32\n",
      "Word: taking, Deprel: ccomp, Head: saw\n",
      "Word: its, Deprel: nmod:poss, Head: yield\n",
      "Word: yield, Deprel: obj, Head: taking\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 3.36, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n",
      "Word: from, Deprel: case, Head: percent\n",
      "Word: 3.34, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: taking\n",
      "Word: late, Deprel: advmod, Head: Thursday\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: taking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The report forecasts there will be 71,079 hot spots worldwide this year up from just 14,752 in 2002 and 1,214 in 2001'\n",
      "Word: The, Deprel: det, Head: report\n",
      "Word: report, Deprel: nsubj, Head: forecasts\n",
      "Word: forecasts, Deprel: root, Head: ROOT\n",
      "Word: there, Deprel: expl, Head: be\n",
      "Word: will, Deprel: aux, Head: be\n",
      "Word: be, Deprel: ccomp, Head: forecasts\n",
      "Word: 71,079, Deprel: nummod, Head: spots\n",
      "Word: hot, Deprel: amod, Head: spots\n",
      "Word: spots, Deprel: nsubj, Head: be\n",
      "Word: worldwide, Deprel: advmod, Head: spots\n",
      "Word: this, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: be\n",
      "Word: up, Deprel: advmod, Head: be\n",
      "Word: from, Deprel: case, Head: 14,752\n",
      "Word: just, Deprel: advmod, Head: 14,752\n",
      "Word: 14,752, Deprel: obl, Head: up\n",
      "Word: in, Deprel: case, Head: 2002\n",
      "Word: 2002, Deprel: nmod, Head: 14,752\n",
      "Word: and, Deprel: cc, Head: 1,214\n",
      "Word: 1,214, Deprel: conj, Head: 14,752\n",
      "Word: in, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: nmod, Head: 1,214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The report also claims that there will be up to 9.3 million visitors to hot spots this year up again from the meagre 2.5 million in 2002'\n",
      "Word: The, Deprel: det, Head: report\n",
      "Word: report, Deprel: nsubj, Head: claims\n",
      "Word: also, Deprel: advmod, Head: claims\n",
      "Word: claims, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: be\n",
      "Word: there, Deprel: expl, Head: be\n",
      "Word: will, Deprel: aux, Head: be\n",
      "Word: be, Deprel: ccomp, Head: claims\n",
      "Word: up, Deprel: advmod, Head: million\n",
      "Word: to, Deprel: fixed, Head: up\n",
      "Word: 9.3, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: visitors\n",
      "Word: visitors, Deprel: nsubj, Head: be\n",
      "Word: to, Deprel: case, Head: spots\n",
      "Word: hot, Deprel: amod, Head: spots\n",
      "Word: spots, Deprel: obl, Head: be\n",
      "Word: this, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: be\n",
      "Word: up, Deprel: advmod, Head: be\n",
      "Word: again, Deprel: advmod, Head: be\n",
      "Word: from, Deprel: case, Head: million\n",
      "Word: the, Deprel: det, Head: million\n",
      "Word: meagre, Deprel: amod, Head: million\n",
      "Word: 2.5, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obl, Head: be\n",
      "Word: in, Deprel: case, Head: 2002\n",
      "Word: 2002, Deprel: nmod, Head: million\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A new study conducted in Europe found the medicine worked just as well as an earlier disputed study sponsored by ImClone Systems said it did'\n",
      "Word: A, Deprel: det, Head: study\n",
      "Word: new, Deprel: amod, Head: study\n",
      "Word: study, Deprel: nsubj, Head: found\n",
      "Word: conducted, Deprel: acl, Head: study\n",
      "Word: in, Deprel: case, Head: Europe\n",
      "Word: Europe, Deprel: obl, Head: conducted\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: medicine\n",
      "Word: medicine, Deprel: nsubj, Head: worked\n",
      "Word: worked, Deprel: ccomp, Head: found\n",
      "Word: just, Deprel: advmod, Head: as\n",
      "Word: as, Deprel: advmod, Head: worked\n",
      "Word: well, Deprel: fixed, Head: as\n",
      "Word: as, Deprel: fixed, Head: as\n",
      "Word: an, Deprel: det, Head: study\n",
      "Word: earlier, Deprel: amod, Head: study\n",
      "Word: disputed, Deprel: amod, Head: study\n",
      "Word: study, Deprel: obl, Head: worked\n",
      "Word: sponsored, Deprel: acl, Head: study\n",
      "Word: by, Deprel: case, Head: Systems\n",
      "Word: ImClone, Deprel: compound, Head: Systems\n",
      "Word: Systems, Deprel: obl, Head: sponsored\n",
      "Word: said, Deprel: advcl, Head: worked\n",
      "Word: it, Deprel: nsubj, Head: did\n",
      "Word: did, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Doctors concluded Erbitux the cancer drug that enmeshed ImClone Systems in an insider trading scandal worked just as well as an earlier company-sponsored study said it did'\n",
      "Word: Doctors, Deprel: nsubj, Head: concluded\n",
      "Word: concluded, Deprel: root, Head: ROOT\n",
      "Word: Erbitux, Deprel: nsubj, Head: worked\n",
      "Word: the, Deprel: det, Head: drug\n",
      "Word: cancer, Deprel: compound, Head: drug\n",
      "Word: drug, Deprel: nsubj, Head: worked\n",
      "Word: that, Deprel: nsubj, Head: enmeshed\n",
      "Word: enmeshed, Deprel: acl:relcl, Head: drug\n",
      "Word: ImClone, Deprel: compound, Head: Systems\n",
      "Word: Systems, Deprel: obj, Head: enmeshed\n",
      "Word: in, Deprel: case, Head: scandal\n",
      "Word: an, Deprel: det, Head: scandal\n",
      "Word: insider, Deprel: compound, Head: scandal\n",
      "Word: trading, Deprel: compound, Head: scandal\n",
      "Word: scandal, Deprel: obl, Head: enmeshed\n",
      "Word: worked, Deprel: ccomp, Head: concluded\n",
      "Word: just, Deprel: advmod, Head: said\n",
      "Word: as, Deprel: cc, Head: said\n",
      "Word: well, Deprel: fixed, Head: as\n",
      "Word: as, Deprel: fixed, Head: as\n",
      "Word: an, Deprel: det, Head: study\n",
      "Word: earlier, Deprel: amod, Head: study\n",
      "Word: company-sponsored, Deprel: amod, Head: study\n",
      "Word: study, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: advcl, Head: worked\n",
      "Word: it, Deprel: nsubj, Head: did\n",
      "Word: did, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The bank s shares fell 45 cents in trading yesterday to 91.51 per share'\n",
      "Word: The, Deprel: det, Head: bank\n",
      "Word: bank, Deprel: nmod:poss, Head: shares\n",
      "Word: s, Deprel: case, Head: bank\n",
      "Word: shares, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 45, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: fell\n",
      "Word: in, Deprel: case, Head: trading\n",
      "Word: trading, Deprel: obl, Head: fell\n",
      "Word: yesterday, Deprel: obl:tmod, Head: fell\n",
      "Word: to, Deprel: case, Head: 91.51\n",
      "Word: 91.51, Deprel: obl, Head: fell\n",
      "Word: per, Deprel: case, Head: share\n",
      "Word: share, Deprel: nmod, Head: 91.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of M T which is based in Buffalo fell 41 cents to 91.51'\n",
      "Word: Shares, Deprel: nsubj, Head: fell\n",
      "Word: of, Deprel: case, Head: T\n",
      "Word: M, Deprel: compound, Head: T\n",
      "Word: T, Deprel: nmod, Head: Shares\n",
      "Word: which, Deprel: nsubj:pass, Head: based\n",
      "Word: is, Deprel: aux:pass, Head: based\n",
      "Word: based, Deprel: acl:relcl, Head: Shares\n",
      "Word: in, Deprel: case, Head: Buffalo\n",
      "Word: Buffalo, Deprel: obl, Head: based\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 41, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: fell\n",
      "Word: to, Deprel: case, Head: 91.51\n",
      "Word: 91.51, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Her lawyer Donald Levine told The Telegraph she had been offered US250,000 to tell her story exclusively to Australian TV'\n",
      "Word: Her, Deprel: nmod:poss, Head: lawyer\n",
      "Word: lawyer, Deprel: nsubj, Head: told\n",
      "Word: Donald, Deprel: nsubj, Head: told\n",
      "Word: Levine, Deprel: flat, Head: Donald\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: The, Deprel: det, Head: Telegraph\n",
      "Word: Telegraph, Deprel: iobj, Head: told\n",
      "Word: she, Deprel: nsubj, Head: offered\n",
      "Word: had, Deprel: aux, Head: offered\n",
      "Word: been, Deprel: aux:pass, Head: offered\n",
      "Word: offered, Deprel: ccomp, Head: told\n",
      "Word: US250,000, Deprel: obj, Head: offered\n",
      "Word: to, Deprel: mark, Head: tell\n",
      "Word: tell, Deprel: advcl, Head: offered\n",
      "Word: her, Deprel: nmod:poss, Head: story\n",
      "Word: story, Deprel: obj, Head: tell\n",
      "Word: exclusively, Deprel: advmod, Head: tell\n",
      "Word: to, Deprel: case, Head: TV\n",
      "Word: Australian, Deprel: amod, Head: TV\n",
      "Word: TV, Deprel: obl, Head: tell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Levine said she had been offered 400,000 to tell her story to an Australian TV network'\n",
      "Word: Mr, Deprel: nsubj, Head: said\n",
      "Word: Levine, Deprel: flat, Head: Mr\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: she, Deprel: nsubj, Head: offered\n",
      "Word: had, Deprel: aux, Head: offered\n",
      "Word: been, Deprel: aux, Head: offered\n",
      "Word: offered, Deprel: ccomp, Head: said\n",
      "Word: 400,000, Deprel: obj, Head: offered\n",
      "Word: to, Deprel: mark, Head: tell\n",
      "Word: tell, Deprel: advcl, Head: offered\n",
      "Word: her, Deprel: nmod:poss, Head: story\n",
      "Word: story, Deprel: obj, Head: tell\n",
      "Word: to, Deprel: case, Head: network\n",
      "Word: an, Deprel: det, Head: network\n",
      "Word: Australian, Deprel: amod, Head: network\n",
      "Word: TV, Deprel: compound, Head: network\n",
      "Word: network, Deprel: obl, Head: tell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Perry has called lawmakers into two special sessions to address congressional redistricting'\n",
      "Word: Perry, Deprel: nsubj, Head: called\n",
      "Word: has, Deprel: aux, Head: called\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: lawmakers, Deprel: obj, Head: called\n",
      "Word: into, Deprel: case, Head: sessions\n",
      "Word: two, Deprel: nummod, Head: sessions\n",
      "Word: special, Deprel: amod, Head: sessions\n",
      "Word: sessions, Deprel: obl, Head: called\n",
      "Word: to, Deprel: mark, Head: address\n",
      "Word: address, Deprel: advcl, Head: called\n",
      "Word: congressional, Deprel: amod, Head: redistricting\n",
      "Word: redistricting, Deprel: obj, Head: address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Perry has since called two special legislative sessions to try force the redistricting plan through'\n",
      "Word: Perry, Deprel: nsubj, Head: called\n",
      "Word: has, Deprel: aux, Head: called\n",
      "Word: since, Deprel: advmod, Head: called\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: two, Deprel: nummod, Head: sessions\n",
      "Word: special, Deprel: amod, Head: sessions\n",
      "Word: legislative, Deprel: amod, Head: sessions\n",
      "Word: sessions, Deprel: obj, Head: called\n",
      "Word: to, Deprel: mark, Head: try\n",
      "Word: try, Deprel: advcl, Head: called\n",
      "Word: force, Deprel: xcomp, Head: try\n",
      "Word: the, Deprel: det, Head: plan\n",
      "Word: redistricting, Deprel: compound, Head: plan\n",
      "Word: plan, Deprel: obj, Head: force\n",
      "Word: through, Deprel: advmod, Head: force\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In the latest violence insurgents threw a bomb at a U.S convoy in northern Baghdad killing one soldier'\n",
      "Word: In, Deprel: case, Head: insurgents\n",
      "Word: the, Deprel: det, Head: insurgents\n",
      "Word: latest, Deprel: amod, Head: insurgents\n",
      "Word: violence, Deprel: compound, Head: insurgents\n",
      "Word: insurgents, Deprel: nsubj, Head: threw\n",
      "Word: threw, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: bomb\n",
      "Word: bomb, Deprel: obj, Head: threw\n",
      "Word: at, Deprel: case, Head: convoy\n",
      "Word: a, Deprel: det, Head: convoy\n",
      "Word: U.S, Deprel: compound, Head: convoy\n",
      "Word: convoy, Deprel: obl, Head: threw\n",
      "Word: in, Deprel: case, Head: Baghdad\n",
      "Word: northern, Deprel: amod, Head: Baghdad\n",
      "Word: Baghdad, Deprel: nmod, Head: convoy\n",
      "Word: killing, Deprel: advcl, Head: threw\n",
      "Word: one, Deprel: nummod, Head: soldier\n",
      "Word: soldier, Deprel: obj, Head: killing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Early Monday insurgents threw a homemade bomb at a U.S convoy in northern Baghdad killing an American soldier'\n",
      "Word: Early, Deprel: amod, Head: insurgents\n",
      "Word: Monday, Deprel: compound, Head: insurgents\n",
      "Word: insurgents, Deprel: nsubj, Head: threw\n",
      "Word: threw, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: bomb\n",
      "Word: homemade, Deprel: amod, Head: bomb\n",
      "Word: bomb, Deprel: obj, Head: threw\n",
      "Word: at, Deprel: case, Head: convoy\n",
      "Word: a, Deprel: det, Head: convoy\n",
      "Word: U.S, Deprel: compound, Head: convoy\n",
      "Word: convoy, Deprel: obl, Head: threw\n",
      "Word: in, Deprel: case, Head: Baghdad\n",
      "Word: northern, Deprel: amod, Head: Baghdad\n",
      "Word: Baghdad, Deprel: nmod, Head: convoy\n",
      "Word: killing, Deprel: advcl, Head: threw\n",
      "Word: an, Deprel: det, Head: soldier\n",
      "Word: American, Deprel: amod, Head: soldier\n",
      "Word: soldier, Deprel: obj, Head: killing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Consumer groups are against the changes saying they hurt individuality in markets'\n",
      "Word: Consumer, Deprel: compound, Head: groups\n",
      "Word: groups, Deprel: nsubj, Head: changes\n",
      "Word: are, Deprel: cop, Head: changes\n",
      "Word: against, Deprel: case, Head: changes\n",
      "Word: the, Deprel: det, Head: changes\n",
      "Word: changes, Deprel: root, Head: ROOT\n",
      "Word: saying, Deprel: acl, Head: changes\n",
      "Word: they, Deprel: nsubj, Head: hurt\n",
      "Word: hurt, Deprel: ccomp, Head: saying\n",
      "Word: individuality, Deprel: obj, Head: hurt\n",
      "Word: in, Deprel: case, Head: markets\n",
      "Word: markets, Deprel: obl, Head: hurt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Consumer groups oppose the changes saying they would concentrate too many outlets in too few media empires'\n",
      "Word: Consumer, Deprel: compound, Head: groups\n",
      "Word: groups, Deprel: nsubj, Head: oppose\n",
      "Word: oppose, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: changes\n",
      "Word: changes, Deprel: obj, Head: oppose\n",
      "Word: saying, Deprel: acl, Head: changes\n",
      "Word: they, Deprel: nsubj, Head: concentrate\n",
      "Word: would, Deprel: aux, Head: concentrate\n",
      "Word: concentrate, Deprel: ccomp, Head: saying\n",
      "Word: too, Deprel: advmod, Head: many\n",
      "Word: many, Deprel: amod, Head: outlets\n",
      "Word: outlets, Deprel: obj, Head: concentrate\n",
      "Word: in, Deprel: case, Head: empires\n",
      "Word: too, Deprel: advmod, Head: few\n",
      "Word: few, Deprel: amod, Head: empires\n",
      "Word: media, Deprel: compound, Head: empires\n",
      "Word: empires, Deprel: obl, Head: concentrate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'AirTran officials and a Boeing official declined to comment yesterday'\n",
      "Word: AirTran, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: declined\n",
      "Word: and, Deprel: cc, Head: official\n",
      "Word: a, Deprel: det, Head: official\n",
      "Word: Boeing, Deprel: compound, Head: official\n",
      "Word: official, Deprel: conj, Head: officials\n",
      "Word: declined, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: comment\n",
      "Word: comment, Deprel: xcomp, Head: declined\n",
      "Word: yesterday, Deprel: obl:tmod, Head: comment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Trish York a spokeswoman for Boeing declined to comment on the deal'\n",
      "Word: Trish, Deprel: nsubj, Head: declined\n",
      "Word: York, Deprel: flat, Head: Trish\n",
      "Word: a, Deprel: det, Head: spokeswoman\n",
      "Word: spokeswoman, Deprel: appos, Head: Trish\n",
      "Word: for, Deprel: case, Head: Boeing\n",
      "Word: Boeing, Deprel: nmod, Head: spokeswoman\n",
      "Word: declined, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: comment\n",
      "Word: comment, Deprel: xcomp, Head: declined\n",
      "Word: on, Deprel: case, Head: deal\n",
      "Word: the, Deprel: det, Head: deal\n",
      "Word: deal, Deprel: obl, Head: comment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The lawsuit names Shelley a Democrat and registrars in Los Angeles Orange and San Diego counties'\n",
      "Word: The, Deprel: det, Head: lawsuit\n",
      "Word: lawsuit, Deprel: nsubj, Head: names\n",
      "Word: names, Deprel: root, Head: ROOT\n",
      "Word: Shelley, Deprel: obj, Head: names\n",
      "Word: a, Deprel: det, Head: Democrat\n",
      "Word: Democrat, Deprel: xcomp, Head: names\n",
      "Word: and, Deprel: cc, Head: registrars\n",
      "Word: registrars, Deprel: conj, Head: Democrat\n",
      "Word: in, Deprel: case, Head: Orange\n",
      "Word: Los, Deprel: compound, Head: Angeles\n",
      "Word: Angeles, Deprel: compound, Head: Orange\n",
      "Word: Orange, Deprel: nmod, Head: Democrat\n",
      "Word: and, Deprel: cc, Head: counties\n",
      "Word: San, Deprel: compound, Head: counties\n",
      "Word: Diego, Deprel: flat, Head: San\n",
      "Word: counties, Deprel: conj, Head: Orange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The lawsuit named Secretary of State Kevin Shelley a Democrat and the registrars of voters in Los Angeles Orange and San Diego counties'\n",
      "Word: The, Deprel: det, Head: lawsuit\n",
      "Word: lawsuit, Deprel: nsubj, Head: named\n",
      "Word: named, Deprel: root, Head: ROOT\n",
      "Word: Secretary, Deprel: obj, Head: named\n",
      "Word: of, Deprel: case, Head: State\n",
      "Word: State, Deprel: nmod, Head: Secretary\n",
      "Word: Kevin, Deprel: flat, Head: Secretary\n",
      "Word: Shelley, Deprel: flat, Head: Kevin\n",
      "Word: a, Deprel: det, Head: Democrat\n",
      "Word: Democrat, Deprel: appos, Head: Secretary\n",
      "Word: and, Deprel: cc, Head: registrars\n",
      "Word: the, Deprel: det, Head: registrars\n",
      "Word: registrars, Deprel: conj, Head: Secretary\n",
      "Word: of, Deprel: case, Head: voters\n",
      "Word: voters, Deprel: nmod, Head: registrars\n",
      "Word: in, Deprel: case, Head: Orange\n",
      "Word: Los, Deprel: compound, Head: Angeles\n",
      "Word: Angeles, Deprel: compound, Head: Orange\n",
      "Word: Orange, Deprel: nmod, Head: voters\n",
      "Word: and, Deprel: cc, Head: counties\n",
      "Word: San, Deprel: compound, Head: counties\n",
      "Word: Diego, Deprel: flat, Head: San\n",
      "Word: counties, Deprel: conj, Head: Orange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Negotiators said Friday they made good progress during their latest round of talks on creating a Central American Free Trade Agreement'\n",
      "Word: Negotiators, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Friday, Deprel: obl:tmod, Head: said\n",
      "Word: they, Deprel: nsubj, Head: made\n",
      "Word: made, Deprel: ccomp, Head: said\n",
      "Word: good, Deprel: amod, Head: progress\n",
      "Word: progress, Deprel: obj, Head: made\n",
      "Word: during, Deprel: case, Head: round\n",
      "Word: their, Deprel: nmod:poss, Head: round\n",
      "Word: latest, Deprel: amod, Head: round\n",
      "Word: round, Deprel: obl, Head: made\n",
      "Word: of, Deprel: case, Head: talks\n",
      "Word: talks, Deprel: nmod, Head: round\n",
      "Word: on, Deprel: mark, Head: creating\n",
      "Word: creating, Deprel: acl, Head: talks\n",
      "Word: a, Deprel: det, Head: Agreement\n",
      "Word: Central, Deprel: amod, Head: Agreement\n",
      "Word: American, Deprel: amod, Head: Agreement\n",
      "Word: Free, Deprel: amod, Head: Agreement\n",
      "Word: Trade, Deprel: compound, Head: Agreement\n",
      "Word: Agreement, Deprel: obj, Head: creating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Negotiators said Friday they made progress during their latest round of free-trade negotiations between the United States and five Central American countries this week in Houston'\n",
      "Word: Negotiators, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Friday, Deprel: obl:tmod, Head: said\n",
      "Word: they, Deprel: nsubj, Head: made\n",
      "Word: made, Deprel: ccomp, Head: said\n",
      "Word: progress, Deprel: obj, Head: made\n",
      "Word: during, Deprel: case, Head: round\n",
      "Word: their, Deprel: nmod:poss, Head: round\n",
      "Word: latest, Deprel: amod, Head: round\n",
      "Word: round, Deprel: obl, Head: made\n",
      "Word: of, Deprel: case, Head: negotiations\n",
      "Word: free-trade, Deprel: compound, Head: negotiations\n",
      "Word: negotiations, Deprel: nmod, Head: round\n",
      "Word: between, Deprel: case, Head: States\n",
      "Word: the, Deprel: det, Head: States\n",
      "Word: United, Deprel: amod, Head: States\n",
      "Word: States, Deprel: nmod, Head: negotiations\n",
      "Word: and, Deprel: cc, Head: countries\n",
      "Word: five, Deprel: nummod, Head: countries\n",
      "Word: Central, Deprel: amod, Head: countries\n",
      "Word: American, Deprel: amod, Head: countries\n",
      "Word: countries, Deprel: conj, Head: States\n",
      "Word: this, Deprel: det, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: made\n",
      "Word: in, Deprel: case, Head: Houston\n",
      "Word: Houston, Deprel: nmod, Head: week\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It s very difficult to do large syndicated loans in Japan where there is a lack of expertise says one banker'\n",
      "Word: It, Deprel: expl, Head: difficult\n",
      "Word: s, Deprel: cop, Head: difficult\n",
      "Word: very, Deprel: advmod, Head: difficult\n",
      "Word: difficult, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: do\n",
      "Word: do, Deprel: csubj, Head: difficult\n",
      "Word: large, Deprel: amod, Head: loans\n",
      "Word: syndicated, Deprel: amod, Head: loans\n",
      "Word: loans, Deprel: obj, Head: do\n",
      "Word: in, Deprel: case, Head: Japan\n",
      "Word: Japan, Deprel: nmod, Head: loans\n",
      "Word: where, Deprel: advmod, Head: is\n",
      "Word: there, Deprel: expl, Head: is\n",
      "Word: is, Deprel: acl:relcl, Head: loans\n",
      "Word: a, Deprel: det, Head: lack\n",
      "Word: lack, Deprel: nsubj, Head: is\n",
      "Word: of, Deprel: case, Head: expertise\n",
      "Word: expertise, Deprel: nmod, Head: lack\n",
      "Word: says, Deprel: parataxis, Head: difficult\n",
      "Word: one, Deprel: nummod, Head: banker\n",
      "Word: banker, Deprel: obj, Head: says\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It is very difficult to do large syndicated loans in Japan says one banker'\n",
      "Word: It, Deprel: expl, Head: difficult\n",
      "Word: is, Deprel: cop, Head: difficult\n",
      "Word: very, Deprel: advmod, Head: difficult\n",
      "Word: difficult, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: do\n",
      "Word: do, Deprel: csubj, Head: difficult\n",
      "Word: large, Deprel: amod, Head: loans\n",
      "Word: syndicated, Deprel: amod, Head: loans\n",
      "Word: loans, Deprel: obj, Head: do\n",
      "Word: in, Deprel: case, Head: Japan\n",
      "Word: Japan, Deprel: nmod, Head: loans\n",
      "Word: says, Deprel: parataxis, Head: difficult\n",
      "Word: one, Deprel: nummod, Head: banker\n",
      "Word: banker, Deprel: obj, Head: says\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The case comes out of Illinois and involves a for-profit company called Telemarketing Associates Inc'\n",
      "Word: The, Deprel: det, Head: case\n",
      "Word: case, Deprel: nsubj, Head: comes\n",
      "Word: comes, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: case, Head: Illinois\n",
      "Word: of, Deprel: case, Head: Illinois\n",
      "Word: Illinois, Deprel: obl, Head: comes\n",
      "Word: and, Deprel: cc, Head: involves\n",
      "Word: involves, Deprel: conj, Head: comes\n",
      "Word: a, Deprel: det, Head: company\n",
      "Word: for-profit, Deprel: amod, Head: company\n",
      "Word: company, Deprel: obj, Head: involves\n",
      "Word: called, Deprel: acl, Head: company\n",
      "Word: Telemarketing, Deprel: compound, Head: Associates\n",
      "Word: Associates, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: obj, Head: called\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The case decided Monday centered around an Illinois fund-raiser Telemarketing Associates'\n",
      "Word: The, Deprel: det, Head: case\n",
      "Word: case, Deprel: nsubj, Head: decided\n",
      "Word: decided, Deprel: root, Head: ROOT\n",
      "Word: Monday, Deprel: obl:tmod, Head: decided\n",
      "Word: centered, Deprel: advcl, Head: decided\n",
      "Word: around, Deprel: case, Head: Associates\n",
      "Word: an, Deprel: det, Head: Associates\n",
      "Word: Illinois, Deprel: compound, Head: Associates\n",
      "Word: fund-raiser, Deprel: compound, Head: Associates\n",
      "Word: Telemarketing, Deprel: compound, Head: Associates\n",
      "Word: Associates, Deprel: obl, Head: centered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Every Thursday a grains management committee meets in the Commission s agriculture directorate to decide the outcome of a weekly export tender'\n",
      "Word: Every, Deprel: det, Head: Thursday\n",
      "Word: Thursday, Deprel: obl:tmod, Head: meets\n",
      "Word: a, Deprel: det, Head: committee\n",
      "Word: grains, Deprel: compound, Head: management\n",
      "Word: management, Deprel: compound, Head: committee\n",
      "Word: committee, Deprel: nsubj, Head: meets\n",
      "Word: meets, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: directorate\n",
      "Word: the, Deprel: det, Head: Commission\n",
      "Word: Commission, Deprel: nmod:poss, Head: directorate\n",
      "Word: s, Deprel: case, Head: Commission\n",
      "Word: agriculture, Deprel: compound, Head: directorate\n",
      "Word: directorate, Deprel: obl, Head: meets\n",
      "Word: to, Deprel: mark, Head: decide\n",
      "Word: decide, Deprel: advcl, Head: meets\n",
      "Word: the, Deprel: det, Head: outcome\n",
      "Word: outcome, Deprel: obj, Head: decide\n",
      "Word: of, Deprel: case, Head: tender\n",
      "Word: a, Deprel: det, Head: tender\n",
      "Word: weekly, Deprel: amod, Head: tender\n",
      "Word: export, Deprel: compound, Head: tender\n",
      "Word: tender, Deprel: nmod, Head: outcome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A grains management committee normally meets each Thursday in the Commission s agriculture unit another target of Wednesday s raids to decide the outcome of a weekly export tender'\n",
      "Word: A, Deprel: det, Head: committee\n",
      "Word: grains, Deprel: compound, Head: management\n",
      "Word: management, Deprel: compound, Head: committee\n",
      "Word: committee, Deprel: nsubj, Head: meets\n",
      "Word: normally, Deprel: advmod, Head: meets\n",
      "Word: meets, Deprel: root, Head: ROOT\n",
      "Word: each, Deprel: det, Head: Thursday\n",
      "Word: Thursday, Deprel: obl:tmod, Head: meets\n",
      "Word: in, Deprel: case, Head: unit\n",
      "Word: the, Deprel: det, Head: Commission\n",
      "Word: Commission, Deprel: nmod:poss, Head: unit\n",
      "Word: s, Deprel: case, Head: Commission\n",
      "Word: agriculture, Deprel: compound, Head: unit\n",
      "Word: unit, Deprel: obl, Head: meets\n",
      "Word: another, Deprel: det, Head: target\n",
      "Word: target, Deprel: obj, Head: meets\n",
      "Word: of, Deprel: case, Head: raids\n",
      "Word: Wednesday, Deprel: nmod:poss, Head: raids\n",
      "Word: s, Deprel: case, Head: Wednesday\n",
      "Word: raids, Deprel: nmod, Head: target\n",
      "Word: to, Deprel: mark, Head: decide\n",
      "Word: decide, Deprel: advcl, Head: meets\n",
      "Word: the, Deprel: det, Head: outcome\n",
      "Word: outcome, Deprel: obj, Head: decide\n",
      "Word: of, Deprel: case, Head: tender\n",
      "Word: a, Deprel: det, Head: tender\n",
      "Word: weekly, Deprel: amod, Head: tender\n",
      "Word: export, Deprel: compound, Head: tender\n",
      "Word: tender, Deprel: nmod, Head: outcome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He urged Congress to send me the final bill as soon as possible so that I can sign it into law'\n",
      "Word: He, Deprel: nsubj, Head: urged\n",
      "Word: urged, Deprel: root, Head: ROOT\n",
      "Word: Congress, Deprel: iobj, Head: urged\n",
      "Word: to, Deprel: mark, Head: send\n",
      "Word: send, Deprel: xcomp, Head: urged\n",
      "Word: me, Deprel: iobj, Head: send\n",
      "Word: the, Deprel: det, Head: bill\n",
      "Word: final, Deprel: amod, Head: bill\n",
      "Word: bill, Deprel: obj, Head: send\n",
      "Word: as, Deprel: advmod, Head: soon\n",
      "Word: soon, Deprel: advmod, Head: send\n",
      "Word: as, Deprel: mark, Head: possible\n",
      "Word: possible, Deprel: advcl, Head: soon\n",
      "Word: so, Deprel: mark, Head: sign\n",
      "Word: that, Deprel: fixed, Head: so\n",
      "Word: I, Deprel: nsubj, Head: sign\n",
      "Word: can, Deprel: aux, Head: sign\n",
      "Word: sign, Deprel: advcl, Head: send\n",
      "Word: it, Deprel: obj, Head: sign\n",
      "Word: into, Deprel: case, Head: law\n",
      "Word: law, Deprel: obl, Head: sign\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I urge Congress to quickly resolve any differences and send me the final bill as soon as possible so that I can sign it into law he said'\n",
      "Word: I, Deprel: nsubj, Head: urge\n",
      "Word: urge, Deprel: root, Head: ROOT\n",
      "Word: Congress, Deprel: iobj, Head: urge\n",
      "Word: to, Deprel: mark, Head: resolve\n",
      "Word: quickly, Deprel: advmod, Head: resolve\n",
      "Word: resolve, Deprel: xcomp, Head: urge\n",
      "Word: any, Deprel: det, Head: differences\n",
      "Word: differences, Deprel: obj, Head: resolve\n",
      "Word: and, Deprel: cc, Head: send\n",
      "Word: send, Deprel: conj, Head: resolve\n",
      "Word: me, Deprel: iobj, Head: send\n",
      "Word: the, Deprel: det, Head: bill\n",
      "Word: final, Deprel: amod, Head: bill\n",
      "Word: bill, Deprel: obj, Head: send\n",
      "Word: as, Deprel: advmod, Head: soon\n",
      "Word: soon, Deprel: advmod, Head: send\n",
      "Word: as, Deprel: mark, Head: possible\n",
      "Word: possible, Deprel: advcl, Head: soon\n",
      "Word: so, Deprel: mark, Head: sign\n",
      "Word: that, Deprel: fixed, Head: so\n",
      "Word: I, Deprel: nsubj, Head: sign\n",
      "Word: can, Deprel: aux, Head: sign\n",
      "Word: sign, Deprel: advcl, Head: send\n",
      "Word: it, Deprel: obj, Head: sign\n",
      "Word: into, Deprel: case, Head: law\n",
      "Word: law, Deprel: obl, Head: sign\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: sign\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Pingeon is director of litigation for Massachusetts Correctional Legal Services a prisoners rights group'\n",
      "Word: Mr, Deprel: nsubj, Head: director\n",
      "Word: Pingeon, Deprel: flat, Head: Mr\n",
      "Word: is, Deprel: cop, Head: director\n",
      "Word: director, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: litigation\n",
      "Word: litigation, Deprel: nmod, Head: director\n",
      "Word: for, Deprel: case, Head: Services\n",
      "Word: Massachusetts, Deprel: compound, Head: Services\n",
      "Word: Correctional, Deprel: amod, Head: Services\n",
      "Word: Legal, Deprel: amod, Head: Services\n",
      "Word: Services, Deprel: nmod, Head: litigation\n",
      "Word: a, Deprel: det, Head: group\n",
      "Word: prisoners, Deprel: compound, Head: rights\n",
      "Word: rights, Deprel: compound, Head: group\n",
      "Word: group, Deprel: appos, Head: litigation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Pingeon said an attorney for his organization Massachusetts Correctional Legal Services interviewed Assan Tuesday'\n",
      "Word: Pingeon, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: attorney\n",
      "Word: attorney, Deprel: nsubj, Head: interviewed\n",
      "Word: for, Deprel: case, Head: organization\n",
      "Word: his, Deprel: nmod:poss, Head: organization\n",
      "Word: organization, Deprel: nmod, Head: attorney\n",
      "Word: Massachusetts, Deprel: compound, Head: Services\n",
      "Word: Correctional, Deprel: amod, Head: Services\n",
      "Word: Legal, Deprel: amod, Head: Services\n",
      "Word: Services, Deprel: appos, Head: attorney\n",
      "Word: interviewed, Deprel: ccomp, Head: said\n",
      "Word: Assan, Deprel: obj, Head: interviewed\n",
      "Word: Tuesday, Deprel: obj, Head: interviewed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Yee is a 1990 graduate of the U.S Military Academy at West Point New York'\n",
      "Word: Yee, Deprel: nsubj, Head: graduate\n",
      "Word: is, Deprel: cop, Head: graduate\n",
      "Word: a, Deprel: det, Head: graduate\n",
      "Word: 1990, Deprel: compound, Head: graduate\n",
      "Word: graduate, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: Academy\n",
      "Word: the, Deprel: det, Head: Academy\n",
      "Word: U.S, Deprel: compound, Head: Academy\n",
      "Word: Military, Deprel: amod, Head: Academy\n",
      "Word: Academy, Deprel: nmod, Head: graduate\n",
      "Word: at, Deprel: case, Head: Point\n",
      "Word: West, Deprel: compound, Head: Point\n",
      "Word: Point, Deprel: nmod, Head: Academy\n",
      "Word: New, Deprel: amod, Head: York\n",
      "Word: York, Deprel: appos, Head: Point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Yee grew up in the United States and graduated from the U.S Military Academy at West Point'\n",
      "Word: Yee, Deprel: nsubj, Head: grew\n",
      "Word: grew, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: grew\n",
      "Word: in, Deprel: case, Head: States\n",
      "Word: the, Deprel: det, Head: States\n",
      "Word: United, Deprel: amod, Head: States\n",
      "Word: States, Deprel: obl, Head: grew\n",
      "Word: and, Deprel: cc, Head: graduated\n",
      "Word: graduated, Deprel: conj, Head: grew\n",
      "Word: from, Deprel: case, Head: Academy\n",
      "Word: the, Deprel: det, Head: Academy\n",
      "Word: U.S, Deprel: compound, Head: Academy\n",
      "Word: Military, Deprel: amod, Head: Academy\n",
      "Word: Academy, Deprel: obl, Head: graduated\n",
      "Word: at, Deprel: case, Head: Point\n",
      "Word: West, Deprel: compound, Head: Point\n",
      "Word: Point, Deprel: nmod, Head: Academy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'PNC regrets its involvement in the deals Chairman and Chief Executive Officer James Rohr said in a statement'\n",
      "Word: PNC, Deprel: nsubj, Head: regrets\n",
      "Word: regrets, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: involvement\n",
      "Word: involvement, Deprel: obj, Head: regrets\n",
      "Word: in, Deprel: case, Head: deals\n",
      "Word: the, Deprel: det, Head: Chairman\n",
      "Word: deals, Deprel: compound, Head: Chairman\n",
      "Word: Chairman, Deprel: compound, Head: James\n",
      "Word: and, Deprel: cc, Head: Officer\n",
      "Word: Chief, Deprel: compound, Head: Executive\n",
      "Word: Executive, Deprel: amod, Head: Officer\n",
      "Word: Officer, Deprel: conj, Head: Chairman\n",
      "Word: James, Deprel: nsubj, Head: said\n",
      "Word: Rohr, Deprel: flat, Head: James\n",
      "Word: said, Deprel: parataxis, Head: regrets\n",
      "Word: in, Deprel: case, Head: statement\n",
      "Word: a, Deprel: det, Head: statement\n",
      "Word: statement, Deprel: obl, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'James Rohr chairman and chief executive officer said PNC regretted the incident'\n",
      "Word: James, Deprel: compound, Head: chairman\n",
      "Word: Rohr, Deprel: flat, Head: James\n",
      "Word: chairman, Deprel: nsubj, Head: said\n",
      "Word: and, Deprel: cc, Head: officer\n",
      "Word: chief, Deprel: amod, Head: executive\n",
      "Word: executive, Deprel: amod, Head: officer\n",
      "Word: officer, Deprel: conj, Head: chairman\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: PNC, Deprel: nsubj, Head: regretted\n",
      "Word: regretted, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: incident\n",
      "Word: incident, Deprel: obj, Head: regretted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'CCAG supported Bill Curry Rowland s opponent in the 2002 gubernatorial election'\n",
      "Word: CCAG, Deprel: nsubj, Head: supported\n",
      "Word: supported, Deprel: root, Head: ROOT\n",
      "Word: Bill, Deprel: nmod:poss, Head: opponent\n",
      "Word: Curry, Deprel: flat, Head: Bill\n",
      "Word: Rowland, Deprel: flat, Head: Bill\n",
      "Word: s, Deprel: case, Head: Bill\n",
      "Word: opponent, Deprel: obj, Head: supported\n",
      "Word: in, Deprel: case, Head: election\n",
      "Word: the, Deprel: det, Head: election\n",
      "Word: 2002, Deprel: compound, Head: election\n",
      "Word: gubernatorial, Deprel: amod, Head: election\n",
      "Word: election, Deprel: obl, Head: supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Swan s group supported the governor s Democratic opponent Bill Curry in the 2002 election'\n",
      "Word: Mr, Deprel: nmod:poss, Head: group\n",
      "Word: Swan, Deprel: flat, Head: Mr\n",
      "Word: s, Deprel: case, Head: Mr\n",
      "Word: group, Deprel: nsubj, Head: supported\n",
      "Word: supported, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: governor\n",
      "Word: governor, Deprel: nmod:poss, Head: opponent\n",
      "Word: s, Deprel: case, Head: governor\n",
      "Word: Democratic, Deprel: amod, Head: opponent\n",
      "Word: opponent, Deprel: obj, Head: supported\n",
      "Word: Bill, Deprel: appos, Head: opponent\n",
      "Word: Curry, Deprel: flat, Head: Bill\n",
      "Word: in, Deprel: case, Head: election\n",
      "Word: the, Deprel: det, Head: election\n",
      "Word: 2002, Deprel: compound, Head: election\n",
      "Word: election, Deprel: obl, Head: supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'They later fell out and have backed a series of rival Congolese militias in recent years'\n",
      "Word: They, Deprel: nsubj, Head: fell\n",
      "Word: later, Deprel: advmod, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: advmod, Head: fell\n",
      "Word: and, Deprel: cc, Head: backed\n",
      "Word: have, Deprel: aux, Head: backed\n",
      "Word: backed, Deprel: conj, Head: fell\n",
      "Word: a, Deprel: det, Head: series\n",
      "Word: series, Deprel: obj, Head: backed\n",
      "Word: of, Deprel: case, Head: militias\n",
      "Word: rival, Deprel: amod, Head: militias\n",
      "Word: Congolese, Deprel: amod, Head: militias\n",
      "Word: militias, Deprel: nmod, Head: series\n",
      "Word: in, Deprel: case, Head: years\n",
      "Word: recent, Deprel: amod, Head: years\n",
      "Word: years, Deprel: obl, Head: backed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The two invading countries later fell out and have since backed rival factions'\n",
      "Word: The, Deprel: det, Head: countries\n",
      "Word: two, Deprel: nummod, Head: countries\n",
      "Word: invading, Deprel: amod, Head: countries\n",
      "Word: countries, Deprel: nsubj, Head: fell\n",
      "Word: later, Deprel: advmod, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: advmod, Head: fell\n",
      "Word: and, Deprel: cc, Head: backed\n",
      "Word: have, Deprel: aux, Head: backed\n",
      "Word: since, Deprel: advmod, Head: backed\n",
      "Word: backed, Deprel: conj, Head: fell\n",
      "Word: rival, Deprel: amod, Head: factions\n",
      "Word: factions, Deprel: obj, Head: backed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'State health officials said today a young northeast Kansas woman likely has the state s first case of monkeypox among humans or animals'\n",
      "Word: State, Deprel: compound, Head: officials\n",
      "Word: health, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: today, Deprel: obl:tmod, Head: has\n",
      "Word: a, Deprel: det, Head: woman\n",
      "Word: young, Deprel: amod, Head: woman\n",
      "Word: northeast, Deprel: compound, Head: woman\n",
      "Word: Kansas, Deprel: compound, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: has\n",
      "Word: likely, Deprel: advmod, Head: has\n",
      "Word: has, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: state, Deprel: nmod:poss, Head: case\n",
      "Word: s, Deprel: case, Head: state\n",
      "Word: first, Deprel: amod, Head: case\n",
      "Word: case, Deprel: obj, Head: has\n",
      "Word: of, Deprel: case, Head: monkeypox\n",
      "Word: monkeypox, Deprel: nmod, Head: case\n",
      "Word: among, Deprel: case, Head: humans\n",
      "Word: humans, Deprel: nmod, Head: case\n",
      "Word: or, Deprel: cc, Head: animals\n",
      "Word: animals, Deprel: conj, Head: humans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Health officials confirmed today that a northeast Kansas woman has the state s first case of monkeypox and the first case west of the Mississippi River'\n",
      "Word: Health, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: confirmed\n",
      "Word: confirmed, Deprel: root, Head: ROOT\n",
      "Word: today, Deprel: obl:tmod, Head: confirmed\n",
      "Word: that, Deprel: mark, Head: has\n",
      "Word: a, Deprel: det, Head: woman\n",
      "Word: northeast, Deprel: compound, Head: woman\n",
      "Word: Kansas, Deprel: compound, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: has\n",
      "Word: has, Deprel: ccomp, Head: confirmed\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: state, Deprel: nmod:poss, Head: case\n",
      "Word: s, Deprel: case, Head: state\n",
      "Word: first, Deprel: amod, Head: case\n",
      "Word: case, Deprel: obj, Head: has\n",
      "Word: of, Deprel: case, Head: monkeypox\n",
      "Word: monkeypox, Deprel: nmod, Head: case\n",
      "Word: and, Deprel: cc, Head: case\n",
      "Word: the, Deprel: det, Head: case\n",
      "Word: first, Deprel: amod, Head: case\n",
      "Word: case, Deprel: conj, Head: case\n",
      "Word: west, Deprel: advmod, Head: case\n",
      "Word: of, Deprel: case, Head: River\n",
      "Word: the, Deprel: det, Head: River\n",
      "Word: Mississippi, Deprel: compound, Head: River\n",
      "Word: River, Deprel: obl, Head: west\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Another said its members would continue to call the more than 50 million phone numbers on the Federal Trade Commission s list'\n",
      "Word: Another, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: members\n",
      "Word: members, Deprel: nsubj, Head: continue\n",
      "Word: would, Deprel: aux, Head: continue\n",
      "Word: continue, Deprel: ccomp, Head: said\n",
      "Word: to, Deprel: mark, Head: call\n",
      "Word: call, Deprel: xcomp, Head: continue\n",
      "Word: the, Deprel: det, Head: numbers\n",
      "Word: more, Deprel: advmod, Head: million\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 50, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: numbers\n",
      "Word: phone, Deprel: compound, Head: numbers\n",
      "Word: numbers, Deprel: obj, Head: call\n",
      "Word: on, Deprel: case, Head: list\n",
      "Word: the, Deprel: det, Head: Commission\n",
      "Word: Federal, Deprel: amod, Head: Commission\n",
      "Word: Trade, Deprel: compound, Head: Commission\n",
      "Word: Commission, Deprel: nmod:poss, Head: list\n",
      "Word: s, Deprel: case, Head: Commission\n",
      "Word: list, Deprel: obl, Head: call\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Meantime the Direct Marketing Association said its members should not call the nearly 51 million numbers on the list'\n",
      "Word: Meantime, Deprel: advmod, Head: said\n",
      "Word: the, Deprel: det, Head: Association\n",
      "Word: Direct, Deprel: amod, Head: Marketing\n",
      "Word: Marketing, Deprel: compound, Head: Association\n",
      "Word: Association, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: members\n",
      "Word: members, Deprel: nsubj, Head: call\n",
      "Word: should, Deprel: aux, Head: call\n",
      "Word: not, Deprel: advmod, Head: call\n",
      "Word: call, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: numbers\n",
      "Word: nearly, Deprel: advmod, Head: million\n",
      "Word: 51, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: numbers\n",
      "Word: numbers, Deprel: obj, Head: call\n",
      "Word: on, Deprel: case, Head: list\n",
      "Word: the, Deprel: det, Head: list\n",
      "Word: list, Deprel: obl, Head: call\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Veteran entertainer Bob Hope celebrates his 100th birthday and many years in showbusiness on Thursday'\n",
      "Word: Veteran, Deprel: amod, Head: entertainer\n",
      "Word: entertainer, Deprel: compound, Head: Bob\n",
      "Word: Bob, Deprel: nsubj, Head: celebrates\n",
      "Word: Hope, Deprel: flat, Head: Bob\n",
      "Word: celebrates, Deprel: root, Head: ROOT\n",
      "Word: his, Deprel: nmod:poss, Head: birthday\n",
      "Word: 100th, Deprel: amod, Head: birthday\n",
      "Word: birthday, Deprel: obj, Head: celebrates\n",
      "Word: and, Deprel: cc, Head: years\n",
      "Word: many, Deprel: amod, Head: years\n",
      "Word: years, Deprel: conj, Head: birthday\n",
      "Word: in, Deprel: case, Head: showbusiness\n",
      "Word: showbusiness, Deprel: nmod, Head: years\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: nmod, Head: years\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hollywood and the world are gearing up to celebrate legendary entertainer Bob Hope s 100th birthday on Thursday'\n",
      "Word: Hollywood, Deprel: nsubj, Head: gearing\n",
      "Word: and, Deprel: cc, Head: world\n",
      "Word: the, Deprel: det, Head: world\n",
      "Word: world, Deprel: conj, Head: Hollywood\n",
      "Word: are, Deprel: aux, Head: gearing\n",
      "Word: gearing, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: gearing\n",
      "Word: to, Deprel: mark, Head: celebrate\n",
      "Word: celebrate, Deprel: advcl, Head: gearing\n",
      "Word: legendary, Deprel: amod, Head: entertainer\n",
      "Word: entertainer, Deprel: nmod:poss, Head: birthday\n",
      "Word: Bob, Deprel: flat, Head: entertainer\n",
      "Word: Hope, Deprel: flat, Head: entertainer\n",
      "Word: s, Deprel: case, Head: entertainer\n",
      "Word: 100th, Deprel: amod, Head: birthday\n",
      "Word: birthday, Deprel: obj, Head: celebrate\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: nmod, Head: birthday\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Navistar shares were down 44 cents or 1.1 percent at 41.19 on the New York Stock Exchange after falling as low as 39.93'\n",
      "Word: Navistar, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: down\n",
      "Word: were, Deprel: cop, Head: down\n",
      "Word: down, Deprel: root, Head: ROOT\n",
      "Word: 44, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:npmod, Head: down\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.1, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: cents\n",
      "Word: at, Deprel: case, Head: 41.19\n",
      "Word: 41.19, Deprel: obl, Head: down\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: down\n",
      "Word: after, Deprel: mark, Head: falling\n",
      "Word: falling, Deprel: advcl, Head: down\n",
      "Word: as, Deprel: advmod, Head: low\n",
      "Word: low, Deprel: advmod, Head: falling\n",
      "Word: as, Deprel: case, Head: 39.93\n",
      "Word: 39.93, Deprel: obl, Head: low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Navistar shares rose a penny to 41.64 at late afternoon on the New York Stock Exchange after earlier falling as low as 39.93'\n",
      "Word: Navistar, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: penny\n",
      "Word: penny, Deprel: obj, Head: rose\n",
      "Word: to, Deprel: case, Head: 41.64\n",
      "Word: 41.64, Deprel: obl, Head: rose\n",
      "Word: at, Deprel: case, Head: afternoon\n",
      "Word: late, Deprel: amod, Head: afternoon\n",
      "Word: afternoon, Deprel: obl, Head: rose\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: rose\n",
      "Word: after, Deprel: mark, Head: falling\n",
      "Word: earlier, Deprel: advmod, Head: falling\n",
      "Word: falling, Deprel: advcl, Head: rose\n",
      "Word: as, Deprel: advmod, Head: low\n",
      "Word: low, Deprel: advmod, Head: falling\n",
      "Word: as, Deprel: case, Head: 39.93\n",
      "Word: 39.93, Deprel: obl, Head: low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Colin Powell the Secretary of State said contacts with Iran would not stop'\n",
      "Word: Colin, Deprel: nsubj, Head: said\n",
      "Word: Powell, Deprel: flat, Head: Colin\n",
      "Word: the, Deprel: det, Head: Secretary\n",
      "Word: Secretary, Deprel: appos, Head: Colin\n",
      "Word: of, Deprel: case, Head: State\n",
      "Word: State, Deprel: nmod, Head: Secretary\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: contacts, Deprel: nsubj, Head: stop\n",
      "Word: with, Deprel: case, Head: Iran\n",
      "Word: Iran, Deprel: nmod, Head: contacts\n",
      "Word: would, Deprel: aux, Head: stop\n",
      "Word: not, Deprel: advmod, Head: stop\n",
      "Word: stop, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Secretary of State Colin Powell said yesterday that contacts with Iran would continue'\n",
      "Word: Secretary, Deprel: compound, Head: Colin\n",
      "Word: of, Deprel: case, Head: State\n",
      "Word: State, Deprel: nmod, Head: Secretary\n",
      "Word: Colin, Deprel: nsubj, Head: said\n",
      "Word: Powell, Deprel: flat, Head: Colin\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: yesterday, Deprel: obl:tmod, Head: said\n",
      "Word: that, Deprel: mark, Head: continue\n",
      "Word: contacts, Deprel: nsubj, Head: continue\n",
      "Word: with, Deprel: case, Head: Iran\n",
      "Word: Iran, Deprel: nmod, Head: contacts\n",
      "Word: would, Deprel: aux, Head: continue\n",
      "Word: continue, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Declining issues outnumbered advancers nearly 2 to 1 on the New York Stock Exchange'\n",
      "Word: Declining, Deprel: amod, Head: issues\n",
      "Word: issues, Deprel: nsubj, Head: outnumbered\n",
      "Word: outnumbered, Deprel: root, Head: ROOT\n",
      "Word: advancers, Deprel: obj, Head: outnumbered\n",
      "Word: nearly, Deprel: advmod, Head: 2\n",
      "Word: 2, Deprel: obl:npmod, Head: outnumbered\n",
      "Word: to, Deprel: case, Head: 1\n",
      "Word: 1, Deprel: nmod, Head: 2\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: outnumbered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Advancers outnumbered decliners by nearly 8 to 3 on the NYSE and more than 11 to 5 on Nasdaq'\n",
      "Word: Advancers, Deprel: nsubj, Head: outnumbered\n",
      "Word: outnumbered, Deprel: root, Head: ROOT\n",
      "Word: decliners, Deprel: obj, Head: outnumbered\n",
      "Word: by, Deprel: case, Head: 8\n",
      "Word: nearly, Deprel: advmod, Head: 8\n",
      "Word: 8, Deprel: obl, Head: outnumbered\n",
      "Word: to, Deprel: case, Head: 3\n",
      "Word: 3, Deprel: nmod, Head: 8\n",
      "Word: on, Deprel: case, Head: NYSE\n",
      "Word: the, Deprel: det, Head: NYSE\n",
      "Word: NYSE, Deprel: obl, Head: outnumbered\n",
      "Word: and, Deprel: cc, Head: 11\n",
      "Word: more, Deprel: advmod, Head: 11\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 11, Deprel: conj, Head: outnumbered\n",
      "Word: to, Deprel: case, Head: 5\n",
      "Word: 5, Deprel: nmod, Head: 11\n",
      "Word: on, Deprel: case, Head: Nasdaq\n",
      "Word: Nasdaq, Deprel: obl, Head: outnumbered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A floating airfield with a flight deck covering 4.5 acres the ship took about five years to build'\n",
      "Word: A, Deprel: det, Head: airfield\n",
      "Word: floating, Deprel: amod, Head: airfield\n",
      "Word: airfield, Deprel: nsubj, Head: took\n",
      "Word: with, Deprel: case, Head: deck\n",
      "Word: a, Deprel: det, Head: deck\n",
      "Word: flight, Deprel: compound, Head: deck\n",
      "Word: deck, Deprel: nmod, Head: airfield\n",
      "Word: covering, Deprel: acl, Head: deck\n",
      "Word: 4.5, Deprel: nummod, Head: acres\n",
      "Word: acres, Deprel: obj, Head: covering\n",
      "Word: the, Deprel: det, Head: ship\n",
      "Word: ship, Deprel: nsubj, Head: took\n",
      "Word: took, Deprel: root, Head: ROOT\n",
      "Word: about, Deprel: advmod, Head: five\n",
      "Word: five, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obj, Head: took\n",
      "Word: to, Deprel: mark, Head: build\n",
      "Word: build, Deprel: advcl, Head: took\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Reagan a floating airfield with a flight deck covering 4.5 acres is the ninth Nimitz-class carrier to be built at the Newport News shipyard'\n",
      "Word: The, Deprel: det, Head: Reagan\n",
      "Word: Reagan, Deprel: nsubj, Head: carrier\n",
      "Word: a, Deprel: det, Head: airfield\n",
      "Word: floating, Deprel: amod, Head: airfield\n",
      "Word: airfield, Deprel: nsubj, Head: carrier\n",
      "Word: with, Deprel: case, Head: deck\n",
      "Word: a, Deprel: det, Head: deck\n",
      "Word: flight, Deprel: compound, Head: deck\n",
      "Word: deck, Deprel: nmod, Head: airfield\n",
      "Word: covering, Deprel: acl, Head: deck\n",
      "Word: 4.5, Deprel: nummod, Head: acres\n",
      "Word: acres, Deprel: obj, Head: covering\n",
      "Word: is, Deprel: cop, Head: carrier\n",
      "Word: the, Deprel: det, Head: carrier\n",
      "Word: ninth, Deprel: amod, Head: carrier\n",
      "Word: Nimitz-class, Deprel: compound, Head: carrier\n",
      "Word: carrier, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: built\n",
      "Word: be, Deprel: aux:pass, Head: built\n",
      "Word: built, Deprel: acl, Head: carrier\n",
      "Word: at, Deprel: case, Head: shipyard\n",
      "Word: the, Deprel: det, Head: shipyard\n",
      "Word: Newport, Deprel: compound, Head: shipyard\n",
      "Word: News, Deprel: compound, Head: shipyard\n",
      "Word: shipyard, Deprel: obl, Head: built\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Im very proud of the citizens of this state said Gov John Baldacci a casino foe'\n",
      "Word: Im, Deprel: nsubj, Head: proud\n",
      "Word: very, Deprel: advmod, Head: proud\n",
      "Word: proud, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: citizens\n",
      "Word: the, Deprel: det, Head: citizens\n",
      "Word: citizens, Deprel: obl, Head: proud\n",
      "Word: of, Deprel: case, Head: state\n",
      "Word: this, Deprel: det, Head: state\n",
      "Word: state, Deprel: nmod, Head: citizens\n",
      "Word: said, Deprel: parataxis, Head: proud\n",
      "Word: Gov, Deprel: obj, Head: said\n",
      "Word: John, Deprel: flat, Head: Gov\n",
      "Word: Baldacci, Deprel: flat, Head: Gov\n",
      "Word: a, Deprel: det, Head: foe\n",
      "Word: casino, Deprel: compound, Head: foe\n",
      "Word: foe, Deprel: appos, Head: Gov\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I´m very proud of the citizens of this state Gov John Baldacci said after votes from Tuesday´s referendum were counted'\n",
      "Word: I´m, Deprel: nsubj, Head: said\n",
      "Word: very, Deprel: advmod, Head: proud\n",
      "Word: proud, Deprel: amod, Head: I´m\n",
      "Word: of, Deprel: case, Head: citizens\n",
      "Word: the, Deprel: det, Head: citizens\n",
      "Word: citizens, Deprel: obl, Head: proud\n",
      "Word: of, Deprel: case, Head: Gov\n",
      "Word: this, Deprel: det, Head: Gov\n",
      "Word: state, Deprel: compound, Head: Gov\n",
      "Word: Gov, Deprel: nmod, Head: citizens\n",
      "Word: John, Deprel: flat, Head: Gov\n",
      "Word: Baldacci, Deprel: flat, Head: John\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: after, Deprel: case, Head: votes\n",
      "Word: votes, Deprel: obl, Head: counted\n",
      "Word: from, Deprel: case, Head: referendum\n",
      "Word: Tuesday´s, Deprel: compound, Head: referendum\n",
      "Word: referendum, Deprel: nmod, Head: votes\n",
      "Word: were, Deprel: aux:pass, Head: counted\n",
      "Word: counted, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Stout previously worked for General Electric subsidiary GE Capital Service Inc where he was vice president and chief technology and information officer'\n",
      "Word: Stout, Deprel: nsubj, Head: worked\n",
      "Word: previously, Deprel: advmod, Head: worked\n",
      "Word: worked, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: subsidiary\n",
      "Word: General, Deprel: amod, Head: subsidiary\n",
      "Word: Electric, Deprel: compound, Head: subsidiary\n",
      "Word: subsidiary, Deprel: obl, Head: worked\n",
      "Word: GE, Deprel: compound, Head: Capital\n",
      "Word: Capital, Deprel: compound, Head: Service\n",
      "Word: Service, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: appos, Head: subsidiary\n",
      "Word: where, Deprel: advmod, Head: president\n",
      "Word: he, Deprel: nsubj, Head: president\n",
      "Word: was, Deprel: cop, Head: president\n",
      "Word: vice, Deprel: amod, Head: president\n",
      "Word: president, Deprel: acl:relcl, Head: subsidiary\n",
      "Word: and, Deprel: cc, Head: officer\n",
      "Word: chief, Deprel: amod, Head: officer\n",
      "Word: technology, Deprel: compound, Head: officer\n",
      "Word: and, Deprel: cc, Head: information\n",
      "Word: information, Deprel: conj, Head: technology\n",
      "Word: officer, Deprel: conj, Head: president\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Stout comes to Sprint from GE Capital where he served as chief technology and information officer'\n",
      "Word: Stout, Deprel: nsubj, Head: comes\n",
      "Word: comes, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Sprint\n",
      "Word: Sprint, Deprel: obl, Head: comes\n",
      "Word: from, Deprel: case, Head: Capital\n",
      "Word: GE, Deprel: compound, Head: Capital\n",
      "Word: Capital, Deprel: obl, Head: comes\n",
      "Word: where, Deprel: advmod, Head: served\n",
      "Word: he, Deprel: nsubj, Head: served\n",
      "Word: served, Deprel: acl:relcl, Head: Capital\n",
      "Word: as, Deprel: case, Head: officer\n",
      "Word: chief, Deprel: amod, Head: officer\n",
      "Word: technology, Deprel: compound, Head: officer\n",
      "Word: and, Deprel: cc, Head: information\n",
      "Word: information, Deprel: conj, Head: technology\n",
      "Word: officer, Deprel: obl, Head: served\n",
      "\n",
      "Dependencies for Sentence: 'Only Intel Corp s 0.3 percent yield was lower'\n",
      "Word: Only, Deprel: advmod, Head: Corp\n",
      "Word: Intel, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: nmod:poss, Head: yield\n",
      "Word: s, Deprel: case, Head: Corp\n",
      "Word: 0.3, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: yield\n",
      "Word: yield, Deprel: nsubj, Head: lower\n",
      "Word: was, Deprel: cop, Head: lower\n",
      "Word: lower, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Only Intel Corp has a lower dividend yield'\n",
      "Word: Only, Deprel: advmod, Head: Corp\n",
      "Word: Intel, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: nsubj, Head: has\n",
      "Word: has, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: yield\n",
      "Word: lower, Deprel: amod, Head: yield\n",
      "Word: dividend, Deprel: compound, Head: yield\n",
      "Word: yield, Deprel: obj, Head: has\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'An injured woman co-worker also was hospitalized and was listed in good condition'\n",
      "Word: An, Deprel: det, Head: co-worker\n",
      "Word: injured, Deprel: amod, Head: co-worker\n",
      "Word: woman, Deprel: compound, Head: co-worker\n",
      "Word: co-worker, Deprel: nsubj:pass, Head: hospitalized\n",
      "Word: also, Deprel: advmod, Head: hospitalized\n",
      "Word: was, Deprel: aux:pass, Head: hospitalized\n",
      "Word: hospitalized, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: listed\n",
      "Word: was, Deprel: aux:pass, Head: listed\n",
      "Word: listed, Deprel: conj, Head: hospitalized\n",
      "Word: in, Deprel: case, Head: condition\n",
      "Word: good, Deprel: amod, Head: condition\n",
      "Word: condition, Deprel: obl, Head: listed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman was listed in good condition at Memorial s HealthPark campus he said'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj:pass, Head: listed\n",
      "Word: was, Deprel: aux:pass, Head: listed\n",
      "Word: listed, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: condition\n",
      "Word: good, Deprel: amod, Head: condition\n",
      "Word: condition, Deprel: obl, Head: listed\n",
      "Word: at, Deprel: case, Head: campus\n",
      "Word: Memorial, Deprel: nmod:poss, Head: campus\n",
      "Word: s, Deprel: case, Head: Memorial\n",
      "Word: HealthPark, Deprel: compound, Head: campus\n",
      "Word: campus, Deprel: obl, Head: listed\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: campus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The shooting victim was taken to Kings County Hospital Center where he later died the police said'\n",
      "Word: The, Deprel: det, Head: victim\n",
      "Word: shooting, Deprel: compound, Head: victim\n",
      "Word: victim, Deprel: nsubj:pass, Head: taken\n",
      "Word: was, Deprel: aux:pass, Head: taken\n",
      "Word: taken, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Center\n",
      "Word: Kings, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: Center\n",
      "Word: Hospital, Deprel: compound, Head: Center\n",
      "Word: Center, Deprel: obl, Head: taken\n",
      "Word: where, Deprel: advmod, Head: died\n",
      "Word: he, Deprel: nsubj, Head: died\n",
      "Word: later, Deprel: advmod, Head: died\n",
      "Word: died, Deprel: advcl, Head: taken\n",
      "Word: the, Deprel: det, Head: police\n",
      "Word: police, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: ccomp, Head: died\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The victim who was not identified was taken to Kings County Hospital where he was pronounced dead'\n",
      "Word: The, Deprel: det, Head: victim\n",
      "Word: victim, Deprel: nsubj:pass, Head: taken\n",
      "Word: who, Deprel: nsubj:pass, Head: identified\n",
      "Word: was, Deprel: aux:pass, Head: identified\n",
      "Word: not, Deprel: advmod, Head: identified\n",
      "Word: identified, Deprel: acl:relcl, Head: victim\n",
      "Word: was, Deprel: aux:pass, Head: taken\n",
      "Word: taken, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Hospital\n",
      "Word: Kings, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: Hospital\n",
      "Word: Hospital, Deprel: obl, Head: taken\n",
      "Word: where, Deprel: advmod, Head: pronounced\n",
      "Word: he, Deprel: nsubj:pass, Head: pronounced\n",
      "Word: was, Deprel: aux:pass, Head: pronounced\n",
      "Word: pronounced, Deprel: advcl, Head: taken\n",
      "Word: dead, Deprel: xcomp, Head: pronounced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'MGM NBC and Liberty executives were not immediately available for comment'\n",
      "Word: MGM, Deprel: compound, Head: executives\n",
      "Word: NBC, Deprel: compound, Head: executives\n",
      "Word: and, Deprel: cc, Head: Liberty\n",
      "Word: Liberty, Deprel: conj, Head: NBC\n",
      "Word: executives, Deprel: nsubj, Head: available\n",
      "Word: were, Deprel: cop, Head: available\n",
      "Word: not, Deprel: advmod, Head: available\n",
      "Word: immediately, Deprel: advmod, Head: available\n",
      "Word: available, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: comment\n",
      "Word: comment, Deprel: obl, Head: available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A Microsoft spokesman was not immediately available to comment'\n",
      "Word: A, Deprel: det, Head: spokesman\n",
      "Word: Microsoft, Deprel: compound, Head: spokesman\n",
      "Word: spokesman, Deprel: nsubj, Head: available\n",
      "Word: was, Deprel: cop, Head: available\n",
      "Word: not, Deprel: advmod, Head: available\n",
      "Word: immediately, Deprel: advmod, Head: available\n",
      "Word: available, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: comment\n",
      "Word: comment, Deprel: advcl, Head: available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new analysis found that 32 of the 16,608 participants developed ovarian cancer during about 5 years of follow-up'\n",
      "Word: The, Deprel: det, Head: analysis\n",
      "Word: new, Deprel: amod, Head: analysis\n",
      "Word: analysis, Deprel: nsubj, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: developed\n",
      "Word: 32, Deprel: nsubj, Head: developed\n",
      "Word: of, Deprel: case, Head: participants\n",
      "Word: the, Deprel: det, Head: participants\n",
      "Word: 16,608, Deprel: nummod, Head: participants\n",
      "Word: participants, Deprel: nmod, Head: 32\n",
      "Word: developed, Deprel: ccomp, Head: found\n",
      "Word: ovarian, Deprel: amod, Head: cancer\n",
      "Word: cancer, Deprel: obj, Head: developed\n",
      "Word: during, Deprel: case, Head: years\n",
      "Word: about, Deprel: advmod, Head: 5\n",
      "Word: 5, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl, Head: developed\n",
      "Word: of, Deprel: case, Head: follow-up\n",
      "Word: follow-up, Deprel: nmod, Head: years\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new analysis found that 32 of 16,608 participants developed ovarian cancer in about 5 1/2 years of follow-up including 20 women taking hormones'\n",
      "Word: The, Deprel: det, Head: analysis\n",
      "Word: new, Deprel: amod, Head: analysis\n",
      "Word: analysis, Deprel: nsubj, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: developed\n",
      "Word: 32, Deprel: nsubj, Head: developed\n",
      "Word: of, Deprel: case, Head: participants\n",
      "Word: 16,608, Deprel: nummod, Head: participants\n",
      "Word: participants, Deprel: nmod, Head: 32\n",
      "Word: developed, Deprel: ccomp, Head: found\n",
      "Word: ovarian, Deprel: amod, Head: cancer\n",
      "Word: cancer, Deprel: obj, Head: developed\n",
      "Word: in, Deprel: case, Head: years\n",
      "Word: about, Deprel: advmod, Head: 5\n",
      "Word: 5, Deprel: nummod, Head: years\n",
      "Word: 1/2, Deprel: compound, Head: 5\n",
      "Word: years, Deprel: obl, Head: developed\n",
      "Word: of, Deprel: case, Head: follow-up\n",
      "Word: follow-up, Deprel: nmod, Head: years\n",
      "Word: including, Deprel: case, Head: women\n",
      "Word: 20, Deprel: nummod, Head: women\n",
      "Word: women, Deprel: nmod, Head: years\n",
      "Word: taking, Deprel: acl, Head: women\n",
      "Word: hormones, Deprel: obj, Head: taking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'They reported symptoms of fever headache rash and muscle aches'\n",
      "Word: They, Deprel: nsubj, Head: reported\n",
      "Word: reported, Deprel: root, Head: ROOT\n",
      "Word: symptoms, Deprel: obj, Head: reported\n",
      "Word: of, Deprel: case, Head: rash\n",
      "Word: fever, Deprel: compound, Head: headache\n",
      "Word: headache, Deprel: compound, Head: rash\n",
      "Word: rash, Deprel: nmod, Head: symptoms\n",
      "Word: and, Deprel: cc, Head: aches\n",
      "Word: muscle, Deprel: compound, Head: aches\n",
      "Word: aches, Deprel: conj, Head: rash\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Symptoms include a stiff neck fever headache and sensitivity to light'\n",
      "Word: Symptoms, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: headache\n",
      "Word: stiff, Deprel: amod, Head: headache\n",
      "Word: neck, Deprel: compound, Head: fever\n",
      "Word: fever, Deprel: compound, Head: headache\n",
      "Word: headache, Deprel: obj, Head: include\n",
      "Word: and, Deprel: cc, Head: sensitivity\n",
      "Word: sensitivity, Deprel: conj, Head: headache\n",
      "Word: to, Deprel: case, Head: light\n",
      "Word: light, Deprel: nmod, Head: sensitivity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We ve become like total strangers Klein quotes him as saying'\n",
      "Word: We, Deprel: nsubj, Head: become\n",
      "Word: ve, Deprel: aux, Head: become\n",
      "Word: become, Deprel: root, Head: ROOT\n",
      "Word: like, Deprel: case, Head: strangers\n",
      "Word: total, Deprel: amod, Head: strangers\n",
      "Word: strangers, Deprel: obl, Head: become\n",
      "Word: Klein, Deprel: nsubj, Head: quotes\n",
      "Word: quotes, Deprel: acl:relcl, Head: strangers\n",
      "Word: him, Deprel: obj, Head: quotes\n",
      "Word: as, Deprel: mark, Head: saying\n",
      "Word: saying, Deprel: advcl, Head: quotes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We ve become like total strangers John told a pal two days before his death'\n",
      "Word: We, Deprel: nsubj, Head: become\n",
      "Word: ve, Deprel: aux, Head: become\n",
      "Word: become, Deprel: root, Head: ROOT\n",
      "Word: like, Deprel: case, Head: strangers\n",
      "Word: total, Deprel: amod, Head: strangers\n",
      "Word: strangers, Deprel: obl, Head: become\n",
      "Word: John, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: acl:relcl, Head: strangers\n",
      "Word: a, Deprel: det, Head: pal\n",
      "Word: pal, Deprel: obj, Head: told\n",
      "Word: two, Deprel: nummod, Head: days\n",
      "Word: days, Deprel: nmod:npmod, Head: death\n",
      "Word: before, Deprel: case, Head: death\n",
      "Word: his, Deprel: nmod:poss, Head: death\n",
      "Word: death, Deprel: obl, Head: told\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Davey graduated Saturday from Northwest College which is affiliated with the Assemblies of God with a bachelor of arts degree in religion and philosophy'\n",
      "Word: Davey, Deprel: nsubj, Head: graduated\n",
      "Word: graduated, Deprel: root, Head: ROOT\n",
      "Word: Saturday, Deprel: obl:tmod, Head: graduated\n",
      "Word: from, Deprel: case, Head: College\n",
      "Word: Northwest, Deprel: compound, Head: College\n",
      "Word: College, Deprel: obl, Head: graduated\n",
      "Word: which, Deprel: nsubj:pass, Head: affiliated\n",
      "Word: is, Deprel: aux:pass, Head: affiliated\n",
      "Word: affiliated, Deprel: acl:relcl, Head: College\n",
      "Word: with, Deprel: case, Head: Assemblies\n",
      "Word: the, Deprel: det, Head: Assemblies\n",
      "Word: Assemblies, Deprel: obl, Head: affiliated\n",
      "Word: of, Deprel: case, Head: God\n",
      "Word: God, Deprel: nmod, Head: Assemblies\n",
      "Word: with, Deprel: case, Head: degree\n",
      "Word: a, Deprel: det, Head: degree\n",
      "Word: bachelor, Deprel: compound, Head: degree\n",
      "Word: of, Deprel: case, Head: arts\n",
      "Word: arts, Deprel: nmod, Head: bachelor\n",
      "Word: degree, Deprel: obl, Head: affiliated\n",
      "Word: in, Deprel: case, Head: religion\n",
      "Word: religion, Deprel: nmod, Head: degree\n",
      "Word: and, Deprel: cc, Head: philosophy\n",
      "Word: philosophy, Deprel: conj, Head: religion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Davey started attending Northwest College which is affiliated with the Assemblies of God in 1999 with plans to become a minister'\n",
      "Word: Davey, Deprel: nsubj, Head: started\n",
      "Word: started, Deprel: root, Head: ROOT\n",
      "Word: attending, Deprel: xcomp, Head: started\n",
      "Word: Northwest, Deprel: compound, Head: College\n",
      "Word: College, Deprel: obj, Head: attending\n",
      "Word: which, Deprel: nsubj:pass, Head: affiliated\n",
      "Word: is, Deprel: aux:pass, Head: affiliated\n",
      "Word: affiliated, Deprel: acl:relcl, Head: College\n",
      "Word: with, Deprel: case, Head: Assemblies\n",
      "Word: the, Deprel: det, Head: Assemblies\n",
      "Word: Assemblies, Deprel: obl, Head: affiliated\n",
      "Word: of, Deprel: case, Head: God\n",
      "Word: God, Deprel: nmod, Head: Assemblies\n",
      "Word: in, Deprel: case, Head: 1999\n",
      "Word: 1999, Deprel: obl, Head: affiliated\n",
      "Word: with, Deprel: case, Head: plans\n",
      "Word: plans, Deprel: obl, Head: affiliated\n",
      "Word: to, Deprel: mark, Head: become\n",
      "Word: become, Deprel: acl, Head: plans\n",
      "Word: a, Deprel: det, Head: minister\n",
      "Word: minister, Deprel: xcomp, Head: become\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Veteran stage and screen actor Hume Cronyn died of cancer Sunday'\n",
      "Word: Veteran, Deprel: amod, Head: stage\n",
      "Word: stage, Deprel: nsubj, Head: died\n",
      "Word: and, Deprel: cc, Head: actor\n",
      "Word: screen, Deprel: compound, Head: actor\n",
      "Word: actor, Deprel: conj, Head: stage\n",
      "Word: Hume, Deprel: appos, Head: actor\n",
      "Word: Cronyn, Deprel: flat, Head: Hume\n",
      "Word: died, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: cancer\n",
      "Word: cancer, Deprel: obl, Head: died\n",
      "Word: Sunday, Deprel: obl:tmod, Head: died\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Character actor Hume Cronyn 91 died Sunday at his home in Connecticut'\n",
      "Word: Character, Deprel: compound, Head: actor\n",
      "Word: actor, Deprel: nsubj, Head: died\n",
      "Word: Hume, Deprel: flat, Head: actor\n",
      "Word: Cronyn, Deprel: flat, Head: actor\n",
      "Word: 91, Deprel: nummod, Head: actor\n",
      "Word: died, Deprel: root, Head: ROOT\n",
      "Word: Sunday, Deprel: obl:tmod, Head: died\n",
      "Word: at, Deprel: case, Head: home\n",
      "Word: his, Deprel: nmod:poss, Head: home\n",
      "Word: home, Deprel: obl, Head: died\n",
      "Word: in, Deprel: case, Head: Connecticut\n",
      "Word: Connecticut, Deprel: nmod, Head: home\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Scrimshaw Supervisor Best Minister and Ten Most Wanted are expected to complete the Belmont field'\n",
      "Word: Scrimshaw, Deprel: compound, Head: Supervisor\n",
      "Word: Supervisor, Deprel: compound, Head: Minister\n",
      "Word: Best, Deprel: amod, Head: Minister\n",
      "Word: Minister, Deprel: nsubj:pass, Head: expected\n",
      "Word: and, Deprel: cc, Head: Wanted\n",
      "Word: Ten, Deprel: compound, Head: Wanted\n",
      "Word: Most, Deprel: advmod, Head: Wanted\n",
      "Word: Wanted, Deprel: conj, Head: Minister\n",
      "Word: are, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: complete\n",
      "Word: complete, Deprel: xcomp, Head: expected\n",
      "Word: the, Deprel: det, Head: field\n",
      "Word: Belmont, Deprel: compound, Head: field\n",
      "Word: field, Deprel: obj, Head: complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Best Minister Scrimshaw and Ten Most Wanted all had workouts on Monday morning'\n",
      "Word: Best, Deprel: amod, Head: Minister\n",
      "Word: Minister, Deprel: compound, Head: Scrimshaw\n",
      "Word: Scrimshaw, Deprel: nsubj, Head: had\n",
      "Word: and, Deprel: cc, Head: Wanted\n",
      "Word: Ten, Deprel: compound, Head: Wanted\n",
      "Word: Most, Deprel: advmod, Head: Wanted\n",
      "Word: Wanted, Deprel: conj, Head: Scrimshaw\n",
      "Word: all, Deprel: advmod, Head: Wanted\n",
      "Word: had, Deprel: root, Head: ROOT\n",
      "Word: workouts, Deprel: obj, Head: had\n",
      "Word: on, Deprel: case, Head: morning\n",
      "Word: Monday, Deprel: compound, Head: morning\n",
      "Word: morning, Deprel: obl, Head: had\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index IXIC fell 23.54 points or 1.42 percent to 1,630.08'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-laced, Deprel: amod, Head: IXIC\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: 23.54, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: fell\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.42, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,630.08\n",
      "Word: 1,630.08, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index SPX gave up 11.91 points or 1.19 percent at 986.60'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broader, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: amod, Head: s\n",
      "Word: s, Deprel: compound, Head: SPX\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: gave\n",
      "Word: gave, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: gave\n",
      "Word: 11.91, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: gave\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.19, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 986.60\n",
      "Word: 986.60, Deprel: obl, Head: gave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It was a final test before delivering the missile to the armed forces'\n",
      "Word: It, Deprel: nsubj, Head: test\n",
      "Word: was, Deprel: cop, Head: test\n",
      "Word: a, Deprel: det, Head: test\n",
      "Word: final, Deprel: amod, Head: test\n",
      "Word: test, Deprel: root, Head: ROOT\n",
      "Word: before, Deprel: mark, Head: delivering\n",
      "Word: delivering, Deprel: acl, Head: test\n",
      "Word: the, Deprel: det, Head: missile\n",
      "Word: missile, Deprel: obj, Head: delivering\n",
      "Word: to, Deprel: case, Head: forces\n",
      "Word: the, Deprel: det, Head: forces\n",
      "Word: armed, Deprel: amod, Head: forces\n",
      "Word: forces, Deprel: obl, Head: delivering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'State radio said it was the last test before the missile was delivered to the armed forces'\n",
      "Word: State, Deprel: compound, Head: radio\n",
      "Word: radio, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: test\n",
      "Word: was, Deprel: cop, Head: test\n",
      "Word: the, Deprel: det, Head: test\n",
      "Word: last, Deprel: amod, Head: test\n",
      "Word: test, Deprel: ccomp, Head: said\n",
      "Word: before, Deprel: mark, Head: delivered\n",
      "Word: the, Deprel: det, Head: missile\n",
      "Word: missile, Deprel: nsubj:pass, Head: delivered\n",
      "Word: was, Deprel: aux:pass, Head: delivered\n",
      "Word: delivered, Deprel: advcl, Head: test\n",
      "Word: to, Deprel: case, Head: forces\n",
      "Word: the, Deprel: det, Head: forces\n",
      "Word: armed, Deprel: amod, Head: forces\n",
      "Word: forces, Deprel: obl, Head: delivered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Your withdrawal from our country is inevitable whether it happens today or tomorrow and tomorrow will come soon'\n",
      "Word: Your, Deprel: nmod:poss, Head: withdrawal\n",
      "Word: withdrawal, Deprel: nsubj, Head: inevitable\n",
      "Word: from, Deprel: case, Head: country\n",
      "Word: our, Deprel: nmod:poss, Head: country\n",
      "Word: country, Deprel: nmod, Head: withdrawal\n",
      "Word: is, Deprel: cop, Head: inevitable\n",
      "Word: inevitable, Deprel: root, Head: ROOT\n",
      "Word: whether, Deprel: mark, Head: happens\n",
      "Word: it, Deprel: nsubj, Head: happens\n",
      "Word: happens, Deprel: ccomp, Head: inevitable\n",
      "Word: today, Deprel: obl:tmod, Head: happens\n",
      "Word: or, Deprel: cc, Head: tomorrow\n",
      "Word: tomorrow, Deprel: conj, Head: today\n",
      "Word: and, Deprel: cc, Head: come\n",
      "Word: tomorrow, Deprel: nsubj, Head: come\n",
      "Word: will, Deprel: aux, Head: come\n",
      "Word: come, Deprel: conj, Head: inevitable\n",
      "Word: soon, Deprel: advmod, Head: come\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Your withdrawal from our country is inevitable whether it happens today or tomorrow added the voice which signed off giving the date as mid-September'\n",
      "Word: Your, Deprel: nmod:poss, Head: withdrawal\n",
      "Word: withdrawal, Deprel: nsubj, Head: inevitable\n",
      "Word: from, Deprel: case, Head: country\n",
      "Word: our, Deprel: nmod:poss, Head: country\n",
      "Word: country, Deprel: nmod, Head: withdrawal\n",
      "Word: is, Deprel: cop, Head: inevitable\n",
      "Word: inevitable, Deprel: root, Head: ROOT\n",
      "Word: whether, Deprel: mark, Head: happens\n",
      "Word: it, Deprel: nsubj, Head: happens\n",
      "Word: happens, Deprel: ccomp, Head: inevitable\n",
      "Word: today, Deprel: obl:tmod, Head: happens\n",
      "Word: or, Deprel: cc, Head: added\n",
      "Word: tomorrow, Deprel: obl:tmod, Head: added\n",
      "Word: added, Deprel: conj, Head: inevitable\n",
      "Word: the, Deprel: det, Head: voice\n",
      "Word: voice, Deprel: obj, Head: added\n",
      "Word: which, Deprel: nsubj, Head: signed\n",
      "Word: signed, Deprel: acl:relcl, Head: voice\n",
      "Word: off, Deprel: compound:prt, Head: signed\n",
      "Word: giving, Deprel: advcl, Head: signed\n",
      "Word: the, Deprel: det, Head: date\n",
      "Word: date, Deprel: obj, Head: giving\n",
      "Word: as, Deprel: case, Head: mid-September\n",
      "Word: mid-September, Deprel: obl, Head: giving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Deirdre Hisler Government Canyon s manager said the state has long had its eye on this piece of property and is eager to complete the deal to obtain it'\n",
      "Word: Deirdre, Deprel: compound, Head: Canyon\n",
      "Word: Hisler, Deprel: flat, Head: Deirdre\n",
      "Word: Government, Deprel: compound, Head: Canyon\n",
      "Word: Canyon, Deprel: nmod:poss, Head: manager\n",
      "Word: s, Deprel: case, Head: Canyon\n",
      "Word: manager, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: state, Deprel: nsubj, Head: had\n",
      "Word: has, Deprel: aux, Head: had\n",
      "Word: long, Deprel: advmod, Head: had\n",
      "Word: had, Deprel: ccomp, Head: said\n",
      "Word: its, Deprel: nmod:poss, Head: eye\n",
      "Word: eye, Deprel: obj, Head: had\n",
      "Word: on, Deprel: case, Head: piece\n",
      "Word: this, Deprel: det, Head: piece\n",
      "Word: piece, Deprel: obl, Head: had\n",
      "Word: of, Deprel: case, Head: property\n",
      "Word: property, Deprel: nmod, Head: piece\n",
      "Word: and, Deprel: cc, Head: eager\n",
      "Word: is, Deprel: cop, Head: eager\n",
      "Word: eager, Deprel: conj, Head: had\n",
      "Word: to, Deprel: mark, Head: complete\n",
      "Word: complete, Deprel: xcomp, Head: eager\n",
      "Word: the, Deprel: det, Head: deal\n",
      "Word: deal, Deprel: obj, Head: complete\n",
      "Word: to, Deprel: mark, Head: obtain\n",
      "Word: obtain, Deprel: advcl, Head: complete\n",
      "Word: it, Deprel: obj, Head: obtain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Deirdre Hisler Government Canyon s manager said the state long has coveted this piece of property and is eager to complete the deal'\n",
      "Word: Deirdre, Deprel: compound, Head: Canyon\n",
      "Word: Hisler, Deprel: flat, Head: Deirdre\n",
      "Word: Government, Deprel: compound, Head: Canyon\n",
      "Word: Canyon, Deprel: nmod:poss, Head: manager\n",
      "Word: s, Deprel: case, Head: Canyon\n",
      "Word: manager, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: state, Deprel: nsubj, Head: coveted\n",
      "Word: long, Deprel: advmod, Head: coveted\n",
      "Word: has, Deprel: aux, Head: coveted\n",
      "Word: coveted, Deprel: ccomp, Head: said\n",
      "Word: this, Deprel: det, Head: piece\n",
      "Word: piece, Deprel: obj, Head: coveted\n",
      "Word: of, Deprel: case, Head: property\n",
      "Word: property, Deprel: nmod, Head: piece\n",
      "Word: and, Deprel: cc, Head: eager\n",
      "Word: is, Deprel: cop, Head: eager\n",
      "Word: eager, Deprel: conj, Head: coveted\n",
      "Word: to, Deprel: mark, Head: complete\n",
      "Word: complete, Deprel: xcomp, Head: eager\n",
      "Word: the, Deprel: det, Head: deal\n",
      "Word: deal, Deprel: obj, Head: complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'According to a news release sent by the Terry Schindler-Schiavo Foundation Florida Speaker Johnnie Byrd will introduce Terri s Bill during the special session Monday'\n",
      "Word: According, Deprel: case, Head: release\n",
      "Word: to, Deprel: fixed, Head: According\n",
      "Word: a, Deprel: det, Head: release\n",
      "Word: news, Deprel: compound, Head: release\n",
      "Word: release, Deprel: obl, Head: introduce\n",
      "Word: sent, Deprel: acl, Head: release\n",
      "Word: by, Deprel: case, Head: Foundation\n",
      "Word: the, Deprel: det, Head: Foundation\n",
      "Word: Terry, Deprel: compound, Head: Foundation\n",
      "Word: Schindler-Schiavo, Deprel: flat, Head: Terry\n",
      "Word: Foundation, Deprel: obl, Head: sent\n",
      "Word: Florida, Deprel: compound, Head: Speaker\n",
      "Word: Speaker, Deprel: appos, Head: Foundation\n",
      "Word: Johnnie, Deprel: flat, Head: Speaker\n",
      "Word: Byrd, Deprel: flat, Head: Speaker\n",
      "Word: will, Deprel: aux, Head: introduce\n",
      "Word: introduce, Deprel: root, Head: ROOT\n",
      "Word: Terri, Deprel: nmod:poss, Head: Bill\n",
      "Word: s, Deprel: case, Head: Terri\n",
      "Word: Bill, Deprel: obj, Head: introduce\n",
      "Word: during, Deprel: case, Head: session\n",
      "Word: the, Deprel: det, Head: session\n",
      "Word: special, Deprel: amod, Head: session\n",
      "Word: session, Deprel: obl, Head: introduce\n",
      "Word: Monday, Deprel: nmod:npmod, Head: session\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Florida s Speaker of the House Johnnie Byrd is expected to introduce Terri s Bill during a one-day special session of the state legislature being held today in Tallahassee'\n",
      "Word: Florida, Deprel: nmod:poss, Head: Speaker\n",
      "Word: s, Deprel: case, Head: Florida\n",
      "Word: Speaker, Deprel: nsubj:pass, Head: expected\n",
      "Word: of, Deprel: case, Head: House\n",
      "Word: the, Deprel: det, Head: House\n",
      "Word: House, Deprel: nmod, Head: Speaker\n",
      "Word: Johnnie, Deprel: appos, Head: Speaker\n",
      "Word: Byrd, Deprel: flat, Head: Johnnie\n",
      "Word: is, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: introduce\n",
      "Word: introduce, Deprel: xcomp, Head: expected\n",
      "Word: Terri, Deprel: nmod:poss, Head: Bill\n",
      "Word: s, Deprel: case, Head: Terri\n",
      "Word: Bill, Deprel: obj, Head: introduce\n",
      "Word: during, Deprel: case, Head: session\n",
      "Word: a, Deprel: det, Head: session\n",
      "Word: one-day, Deprel: amod, Head: session\n",
      "Word: special, Deprel: amod, Head: session\n",
      "Word: session, Deprel: obl, Head: introduce\n",
      "Word: of, Deprel: case, Head: legislature\n",
      "Word: the, Deprel: det, Head: legislature\n",
      "Word: state, Deprel: compound, Head: legislature\n",
      "Word: legislature, Deprel: nmod, Head: session\n",
      "Word: being, Deprel: aux:pass, Head: held\n",
      "Word: held, Deprel: acl, Head: legislature\n",
      "Word: today, Deprel: obl:tmod, Head: held\n",
      "Word: in, Deprel: case, Head: Tallahassee\n",
      "Word: Tallahassee, Deprel: obl, Head: held\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Also businesses throughout Utah are volunteering to display Amber alerts on their signs'\n",
      "Word: Also, Deprel: advmod, Head: volunteering\n",
      "Word: businesses, Deprel: nsubj, Head: volunteering\n",
      "Word: throughout, Deprel: case, Head: Utah\n",
      "Word: Utah, Deprel: nmod, Head: businesses\n",
      "Word: are, Deprel: aux, Head: volunteering\n",
      "Word: volunteering, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: display\n",
      "Word: display, Deprel: xcomp, Head: volunteering\n",
      "Word: Amber, Deprel: compound, Head: alerts\n",
      "Word: alerts, Deprel: obj, Head: display\n",
      "Word: on, Deprel: case, Head: signs\n",
      "Word: their, Deprel: nmod:poss, Head: signs\n",
      "Word: signs, Deprel: obl, Head: display\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Other businesses are volunteering to put the alerts on their electronic signs and billboards'\n",
      "Word: Other, Deprel: amod, Head: businesses\n",
      "Word: businesses, Deprel: nsubj, Head: volunteering\n",
      "Word: are, Deprel: aux, Head: volunteering\n",
      "Word: volunteering, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: put\n",
      "Word: put, Deprel: advcl, Head: volunteering\n",
      "Word: the, Deprel: det, Head: alerts\n",
      "Word: alerts, Deprel: obj, Head: put\n",
      "Word: on, Deprel: case, Head: signs\n",
      "Word: their, Deprel: nmod:poss, Head: signs\n",
      "Word: electronic, Deprel: amod, Head: signs\n",
      "Word: signs, Deprel: obl, Head: put\n",
      "Word: and, Deprel: cc, Head: billboards\n",
      "Word: billboards, Deprel: conj, Head: signs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Thanks to the euro s rise against the Japanese currency the dollar was at 117.24 yen well above the overnight 10-month low of 116 yen'\n",
      "Word: Thanks, Deprel: obl:tmod, Head: yen\n",
      "Word: to, Deprel: case, Head: rise\n",
      "Word: the, Deprel: det, Head: euro\n",
      "Word: euro, Deprel: nmod:poss, Head: rise\n",
      "Word: s, Deprel: case, Head: euro\n",
      "Word: rise, Deprel: nmod, Head: Thanks\n",
      "Word: against, Deprel: case, Head: currency\n",
      "Word: the, Deprel: det, Head: currency\n",
      "Word: Japanese, Deprel: amod, Head: currency\n",
      "Word: currency, Deprel: nmod, Head: rise\n",
      "Word: the, Deprel: det, Head: dollar\n",
      "Word: dollar, Deprel: nsubj, Head: yen\n",
      "Word: was, Deprel: cop, Head: yen\n",
      "Word: at, Deprel: case, Head: yen\n",
      "Word: 117.24, Deprel: nummod, Head: yen\n",
      "Word: yen, Deprel: root, Head: ROOT\n",
      "Word: well, Deprel: advmod, Head: low\n",
      "Word: above, Deprel: case, Head: low\n",
      "Word: the, Deprel: det, Head: low\n",
      "Word: overnight, Deprel: amod, Head: low\n",
      "Word: 10-month, Deprel: amod, Head: low\n",
      "Word: low, Deprel: nmod, Head: yen\n",
      "Word: of, Deprel: case, Head: yen\n",
      "Word: 116, Deprel: nummod, Head: yen\n",
      "Word: yen, Deprel: nmod, Head: low\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The euro s rise against the yen and speculation of Japanese intervention helped the dollar firm to 117.25 yen well above a 10-month low of 116 yen hit on Thursday'\n",
      "Word: The, Deprel: det, Head: euro\n",
      "Word: euro, Deprel: nmod:poss, Head: rise\n",
      "Word: s, Deprel: case, Head: euro\n",
      "Word: rise, Deprel: nsubj, Head: helped\n",
      "Word: against, Deprel: case, Head: yen\n",
      "Word: the, Deprel: det, Head: yen\n",
      "Word: yen, Deprel: nmod, Head: rise\n",
      "Word: and, Deprel: cc, Head: speculation\n",
      "Word: speculation, Deprel: conj, Head: rise\n",
      "Word: of, Deprel: case, Head: intervention\n",
      "Word: Japanese, Deprel: amod, Head: intervention\n",
      "Word: intervention, Deprel: nmod, Head: speculation\n",
      "Word: helped, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: firm\n",
      "Word: dollar, Deprel: compound, Head: firm\n",
      "Word: firm, Deprel: obj, Head: helped\n",
      "Word: to, Deprel: case, Head: yen\n",
      "Word: 117.25, Deprel: nummod, Head: yen\n",
      "Word: yen, Deprel: obl, Head: helped\n",
      "Word: well, Deprel: advmod, Head: low\n",
      "Word: above, Deprel: case, Head: low\n",
      "Word: a, Deprel: det, Head: low\n",
      "Word: 10-month, Deprel: amod, Head: low\n",
      "Word: low, Deprel: obl, Head: helped\n",
      "Word: of, Deprel: case, Head: yen\n",
      "Word: 116, Deprel: nummod, Head: yen\n",
      "Word: yen, Deprel: nmod, Head: low\n",
      "Word: hit, Deprel: acl, Head: low\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: hit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Former South African Archbishop Desmond Tutu said Sunday he did not see what all the fuss was over appointing a gay bishop but urged homosexual clergy to remain celibate'\n",
      "Word: Former, Deprel: amod, Head: Archbishop\n",
      "Word: South, Deprel: compound, Head: African\n",
      "Word: African, Deprel: amod, Head: Archbishop\n",
      "Word: Archbishop, Deprel: nsubj, Head: said\n",
      "Word: Desmond, Deprel: flat, Head: Archbishop\n",
      "Word: Tutu, Deprel: flat, Head: Archbishop\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Sunday, Deprel: obl:tmod, Head: said\n",
      "Word: he, Deprel: nsubj, Head: see\n",
      "Word: did, Deprel: aux, Head: see\n",
      "Word: not, Deprel: advmod, Head: see\n",
      "Word: see, Deprel: ccomp, Head: said\n",
      "Word: what, Deprel: obj, Head: see\n",
      "Word: all, Deprel: det:predet, Head: fuss\n",
      "Word: the, Deprel: det, Head: fuss\n",
      "Word: fuss, Deprel: nsubj, Head: what\n",
      "Word: was, Deprel: cop, Head: what\n",
      "Word: over, Deprel: mark, Head: appointing\n",
      "Word: appointing, Deprel: advcl, Head: what\n",
      "Word: a, Deprel: det, Head: bishop\n",
      "Word: gay, Deprel: amod, Head: bishop\n",
      "Word: bishop, Deprel: obj, Head: appointing\n",
      "Word: but, Deprel: cc, Head: urged\n",
      "Word: urged, Deprel: conj, Head: see\n",
      "Word: homosexual, Deprel: amod, Head: clergy\n",
      "Word: clergy, Deprel: iobj, Head: urged\n",
      "Word: to, Deprel: mark, Head: remain\n",
      "Word: remain, Deprel: xcomp, Head: urged\n",
      "Word: celibate, Deprel: xcomp, Head: remain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'South Africa s Nobel laureate Archbishop Desmond Tutu says he does not understand all the fuss about appointing a gay bishop but he has urged homosexual clergy to remain celibate'\n",
      "Word: South, Deprel: compound, Head: Africa\n",
      "Word: Africa, Deprel: nmod:poss, Head: Archbishop\n",
      "Word: s, Deprel: case, Head: Africa\n",
      "Word: Nobel, Deprel: compound, Head: laureate\n",
      "Word: laureate, Deprel: compound, Head: Archbishop\n",
      "Word: Archbishop, Deprel: nsubj, Head: says\n",
      "Word: Desmond, Deprel: flat, Head: Archbishop\n",
      "Word: Tutu, Deprel: flat, Head: Archbishop\n",
      "Word: says, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: understand\n",
      "Word: does, Deprel: aux, Head: understand\n",
      "Word: not, Deprel: advmod, Head: understand\n",
      "Word: understand, Deprel: ccomp, Head: says\n",
      "Word: all, Deprel: det:predet, Head: fuss\n",
      "Word: the, Deprel: det, Head: fuss\n",
      "Word: fuss, Deprel: obj, Head: understand\n",
      "Word: about, Deprel: mark, Head: appointing\n",
      "Word: appointing, Deprel: acl, Head: fuss\n",
      "Word: a, Deprel: det, Head: bishop\n",
      "Word: gay, Deprel: amod, Head: bishop\n",
      "Word: bishop, Deprel: obj, Head: appointing\n",
      "Word: but, Deprel: cc, Head: urged\n",
      "Word: he, Deprel: nsubj, Head: urged\n",
      "Word: has, Deprel: aux, Head: urged\n",
      "Word: urged, Deprel: conj, Head: says\n",
      "Word: homosexual, Deprel: amod, Head: clergy\n",
      "Word: clergy, Deprel: iobj, Head: urged\n",
      "Word: to, Deprel: mark, Head: remain\n",
      "Word: remain, Deprel: xcomp, Head: urged\n",
      "Word: celibate, Deprel: xcomp, Head: remain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Russian stocks fell after the arrest last Saturday of Mikhail Khodorkovsky chief executive of Yukos Oil on charges of fraud and tax evasion'\n",
      "Word: Russian, Deprel: amod, Head: stocks\n",
      "Word: stocks, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: after, Deprel: case, Head: arrest\n",
      "Word: the, Deprel: det, Head: arrest\n",
      "Word: arrest, Deprel: obl, Head: fell\n",
      "Word: last, Deprel: amod, Head: Saturday\n",
      "Word: Saturday, Deprel: obl:tmod, Head: fell\n",
      "Word: of, Deprel: case, Head: executive\n",
      "Word: Mikhail, Deprel: compound, Head: executive\n",
      "Word: Khodorkovsky, Deprel: flat, Head: Mikhail\n",
      "Word: chief, Deprel: amod, Head: executive\n",
      "Word: executive, Deprel: nmod, Head: Saturday\n",
      "Word: of, Deprel: case, Head: Oil\n",
      "Word: Yukos, Deprel: compound, Head: Oil\n",
      "Word: Oil, Deprel: nmod, Head: executive\n",
      "Word: on, Deprel: case, Head: charges\n",
      "Word: charges, Deprel: obl, Head: fell\n",
      "Word: of, Deprel: case, Head: fraud\n",
      "Word: fraud, Deprel: nmod, Head: charges\n",
      "Word: and, Deprel: cc, Head: evasion\n",
      "Word: tax, Deprel: compound, Head: evasion\n",
      "Word: evasion, Deprel: conj, Head: fraud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The weekend arrest of Russia s richest man Mikhail Khodorkovsky chief executive of oil major YUKOS on charges of fraud and tax evasion unnerved financial markets'\n",
      "Word: The, Deprel: det, Head: arrest\n",
      "Word: weekend, Deprel: compound, Head: arrest\n",
      "Word: arrest, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: executive\n",
      "Word: Russia, Deprel: nmod:poss, Head: executive\n",
      "Word: s, Deprel: case, Head: Russia\n",
      "Word: richest, Deprel: amod, Head: man\n",
      "Word: man, Deprel: compound, Head: executive\n",
      "Word: Mikhail, Deprel: compound, Head: executive\n",
      "Word: Khodorkovsky, Deprel: flat, Head: Mikhail\n",
      "Word: chief, Deprel: amod, Head: executive\n",
      "Word: executive, Deprel: nmod, Head: arrest\n",
      "Word: of, Deprel: case, Head: YUKOS\n",
      "Word: oil, Deprel: compound, Head: YUKOS\n",
      "Word: major, Deprel: amod, Head: YUKOS\n",
      "Word: YUKOS, Deprel: nmod, Head: executive\n",
      "Word: on, Deprel: case, Head: charges\n",
      "Word: charges, Deprel: nmod, Head: arrest\n",
      "Word: of, Deprel: case, Head: fraud\n",
      "Word: fraud, Deprel: nmod, Head: charges\n",
      "Word: and, Deprel: cc, Head: evasion\n",
      "Word: tax, Deprel: compound, Head: evasion\n",
      "Word: evasion, Deprel: conj, Head: fraud\n",
      "Word: unnerved, Deprel: amod, Head: markets\n",
      "Word: financial, Deprel: amod, Head: markets\n",
      "Word: markets, Deprel: conj, Head: fraud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Reuters witnesses said many houses had been flattened and the city squares were packed with crying children and the homeless huddled in blankets to protect them from the cold'\n",
      "Word: Reuters, Deprel: compound, Head: witnesses\n",
      "Word: witnesses, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: many, Deprel: amod, Head: houses\n",
      "Word: houses, Deprel: nsubj:pass, Head: flattened\n",
      "Word: had, Deprel: aux, Head: flattened\n",
      "Word: been, Deprel: aux:pass, Head: flattened\n",
      "Word: flattened, Deprel: ccomp, Head: said\n",
      "Word: and, Deprel: cc, Head: packed\n",
      "Word: the, Deprel: det, Head: squares\n",
      "Word: city, Deprel: compound, Head: squares\n",
      "Word: squares, Deprel: nsubj:pass, Head: packed\n",
      "Word: were, Deprel: aux:pass, Head: packed\n",
      "Word: packed, Deprel: conj, Head: flattened\n",
      "Word: with, Deprel: case, Head: children\n",
      "Word: crying, Deprel: amod, Head: children\n",
      "Word: children, Deprel: obl, Head: packed\n",
      "Word: and, Deprel: cc, Head: homeless\n",
      "Word: the, Deprel: det, Head: homeless\n",
      "Word: homeless, Deprel: conj, Head: children\n",
      "Word: huddled, Deprel: acl, Head: homeless\n",
      "Word: in, Deprel: case, Head: blankets\n",
      "Word: blankets, Deprel: obl, Head: huddled\n",
      "Word: to, Deprel: mark, Head: protect\n",
      "Word: protect, Deprel: advcl, Head: huddled\n",
      "Word: them, Deprel: obj, Head: protect\n",
      "Word: from, Deprel: case, Head: cold\n",
      "Word: the, Deprel: det, Head: cold\n",
      "Word: cold, Deprel: obl, Head: protect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Reuters witnesses said public squares were packed with crying children and people left homeless huddled in blankets to protect them from the cold'\n",
      "Word: Reuters, Deprel: compound, Head: witnesses\n",
      "Word: witnesses, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: public, Deprel: amod, Head: squares\n",
      "Word: squares, Deprel: nsubj:pass, Head: packed\n",
      "Word: were, Deprel: aux:pass, Head: packed\n",
      "Word: packed, Deprel: ccomp, Head: said\n",
      "Word: with, Deprel: case, Head: children\n",
      "Word: crying, Deprel: amod, Head: children\n",
      "Word: children, Deprel: obl, Head: packed\n",
      "Word: and, Deprel: cc, Head: people\n",
      "Word: people, Deprel: conj, Head: children\n",
      "Word: left, Deprel: acl, Head: people\n",
      "Word: homeless, Deprel: xcomp, Head: left\n",
      "Word: huddled, Deprel: advcl, Head: left\n",
      "Word: in, Deprel: case, Head: blankets\n",
      "Word: blankets, Deprel: obl, Head: huddled\n",
      "Word: to, Deprel: mark, Head: protect\n",
      "Word: protect, Deprel: advcl, Head: huddled\n",
      "Word: them, Deprel: obj, Head: protect\n",
      "Word: from, Deprel: case, Head: cold\n",
      "Word: the, Deprel: det, Head: cold\n",
      "Word: cold, Deprel: obl, Head: protect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'For the year it expects sales of 94 million and a profit of 26 cents a share from continuing operations'\n",
      "Word: For, Deprel: case, Head: year\n",
      "Word: the, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl, Head: expects\n",
      "Word: it, Deprel: nsubj, Head: expects\n",
      "Word: expects, Deprel: root, Head: ROOT\n",
      "Word: sales, Deprel: obj, Head: expects\n",
      "Word: of, Deprel: case, Head: million\n",
      "Word: 94, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nmod, Head: sales\n",
      "Word: and, Deprel: cc, Head: profit\n",
      "Word: a, Deprel: det, Head: profit\n",
      "Word: profit, Deprel: conj, Head: million\n",
      "Word: of, Deprel: case, Head: cents\n",
      "Word: 26, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: nmod, Head: profit\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:tmod, Head: cents\n",
      "Word: from, Deprel: case, Head: operations\n",
      "Word: continuing, Deprel: compound, Head: operations\n",
      "Word: operations, Deprel: nmod, Head: cents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This is an increase from the 22.5 million and 5 cents a share previously forecast'\n",
      "Word: This, Deprel: nsubj, Head: increase\n",
      "Word: is, Deprel: cop, Head: increase\n",
      "Word: an, Deprel: det, Head: increase\n",
      "Word: increase, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: million\n",
      "Word: the, Deprel: det, Head: million\n",
      "Word: 22.5, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nmod, Head: increase\n",
      "Word: and, Deprel: cc, Head: cents\n",
      "Word: 5, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: conj, Head: million\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:tmod, Head: cents\n",
      "Word: previously, Deprel: advmod, Head: forecast\n",
      "Word: forecast, Deprel: acl, Head: million\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In September Hewlett-Packard signed a development and marketing deal with the company'\n",
      "Word: In, Deprel: case, Head: September\n",
      "Word: September, Deprel: obl, Head: signed\n",
      "Word: Hewlett-Packard, Deprel: nsubj, Head: signed\n",
      "Word: signed, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: deal\n",
      "Word: development, Deprel: compound, Head: deal\n",
      "Word: and, Deprel: cc, Head: marketing\n",
      "Word: marketing, Deprel: conj, Head: development\n",
      "Word: deal, Deprel: obj, Head: signed\n",
      "Word: with, Deprel: case, Head: company\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nmod, Head: deal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Four months later it signed a joint marketing agreement with Hewlett-Packard Co'\n",
      "Word: Four, Deprel: nummod, Head: months\n",
      "Word: months, Deprel: obl:npmod, Head: later\n",
      "Word: later, Deprel: advmod, Head: signed\n",
      "Word: it, Deprel: nsubj, Head: signed\n",
      "Word: signed, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: agreement\n",
      "Word: joint, Deprel: amod, Head: agreement\n",
      "Word: marketing, Deprel: compound, Head: agreement\n",
      "Word: agreement, Deprel: obj, Head: signed\n",
      "Word: with, Deprel: case, Head: Co\n",
      "Word: Hewlett-Packard, Deprel: compound, Head: Co\n",
      "Word: Co, Deprel: nmod, Head: agreement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Consumers would still have to get a descrambling security card from their cable operator to plug into the set'\n",
      "Word: Consumers, Deprel: nsubj, Head: have\n",
      "Word: would, Deprel: aux, Head: have\n",
      "Word: still, Deprel: advmod, Head: have\n",
      "Word: have, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: get\n",
      "Word: get, Deprel: xcomp, Head: have\n",
      "Word: a, Deprel: det, Head: card\n",
      "Word: descrambling, Deprel: amod, Head: card\n",
      "Word: security, Deprel: compound, Head: card\n",
      "Word: card, Deprel: obj, Head: get\n",
      "Word: from, Deprel: case, Head: operator\n",
      "Word: their, Deprel: nmod:poss, Head: operator\n",
      "Word: cable, Deprel: compound, Head: operator\n",
      "Word: operator, Deprel: obl, Head: get\n",
      "Word: to, Deprel: mark, Head: plug\n",
      "Word: plug, Deprel: advcl, Head: get\n",
      "Word: into, Deprel: case, Head: set\n",
      "Word: the, Deprel: det, Head: set\n",
      "Word: set, Deprel: obl, Head: plug\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'To watch pay television consumers would insert into the set a security card provided by their cable service'\n",
      "Word: To, Deprel: mark, Head: watch\n",
      "Word: watch, Deprel: advcl, Head: insert\n",
      "Word: pay, Deprel: compound, Head: television\n",
      "Word: television, Deprel: compound, Head: consumers\n",
      "Word: consumers, Deprel: nsubj, Head: insert\n",
      "Word: would, Deprel: aux, Head: insert\n",
      "Word: insert, Deprel: root, Head: ROOT\n",
      "Word: into, Deprel: mark, Head: set\n",
      "Word: the, Deprel: det, Head: set\n",
      "Word: set, Deprel: obl, Head: insert\n",
      "Word: a, Deprel: det, Head: card\n",
      "Word: security, Deprel: compound, Head: card\n",
      "Word: card, Deprel: obj, Head: insert\n",
      "Word: provided, Deprel: acl, Head: card\n",
      "Word: by, Deprel: case, Head: service\n",
      "Word: their, Deprel: nmod:poss, Head: service\n",
      "Word: cable, Deprel: compound, Head: service\n",
      "Word: service, Deprel: obl:agent, Head: provided\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Friday the Concorde started up around sunrise and seemed to launch itself straight out of the rising sun'\n",
      "Word: On, Deprel: case, Head: Friday\n",
      "Word: Friday, Deprel: obl, Head: started\n",
      "Word: the, Deprel: det, Head: Concorde\n",
      "Word: Concorde, Deprel: nsubj, Head: started\n",
      "Word: started, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: started\n",
      "Word: around, Deprel: case, Head: sunrise\n",
      "Word: sunrise, Deprel: obl, Head: started\n",
      "Word: and, Deprel: cc, Head: seemed\n",
      "Word: seemed, Deprel: conj, Head: started\n",
      "Word: to, Deprel: mark, Head: launch\n",
      "Word: launch, Deprel: xcomp, Head: seemed\n",
      "Word: itself, Deprel: obj, Head: launch\n",
      "Word: straight, Deprel: advmod, Head: sun\n",
      "Word: out, Deprel: case, Head: sun\n",
      "Word: of, Deprel: case, Head: sun\n",
      "Word: the, Deprel: det, Head: sun\n",
      "Word: rising, Deprel: amod, Head: sun\n",
      "Word: sun, Deprel: obl, Head: launch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Yesterday the Concorde seemed to launch itself straight out of the rising sun'\n",
      "Word: Yesterday, Deprel: obl:tmod, Head: seemed\n",
      "Word: the, Deprel: det, Head: Concorde\n",
      "Word: Concorde, Deprel: nsubj, Head: seemed\n",
      "Word: seemed, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: launch\n",
      "Word: launch, Deprel: xcomp, Head: seemed\n",
      "Word: itself, Deprel: obj, Head: launch\n",
      "Word: straight, Deprel: advmod, Head: sun\n",
      "Word: out, Deprel: case, Head: sun\n",
      "Word: of, Deprel: case, Head: sun\n",
      "Word: the, Deprel: det, Head: sun\n",
      "Word: rising, Deprel: amod, Head: sun\n",
      "Word: sun, Deprel: obl, Head: launch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A Stage 1 episode is declared when ozone levels reach 0.20 parts per million'\n",
      "Word: A, Deprel: det, Head: episode\n",
      "Word: Stage, Deprel: compound, Head: episode\n",
      "Word: 1, Deprel: nummod, Head: Stage\n",
      "Word: episode, Deprel: nsubj:pass, Head: declared\n",
      "Word: is, Deprel: aux:pass, Head: declared\n",
      "Word: declared, Deprel: root, Head: ROOT\n",
      "Word: when, Deprel: advmod, Head: reach\n",
      "Word: ozone, Deprel: compound, Head: levels\n",
      "Word: levels, Deprel: nsubj, Head: reach\n",
      "Word: reach, Deprel: advcl, Head: declared\n",
      "Word: 0.20, Deprel: nummod, Head: parts\n",
      "Word: parts, Deprel: obj, Head: reach\n",
      "Word: per, Deprel: case, Head: million\n",
      "Word: million, Deprel: nmod, Head: parts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The federal standard for ozone is 0.12 parts per million'\n",
      "Word: The, Deprel: det, Head: standard\n",
      "Word: federal, Deprel: amod, Head: standard\n",
      "Word: standard, Deprel: nsubj, Head: parts\n",
      "Word: for, Deprel: case, Head: ozone\n",
      "Word: ozone, Deprel: nmod, Head: standard\n",
      "Word: is, Deprel: cop, Head: parts\n",
      "Word: 0.12, Deprel: nummod, Head: parts\n",
      "Word: parts, Deprel: root, Head: ROOT\n",
      "Word: per, Deprel: case, Head: million\n",
      "Word: million, Deprel: nmod, Head: parts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'After Hughes refused to rehire Hernandez he complained to the Equal Employment Opportunity Commission'\n",
      "Word: After, Deprel: mark, Head: refused\n",
      "Word: Hughes, Deprel: nsubj, Head: refused\n",
      "Word: refused, Deprel: advcl, Head: complained\n",
      "Word: to, Deprel: mark, Head: rehire\n",
      "Word: rehire, Deprel: xcomp, Head: refused\n",
      "Word: Hernandez, Deprel: obj, Head: rehire\n",
      "Word: he, Deprel: nsubj, Head: complained\n",
      "Word: complained, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Commission\n",
      "Word: the, Deprel: det, Head: Commission\n",
      "Word: Equal, Deprel: amod, Head: Employment\n",
      "Word: Employment, Deprel: compound, Head: Opportunity\n",
      "Word: Opportunity, Deprel: compound, Head: Commission\n",
      "Word: Commission, Deprel: obl, Head: complained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hernandez filed an Equal Employment Opportunity Commission complaint and sued'\n",
      "Word: Hernandez, Deprel: nsubj, Head: filed\n",
      "Word: filed, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: complaint\n",
      "Word: Equal, Deprel: amod, Head: Employment\n",
      "Word: Employment, Deprel: compound, Head: Opportunity\n",
      "Word: Opportunity, Deprel: compound, Head: Commission\n",
      "Word: Commission, Deprel: compound, Head: complaint\n",
      "Word: complaint, Deprel: obj, Head: filed\n",
      "Word: and, Deprel: cc, Head: sued\n",
      "Word: sued, Deprel: conj, Head: filed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The three grocery chains were relying on store managers and replacement workers to keep their stores open'\n",
      "Word: The, Deprel: det, Head: chains\n",
      "Word: three, Deprel: nummod, Head: chains\n",
      "Word: grocery, Deprel: compound, Head: chains\n",
      "Word: chains, Deprel: nsubj, Head: relying\n",
      "Word: were, Deprel: aux, Head: relying\n",
      "Word: relying, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: managers\n",
      "Word: store, Deprel: compound, Head: managers\n",
      "Word: managers, Deprel: obl, Head: relying\n",
      "Word: and, Deprel: cc, Head: workers\n",
      "Word: replacement, Deprel: compound, Head: workers\n",
      "Word: workers, Deprel: conj, Head: managers\n",
      "Word: to, Deprel: mark, Head: keep\n",
      "Word: keep, Deprel: advcl, Head: relying\n",
      "Word: their, Deprel: nmod:poss, Head: stores\n",
      "Word: stores, Deprel: obj, Head: keep\n",
      "Word: open, Deprel: xcomp, Head: keep\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The supermarket chains have used managers and replacement workers to keep their stores open often at reduced hours'\n",
      "Word: The, Deprel: det, Head: chains\n",
      "Word: supermarket, Deprel: compound, Head: chains\n",
      "Word: chains, Deprel: nsubj, Head: used\n",
      "Word: have, Deprel: aux, Head: used\n",
      "Word: used, Deprel: root, Head: ROOT\n",
      "Word: managers, Deprel: obj, Head: used\n",
      "Word: and, Deprel: cc, Head: workers\n",
      "Word: replacement, Deprel: compound, Head: workers\n",
      "Word: workers, Deprel: conj, Head: managers\n",
      "Word: to, Deprel: mark, Head: keep\n",
      "Word: keep, Deprel: advcl, Head: used\n",
      "Word: their, Deprel: nmod:poss, Head: stores\n",
      "Word: stores, Deprel: obj, Head: keep\n",
      "Word: open, Deprel: xcomp, Head: keep\n",
      "Word: often, Deprel: advmod, Head: open\n",
      "Word: at, Deprel: case, Head: hours\n",
      "Word: reduced, Deprel: amod, Head: hours\n",
      "Word: hours, Deprel: obl, Head: open\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dewhurst s proposal calls for an abrupt end to the controversial Robin Hood plan for school finance'\n",
      "Word: Dewhurst, Deprel: nmod:poss, Head: proposal\n",
      "Word: s, Deprel: case, Head: Dewhurst\n",
      "Word: proposal, Deprel: nsubj, Head: calls\n",
      "Word: calls, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: end\n",
      "Word: an, Deprel: det, Head: end\n",
      "Word: abrupt, Deprel: amod, Head: end\n",
      "Word: end, Deprel: obl, Head: calls\n",
      "Word: to, Deprel: case, Head: plan\n",
      "Word: the, Deprel: det, Head: plan\n",
      "Word: controversial, Deprel: amod, Head: plan\n",
      "Word: Robin, Deprel: compound, Head: Hood\n",
      "Word: Hood, Deprel: compound, Head: plan\n",
      "Word: plan, Deprel: nmod, Head: end\n",
      "Word: for, Deprel: case, Head: finance\n",
      "Word: school, Deprel: compound, Head: finance\n",
      "Word: finance, Deprel: nmod, Head: plan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The committee would propose a replacement for the Robin Hood school finance system'\n",
      "Word: The, Deprel: det, Head: committee\n",
      "Word: committee, Deprel: nsubj, Head: propose\n",
      "Word: would, Deprel: aux, Head: propose\n",
      "Word: propose, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: replacement\n",
      "Word: replacement, Deprel: obj, Head: propose\n",
      "Word: for, Deprel: case, Head: system\n",
      "Word: the, Deprel: det, Head: system\n",
      "Word: Robin, Deprel: compound, Head: Hood\n",
      "Word: Hood, Deprel: compound, Head: school\n",
      "Word: school, Deprel: compound, Head: system\n",
      "Word: finance, Deprel: compound, Head: system\n",
      "Word: system, Deprel: nmod, Head: replacement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Other countries and private creditors are owed at least 80 billion in addition'\n",
      "Word: Other, Deprel: amod, Head: countries\n",
      "Word: countries, Deprel: nsubj, Head: owed\n",
      "Word: and, Deprel: cc, Head: creditors\n",
      "Word: private, Deprel: amod, Head: creditors\n",
      "Word: creditors, Deprel: conj, Head: countries\n",
      "Word: are, Deprel: aux, Head: owed\n",
      "Word: owed, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: least\n",
      "Word: least, Deprel: nmod, Head: billion\n",
      "Word: 80, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obj, Head: owed\n",
      "Word: in, Deprel: case, Head: addition\n",
      "Word: addition, Deprel: obl, Head: owed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Other countries are owed at least US80 billion 108.52 billion'\n",
      "Word: Other, Deprel: amod, Head: countries\n",
      "Word: countries, Deprel: nsubj, Head: owed\n",
      "Word: are, Deprel: aux, Head: owed\n",
      "Word: owed, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: least\n",
      "Word: least, Deprel: nmod, Head: US80\n",
      "Word: US80, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obj, Head: owed\n",
      "Word: 108.52, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: nummod, Head: billion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Telemarketers who call numbers on the list after Oct 1 could face fines of up to 11,000 per call'\n",
      "Word: Telemarketers, Deprel: nsubj, Head: face\n",
      "Word: who, Deprel: nsubj, Head: call\n",
      "Word: call, Deprel: acl:relcl, Head: Telemarketers\n",
      "Word: numbers, Deprel: obj, Head: call\n",
      "Word: on, Deprel: case, Head: list\n",
      "Word: the, Deprel: det, Head: list\n",
      "Word: list, Deprel: obl, Head: call\n",
      "Word: after, Deprel: case, Head: Oct\n",
      "Word: Oct, Deprel: obl, Head: call\n",
      "Word: 1, Deprel: nummod, Head: Oct\n",
      "Word: could, Deprel: aux, Head: face\n",
      "Word: face, Deprel: root, Head: ROOT\n",
      "Word: fines, Deprel: obj, Head: face\n",
      "Word: of, Deprel: case, Head: 11,000\n",
      "Word: up, Deprel: advmod, Head: 11,000\n",
      "Word: to, Deprel: fixed, Head: up\n",
      "Word: 11,000, Deprel: nmod, Head: fines\n",
      "Word: per, Deprel: case, Head: call\n",
      "Word: call, Deprel: nmod, Head: 11,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Under the law telemarketers who call numbers on the list can be fined up to 11,000 for each violation'\n",
      "Word: Under, Deprel: case, Head: telemarketers\n",
      "Word: the, Deprel: det, Head: telemarketers\n",
      "Word: law, Deprel: compound, Head: telemarketers\n",
      "Word: telemarketers, Deprel: obl, Head: fined\n",
      "Word: who, Deprel: nsubj, Head: call\n",
      "Word: call, Deprel: acl:relcl, Head: telemarketers\n",
      "Word: numbers, Deprel: obj, Head: call\n",
      "Word: on, Deprel: case, Head: list\n",
      "Word: the, Deprel: det, Head: list\n",
      "Word: list, Deprel: obl, Head: call\n",
      "Word: can, Deprel: aux, Head: fined\n",
      "Word: be, Deprel: aux:pass, Head: fined\n",
      "Word: fined, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: advmod, Head: 11,000\n",
      "Word: to, Deprel: fixed, Head: up\n",
      "Word: 11,000, Deprel: obl, Head: fined\n",
      "Word: for, Deprel: case, Head: violation\n",
      "Word: each, Deprel: det, Head: violation\n",
      "Word: violation, Deprel: obl, Head: fined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'While waiting for a bomb squad to arrive the bomb exploded killing Wells'\n",
      "Word: While, Deprel: mark, Head: waiting\n",
      "Word: waiting, Deprel: advcl, Head: exploded\n",
      "Word: for, Deprel: case, Head: squad\n",
      "Word: a, Deprel: det, Head: squad\n",
      "Word: bomb, Deprel: compound, Head: squad\n",
      "Word: squad, Deprel: obl, Head: waiting\n",
      "Word: to, Deprel: mark, Head: arrive\n",
      "Word: arrive, Deprel: advcl, Head: waiting\n",
      "Word: the, Deprel: det, Head: bomb\n",
      "Word: bomb, Deprel: nsubj, Head: exploded\n",
      "Word: exploded, Deprel: root, Head: ROOT\n",
      "Word: killing, Deprel: xcomp, Head: exploded\n",
      "Word: Wells, Deprel: obj, Head: killing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The bomb exploded while authorities waited for a bomb squad to arrive'\n",
      "Word: The, Deprel: det, Head: bomb\n",
      "Word: bomb, Deprel: nsubj, Head: exploded\n",
      "Word: exploded, Deprel: root, Head: ROOT\n",
      "Word: while, Deprel: mark, Head: waited\n",
      "Word: authorities, Deprel: nsubj, Head: waited\n",
      "Word: waited, Deprel: advcl, Head: exploded\n",
      "Word: for, Deprel: case, Head: squad\n",
      "Word: a, Deprel: det, Head: squad\n",
      "Word: bomb, Deprel: compound, Head: squad\n",
      "Word: squad, Deprel: obl, Head: waited\n",
      "Word: to, Deprel: mark, Head: arrive\n",
      "Word: arrive, Deprel: advcl, Head: waited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He explained that he found Antetonitrus when he came to Wits in 2001 as a post-doctoral research assistant at England s University of Bristol'\n",
      "Word: He, Deprel: nsubj, Head: explained\n",
      "Word: explained, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: found\n",
      "Word: he, Deprel: nsubj, Head: found\n",
      "Word: found, Deprel: ccomp, Head: explained\n",
      "Word: Antetonitrus, Deprel: obj, Head: found\n",
      "Word: when, Deprel: advmod, Head: came\n",
      "Word: he, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: advcl, Head: found\n",
      "Word: to, Deprel: case, Head: Wits\n",
      "Word: Wits, Deprel: obl, Head: came\n",
      "Word: in, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: came\n",
      "Word: as, Deprel: case, Head: assistant\n",
      "Word: a, Deprel: det, Head: assistant\n",
      "Word: post-doctoral, Deprel: amod, Head: assistant\n",
      "Word: research, Deprel: compound, Head: assistant\n",
      "Word: assistant, Deprel: obl, Head: came\n",
      "Word: at, Deprel: case, Head: University\n",
      "Word: England, Deprel: nmod:poss, Head: University\n",
      "Word: s, Deprel: case, Head: England\n",
      "Word: University, Deprel: nmod, Head: assistant\n",
      "Word: of, Deprel: case, Head: Bristol\n",
      "Word: Bristol, Deprel: nmod, Head: University\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He explained that he found antetonitrus when he came to Wits in 2001 while a post-doctoral research assistant at Bristol University in Britain'\n",
      "Word: He, Deprel: nsubj, Head: explained\n",
      "Word: explained, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: found\n",
      "Word: he, Deprel: nsubj, Head: found\n",
      "Word: found, Deprel: ccomp, Head: explained\n",
      "Word: antetonitrus, Deprel: obj, Head: found\n",
      "Word: when, Deprel: advmod, Head: came\n",
      "Word: he, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: advcl, Head: found\n",
      "Word: to, Deprel: case, Head: Wits\n",
      "Word: Wits, Deprel: obl, Head: came\n",
      "Word: in, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: came\n",
      "Word: while, Deprel: mark, Head: assistant\n",
      "Word: a, Deprel: det, Head: assistant\n",
      "Word: post-doctoral, Deprel: amod, Head: assistant\n",
      "Word: research, Deprel: compound, Head: assistant\n",
      "Word: assistant, Deprel: advcl, Head: came\n",
      "Word: at, Deprel: case, Head: University\n",
      "Word: Bristol, Deprel: compound, Head: University\n",
      "Word: University, Deprel: nmod, Head: assistant\n",
      "Word: in, Deprel: case, Head: Britain\n",
      "Word: Britain, Deprel: nmod, Head: University\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Air Canada the largest airline in Canada and No 11 in the world has been under court protection from creditors since April 1'\n",
      "Word: Air, Deprel: nsubj, Head: protection\n",
      "Word: Canada, Deprel: flat, Head: Air\n",
      "Word: the, Deprel: det, Head: airline\n",
      "Word: largest, Deprel: amod, Head: airline\n",
      "Word: airline, Deprel: nsubj, Head: protection\n",
      "Word: in, Deprel: case, Head: Canada\n",
      "Word: Canada, Deprel: nmod, Head: airline\n",
      "Word: and, Deprel: cc, Head: 11\n",
      "Word: No, Deprel: det, Head: 11\n",
      "Word: 11, Deprel: conj, Head: airline\n",
      "Word: in, Deprel: case, Head: world\n",
      "Word: the, Deprel: det, Head: world\n",
      "Word: world, Deprel: nmod, Head: 11\n",
      "Word: has, Deprel: aux, Head: protection\n",
      "Word: been, Deprel: cop, Head: protection\n",
      "Word: under, Deprel: case, Head: protection\n",
      "Word: court, Deprel: compound, Head: protection\n",
      "Word: protection, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: creditors\n",
      "Word: creditors, Deprel: nmod, Head: protection\n",
      "Word: since, Deprel: case, Head: April\n",
      "Word: April, Deprel: obl, Head: protection\n",
      "Word: 1, Deprel: nummod, Head: April\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The No 11 airline in the world Air Canada has been under court protection from creditors since April 1'\n",
      "Word: The, Deprel: det, Head: airline\n",
      "Word: No, Deprel: det, Head: 11\n",
      "Word: 11, Deprel: nummod, Head: airline\n",
      "Word: airline, Deprel: nsubj, Head: protection\n",
      "Word: in, Deprel: case, Head: world\n",
      "Word: the, Deprel: det, Head: world\n",
      "Word: world, Deprel: nmod, Head: airline\n",
      "Word: Air, Deprel: appos, Head: world\n",
      "Word: Canada, Deprel: flat, Head: Air\n",
      "Word: has, Deprel: aux, Head: protection\n",
      "Word: been, Deprel: cop, Head: protection\n",
      "Word: under, Deprel: case, Head: protection\n",
      "Word: court, Deprel: compound, Head: protection\n",
      "Word: protection, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: creditors\n",
      "Word: creditors, Deprel: nmod, Head: protection\n",
      "Word: since, Deprel: case, Head: April\n",
      "Word: April, Deprel: obl, Head: protection\n",
      "Word: 1, Deprel: nummod, Head: April\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The security official s backup could n't fill in because he was on active military duty Strutt said'\n",
      "Word: The, Deprel: det, Head: official\n",
      "Word: security, Deprel: compound, Head: official\n",
      "Word: official, Deprel: nmod:poss, Head: backup\n",
      "Word: s, Deprel: case, Head: official\n",
      "Word: backup, Deprel: nsubj, Head: fill\n",
      "Word: could, Deprel: aux, Head: fill\n",
      "Word: n't, Deprel: advmod, Head: fill\n",
      "Word: fill, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: compound:prt, Head: fill\n",
      "Word: because, Deprel: mark, Head: duty\n",
      "Word: he, Deprel: nsubj, Head: duty\n",
      "Word: was, Deprel: cop, Head: duty\n",
      "Word: on, Deprel: case, Head: duty\n",
      "Word: active, Deprel: amod, Head: duty\n",
      "Word: military, Deprel: amod, Head: duty\n",
      "Word: duty, Deprel: advcl, Head: fill\n",
      "Word: Strutt, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: duty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The security official s backup was on active duty and the lottery association did n't have a replacement in New Jersey Strutt said'\n",
      "Word: The, Deprel: det, Head: official\n",
      "Word: security, Deprel: compound, Head: official\n",
      "Word: official, Deprel: nmod:poss, Head: backup\n",
      "Word: s, Deprel: case, Head: official\n",
      "Word: backup, Deprel: nsubj, Head: duty\n",
      "Word: was, Deprel: cop, Head: duty\n",
      "Word: on, Deprel: case, Head: duty\n",
      "Word: active, Deprel: amod, Head: duty\n",
      "Word: duty, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: have\n",
      "Word: the, Deprel: det, Head: association\n",
      "Word: lottery, Deprel: compound, Head: association\n",
      "Word: association, Deprel: nsubj, Head: have\n",
      "Word: did, Deprel: aux, Head: have\n",
      "Word: n't, Deprel: advmod, Head: have\n",
      "Word: have, Deprel: conj, Head: duty\n",
      "Word: a, Deprel: det, Head: replacement\n",
      "Word: replacement, Deprel: obj, Head: have\n",
      "Word: in, Deprel: case, Head: Jersey\n",
      "Word: New, Deprel: amod, Head: Jersey\n",
      "Word: Jersey, Deprel: compound, Head: Strutt\n",
      "Word: Strutt, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl, Head: replacement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The jury also found Gonzales guilty of using excessive force by dousing Olvera-Carrera with pepper spray'\n",
      "Word: The, Deprel: det, Head: jury\n",
      "Word: jury, Deprel: nsubj, Head: found\n",
      "Word: also, Deprel: advmod, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: Gonzales, Deprel: obj, Head: found\n",
      "Word: guilty, Deprel: xcomp, Head: found\n",
      "Word: of, Deprel: mark, Head: using\n",
      "Word: using, Deprel: advcl, Head: guilty\n",
      "Word: excessive, Deprel: amod, Head: force\n",
      "Word: force, Deprel: obj, Head: using\n",
      "Word: by, Deprel: mark, Head: dousing\n",
      "Word: dousing, Deprel: advcl, Head: using\n",
      "Word: Olvera-Carrera, Deprel: obj, Head: dousing\n",
      "Word: with, Deprel: case, Head: spray\n",
      "Word: pepper, Deprel: compound, Head: spray\n",
      "Word: spray, Deprel: obl, Head: dousing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Gonzales was found guilty of using excessive force by spraying Olvera with pepper spray'\n",
      "Word: Gonzales, Deprel: nsubj:pass, Head: found\n",
      "Word: was, Deprel: aux:pass, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: guilty, Deprel: xcomp, Head: found\n",
      "Word: of, Deprel: mark, Head: using\n",
      "Word: using, Deprel: advcl, Head: guilty\n",
      "Word: excessive, Deprel: amod, Head: force\n",
      "Word: force, Deprel: obj, Head: using\n",
      "Word: by, Deprel: mark, Head: spraying\n",
      "Word: spraying, Deprel: advcl, Head: using\n",
      "Word: Olvera, Deprel: obj, Head: spraying\n",
      "Word: with, Deprel: case, Head: spray\n",
      "Word: pepper, Deprel: compound, Head: spray\n",
      "Word: spray, Deprel: obl, Head: spraying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The bodies of some of the dead pulled out from under the train were laid out beside the tracks while emergency services brought in wooden coffins'\n",
      "Word: The, Deprel: det, Head: bodies\n",
      "Word: bodies, Deprel: nsubj:pass, Head: laid\n",
      "Word: of, Deprel: case, Head: some\n",
      "Word: some, Deprel: nmod, Head: bodies\n",
      "Word: of, Deprel: case, Head: dead\n",
      "Word: the, Deprel: det, Head: dead\n",
      "Word: dead, Deprel: nmod, Head: some\n",
      "Word: pulled, Deprel: acl, Head: bodies\n",
      "Word: out, Deprel: compound:prt, Head: pulled\n",
      "Word: from, Deprel: case, Head: train\n",
      "Word: under, Deprel: case, Head: train\n",
      "Word: the, Deprel: det, Head: train\n",
      "Word: train, Deprel: obl, Head: pulled\n",
      "Word: were, Deprel: aux:pass, Head: laid\n",
      "Word: laid, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: compound:prt, Head: laid\n",
      "Word: beside, Deprel: case, Head: tracks\n",
      "Word: the, Deprel: det, Head: tracks\n",
      "Word: tracks, Deprel: obl, Head: laid\n",
      "Word: while, Deprel: mark, Head: brought\n",
      "Word: emergency, Deprel: compound, Head: services\n",
      "Word: services, Deprel: nsubj, Head: brought\n",
      "Word: brought, Deprel: advcl, Head: laid\n",
      "Word: in, Deprel: compound:prt, Head: brought\n",
      "Word: wooden, Deprel: amod, Head: coffins\n",
      "Word: coffins, Deprel: obj, Head: brought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The bodies of many of the dead pulled from under the partially derailed train were laid out by the tracks awaiting identification'\n",
      "Word: The, Deprel: det, Head: bodies\n",
      "Word: bodies, Deprel: nsubj:pass, Head: laid\n",
      "Word: of, Deprel: case, Head: many\n",
      "Word: many, Deprel: nmod, Head: bodies\n",
      "Word: of, Deprel: case, Head: dead\n",
      "Word: the, Deprel: det, Head: dead\n",
      "Word: dead, Deprel: nmod, Head: many\n",
      "Word: pulled, Deprel: acl, Head: dead\n",
      "Word: from, Deprel: case, Head: train\n",
      "Word: under, Deprel: case, Head: train\n",
      "Word: the, Deprel: det, Head: train\n",
      "Word: partially, Deprel: advmod, Head: derailed\n",
      "Word: derailed, Deprel: amod, Head: train\n",
      "Word: train, Deprel: obl, Head: pulled\n",
      "Word: were, Deprel: aux:pass, Head: laid\n",
      "Word: laid, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: compound:prt, Head: laid\n",
      "Word: by, Deprel: case, Head: tracks\n",
      "Word: the, Deprel: det, Head: tracks\n",
      "Word: tracks, Deprel: obl:agent, Head: laid\n",
      "Word: awaiting, Deprel: acl, Head: tracks\n",
      "Word: identification, Deprel: obj, Head: awaiting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Garner said the self-proclaimed mayor of Baghdad Mohammed Mohsen al-Zubaidi was released after two days in coalition custody'\n",
      "Word: Garner, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: mayor\n",
      "Word: self-proclaimed, Deprel: amod, Head: mayor\n",
      "Word: mayor, Deprel: nsubj:pass, Head: released\n",
      "Word: of, Deprel: case, Head: Baghdad\n",
      "Word: Baghdad, Deprel: nmod, Head: mayor\n",
      "Word: Mohammed, Deprel: appos, Head: mayor\n",
      "Word: Mohsen, Deprel: flat, Head: Mohammed\n",
      "Word: al-Zubaidi, Deprel: flat, Head: Mohammed\n",
      "Word: was, Deprel: aux:pass, Head: released\n",
      "Word: released, Deprel: ccomp, Head: said\n",
      "Word: after, Deprel: case, Head: days\n",
      "Word: two, Deprel: nummod, Head: days\n",
      "Word: days, Deprel: obl, Head: released\n",
      "Word: in, Deprel: case, Head: custody\n",
      "Word: coalition, Deprel: compound, Head: custody\n",
      "Word: custody, Deprel: nmod, Head: days\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Garner said self-proclaimed Baghdad mayor Mohammed Mohsen Zubaidi was released 48 hours after his detention in late April'\n",
      "Word: Garner, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: self-proclaimed, Deprel: amod, Head: mayor\n",
      "Word: Baghdad, Deprel: compound, Head: mayor\n",
      "Word: mayor, Deprel: compound, Head: Mohammed\n",
      "Word: Mohammed, Deprel: nsubj:pass, Head: released\n",
      "Word: Mohsen, Deprel: flat, Head: Mohammed\n",
      "Word: Zubaidi, Deprel: flat, Head: Mohammed\n",
      "Word: was, Deprel: aux:pass, Head: released\n",
      "Word: released, Deprel: ccomp, Head: said\n",
      "Word: 48, Deprel: nummod, Head: hours\n",
      "Word: hours, Deprel: nmod:npmod, Head: detention\n",
      "Word: after, Deprel: case, Head: detention\n",
      "Word: his, Deprel: nmod:poss, Head: detention\n",
      "Word: detention, Deprel: obl, Head: released\n",
      "Word: in, Deprel: case, Head: April\n",
      "Word: late, Deprel: amod, Head: April\n",
      "Word: April, Deprel: nmod, Head: detention\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Enron company executives engaged in widespread and pervasive fraud prosecutor Samuel Buell told the Associated Press'\n",
      "Word: Enron, Deprel: compound, Head: executives\n",
      "Word: company, Deprel: compound, Head: executives\n",
      "Word: executives, Deprel: nsubj, Head: engaged\n",
      "Word: engaged, Deprel: ccomp, Head: told\n",
      "Word: in, Deprel: case, Head: prosecutor\n",
      "Word: widespread, Deprel: amod, Head: prosecutor\n",
      "Word: and, Deprel: cc, Head: pervasive\n",
      "Word: pervasive, Deprel: conj, Head: widespread\n",
      "Word: fraud, Deprel: compound, Head: prosecutor\n",
      "Word: prosecutor, Deprel: compound, Head: Samuel\n",
      "Word: Samuel, Deprel: nsubj, Head: told\n",
      "Word: Buell, Deprel: flat, Head: Samuel\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: Press\n",
      "Word: Associated, Deprel: amod, Head: Press\n",
      "Word: Press, Deprel: iobj, Head: told\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Enron company executives engaged in widespread and pervasive fraud to manipulate the company s earnings results Buell said'\n",
      "Word: Enron, Deprel: compound, Head: executives\n",
      "Word: company, Deprel: compound, Head: executives\n",
      "Word: executives, Deprel: nsubj, Head: engaged\n",
      "Word: engaged, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: fraud\n",
      "Word: widespread, Deprel: amod, Head: fraud\n",
      "Word: and, Deprel: cc, Head: pervasive\n",
      "Word: pervasive, Deprel: conj, Head: widespread\n",
      "Word: fraud, Deprel: obl, Head: engaged\n",
      "Word: to, Deprel: mark, Head: manipulate\n",
      "Word: manipulate, Deprel: advcl, Head: engaged\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nmod:poss, Head: results\n",
      "Word: s, Deprel: case, Head: company\n",
      "Word: earnings, Deprel: compound, Head: results\n",
      "Word: results, Deprel: obj, Head: manipulate\n",
      "Word: Buell, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: engaged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It seems to me we re just dealing with bragging rights here who wins and who loses said Gammerman who heard the case without a jury'\n",
      "Word: It, Deprel: expl, Head: seems\n",
      "Word: seems, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: me\n",
      "Word: me, Deprel: obl, Head: seems\n",
      "Word: we, Deprel: nsubj, Head: dealing\n",
      "Word: re, Deprel: aux, Head: dealing\n",
      "Word: just, Deprel: advmod, Head: dealing\n",
      "Word: dealing, Deprel: ccomp, Head: seems\n",
      "Word: with, Deprel: case, Head: rights\n",
      "Word: bragging, Deprel: compound, Head: rights\n",
      "Word: rights, Deprel: obl, Head: dealing\n",
      "Word: here, Deprel: advmod, Head: rights\n",
      "Word: who, Deprel: nsubj, Head: wins\n",
      "Word: wins, Deprel: acl:relcl, Head: rights\n",
      "Word: and, Deprel: cc, Head: said\n",
      "Word: who, Deprel: nsubj, Head: loses\n",
      "Word: loses, Deprel: conj, Head: wins\n",
      "Word: said, Deprel: conj, Head: seems\n",
      "Word: Gammerman, Deprel: obj, Head: said\n",
      "Word: who, Deprel: nsubj, Head: heard\n",
      "Word: heard, Deprel: acl:relcl, Head: Gammerman\n",
      "Word: the, Deprel: det, Head: case\n",
      "Word: case, Deprel: obj, Head: heard\n",
      "Word: without, Deprel: case, Head: jury\n",
      "Word: a, Deprel: det, Head: jury\n",
      "Word: jury, Deprel: obl, Head: heard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Leaving aside attorney fees we re dealing with bragging rights of who wins and who loses said Gammerman'\n",
      "Word: Leaving, Deprel: advcl, Head: dealing\n",
      "Word: aside, Deprel: compound:prt, Head: Leaving\n",
      "Word: attorney, Deprel: compound, Head: fees\n",
      "Word: fees, Deprel: obj, Head: Leaving\n",
      "Word: we, Deprel: nsubj, Head: dealing\n",
      "Word: re, Deprel: aux, Head: dealing\n",
      "Word: dealing, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: rights\n",
      "Word: bragging, Deprel: compound, Head: rights\n",
      "Word: rights, Deprel: obl, Head: dealing\n",
      "Word: of, Deprel: mark, Head: wins\n",
      "Word: who, Deprel: nsubj, Head: wins\n",
      "Word: wins, Deprel: acl, Head: rights\n",
      "Word: and, Deprel: cc, Head: loses\n",
      "Word: who, Deprel: nsubj, Head: loses\n",
      "Word: loses, Deprel: conj, Head: wins\n",
      "Word: said, Deprel: ccomp, Head: loses\n",
      "Word: Gammerman, Deprel: obj, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Customers that pay the 1,219 entrance fee get SMS 2003 with 10 device client access licenses'\n",
      "Word: Customers, Deprel: nsubj, Head: get\n",
      "Word: that, Deprel: nsubj, Head: pay\n",
      "Word: pay, Deprel: acl:relcl, Head: Customers\n",
      "Word: the, Deprel: det, Head: fee\n",
      "Word: 1,219, Deprel: nummod, Head: fee\n",
      "Word: entrance, Deprel: compound, Head: fee\n",
      "Word: fee, Deprel: obj, Head: pay\n",
      "Word: get, Deprel: root, Head: ROOT\n",
      "Word: SMS, Deprel: obj, Head: get\n",
      "Word: 2003, Deprel: nummod, Head: SMS\n",
      "Word: with, Deprel: case, Head: licenses\n",
      "Word: 10, Deprel: nummod, Head: device\n",
      "Word: device, Deprel: compound, Head: licenses\n",
      "Word: client, Deprel: compound, Head: licenses\n",
      "Word: access, Deprel: compound, Head: licenses\n",
      "Word: licenses, Deprel: obl, Head: get\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Retail pricing for SMS 2003 with 10 device client access licenses is 1,219'\n",
      "Word: Retail, Deprel: compound, Head: pricing\n",
      "Word: pricing, Deprel: nsubj, Head: 1,219\n",
      "Word: for, Deprel: case, Head: SMS\n",
      "Word: SMS, Deprel: nmod, Head: pricing\n",
      "Word: 2003, Deprel: nummod, Head: SMS\n",
      "Word: with, Deprel: case, Head: licenses\n",
      "Word: 10, Deprel: nummod, Head: device\n",
      "Word: device, Deprel: compound, Head: licenses\n",
      "Word: client, Deprel: compound, Head: access\n",
      "Word: access, Deprel: compound, Head: licenses\n",
      "Word: licenses, Deprel: nmod, Head: pricing\n",
      "Word: is, Deprel: cop, Head: 1,219\n",
      "Word: 1,219, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Results of the 2001 Aboriginal Peoples Survey released yesterday by Statistics Canada suggest living standards have improved but still lag for those off reserves'\n",
      "Word: Results, Deprel: nsubj, Head: suggest\n",
      "Word: of, Deprel: case, Head: Survey\n",
      "Word: the, Deprel: det, Head: Survey\n",
      "Word: 2001, Deprel: compound, Head: Survey\n",
      "Word: Aboriginal, Deprel: amod, Head: Peoples\n",
      "Word: Peoples, Deprel: compound, Head: Survey\n",
      "Word: Survey, Deprel: nmod, Head: Results\n",
      "Word: released, Deprel: acl, Head: Survey\n",
      "Word: yesterday, Deprel: obl:tmod, Head: released\n",
      "Word: by, Deprel: case, Head: Statistics\n",
      "Word: Statistics, Deprel: obl, Head: released\n",
      "Word: Canada, Deprel: flat, Head: Statistics\n",
      "Word: suggest, Deprel: root, Head: ROOT\n",
      "Word: living, Deprel: compound, Head: standards\n",
      "Word: standards, Deprel: nsubj, Head: improved\n",
      "Word: have, Deprel: aux, Head: improved\n",
      "Word: improved, Deprel: ccomp, Head: suggest\n",
      "Word: but, Deprel: cc, Head: lag\n",
      "Word: still, Deprel: advmod, Head: lag\n",
      "Word: lag, Deprel: conj, Head: improved\n",
      "Word: for, Deprel: case, Head: those\n",
      "Word: those, Deprel: obl, Head: improved\n",
      "Word: off, Deprel: case, Head: reserves\n",
      "Word: reserves, Deprel: nmod, Head: those\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The 2001 Aboriginal Peoples Survey released Wednesday by Statistics Canada says living standards have improved but still lag for the Inuit and those who leave their often impoverished reserves'\n",
      "Word: The, Deprel: det, Head: Survey\n",
      "Word: 2001, Deprel: compound, Head: Survey\n",
      "Word: Aboriginal, Deprel: amod, Head: Peoples\n",
      "Word: Peoples, Deprel: compound, Head: Survey\n",
      "Word: Survey, Deprel: nsubj, Head: says\n",
      "Word: released, Deprel: acl, Head: Survey\n",
      "Word: Wednesday, Deprel: obl:tmod, Head: released\n",
      "Word: by, Deprel: case, Head: Canada\n",
      "Word: Statistics, Deprel: compound, Head: Canada\n",
      "Word: Canada, Deprel: nmod, Head: Wednesday\n",
      "Word: says, Deprel: root, Head: ROOT\n",
      "Word: living, Deprel: compound, Head: standards\n",
      "Word: standards, Deprel: nsubj, Head: improved\n",
      "Word: have, Deprel: aux, Head: improved\n",
      "Word: improved, Deprel: ccomp, Head: says\n",
      "Word: but, Deprel: cc, Head: lag\n",
      "Word: still, Deprel: advmod, Head: lag\n",
      "Word: lag, Deprel: conj, Head: improved\n",
      "Word: for, Deprel: case, Head: Inuit\n",
      "Word: the, Deprel: det, Head: Inuit\n",
      "Word: Inuit, Deprel: obl, Head: improved\n",
      "Word: and, Deprel: cc, Head: those\n",
      "Word: those, Deprel: conj, Head: Inuit\n",
      "Word: who, Deprel: nsubj, Head: leave\n",
      "Word: leave, Deprel: acl:relcl, Head: those\n",
      "Word: their, Deprel: nmod:poss, Head: reserves\n",
      "Word: often, Deprel: advmod, Head: impoverished\n",
      "Word: impoverished, Deprel: amod, Head: reserves\n",
      "Word: reserves, Deprel: obj, Head: leave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The recent turnaround in the stock market and an easing in unemployment claims should keep consumer expectations at current levels and may signal more favorable economic times ahead'\n",
      "Word: The, Deprel: det, Head: turnaround\n",
      "Word: recent, Deprel: amod, Head: turnaround\n",
      "Word: turnaround, Deprel: nsubj, Head: keep\n",
      "Word: in, Deprel: case, Head: market\n",
      "Word: the, Deprel: det, Head: market\n",
      "Word: stock, Deprel: compound, Head: market\n",
      "Word: market, Deprel: nmod, Head: turnaround\n",
      "Word: and, Deprel: cc, Head: easing\n",
      "Word: an, Deprel: det, Head: easing\n",
      "Word: easing, Deprel: conj, Head: turnaround\n",
      "Word: in, Deprel: case, Head: claims\n",
      "Word: unemployment, Deprel: compound, Head: claims\n",
      "Word: claims, Deprel: nmod, Head: easing\n",
      "Word: should, Deprel: aux, Head: keep\n",
      "Word: keep, Deprel: root, Head: ROOT\n",
      "Word: consumer, Deprel: compound, Head: expectations\n",
      "Word: expectations, Deprel: obj, Head: keep\n",
      "Word: at, Deprel: case, Head: levels\n",
      "Word: current, Deprel: amod, Head: levels\n",
      "Word: levels, Deprel: obl, Head: keep\n",
      "Word: and, Deprel: cc, Head: signal\n",
      "Word: may, Deprel: aux, Head: signal\n",
      "Word: signal, Deprel: conj, Head: keep\n",
      "Word: more, Deprel: advmod, Head: favorable\n",
      "Word: favorable, Deprel: amod, Head: times\n",
      "Word: economic, Deprel: amod, Head: times\n",
      "Word: times, Deprel: obj, Head: signal\n",
      "Word: ahead, Deprel: advmod, Head: signal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The recent turnaround in the stock market and an easing in unemployment claims may signal more favorable economic times ahead she said'\n",
      "Word: The, Deprel: det, Head: turnaround\n",
      "Word: recent, Deprel: amod, Head: turnaround\n",
      "Word: turnaround, Deprel: nsubj, Head: signal\n",
      "Word: in, Deprel: case, Head: market\n",
      "Word: the, Deprel: det, Head: market\n",
      "Word: stock, Deprel: compound, Head: market\n",
      "Word: market, Deprel: nmod, Head: turnaround\n",
      "Word: and, Deprel: cc, Head: easing\n",
      "Word: an, Deprel: det, Head: easing\n",
      "Word: easing, Deprel: conj, Head: turnaround\n",
      "Word: in, Deprel: case, Head: claims\n",
      "Word: unemployment, Deprel: compound, Head: claims\n",
      "Word: claims, Deprel: nmod, Head: easing\n",
      "Word: may, Deprel: aux, Head: signal\n",
      "Word: signal, Deprel: root, Head: ROOT\n",
      "Word: more, Deprel: advmod, Head: favorable\n",
      "Word: favorable, Deprel: amod, Head: times\n",
      "Word: economic, Deprel: amod, Head: times\n",
      "Word: times, Deprel: obj, Head: signal\n",
      "Word: ahead, Deprel: advmod, Head: signal\n",
      "Word: she, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: signal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'While the day s trading was lackluster the Standard Poor s 500 index was preparing to close out its best three-month period since the fourth quarter of 1998'\n",
      "Word: While, Deprel: mark, Head: lackluster\n",
      "Word: the, Deprel: det, Head: day\n",
      "Word: day, Deprel: nmod:poss, Head: trading\n",
      "Word: s, Deprel: case, Head: day\n",
      "Word: trading, Deprel: nsubj, Head: lackluster\n",
      "Word: was, Deprel: cop, Head: lackluster\n",
      "Word: lackluster, Deprel: advcl, Head: preparing\n",
      "Word: the, Deprel: det, Head: Poor\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: nmod:poss, Head: index\n",
      "Word: s, Deprel: case, Head: Poor\n",
      "Word: 500, Deprel: nummod, Head: index\n",
      "Word: index, Deprel: nsubj, Head: preparing\n",
      "Word: was, Deprel: aux, Head: preparing\n",
      "Word: preparing, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: close\n",
      "Word: close, Deprel: xcomp, Head: preparing\n",
      "Word: out, Deprel: compound:prt, Head: close\n",
      "Word: its, Deprel: nmod:poss, Head: period\n",
      "Word: best, Deprel: amod, Head: period\n",
      "Word: three-month, Deprel: amod, Head: period\n",
      "Word: period, Deprel: obj, Head: close\n",
      "Word: since, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: fourth, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: close\n",
      "Word: of, Deprel: case, Head: 1998\n",
      "Word: 1998, Deprel: nmod, Head: quarter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Standard Poor s 500 stock index ended the quarter up 120 points a gain of 14 percent the best performance for that broad market benchmark since 1998'\n",
      "Word: The, Deprel: det, Head: Poor\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: nmod:poss, Head: index\n",
      "Word: s, Deprel: case, Head: Poor\n",
      "Word: 500, Deprel: nummod, Head: index\n",
      "Word: stock, Deprel: compound, Head: index\n",
      "Word: index, Deprel: nsubj, Head: ended\n",
      "Word: ended, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: quarter, Deprel: obj, Head: ended\n",
      "Word: up, Deprel: advmod, Head: ended\n",
      "Word: 120, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl, Head: ended\n",
      "Word: a, Deprel: det, Head: gain\n",
      "Word: gain, Deprel: obj, Head: ended\n",
      "Word: of, Deprel: case, Head: percent\n",
      "Word: 14, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: nmod, Head: gain\n",
      "Word: the, Deprel: det, Head: performance\n",
      "Word: best, Deprel: amod, Head: performance\n",
      "Word: performance, Deprel: obj, Head: ended\n",
      "Word: for, Deprel: case, Head: benchmark\n",
      "Word: that, Deprel: det, Head: benchmark\n",
      "Word: broad, Deprel: amod, Head: market\n",
      "Word: market, Deprel: compound, Head: benchmark\n",
      "Word: benchmark, Deprel: nmod, Head: performance\n",
      "Word: since, Deprel: case, Head: 1998\n",
      "Word: 1998, Deprel: nmod, Head: performance\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Researchers found the fossils in a semidesert area of Venezuela about 250 miles west of Caracas'\n",
      "Word: Researchers, Deprel: nsubj, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: fossils\n",
      "Word: fossils, Deprel: obj, Head: found\n",
      "Word: in, Deprel: case, Head: area\n",
      "Word: a, Deprel: det, Head: area\n",
      "Word: semidesert, Deprel: compound, Head: area\n",
      "Word: area, Deprel: nmod, Head: fossils\n",
      "Word: of, Deprel: case, Head: Venezuela\n",
      "Word: Venezuela, Deprel: nmod, Head: area\n",
      "Word: about, Deprel: advmod, Head: 250\n",
      "Word: 250, Deprel: nummod, Head: miles\n",
      "Word: miles, Deprel: obl:npmod, Head: west\n",
      "Word: west, Deprel: advmod, Head: found\n",
      "Word: of, Deprel: case, Head: Caracas\n",
      "Word: Caracas, Deprel: obl, Head: west\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Phoberomys skeleton was unearthed 250 miles west of Caracas Venezuela'\n",
      "Word: Phoberomys, Deprel: compound, Head: skeleton\n",
      "Word: skeleton, Deprel: nsubj:pass, Head: unearthed\n",
      "Word: was, Deprel: aux:pass, Head: unearthed\n",
      "Word: unearthed, Deprel: root, Head: ROOT\n",
      "Word: 250, Deprel: nummod, Head: miles\n",
      "Word: miles, Deprel: obl:npmod, Head: west\n",
      "Word: west, Deprel: advmod, Head: unearthed\n",
      "Word: of, Deprel: case, Head: Venezuela\n",
      "Word: Caracas, Deprel: compound, Head: Venezuela\n",
      "Word: Venezuela, Deprel: obl, Head: west\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'ONA explicitly stated that it did not receive intelligence material indicating that Jemaah Islamiyah terrorist network was planning to mount an operation in Bali'\n",
      "Word: ONA, Deprel: nsubj, Head: stated\n",
      "Word: explicitly, Deprel: advmod, Head: stated\n",
      "Word: stated, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: receive\n",
      "Word: it, Deprel: nsubj, Head: receive\n",
      "Word: did, Deprel: aux, Head: receive\n",
      "Word: not, Deprel: advmod, Head: receive\n",
      "Word: receive, Deprel: ccomp, Head: stated\n",
      "Word: intelligence, Deprel: compound, Head: material\n",
      "Word: material, Deprel: obj, Head: receive\n",
      "Word: indicating, Deprel: acl, Head: material\n",
      "Word: that, Deprel: mark, Head: planning\n",
      "Word: Jemaah, Deprel: compound, Head: Islamiyah\n",
      "Word: Islamiyah, Deprel: compound, Head: network\n",
      "Word: terrorist, Deprel: compound, Head: network\n",
      "Word: network, Deprel: nsubj, Head: planning\n",
      "Word: was, Deprel: aux, Head: planning\n",
      "Word: planning, Deprel: ccomp, Head: indicating\n",
      "Word: to, Deprel: mark, Head: mount\n",
      "Word: mount, Deprel: xcomp, Head: planning\n",
      "Word: an, Deprel: det, Head: operation\n",
      "Word: operation, Deprel: obj, Head: mount\n",
      "Word: in, Deprel: case, Head: Bali\n",
      "Word: Bali, Deprel: obl, Head: mount\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But at no stage did ONA receive intelligence material indicating that Jemaah Islamiyah was planning to mount an operation in Bali'\n",
      "Word: But, Deprel: cc, Head: receive\n",
      "Word: at, Deprel: case, Head: stage\n",
      "Word: no, Deprel: det, Head: stage\n",
      "Word: stage, Deprel: obl, Head: receive\n",
      "Word: did, Deprel: aux, Head: receive\n",
      "Word: ONA, Deprel: nsubj, Head: receive\n",
      "Word: receive, Deprel: root, Head: ROOT\n",
      "Word: intelligence, Deprel: compound, Head: material\n",
      "Word: material, Deprel: obj, Head: receive\n",
      "Word: indicating, Deprel: acl, Head: material\n",
      "Word: that, Deprel: mark, Head: planning\n",
      "Word: Jemaah, Deprel: compound, Head: Islamiyah\n",
      "Word: Islamiyah, Deprel: nsubj, Head: planning\n",
      "Word: was, Deprel: aux, Head: planning\n",
      "Word: planning, Deprel: ccomp, Head: indicating\n",
      "Word: to, Deprel: mark, Head: mount\n",
      "Word: mount, Deprel: xcomp, Head: planning\n",
      "Word: an, Deprel: det, Head: operation\n",
      "Word: operation, Deprel: obj, Head: mount\n",
      "Word: in, Deprel: case, Head: Bali\n",
      "Word: Bali, Deprel: obl, Head: mount\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Those reports were denied by the interior minister Prince Nayef'\n",
      "Word: Those, Deprel: det, Head: reports\n",
      "Word: reports, Deprel: nsubj:pass, Head: denied\n",
      "Word: were, Deprel: aux:pass, Head: denied\n",
      "Word: denied, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: minister\n",
      "Word: the, Deprel: det, Head: minister\n",
      "Word: interior, Deprel: compound, Head: minister\n",
      "Word: minister, Deprel: obl:agent, Head: denied\n",
      "Word: Prince, Deprel: appos, Head: minister\n",
      "Word: Nayef, Deprel: flat, Head: Prince\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'However the Saudi interior minister Prince Nayef denied the reports'\n",
      "Word: However, Deprel: advmod, Head: denied\n",
      "Word: the, Deprel: det, Head: minister\n",
      "Word: Saudi, Deprel: amod, Head: minister\n",
      "Word: interior, Deprel: compound, Head: minister\n",
      "Word: minister, Deprel: compound, Head: Prince\n",
      "Word: Prince, Deprel: nsubj, Head: denied\n",
      "Word: Nayef, Deprel: flat, Head: Prince\n",
      "Word: denied, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: reports\n",
      "Word: reports, Deprel: obj, Head: denied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bryant previously said that hike had a greater impact on demand than officials expected'\n",
      "Word: Bryant, Deprel: nsubj, Head: said\n",
      "Word: previously, Deprel: advmod, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: had\n",
      "Word: hike, Deprel: nsubj, Head: had\n",
      "Word: had, Deprel: ccomp, Head: said\n",
      "Word: a, Deprel: det, Head: impact\n",
      "Word: greater, Deprel: amod, Head: impact\n",
      "Word: impact, Deprel: obj, Head: had\n",
      "Word: on, Deprel: case, Head: demand\n",
      "Word: demand, Deprel: nmod, Head: impact\n",
      "Word: than, Deprel: mark, Head: expected\n",
      "Word: officials, Deprel: nsubj, Head: expected\n",
      "Word: expected, Deprel: advcl, Head: had\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Chief financial officer Andy Bryant has said that hike had a greater affect volume than officials expected'\n",
      "Word: Chief, Deprel: amod, Head: officer\n",
      "Word: financial, Deprel: amod, Head: officer\n",
      "Word: officer, Deprel: compound, Head: Andy\n",
      "Word: Andy, Deprel: nsubj, Head: said\n",
      "Word: Bryant, Deprel: flat, Head: Andy\n",
      "Word: has, Deprel: aux, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: had\n",
      "Word: hike, Deprel: nsubj, Head: had\n",
      "Word: had, Deprel: ccomp, Head: said\n",
      "Word: a, Deprel: det, Head: volume\n",
      "Word: greater, Deprel: amod, Head: volume\n",
      "Word: affect, Deprel: compound, Head: volume\n",
      "Word: volume, Deprel: obj, Head: had\n",
      "Word: than, Deprel: mark, Head: expected\n",
      "Word: officials, Deprel: nsubj, Head: expected\n",
      "Word: expected, Deprel: advcl, Head: had\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The American women who are defending champions will play in Philadelphia on Sept 25 and conclude group competition in Columbus on Sept 28'\n",
      "Word: The, Deprel: det, Head: women\n",
      "Word: American, Deprel: amod, Head: women\n",
      "Word: women, Deprel: nsubj, Head: play\n",
      "Word: who, Deprel: nsubj, Head: defending\n",
      "Word: are, Deprel: aux, Head: defending\n",
      "Word: defending, Deprel: acl:relcl, Head: women\n",
      "Word: champions, Deprel: obj, Head: defending\n",
      "Word: will, Deprel: aux, Head: play\n",
      "Word: play, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: Philadelphia\n",
      "Word: Philadelphia, Deprel: obl, Head: play\n",
      "Word: on, Deprel: case, Head: Sept\n",
      "Word: Sept, Deprel: obl, Head: play\n",
      "Word: 25, Deprel: nummod, Head: Sept\n",
      "Word: and, Deprel: cc, Head: conclude\n",
      "Word: conclude, Deprel: conj, Head: play\n",
      "Word: group, Deprel: compound, Head: competition\n",
      "Word: competition, Deprel: obj, Head: conclude\n",
      "Word: in, Deprel: case, Head: Columbus\n",
      "Word: Columbus, Deprel: nmod, Head: competition\n",
      "Word: on, Deprel: case, Head: 28\n",
      "Word: Sept, Deprel: compound, Head: 28\n",
      "Word: 28, Deprel: obl, Head: conclude\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The U.S women who are defending champions will play on Sept 25 in Philadelphia and conclude group competition on Sept 28 in Columbus Ohio'\n",
      "Word: The, Deprel: det, Head: women\n",
      "Word: U.S, Deprel: compound, Head: women\n",
      "Word: women, Deprel: nsubj, Head: play\n",
      "Word: who, Deprel: nsubj, Head: defending\n",
      "Word: are, Deprel: aux, Head: defending\n",
      "Word: defending, Deprel: acl:relcl, Head: women\n",
      "Word: champions, Deprel: obj, Head: defending\n",
      "Word: will, Deprel: aux, Head: play\n",
      "Word: play, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: Sept\n",
      "Word: Sept, Deprel: obl, Head: play\n",
      "Word: 25, Deprel: nummod, Head: Sept\n",
      "Word: in, Deprel: case, Head: Philadelphia\n",
      "Word: Philadelphia, Deprel: nmod, Head: Sept\n",
      "Word: and, Deprel: cc, Head: conclude\n",
      "Word: conclude, Deprel: conj, Head: play\n",
      "Word: group, Deprel: compound, Head: competition\n",
      "Word: competition, Deprel: obj, Head: conclude\n",
      "Word: on, Deprel: case, Head: Sept\n",
      "Word: Sept, Deprel: nmod, Head: competition\n",
      "Word: 28, Deprel: nummod, Head: Sept\n",
      "Word: in, Deprel: case, Head: Ohio\n",
      "Word: Columbus, Deprel: compound, Head: Ohio\n",
      "Word: Ohio, Deprel: nmod, Head: Sept\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Judge Leroy Millette Jr can reduce the punishment to life in prison without parole when Muhammad is formally sentenced Feb 12 but Virginia judges rarely take such action'\n",
      "Word: Judge, Deprel: compound, Head: Leroy\n",
      "Word: Leroy, Deprel: nsubj, Head: reduce\n",
      "Word: Millette, Deprel: flat, Head: Leroy\n",
      "Word: Jr, Deprel: flat, Head: Leroy\n",
      "Word: can, Deprel: aux, Head: reduce\n",
      "Word: reduce, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: punishment\n",
      "Word: punishment, Deprel: obj, Head: reduce\n",
      "Word: to, Deprel: case, Head: life\n",
      "Word: life, Deprel: obl, Head: reduce\n",
      "Word: in, Deprel: case, Head: prison\n",
      "Word: prison, Deprel: nmod, Head: life\n",
      "Word: without, Deprel: case, Head: parole\n",
      "Word: parole, Deprel: obl, Head: reduce\n",
      "Word: when, Deprel: advmod, Head: sentenced\n",
      "Word: Muhammad, Deprel: nsubj:pass, Head: sentenced\n",
      "Word: is, Deprel: aux:pass, Head: sentenced\n",
      "Word: formally, Deprel: advmod, Head: sentenced\n",
      "Word: sentenced, Deprel: advcl, Head: reduce\n",
      "Word: Feb, Deprel: obl:tmod, Head: sentenced\n",
      "Word: 12, Deprel: nummod, Head: Feb\n",
      "Word: but, Deprel: cc, Head: take\n",
      "Word: Virginia, Deprel: compound, Head: judges\n",
      "Word: judges, Deprel: nsubj, Head: take\n",
      "Word: rarely, Deprel: advmod, Head: take\n",
      "Word: take, Deprel: conj, Head: reduce\n",
      "Word: such, Deprel: amod, Head: action\n",
      "Word: action, Deprel: obj, Head: take\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Though the judge can reduce the punishment to life in prison without parole experts say Virginia judges rarely take that opportunity'\n",
      "Word: Though, Deprel: mark, Head: reduce\n",
      "Word: the, Deprel: det, Head: judge\n",
      "Word: judge, Deprel: nsubj, Head: reduce\n",
      "Word: can, Deprel: aux, Head: reduce\n",
      "Word: reduce, Deprel: advcl, Head: say\n",
      "Word: the, Deprel: det, Head: punishment\n",
      "Word: punishment, Deprel: obj, Head: reduce\n",
      "Word: to, Deprel: case, Head: life\n",
      "Word: life, Deprel: obl, Head: reduce\n",
      "Word: in, Deprel: case, Head: prison\n",
      "Word: prison, Deprel: nmod, Head: life\n",
      "Word: without, Deprel: case, Head: experts\n",
      "Word: parole, Deprel: compound, Head: experts\n",
      "Word: experts, Deprel: obl, Head: reduce\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: Virginia, Deprel: compound, Head: judges\n",
      "Word: judges, Deprel: nsubj, Head: take\n",
      "Word: rarely, Deprel: advmod, Head: take\n",
      "Word: take, Deprel: ccomp, Head: say\n",
      "Word: that, Deprel: det, Head: opportunity\n",
      "Word: opportunity, Deprel: obj, Head: take\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr McDonnell is leading Grant Thornton International s inquiry into the Italian business'\n",
      "Word: Mr, Deprel: nsubj, Head: leading\n",
      "Word: McDonnell, Deprel: flat, Head: Mr\n",
      "Word: is, Deprel: aux, Head: leading\n",
      "Word: leading, Deprel: root, Head: ROOT\n",
      "Word: Grant, Deprel: compound, Head: International\n",
      "Word: Thornton, Deprel: compound, Head: International\n",
      "Word: International, Deprel: nmod:poss, Head: inquiry\n",
      "Word: s, Deprel: case, Head: International\n",
      "Word: inquiry, Deprel: obj, Head: leading\n",
      "Word: into, Deprel: case, Head: business\n",
      "Word: the, Deprel: det, Head: business\n",
      "Word: Italian, Deprel: amod, Head: business\n",
      "Word: business, Deprel: nmod, Head: inquiry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr McDonnell wants to establish if the Italian business followed Grant Thornton s audit procedures'\n",
      "Word: Mr, Deprel: nsubj, Head: wants\n",
      "Word: McDonnell, Deprel: flat, Head: Mr\n",
      "Word: wants, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: establish\n",
      "Word: establish, Deprel: xcomp, Head: wants\n",
      "Word: if, Deprel: mark, Head: followed\n",
      "Word: the, Deprel: det, Head: business\n",
      "Word: Italian, Deprel: amod, Head: business\n",
      "Word: business, Deprel: nsubj, Head: followed\n",
      "Word: followed, Deprel: ccomp, Head: establish\n",
      "Word: Grant, Deprel: nmod:poss, Head: procedures\n",
      "Word: Thornton, Deprel: flat, Head: Grant\n",
      "Word: s, Deprel: case, Head: Grant\n",
      "Word: audit, Deprel: compound, Head: procedures\n",
      "Word: procedures, Deprel: obj, Head: followed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A spokeswoman at Strong Memorial Hospital said Doud was in satisfactory condition Tuesday night'\n",
      "Word: A, Deprel: det, Head: spokeswoman\n",
      "Word: spokeswoman, Deprel: nsubj, Head: said\n",
      "Word: at, Deprel: case, Head: Hospital\n",
      "Word: Strong, Deprel: amod, Head: Hospital\n",
      "Word: Memorial, Deprel: compound, Head: Hospital\n",
      "Word: Hospital, Deprel: nmod, Head: spokeswoman\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Doud, Deprel: nsubj, Head: condition\n",
      "Word: was, Deprel: cop, Head: condition\n",
      "Word: in, Deprel: case, Head: condition\n",
      "Word: satisfactory, Deprel: amod, Head: condition\n",
      "Word: condition, Deprel: ccomp, Head: said\n",
      "Word: Tuesday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: condition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A spokesman at Strong Memorial Hospital said Doud was under evaluation Tuesday evening in the emergency room'\n",
      "Word: A, Deprel: det, Head: spokesman\n",
      "Word: spokesman, Deprel: nsubj, Head: said\n",
      "Word: at, Deprel: case, Head: Hospital\n",
      "Word: Strong, Deprel: amod, Head: Hospital\n",
      "Word: Memorial, Deprel: compound, Head: Hospital\n",
      "Word: Hospital, Deprel: nmod, Head: spokesman\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Doud, Deprel: nsubj, Head: evaluation\n",
      "Word: was, Deprel: cop, Head: evaluation\n",
      "Word: under, Deprel: case, Head: evaluation\n",
      "Word: evaluation, Deprel: ccomp, Head: said\n",
      "Word: Tuesday, Deprel: compound, Head: evening\n",
      "Word: evening, Deprel: obl:tmod, Head: evaluation\n",
      "Word: in, Deprel: case, Head: room\n",
      "Word: the, Deprel: det, Head: room\n",
      "Word: emergency, Deprel: compound, Head: room\n",
      "Word: room, Deprel: obl, Head: evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Ray Brent Marsh 29 faces multiple counts of burial service fraud making false statements abuse of a dead body and theft'\n",
      "Word: Ray, Deprel: nsubj, Head: faces\n",
      "Word: Brent, Deprel: flat, Head: Ray\n",
      "Word: Marsh, Deprel: flat, Head: Ray\n",
      "Word: 29, Deprel: nummod, Head: Ray\n",
      "Word: faces, Deprel: root, Head: ROOT\n",
      "Word: multiple, Deprel: amod, Head: counts\n",
      "Word: counts, Deprel: obj, Head: faces\n",
      "Word: of, Deprel: case, Head: fraud\n",
      "Word: burial, Deprel: compound, Head: service\n",
      "Word: service, Deprel: compound, Head: fraud\n",
      "Word: fraud, Deprel: nmod, Head: counts\n",
      "Word: making, Deprel: acl, Head: counts\n",
      "Word: false, Deprel: amod, Head: statements\n",
      "Word: statements, Deprel: compound, Head: abuse\n",
      "Word: abuse, Deprel: obj, Head: making\n",
      "Word: of, Deprel: case, Head: body\n",
      "Word: a, Deprel: det, Head: body\n",
      "Word: dead, Deprel: amod, Head: body\n",
      "Word: body, Deprel: nmod, Head: abuse\n",
      "Word: and, Deprel: cc, Head: theft\n",
      "Word: theft, Deprel: conj, Head: body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Ray Brent Marsh 29 also faces charges of abuse of a body and theft'\n",
      "Word: Ray, Deprel: nsubj, Head: faces\n",
      "Word: Brent, Deprel: flat, Head: Ray\n",
      "Word: Marsh, Deprel: flat, Head: Ray\n",
      "Word: 29, Deprel: nummod, Head: Ray\n",
      "Word: also, Deprel: advmod, Head: faces\n",
      "Word: faces, Deprel: root, Head: ROOT\n",
      "Word: charges, Deprel: obj, Head: faces\n",
      "Word: of, Deprel: case, Head: abuse\n",
      "Word: abuse, Deprel: nmod, Head: charges\n",
      "Word: of, Deprel: case, Head: body\n",
      "Word: a, Deprel: det, Head: body\n",
      "Word: body, Deprel: nmod, Head: abuse\n",
      "Word: and, Deprel: cc, Head: theft\n",
      "Word: theft, Deprel: conj, Head: body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'After that college President Paul Pribbenow told him to wrap up his speech'\n",
      "Word: After, Deprel: advmod, Head: told\n",
      "Word: that, Deprel: det, Head: President\n",
      "Word: college, Deprel: compound, Head: President\n",
      "Word: President, Deprel: nsubj, Head: told\n",
      "Word: Paul, Deprel: flat, Head: President\n",
      "Word: Pribbenow, Deprel: flat, Head: President\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: him, Deprel: iobj, Head: told\n",
      "Word: to, Deprel: mark, Head: wrap\n",
      "Word: wrap, Deprel: xcomp, Head: told\n",
      "Word: up, Deprel: compound:prt, Head: wrap\n",
      "Word: his, Deprel: nmod:poss, Head: speech\n",
      "Word: speech, Deprel: obj, Head: wrap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'After Hedges microphone was unplugged for a second time Pribbenow told him to wrap up his speech'\n",
      "Word: After, Deprel: mark, Head: unplugged\n",
      "Word: Hedges, Deprel: compound, Head: microphone\n",
      "Word: microphone, Deprel: nsubj:pass, Head: unplugged\n",
      "Word: was, Deprel: aux:pass, Head: unplugged\n",
      "Word: unplugged, Deprel: advcl, Head: told\n",
      "Word: for, Deprel: case, Head: time\n",
      "Word: a, Deprel: det, Head: time\n",
      "Word: second, Deprel: amod, Head: time\n",
      "Word: time, Deprel: obl, Head: unplugged\n",
      "Word: Pribbenow, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: him, Deprel: iobj, Head: told\n",
      "Word: to, Deprel: mark, Head: wrap\n",
      "Word: wrap, Deprel: xcomp, Head: told\n",
      "Word: up, Deprel: compound:prt, Head: wrap\n",
      "Word: his, Deprel: nmod:poss, Head: speech\n",
      "Word: speech, Deprel: obj, Head: wrap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'For the 12-month period ending June 30 high-speed lines installed in homes and businesses increased by 45 percent'\n",
      "Word: For, Deprel: case, Head: period\n",
      "Word: the, Deprel: det, Head: period\n",
      "Word: 12-month, Deprel: amod, Head: period\n",
      "Word: period, Deprel: obl, Head: increased\n",
      "Word: ending, Deprel: acl, Head: period\n",
      "Word: June, Deprel: compound, Head: lines\n",
      "Word: 30, Deprel: nummod, Head: June\n",
      "Word: high-speed, Deprel: compound, Head: lines\n",
      "Word: lines, Deprel: nsubj, Head: increased\n",
      "Word: installed, Deprel: acl, Head: lines\n",
      "Word: in, Deprel: case, Head: homes\n",
      "Word: homes, Deprel: obl, Head: installed\n",
      "Word: and, Deprel: cc, Head: businesses\n",
      "Word: businesses, Deprel: conj, Head: homes\n",
      "Word: increased, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: percent\n",
      "Word: 45, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: increased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'For the full year period ending June 30 2003 high-speed lines increased by 45 percent'\n",
      "Word: For, Deprel: case, Head: period\n",
      "Word: the, Deprel: det, Head: period\n",
      "Word: full, Deprel: amod, Head: year\n",
      "Word: year, Deprel: compound, Head: period\n",
      "Word: period, Deprel: obl, Head: increased\n",
      "Word: ending, Deprel: acl, Head: period\n",
      "Word: June, Deprel: obl:tmod, Head: ending\n",
      "Word: 30, Deprel: nummod, Head: June\n",
      "Word: 2003, Deprel: nummod, Head: June\n",
      "Word: high-speed, Deprel: compound, Head: lines\n",
      "Word: lines, Deprel: nsubj, Head: increased\n",
      "Word: increased, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: percent\n",
      "Word: 45, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: increased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Ricky Clemons brief troubled Missouri basketball career is over'\n",
      "Word: Ricky, Deprel: compound, Head: career\n",
      "Word: Clemons, Deprel: flat, Head: Ricky\n",
      "Word: brief, Deprel: amod, Head: career\n",
      "Word: troubled, Deprel: amod, Head: career\n",
      "Word: Missouri, Deprel: compound, Head: career\n",
      "Word: basketball, Deprel: compound, Head: career\n",
      "Word: career, Deprel: nsubj, Head: over\n",
      "Word: is, Deprel: cop, Head: over\n",
      "Word: over, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Missouri kicked Ricky Clemons off its team ending his troubled career there'\n",
      "Word: Missouri, Deprel: nsubj, Head: kicked\n",
      "Word: kicked, Deprel: root, Head: ROOT\n",
      "Word: Ricky, Deprel: obj, Head: kicked\n",
      "Word: Clemons, Deprel: flat, Head: Ricky\n",
      "Word: off, Deprel: case, Head: team\n",
      "Word: its, Deprel: nmod:poss, Head: team\n",
      "Word: team, Deprel: obl, Head: kicked\n",
      "Word: ending, Deprel: advcl, Head: kicked\n",
      "Word: his, Deprel: nmod:poss, Head: career\n",
      "Word: troubled, Deprel: amod, Head: career\n",
      "Word: career, Deprel: obj, Head: ending\n",
      "Word: there, Deprel: advmod, Head: ending\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'US military officials say rotor wash from the helicopter might have blown down the banner'\n",
      "Word: US, Deprel: compound, Head: officials\n",
      "Word: military, Deprel: amod, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: say\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: rotor, Deprel: compound, Head: wash\n",
      "Word: wash, Deprel: nsubj, Head: blown\n",
      "Word: from, Deprel: case, Head: helicopter\n",
      "Word: the, Deprel: det, Head: helicopter\n",
      "Word: helicopter, Deprel: nmod, Head: wash\n",
      "Word: might, Deprel: aux, Head: blown\n",
      "Word: have, Deprel: aux, Head: blown\n",
      "Word: blown, Deprel: ccomp, Head: say\n",
      "Word: down, Deprel: compound:prt, Head: blown\n",
      "Word: the, Deprel: det, Head: banner\n",
      "Word: banner, Deprel: obj, Head: blown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'US officials said downward rotor wash generated by the hovering helicopter stripped the flag from the tower'\n",
      "Word: US, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: downward, Deprel: amod, Head: wash\n",
      "Word: rotor, Deprel: compound, Head: wash\n",
      "Word: wash, Deprel: nsubj, Head: stripped\n",
      "Word: generated, Deprel: acl, Head: wash\n",
      "Word: by, Deprel: case, Head: helicopter\n",
      "Word: the, Deprel: det, Head: helicopter\n",
      "Word: hovering, Deprel: amod, Head: helicopter\n",
      "Word: helicopter, Deprel: obl, Head: generated\n",
      "Word: stripped, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: flag\n",
      "Word: flag, Deprel: obj, Head: stripped\n",
      "Word: from, Deprel: case, Head: tower\n",
      "Word: the, Deprel: det, Head: tower\n",
      "Word: tower, Deprel: obl, Head: stripped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The industry s largest association is urging its members not call the more than 50 million home and cellular numbers on the list'\n",
      "Word: The, Deprel: det, Head: industry\n",
      "Word: industry, Deprel: nmod:poss, Head: association\n",
      "Word: s, Deprel: case, Head: industry\n",
      "Word: largest, Deprel: amod, Head: association\n",
      "Word: association, Deprel: nsubj, Head: urging\n",
      "Word: is, Deprel: aux, Head: urging\n",
      "Word: urging, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: members\n",
      "Word: members, Deprel: iobj, Head: urging\n",
      "Word: not, Deprel: advmod, Head: call\n",
      "Word: call, Deprel: xcomp, Head: urging\n",
      "Word: the, Deprel: det, Head: numbers\n",
      "Word: more, Deprel: advmod, Head: million\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 50, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: numbers\n",
      "Word: home, Deprel: compound, Head: numbers\n",
      "Word: and, Deprel: cc, Head: cellular\n",
      "Word: cellular, Deprel: conj, Head: home\n",
      "Word: numbers, Deprel: obj, Head: call\n",
      "Word: on, Deprel: case, Head: list\n",
      "Word: the, Deprel: det, Head: list\n",
      "Word: list, Deprel: obl, Head: call\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Meantime the Direct Marketing Association said its members should not call the nearly 51 million numbers on the list'\n",
      "Word: Meantime, Deprel: advmod, Head: said\n",
      "Word: the, Deprel: det, Head: Association\n",
      "Word: Direct, Deprel: amod, Head: Marketing\n",
      "Word: Marketing, Deprel: compound, Head: Association\n",
      "Word: Association, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: members\n",
      "Word: members, Deprel: nsubj, Head: call\n",
      "Word: should, Deprel: aux, Head: call\n",
      "Word: not, Deprel: advmod, Head: call\n",
      "Word: call, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: numbers\n",
      "Word: nearly, Deprel: advmod, Head: million\n",
      "Word: 51, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: numbers\n",
      "Word: numbers, Deprel: obj, Head: call\n",
      "Word: on, Deprel: case, Head: list\n",
      "Word: the, Deprel: det, Head: list\n",
      "Word: list, Deprel: obl, Head: call\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The settlement taking effect this week was reached less than two months after O'Malley took the helm of the nation s fourth-largest archdiocese'\n",
      "Word: The, Deprel: det, Head: settlement\n",
      "Word: settlement, Deprel: nsubj:pass, Head: reached\n",
      "Word: taking, Deprel: acl, Head: settlement\n",
      "Word: effect, Deprel: obj, Head: taking\n",
      "Word: this, Deprel: det, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: taking\n",
      "Word: was, Deprel: aux:pass, Head: reached\n",
      "Word: reached, Deprel: root, Head: ROOT\n",
      "Word: less, Deprel: advmod, Head: two\n",
      "Word: than, Deprel: fixed, Head: less\n",
      "Word: two, Deprel: nummod, Head: months\n",
      "Word: months, Deprel: obl:npmod, Head: after\n",
      "Word: after, Deprel: mark, Head: took\n",
      "Word: O'Malley, Deprel: nsubj, Head: took\n",
      "Word: took, Deprel: advcl, Head: reached\n",
      "Word: the, Deprel: det, Head: helm\n",
      "Word: helm, Deprel: obj, Head: took\n",
      "Word: of, Deprel: case, Head: archdiocese\n",
      "Word: the, Deprel: det, Head: nation\n",
      "Word: nation, Deprel: nmod:poss, Head: archdiocese\n",
      "Word: s, Deprel: case, Head: nation\n",
      "Word: fourth-largest, Deprel: amod, Head: archdiocese\n",
      "Word: archdiocese, Deprel: nmod, Head: helm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The 85 million agreement was reached in September less than two months after Archbishop Sean O'Malley took over as leader of the nation s fourth-largest diocese'\n",
      "Word: The, Deprel: det, Head: agreement\n",
      "Word: 85, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: agreement\n",
      "Word: agreement, Deprel: nsubj:pass, Head: reached\n",
      "Word: was, Deprel: aux:pass, Head: reached\n",
      "Word: reached, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: September\n",
      "Word: September, Deprel: obl, Head: reached\n",
      "Word: less, Deprel: advmod, Head: two\n",
      "Word: than, Deprel: fixed, Head: less\n",
      "Word: two, Deprel: nummod, Head: months\n",
      "Word: months, Deprel: obl:tmod, Head: reached\n",
      "Word: after, Deprel: mark, Head: took\n",
      "Word: Archbishop, Deprel: nsubj, Head: took\n",
      "Word: Sean, Deprel: flat, Head: Archbishop\n",
      "Word: O'Malley, Deprel: flat, Head: Archbishop\n",
      "Word: took, Deprel: advcl, Head: reached\n",
      "Word: over, Deprel: compound:prt, Head: took\n",
      "Word: as, Deprel: case, Head: leader\n",
      "Word: leader, Deprel: obl, Head: took\n",
      "Word: of, Deprel: case, Head: diocese\n",
      "Word: the, Deprel: det, Head: nation\n",
      "Word: nation, Deprel: nmod:poss, Head: diocese\n",
      "Word: s, Deprel: case, Head: nation\n",
      "Word: fourth-largest, Deprel: amod, Head: diocese\n",
      "Word: diocese, Deprel: nmod, Head: leader\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The U.S Capitol was evacuated yesterday after authorities detected a possibly hazardous material in the basement of the Senate wing Capitol Police said'\n",
      "Word: The, Deprel: det, Head: Capitol\n",
      "Word: U.S, Deprel: compound, Head: Capitol\n",
      "Word: Capitol, Deprel: nsubj:pass, Head: evacuated\n",
      "Word: was, Deprel: aux:pass, Head: evacuated\n",
      "Word: evacuated, Deprel: root, Head: ROOT\n",
      "Word: yesterday, Deprel: obl:tmod, Head: evacuated\n",
      "Word: after, Deprel: mark, Head: detected\n",
      "Word: authorities, Deprel: nsubj, Head: detected\n",
      "Word: detected, Deprel: advcl, Head: evacuated\n",
      "Word: a, Deprel: det, Head: material\n",
      "Word: possibly, Deprel: advmod, Head: hazardous\n",
      "Word: hazardous, Deprel: amod, Head: material\n",
      "Word: material, Deprel: obj, Head: detected\n",
      "Word: in, Deprel: case, Head: basement\n",
      "Word: the, Deprel: det, Head: basement\n",
      "Word: basement, Deprel: nmod, Head: material\n",
      "Word: of, Deprel: case, Head: Police\n",
      "Word: the, Deprel: det, Head: Police\n",
      "Word: Senate, Deprel: compound, Head: Police\n",
      "Word: wing, Deprel: compound, Head: Police\n",
      "Word: Capitol, Deprel: compound, Head: Police\n",
      "Word: Police, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: material\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'U.S Capitol Police evacuated the Capitol yesterday after a sensor detected a possible biohazard in the Senate wing but authorities later said it was a false alarm'\n",
      "Word: U.S, Deprel: compound, Head: Police\n",
      "Word: Capitol, Deprel: compound, Head: Police\n",
      "Word: Police, Deprel: nsubj, Head: evacuated\n",
      "Word: evacuated, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: Capitol\n",
      "Word: Capitol, Deprel: obj, Head: evacuated\n",
      "Word: yesterday, Deprel: obl:tmod, Head: evacuated\n",
      "Word: after, Deprel: mark, Head: detected\n",
      "Word: a, Deprel: det, Head: sensor\n",
      "Word: sensor, Deprel: nsubj, Head: detected\n",
      "Word: detected, Deprel: advcl, Head: evacuated\n",
      "Word: a, Deprel: det, Head: biohazard\n",
      "Word: possible, Deprel: amod, Head: biohazard\n",
      "Word: biohazard, Deprel: obj, Head: detected\n",
      "Word: in, Deprel: case, Head: wing\n",
      "Word: the, Deprel: det, Head: wing\n",
      "Word: Senate, Deprel: compound, Head: wing\n",
      "Word: wing, Deprel: obl, Head: detected\n",
      "Word: but, Deprel: cc, Head: said\n",
      "Word: authorities, Deprel: nsubj, Head: said\n",
      "Word: later, Deprel: advmod, Head: said\n",
      "Word: said, Deprel: conj, Head: evacuated\n",
      "Word: it, Deprel: nsubj, Head: alarm\n",
      "Word: was, Deprel: cop, Head: alarm\n",
      "Word: a, Deprel: det, Head: alarm\n",
      "Word: false, Deprel: amod, Head: alarm\n",
      "Word: alarm, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The former president also gave numerous speeches in 2002 without compensation said his spokesman Jim Kennedy'\n",
      "Word: The, Deprel: det, Head: president\n",
      "Word: former, Deprel: amod, Head: president\n",
      "Word: president, Deprel: nsubj, Head: gave\n",
      "Word: also, Deprel: advmod, Head: gave\n",
      "Word: gave, Deprel: root, Head: ROOT\n",
      "Word: numerous, Deprel: amod, Head: speeches\n",
      "Word: speeches, Deprel: obj, Head: gave\n",
      "Word: in, Deprel: case, Head: 2002\n",
      "Word: 2002, Deprel: obl, Head: gave\n",
      "Word: without, Deprel: case, Head: compensation\n",
      "Word: compensation, Deprel: obl, Head: gave\n",
      "Word: said, Deprel: advcl, Head: gave\n",
      "Word: his, Deprel: nmod:poss, Head: spokesman\n",
      "Word: spokesman, Deprel: compound, Head: Jim\n",
      "Word: Jim, Deprel: obj, Head: said\n",
      "Word: Kennedy, Deprel: flat, Head: Jim\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'His spokesman Jim Kennedy said the former president also gave more than 70 speeches in 2002 without compensation'\n",
      "Word: His, Deprel: nmod:poss, Head: Jim\n",
      "Word: spokesman, Deprel: compound, Head: Jim\n",
      "Word: Jim, Deprel: nsubj, Head: said\n",
      "Word: Kennedy, Deprel: flat, Head: Jim\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: president\n",
      "Word: former, Deprel: amod, Head: president\n",
      "Word: president, Deprel: nsubj, Head: gave\n",
      "Word: also, Deprel: advmod, Head: gave\n",
      "Word: gave, Deprel: ccomp, Head: said\n",
      "Word: more, Deprel: advmod, Head: 70\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 70, Deprel: nummod, Head: speeches\n",
      "Word: speeches, Deprel: obj, Head: gave\n",
      "Word: in, Deprel: case, Head: 2002\n",
      "Word: 2002, Deprel: obl, Head: gave\n",
      "Word: without, Deprel: case, Head: compensation\n",
      "Word: compensation, Deprel: obl, Head: gave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index SPX was down 0.04 points or 0 percent at 971.52'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broader, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: s\n",
      "Word: Poor, Deprel: amod, Head: s\n",
      "Word: s, Deprel: compound, Head: Index\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: down\n",
      "Word: was, Deprel: cop, Head: down\n",
      "Word: down, Deprel: root, Head: ROOT\n",
      "Word: 0.04, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: down\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 971.52\n",
      "Word: 971.52, Deprel: obl, Head: down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Standard Poor s 500 stock index futures for June were down 2.60 points at 965.70 while Nasdaq futures were down 7.50 points at 1,183.50'\n",
      "Word: Standard, Deprel: amod, Head: Poor\n",
      "Word: Poor, Deprel: nmod:poss, Head: futures\n",
      "Word: s, Deprel: case, Head: Poor\n",
      "Word: 500, Deprel: nummod, Head: index\n",
      "Word: stock, Deprel: compound, Head: index\n",
      "Word: index, Deprel: compound, Head: futures\n",
      "Word: futures, Deprel: nsubj, Head: down\n",
      "Word: for, Deprel: case, Head: June\n",
      "Word: June, Deprel: nmod, Head: futures\n",
      "Word: were, Deprel: cop, Head: down\n",
      "Word: down, Deprel: root, Head: ROOT\n",
      "Word: 2.60, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: down\n",
      "Word: at, Deprel: case, Head: 965.70\n",
      "Word: 965.70, Deprel: obl, Head: down\n",
      "Word: while, Deprel: mark, Head: down\n",
      "Word: Nasdaq, Deprel: compound, Head: futures\n",
      "Word: futures, Deprel: nsubj, Head: down\n",
      "Word: were, Deprel: cop, Head: down\n",
      "Word: down, Deprel: advcl, Head: down\n",
      "Word: 7.50, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: down\n",
      "Word: at, Deprel: case, Head: 1,183.50\n",
      "Word: 1,183.50, Deprel: obl, Head: down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dubbed Project Mad Hatter the Linux-based desktop is being promoted by Sun as a more secure and less expensive alternative to Windows'\n",
      "Word: Dubbed, Deprel: advcl, Head: promoted\n",
      "Word: Project, Deprel: compound, Head: Hatter\n",
      "Word: Mad, Deprel: amod, Head: Hatter\n",
      "Word: Hatter, Deprel: obj, Head: Dubbed\n",
      "Word: the, Deprel: det, Head: desktop\n",
      "Word: Linux-based, Deprel: amod, Head: desktop\n",
      "Word: desktop, Deprel: nsubj:pass, Head: promoted\n",
      "Word: is, Deprel: aux, Head: promoted\n",
      "Word: being, Deprel: aux:pass, Head: promoted\n",
      "Word: promoted, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: Sun\n",
      "Word: Sun, Deprel: obl, Head: promoted\n",
      "Word: as, Deprel: case, Head: alternative\n",
      "Word: a, Deprel: det, Head: alternative\n",
      "Word: more, Deprel: advmod, Head: secure\n",
      "Word: secure, Deprel: amod, Head: alternative\n",
      "Word: and, Deprel: cc, Head: expensive\n",
      "Word: less, Deprel: advmod, Head: expensive\n",
      "Word: expensive, Deprel: conj, Head: secure\n",
      "Word: alternative, Deprel: obl, Head: promoted\n",
      "Word: to, Deprel: case, Head: Windows\n",
      "Word: Windows, Deprel: nmod, Head: alternative\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Designed to compete with Microsoft Corp Project Mad Hatter is being positioned by Sun as a cheaper secure alternative desktop operating system to Microsoft s various desktop offerings'\n",
      "Word: Designed, Deprel: advcl, Head: positioned\n",
      "Word: to, Deprel: mark, Head: compete\n",
      "Word: compete, Deprel: advcl, Head: Designed\n",
      "Word: with, Deprel: case, Head: Hatter\n",
      "Word: Microsoft, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: compound, Head: Hatter\n",
      "Word: Project, Deprel: compound, Head: Hatter\n",
      "Word: Mad, Deprel: amod, Head: Hatter\n",
      "Word: Hatter, Deprel: obl, Head: compete\n",
      "Word: is, Deprel: aux, Head: positioned\n",
      "Word: being, Deprel: aux:pass, Head: positioned\n",
      "Word: positioned, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: Sun\n",
      "Word: Sun, Deprel: obl, Head: positioned\n",
      "Word: as, Deprel: case, Head: system\n",
      "Word: a, Deprel: det, Head: system\n",
      "Word: cheaper, Deprel: amod, Head: system\n",
      "Word: secure, Deprel: amod, Head: system\n",
      "Word: alternative, Deprel: amod, Head: system\n",
      "Word: desktop, Deprel: compound, Head: system\n",
      "Word: operating, Deprel: compound, Head: system\n",
      "Word: system, Deprel: obl, Head: positioned\n",
      "Word: to, Deprel: case, Head: offerings\n",
      "Word: Microsoft, Deprel: nmod:poss, Head: offerings\n",
      "Word: s, Deprel: case, Head: Microsoft\n",
      "Word: various, Deprel: amod, Head: offerings\n",
      "Word: desktop, Deprel: compound, Head: offerings\n",
      "Word: offerings, Deprel: obl, Head: positioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The workers accuse General Dynamics of reverse age discrimination because of a change in retirement benefits in 1997'\n",
      "Word: The, Deprel: det, Head: workers\n",
      "Word: workers, Deprel: nsubj, Head: accuse\n",
      "Word: accuse, Deprel: root, Head: ROOT\n",
      "Word: General, Deprel: compound, Head: Dynamics\n",
      "Word: Dynamics, Deprel: obj, Head: accuse\n",
      "Word: of, Deprel: case, Head: discrimination\n",
      "Word: reverse, Deprel: amod, Head: age\n",
      "Word: age, Deprel: compound, Head: discrimination\n",
      "Word: discrimination, Deprel: obl, Head: accuse\n",
      "Word: because, Deprel: case, Head: change\n",
      "Word: of, Deprel: fixed, Head: because\n",
      "Word: a, Deprel: det, Head: change\n",
      "Word: change, Deprel: obl, Head: accuse\n",
      "Word: in, Deprel: case, Head: benefits\n",
      "Word: retirement, Deprel: compound, Head: benefits\n",
      "Word: benefits, Deprel: nmod, Head: change\n",
      "Word: in, Deprel: case, Head: 1997\n",
      "Word: 1997, Deprel: nmod, Head: change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'General Dynamics was sued when it changed its retirement benefits in 1997'\n",
      "Word: General, Deprel: compound, Head: Dynamics\n",
      "Word: Dynamics, Deprel: nsubj:pass, Head: sued\n",
      "Word: was, Deprel: aux:pass, Head: sued\n",
      "Word: sued, Deprel: root, Head: ROOT\n",
      "Word: when, Deprel: advmod, Head: changed\n",
      "Word: it, Deprel: nsubj, Head: changed\n",
      "Word: changed, Deprel: advcl, Head: sued\n",
      "Word: its, Deprel: nmod:poss, Head: benefits\n",
      "Word: retirement, Deprel: compound, Head: benefits\n",
      "Word: benefits, Deprel: obj, Head: changed\n",
      "Word: in, Deprel: case, Head: 1997\n",
      "Word: 1997, Deprel: obl, Head: changed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The tech-laced Nasdaq Composite Index IXIC eased 5.16 points or 0.32 percent at 1,590.75 breaking a six-day string of gains'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: tech-laced, Deprel: amod, Head: IXIC\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: eased\n",
      "Word: eased, Deprel: root, Head: ROOT\n",
      "Word: 5.16, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: eased\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.32, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 1,590.75\n",
      "Word: 1,590.75, Deprel: obl, Head: eased\n",
      "Word: breaking, Deprel: advcl, Head: eased\n",
      "Word: a, Deprel: det, Head: string\n",
      "Word: six-day, Deprel: amod, Head: string\n",
      "Word: string, Deprel: obj, Head: breaking\n",
      "Word: of, Deprel: case, Head: gains\n",
      "Word: gains, Deprel: nmod, Head: string\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The tech-heavy Nasdaq Composite Index IXIC was off 0.11 percent or 1.78 points at 1,594.13'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: tech-heavy, Deprel: amod, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: off\n",
      "Word: was, Deprel: cop, Head: off\n",
      "Word: off, Deprel: root, Head: ROOT\n",
      "Word: 0.11, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: off\n",
      "Word: or, Deprel: cc, Head: points\n",
      "Word: 1.78, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: conj, Head: percent\n",
      "Word: at, Deprel: case, Head: 1,594.13\n",
      "Word: 1,594.13, Deprel: obl, Head: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A key figure in former state Treasurer Paul Silvester s bribery scheme was accused Wednesday of changing his story about Silvester s alleged corrupt dealings with a Boston investment firm'\n",
      "Word: A, Deprel: det, Head: figure\n",
      "Word: key, Deprel: amod, Head: figure\n",
      "Word: figure, Deprel: nsubj:pass, Head: accused\n",
      "Word: in, Deprel: case, Head: scheme\n",
      "Word: former, Deprel: amod, Head: Treasurer\n",
      "Word: state, Deprel: compound, Head: Treasurer\n",
      "Word: Treasurer, Deprel: nmod:poss, Head: scheme\n",
      "Word: Paul, Deprel: nmod:poss, Head: scheme\n",
      "Word: Silvester, Deprel: flat, Head: Paul\n",
      "Word: s, Deprel: case, Head: Treasurer\n",
      "Word: bribery, Deprel: compound, Head: scheme\n",
      "Word: scheme, Deprel: nmod, Head: figure\n",
      "Word: was, Deprel: aux:pass, Head: accused\n",
      "Word: accused, Deprel: root, Head: ROOT\n",
      "Word: Wednesday, Deprel: obl:tmod, Head: accused\n",
      "Word: of, Deprel: mark, Head: changing\n",
      "Word: changing, Deprel: advcl, Head: accused\n",
      "Word: his, Deprel: nmod:poss, Head: story\n",
      "Word: story, Deprel: obj, Head: changing\n",
      "Word: about, Deprel: case, Head: dealings\n",
      "Word: Silvester, Deprel: nmod:poss, Head: dealings\n",
      "Word: s, Deprel: case, Head: Silvester\n",
      "Word: alleged, Deprel: amod, Head: dealings\n",
      "Word: corrupt, Deprel: amod, Head: dealings\n",
      "Word: dealings, Deprel: nmod, Head: story\n",
      "Word: with, Deprel: case, Head: firm\n",
      "Word: a, Deprel: det, Head: firm\n",
      "Word: Boston, Deprel: compound, Head: firm\n",
      "Word: investment, Deprel: compound, Head: firm\n",
      "Word: firm, Deprel: nmod, Head: dealings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A key player in former state Treasurer Paul Silvester s corruption scheme testified on Tuesday about kickbacks and bribes Silvester traded for state business'\n",
      "Word: A, Deprel: det, Head: player\n",
      "Word: key, Deprel: amod, Head: player\n",
      "Word: player, Deprel: nsubj, Head: testified\n",
      "Word: in, Deprel: case, Head: scheme\n",
      "Word: former, Deprel: amod, Head: Treasurer\n",
      "Word: state, Deprel: compound, Head: Treasurer\n",
      "Word: Treasurer, Deprel: nmod:poss, Head: scheme\n",
      "Word: Paul, Deprel: flat, Head: Treasurer\n",
      "Word: Silvester, Deprel: flat, Head: Treasurer\n",
      "Word: s, Deprel: case, Head: Treasurer\n",
      "Word: corruption, Deprel: compound, Head: scheme\n",
      "Word: scheme, Deprel: nmod, Head: player\n",
      "Word: testified, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: Tuesday\n",
      "Word: Tuesday, Deprel: obl, Head: testified\n",
      "Word: about, Deprel: case, Head: kickbacks\n",
      "Word: kickbacks, Deprel: obl, Head: testified\n",
      "Word: and, Deprel: cc, Head: bribes\n",
      "Word: bribes, Deprel: conj, Head: kickbacks\n",
      "Word: Silvester, Deprel: nsubj, Head: traded\n",
      "Word: traded, Deprel: acl:relcl, Head: kickbacks\n",
      "Word: for, Deprel: case, Head: business\n",
      "Word: state, Deprel: compound, Head: business\n",
      "Word: business, Deprel: obl, Head: traded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The mission of the CAPPS II system has been and always will be aviation security said the administration part of the Homeland Security Department'\n",
      "Word: The, Deprel: det, Head: mission\n",
      "Word: mission, Deprel: nsubj, Head: security\n",
      "Word: of, Deprel: case, Head: system\n",
      "Word: the, Deprel: det, Head: system\n",
      "Word: CAPPS, Deprel: compound, Head: system\n",
      "Word: II, Deprel: nummod, Head: CAPPS\n",
      "Word: system, Deprel: nmod, Head: mission\n",
      "Word: has, Deprel: aux, Head: security\n",
      "Word: been, Deprel: cop, Head: security\n",
      "Word: and, Deprel: cc, Head: be\n",
      "Word: always, Deprel: advmod, Head: be\n",
      "Word: will, Deprel: aux, Head: be\n",
      "Word: be, Deprel: conj, Head: been\n",
      "Word: aviation, Deprel: compound, Head: security\n",
      "Word: security, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: part\n",
      "Word: administration, Deprel: compound, Head: part\n",
      "Word: part, Deprel: obj, Head: said\n",
      "Word: of, Deprel: case, Head: Department\n",
      "Word: the, Deprel: det, Head: Department\n",
      "Word: Homeland, Deprel: compound, Head: Security\n",
      "Word: Security, Deprel: compound, Head: Department\n",
      "Word: Department, Deprel: nmod, Head: part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The mission of the CAPPS II system has been and always will be aviation security they said'\n",
      "Word: The, Deprel: det, Head: mission\n",
      "Word: mission, Deprel: nsubj, Head: security\n",
      "Word: of, Deprel: case, Head: system\n",
      "Word: the, Deprel: det, Head: system\n",
      "Word: CAPPS, Deprel: compound, Head: system\n",
      "Word: II, Deprel: nummod, Head: CAPPS\n",
      "Word: system, Deprel: nmod, Head: mission\n",
      "Word: has, Deprel: aux, Head: security\n",
      "Word: been, Deprel: cop, Head: security\n",
      "Word: and, Deprel: cc, Head: be\n",
      "Word: always, Deprel: advmod, Head: be\n",
      "Word: will, Deprel: aux, Head: be\n",
      "Word: be, Deprel: conj, Head: been\n",
      "Word: aviation, Deprel: compound, Head: security\n",
      "Word: security, Deprel: root, Head: ROOT\n",
      "Word: they, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: security\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hovan did not speak but his lawyer John Speranza said his client did not wake up that day intending to hurt anyone'\n",
      "Word: Hovan, Deprel: nsubj, Head: speak\n",
      "Word: did, Deprel: aux, Head: speak\n",
      "Word: not, Deprel: advmod, Head: speak\n",
      "Word: speak, Deprel: root, Head: ROOT\n",
      "Word: but, Deprel: cc, Head: said\n",
      "Word: his, Deprel: nmod:poss, Head: lawyer\n",
      "Word: lawyer, Deprel: nsubj, Head: said\n",
      "Word: John, Deprel: appos, Head: lawyer\n",
      "Word: Speranza, Deprel: flat, Head: John\n",
      "Word: said, Deprel: conj, Head: speak\n",
      "Word: his, Deprel: nmod:poss, Head: client\n",
      "Word: client, Deprel: nsubj, Head: wake\n",
      "Word: did, Deprel: aux, Head: wake\n",
      "Word: not, Deprel: advmod, Head: wake\n",
      "Word: wake, Deprel: ccomp, Head: said\n",
      "Word: up, Deprel: compound:prt, Head: wake\n",
      "Word: that, Deprel: det, Head: day\n",
      "Word: day, Deprel: obl:tmod, Head: wake\n",
      "Word: intending, Deprel: advcl, Head: wake\n",
      "Word: to, Deprel: mark, Head: hurt\n",
      "Word: hurt, Deprel: xcomp, Head: intending\n",
      "Word: anyone, Deprel: obj, Head: hurt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hovan did not wake up that day intending to hurt anyone defense attorney John Speranza said'\n",
      "Word: Hovan, Deprel: nsubj, Head: wake\n",
      "Word: did, Deprel: aux, Head: wake\n",
      "Word: not, Deprel: advmod, Head: wake\n",
      "Word: wake, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: wake\n",
      "Word: that, Deprel: det, Head: day\n",
      "Word: day, Deprel: obl:tmod, Head: wake\n",
      "Word: intending, Deprel: advcl, Head: wake\n",
      "Word: to, Deprel: mark, Head: hurt\n",
      "Word: hurt, Deprel: xcomp, Head: intending\n",
      "Word: anyone, Deprel: compound, Head: attorney\n",
      "Word: defense, Deprel: compound, Head: attorney\n",
      "Word: attorney, Deprel: obj, Head: hurt\n",
      "Word: John, Deprel: appos, Head: attorney\n",
      "Word: Speranza, Deprel: flat, Head: John\n",
      "Word: said, Deprel: acl:relcl, Head: attorney\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We believe that it is not necessary to have a divisive confirmation fight over a Supreme Court appointment Daschle wrote'\n",
      "Word: We, Deprel: nsubj, Head: believe\n",
      "Word: believe, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: necessary\n",
      "Word: it, Deprel: expl, Head: necessary\n",
      "Word: is, Deprel: cop, Head: necessary\n",
      "Word: not, Deprel: advmod, Head: necessary\n",
      "Word: necessary, Deprel: ccomp, Head: believe\n",
      "Word: to, Deprel: mark, Head: have\n",
      "Word: have, Deprel: csubj, Head: necessary\n",
      "Word: a, Deprel: det, Head: fight\n",
      "Word: divisive, Deprel: amod, Head: fight\n",
      "Word: confirmation, Deprel: compound, Head: fight\n",
      "Word: fight, Deprel: obj, Head: have\n",
      "Word: over, Deprel: case, Head: appointment\n",
      "Word: a, Deprel: det, Head: appointment\n",
      "Word: Supreme, Deprel: amod, Head: Court\n",
      "Word: Court, Deprel: compound, Head: appointment\n",
      "Word: appointment, Deprel: nmod, Head: fight\n",
      "Word: Daschle, Deprel: nsubj, Head: wrote\n",
      "Word: wrote, Deprel: acl:relcl, Head: appointment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We believe that it is not necessary to have a divisive confirmation fight Daschle of South Dakota wrote the Republican president'\n",
      "Word: We, Deprel: nsubj, Head: believe\n",
      "Word: believe, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: necessary\n",
      "Word: it, Deprel: expl, Head: necessary\n",
      "Word: is, Deprel: cop, Head: necessary\n",
      "Word: not, Deprel: advmod, Head: necessary\n",
      "Word: necessary, Deprel: ccomp, Head: believe\n",
      "Word: to, Deprel: mark, Head: have\n",
      "Word: have, Deprel: csubj, Head: necessary\n",
      "Word: a, Deprel: det, Head: fight\n",
      "Word: divisive, Deprel: amod, Head: fight\n",
      "Word: confirmation, Deprel: compound, Head: fight\n",
      "Word: fight, Deprel: obj, Head: have\n",
      "Word: Daschle, Deprel: nsubj, Head: wrote\n",
      "Word: of, Deprel: case, Head: Dakota\n",
      "Word: South, Deprel: compound, Head: Dakota\n",
      "Word: Dakota, Deprel: nmod, Head: Daschle\n",
      "Word: wrote, Deprel: acl:relcl, Head: fight\n",
      "Word: the, Deprel: det, Head: president\n",
      "Word: Republican, Deprel: amod, Head: president\n",
      "Word: president, Deprel: obj, Head: wrote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Yahoo accounts for 159,354 of the BSD sites with 152,054 from NTT/Verio and 129,378 from Infospace the survey found'\n",
      "Word: Yahoo, Deprel: nsubj, Head: accounts\n",
      "Word: accounts, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: 159,354\n",
      "Word: 159,354, Deprel: obl, Head: accounts\n",
      "Word: of, Deprel: case, Head: sites\n",
      "Word: the, Deprel: det, Head: sites\n",
      "Word: BSD, Deprel: compound, Head: sites\n",
      "Word: sites, Deprel: nmod, Head: 159,354\n",
      "Word: with, Deprel: case, Head: 152,054\n",
      "Word: 152,054, Deprel: obl, Head: accounts\n",
      "Word: from, Deprel: case, Head: NTT/Verio\n",
      "Word: NTT/Verio, Deprel: nmod, Head: 152,054\n",
      "Word: and, Deprel: cc, Head: 129,378\n",
      "Word: 129,378, Deprel: conj, Head: NTT/Verio\n",
      "Word: from, Deprel: case, Head: Infospace\n",
      "Word: Infospace, Deprel: obl, Head: accounts\n",
      "Word: the, Deprel: det, Head: survey\n",
      "Word: survey, Deprel: nsubj, Head: found\n",
      "Word: found, Deprel: parataxis, Head: accounts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Another 152,054 are from IP services company NTT/Verio and 129,378 from InfoSpace the survey found'\n",
      "Word: Another, Deprel: det, Head: 152,054\n",
      "Word: 152,054, Deprel: nsubj, Head: company\n",
      "Word: are, Deprel: cop, Head: company\n",
      "Word: from, Deprel: case, Head: company\n",
      "Word: IP, Deprel: compound, Head: services\n",
      "Word: services, Deprel: compound, Head: company\n",
      "Word: company, Deprel: root, Head: ROOT\n",
      "Word: NTT/Verio, Deprel: compound, Head: company\n",
      "Word: and, Deprel: cc, Head: 129,378\n",
      "Word: 129,378, Deprel: conj, Head: company\n",
      "Word: from, Deprel: case, Head: InfoSpace\n",
      "Word: InfoSpace, Deprel: nmod, Head: company\n",
      "Word: the, Deprel: det, Head: survey\n",
      "Word: survey, Deprel: appos, Head: company\n",
      "Word: found, Deprel: acl, Head: survey\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Space Infrared Telescope Facility s mission is to search for the beginnings of the universe'\n",
      "Word: The, Deprel: det, Head: Facility\n",
      "Word: Space, Deprel: compound, Head: Telescope\n",
      "Word: Infrared, Deprel: amod, Head: Telescope\n",
      "Word: Telescope, Deprel: compound, Head: Facility\n",
      "Word: Facility, Deprel: nmod:poss, Head: mission\n",
      "Word: s, Deprel: case, Head: Facility\n",
      "Word: mission, Deprel: nsubj:outer, Head: search\n",
      "Word: is, Deprel: cop, Head: search\n",
      "Word: to, Deprel: mark, Head: search\n",
      "Word: search, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: beginnings\n",
      "Word: the, Deprel: det, Head: beginnings\n",
      "Word: beginnings, Deprel: obl, Head: search\n",
      "Word: of, Deprel: case, Head: universe\n",
      "Word: the, Deprel: det, Head: universe\n",
      "Word: universe, Deprel: nmod, Head: beginnings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'NASA is scheduled to launch the Space Infrared Telescope Facility on Monday morning'\n",
      "Word: NASA, Deprel: nsubj:pass, Head: scheduled\n",
      "Word: is, Deprel: aux:pass, Head: scheduled\n",
      "Word: scheduled, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: launch\n",
      "Word: launch, Deprel: xcomp, Head: scheduled\n",
      "Word: the, Deprel: det, Head: Facility\n",
      "Word: Space, Deprel: compound, Head: Telescope\n",
      "Word: Infrared, Deprel: amod, Head: Telescope\n",
      "Word: Telescope, Deprel: compound, Head: Facility\n",
      "Word: Facility, Deprel: obj, Head: launch\n",
      "Word: on, Deprel: case, Head: morning\n",
      "Word: Monday, Deprel: compound, Head: morning\n",
      "Word: morning, Deprel: obl, Head: launch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Its maker MedImmune Inc based in Gaithersburg made 4 million to 5 million doses this year'\n",
      "Word: Its, Deprel: nmod:poss, Head: Inc\n",
      "Word: maker, Deprel: compound, Head: Inc\n",
      "Word: MedImmune, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: nsubj, Head: made\n",
      "Word: based, Deprel: acl, Head: Inc\n",
      "Word: in, Deprel: case, Head: Gaithersburg\n",
      "Word: Gaithersburg, Deprel: obl, Head: based\n",
      "Word: made, Deprel: root, Head: ROOT\n",
      "Word: 4, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: doses\n",
      "Word: to, Deprel: case, Head: million\n",
      "Word: 5, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nmod, Head: million\n",
      "Word: doses, Deprel: obj, Head: made\n",
      "Word: this, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: made\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'MedImmune Vaccines the maker of FluMist made between 4 million and 5 million doses this year'\n",
      "Word: MedImmune, Deprel: compound, Head: Vaccines\n",
      "Word: Vaccines, Deprel: nsubj, Head: made\n",
      "Word: the, Deprel: det, Head: maker\n",
      "Word: maker, Deprel: nsubj, Head: made\n",
      "Word: of, Deprel: case, Head: FluMist\n",
      "Word: FluMist, Deprel: nmod, Head: maker\n",
      "Word: made, Deprel: root, Head: ROOT\n",
      "Word: between, Deprel: advmod, Head: million\n",
      "Word: 4, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: doses\n",
      "Word: and, Deprel: cc, Head: million\n",
      "Word: 5, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: conj, Head: million\n",
      "Word: doses, Deprel: obj, Head: made\n",
      "Word: this, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: made\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Kaichen appeared Wednesday in federal court on two bank robbery charges'\n",
      "Word: Kaichen, Deprel: nsubj, Head: appeared\n",
      "Word: appeared, Deprel: root, Head: ROOT\n",
      "Word: Wednesday, Deprel: obl:tmod, Head: appeared\n",
      "Word: in, Deprel: case, Head: court\n",
      "Word: federal, Deprel: amod, Head: court\n",
      "Word: court, Deprel: obl, Head: appeared\n",
      "Word: on, Deprel: case, Head: charges\n",
      "Word: two, Deprel: nummod, Head: charges\n",
      "Word: bank, Deprel: compound, Head: charges\n",
      "Word: robbery, Deprel: compound, Head: charges\n",
      "Word: charges, Deprel: obl, Head: appeared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'She appeared in federal court Wednesday but did not enter a plea'\n",
      "Word: She, Deprel: nsubj, Head: appeared\n",
      "Word: appeared, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: court\n",
      "Word: federal, Deprel: amod, Head: court\n",
      "Word: court, Deprel: obl, Head: appeared\n",
      "Word: Wednesday, Deprel: obl:tmod, Head: appeared\n",
      "Word: but, Deprel: cc, Head: enter\n",
      "Word: did, Deprel: aux, Head: enter\n",
      "Word: not, Deprel: advmod, Head: enter\n",
      "Word: enter, Deprel: conj, Head: appeared\n",
      "Word: a, Deprel: det, Head: plea\n",
      "Word: plea, Deprel: obj, Head: enter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In the latest top-level shuffle at CNN Teya Ryan is leaving her post as general manager of U.S programming the network announced'\n",
      "Word: In, Deprel: case, Head: shuffle\n",
      "Word: the, Deprel: det, Head: shuffle\n",
      "Word: latest, Deprel: amod, Head: shuffle\n",
      "Word: top-level, Deprel: amod, Head: shuffle\n",
      "Word: shuffle, Deprel: obl, Head: leaving\n",
      "Word: at, Deprel: case, Head: CNN\n",
      "Word: CNN, Deprel: nmod, Head: shuffle\n",
      "Word: Teya, Deprel: nsubj, Head: leaving\n",
      "Word: Ryan, Deprel: flat, Head: Teya\n",
      "Word: is, Deprel: aux, Head: leaving\n",
      "Word: leaving, Deprel: root, Head: ROOT\n",
      "Word: her, Deprel: nmod:poss, Head: post\n",
      "Word: post, Deprel: obj, Head: leaving\n",
      "Word: as, Deprel: case, Head: manager\n",
      "Word: general, Deprel: amod, Head: manager\n",
      "Word: manager, Deprel: obl, Head: leaving\n",
      "Word: of, Deprel: case, Head: programming\n",
      "Word: U.S, Deprel: compound, Head: programming\n",
      "Word: programming, Deprel: nmod, Head: manager\n",
      "Word: the, Deprel: det, Head: network\n",
      "Word: network, Deprel: nsubj, Head: announced\n",
      "Word: announced, Deprel: acl:relcl, Head: programming\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In CNN s latest move to rejuvenate ratings the network has ousted Teya Ryan general manager of U.S programming'\n",
      "Word: In, Deprel: case, Head: move\n",
      "Word: CNN, Deprel: nmod:poss, Head: move\n",
      "Word: s, Deprel: case, Head: CNN\n",
      "Word: latest, Deprel: amod, Head: move\n",
      "Word: move, Deprel: obl, Head: ousted\n",
      "Word: to, Deprel: mark, Head: rejuvenate\n",
      "Word: rejuvenate, Deprel: acl, Head: move\n",
      "Word: ratings, Deprel: obj, Head: rejuvenate\n",
      "Word: the, Deprel: det, Head: network\n",
      "Word: network, Deprel: nsubj, Head: ousted\n",
      "Word: has, Deprel: aux, Head: ousted\n",
      "Word: ousted, Deprel: root, Head: ROOT\n",
      "Word: Teya, Deprel: obj, Head: ousted\n",
      "Word: Ryan, Deprel: flat, Head: Teya\n",
      "Word: general, Deprel: amod, Head: manager\n",
      "Word: manager, Deprel: appos, Head: Teya\n",
      "Word: of, Deprel: case, Head: programming\n",
      "Word: U.S, Deprel: compound, Head: programming\n",
      "Word: programming, Deprel: nmod, Head: manager\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He is suspected of being a key figure in Jemaah Islamiyah the al-Qa'eda-linked terror group which has been blamed for the bombings'\n",
      "Word: He, Deprel: nsubj:pass, Head: suspected\n",
      "Word: is, Deprel: aux:pass, Head: suspected\n",
      "Word: suspected, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: mark, Head: figure\n",
      "Word: being, Deprel: cop, Head: figure\n",
      "Word: a, Deprel: det, Head: figure\n",
      "Word: key, Deprel: amod, Head: figure\n",
      "Word: figure, Deprel: advcl, Head: suspected\n",
      "Word: in, Deprel: case, Head: Islamiyah\n",
      "Word: Jemaah, Deprel: compound, Head: Islamiyah\n",
      "Word: Islamiyah, Deprel: nmod, Head: figure\n",
      "Word: the, Deprel: det, Head: group\n",
      "Word: al-Qa'eda-linked, Deprel: amod, Head: group\n",
      "Word: terror, Deprel: compound, Head: group\n",
      "Word: group, Deprel: appos, Head: figure\n",
      "Word: which, Deprel: nsubj:pass, Head: blamed\n",
      "Word: has, Deprel: aux, Head: blamed\n",
      "Word: been, Deprel: aux:pass, Head: blamed\n",
      "Word: blamed, Deprel: acl:relcl, Head: group\n",
      "Word: for, Deprel: case, Head: bombings\n",
      "Word: the, Deprel: det, Head: bombings\n",
      "Word: bombings, Deprel: obl, Head: blamed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Samudra 32 is suspected of being a key figure in the al-Qaida-linked terror group Jemaah Islamiyah which has been blamed for carrying out the bombings'\n",
      "Word: Samudra, Deprel: nsubj:pass, Head: suspected\n",
      "Word: 32, Deprel: nummod, Head: Samudra\n",
      "Word: is, Deprel: aux:pass, Head: suspected\n",
      "Word: suspected, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: mark, Head: figure\n",
      "Word: being, Deprel: cop, Head: figure\n",
      "Word: a, Deprel: det, Head: figure\n",
      "Word: key, Deprel: amod, Head: figure\n",
      "Word: figure, Deprel: advcl, Head: suspected\n",
      "Word: in, Deprel: case, Head: group\n",
      "Word: the, Deprel: det, Head: group\n",
      "Word: al-Qaida-linked, Deprel: amod, Head: group\n",
      "Word: terror, Deprel: compound, Head: group\n",
      "Word: group, Deprel: nmod, Head: figure\n",
      "Word: Jemaah, Deprel: compound, Head: Islamiyah\n",
      "Word: Islamiyah, Deprel: appos, Head: group\n",
      "Word: which, Deprel: nsubj:pass, Head: blamed\n",
      "Word: has, Deprel: aux, Head: blamed\n",
      "Word: been, Deprel: aux:pass, Head: blamed\n",
      "Word: blamed, Deprel: acl:relcl, Head: group\n",
      "Word: for, Deprel: mark, Head: carrying\n",
      "Word: carrying, Deprel: advcl, Head: blamed\n",
      "Word: out, Deprel: compound:prt, Head: carrying\n",
      "Word: the, Deprel: det, Head: bombings\n",
      "Word: bombings, Deprel: obj, Head: carrying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'About 100 firefighters are in the bosque today Albuquerque Fire Chief Robert Ortega said'\n",
      "Word: About, Deprel: advmod, Head: 100\n",
      "Word: 100, Deprel: nummod, Head: firefighters\n",
      "Word: firefighters, Deprel: nsubj, Head: bosque\n",
      "Word: are, Deprel: cop, Head: bosque\n",
      "Word: in, Deprel: case, Head: bosque\n",
      "Word: the, Deprel: det, Head: bosque\n",
      "Word: bosque, Deprel: root, Head: ROOT\n",
      "Word: today, Deprel: obl:tmod, Head: bosque\n",
      "Word: Albuquerque, Deprel: compound, Head: Chief\n",
      "Word: Fire, Deprel: compound, Head: Chief\n",
      "Word: Chief, Deprel: compound, Head: Robert\n",
      "Word: Robert, Deprel: nsubj, Head: said\n",
      "Word: Ortega, Deprel: flat, Head: Robert\n",
      "Word: said, Deprel: parataxis, Head: bosque\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We were seconds away from having that happen Albuquerque Fire Chief Robert Ortega said'\n",
      "Word: We, Deprel: nsubj, Head: away\n",
      "Word: were, Deprel: cop, Head: away\n",
      "Word: seconds, Deprel: obl:npmod, Head: away\n",
      "Word: away, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: mark, Head: having\n",
      "Word: having, Deprel: advcl, Head: away\n",
      "Word: that, Deprel: obj, Head: having\n",
      "Word: happen, Deprel: xcomp, Head: having\n",
      "Word: Albuquerque, Deprel: compound, Head: Chief\n",
      "Word: Fire, Deprel: compound, Head: Chief\n",
      "Word: Chief, Deprel: compound, Head: Robert\n",
      "Word: Robert, Deprel: nsubj, Head: said\n",
      "Word: Ortega, Deprel: flat, Head: Robert\n",
      "Word: said, Deprel: ccomp, Head: happen\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The issue has been resolved Marlins President David Samson said through a club spokesman'\n",
      "Word: The, Deprel: det, Head: issue\n",
      "Word: issue, Deprel: nsubj, Head: resolved\n",
      "Word: has, Deprel: aux, Head: resolved\n",
      "Word: been, Deprel: cop, Head: resolved\n",
      "Word: resolved, Deprel: root, Head: ROOT\n",
      "Word: Marlins, Deprel: compound, Head: President\n",
      "Word: President, Deprel: nsubj, Head: said\n",
      "Word: David, Deprel: flat, Head: President\n",
      "Word: Samson, Deprel: flat, Head: President\n",
      "Word: said, Deprel: ccomp, Head: resolved\n",
      "Word: through, Deprel: case, Head: spokesman\n",
      "Word: a, Deprel: det, Head: spokesman\n",
      "Word: club, Deprel: compound, Head: spokesman\n",
      "Word: spokesman, Deprel: obl, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Marlins only said The issue has been resolved'\n",
      "Word: The, Deprel: det, Head: Marlins\n",
      "Word: Marlins, Deprel: nsubj, Head: said\n",
      "Word: only, Deprel: advmod, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: The, Deprel: det, Head: issue\n",
      "Word: issue, Deprel: nsubj:pass, Head: resolved\n",
      "Word: has, Deprel: aux, Head: resolved\n",
      "Word: been, Deprel: aux:pass, Head: resolved\n",
      "Word: resolved, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'China s Health Ministry said five more people had died of Sars and a further 159 were infected'\n",
      "Word: China, Deprel: nmod:poss, Head: Ministry\n",
      "Word: s, Deprel: case, Head: China\n",
      "Word: Health, Deprel: compound, Head: Ministry\n",
      "Word: Ministry, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: five, Deprel: nummod, Head: people\n",
      "Word: more, Deprel: amod, Head: people\n",
      "Word: people, Deprel: nsubj, Head: died\n",
      "Word: had, Deprel: aux, Head: died\n",
      "Word: died, Deprel: ccomp, Head: said\n",
      "Word: of, Deprel: case, Head: Sars\n",
      "Word: Sars, Deprel: obl, Head: died\n",
      "Word: and, Deprel: cc, Head: infected\n",
      "Word: a, Deprel: det, Head: 159\n",
      "Word: further, Deprel: amod, Head: 159\n",
      "Word: 159, Deprel: nsubj:pass, Head: infected\n",
      "Word: were, Deprel: aux:pass, Head: infected\n",
      "Word: infected, Deprel: conj, Head: died\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Monday China said nine more people had died from SARS and that 160 more were infected with the virus'\n",
      "Word: On, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: said\n",
      "Word: China, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: nine, Deprel: nummod, Head: people\n",
      "Word: more, Deprel: amod, Head: people\n",
      "Word: people, Deprel: nsubj, Head: died\n",
      "Word: had, Deprel: aux, Head: died\n",
      "Word: died, Deprel: ccomp, Head: said\n",
      "Word: from, Deprel: case, Head: SARS\n",
      "Word: SARS, Deprel: obl, Head: died\n",
      "Word: and, Deprel: cc, Head: infected\n",
      "Word: that, Deprel: mark, Head: infected\n",
      "Word: 160, Deprel: nummod, Head: more\n",
      "Word: more, Deprel: nsubj:pass, Head: infected\n",
      "Word: were, Deprel: aux:pass, Head: infected\n",
      "Word: infected, Deprel: conj, Head: died\n",
      "Word: with, Deprel: case, Head: virus\n",
      "Word: the, Deprel: det, Head: virus\n",
      "Word: virus, Deprel: obl, Head: infected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The respected medical journal Lancet has called for a complete ban on tobacco in the United Kingdom'\n",
      "Word: The, Deprel: det, Head: journal\n",
      "Word: respected, Deprel: amod, Head: journal\n",
      "Word: medical, Deprel: amod, Head: journal\n",
      "Word: journal, Deprel: compound, Head: Lancet\n",
      "Word: Lancet, Deprel: nsubj, Head: called\n",
      "Word: has, Deprel: aux, Head: called\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: ban\n",
      "Word: a, Deprel: det, Head: ban\n",
      "Word: complete, Deprel: amod, Head: ban\n",
      "Word: ban, Deprel: obl, Head: called\n",
      "Word: on, Deprel: case, Head: tobacco\n",
      "Word: tobacco, Deprel: nmod, Head: ban\n",
      "Word: in, Deprel: case, Head: Kingdom\n",
      "Word: the, Deprel: det, Head: Kingdom\n",
      "Word: United, Deprel: amod, Head: Kingdom\n",
      "Word: Kingdom, Deprel: nmod, Head: ban\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A leading U.K medical journal called Friday for a complete ban on tobacco prompting outrage from smokers groups'\n",
      "Word: A, Deprel: det, Head: journal\n",
      "Word: leading, Deprel: amod, Head: journal\n",
      "Word: U.K, Deprel: compound, Head: journal\n",
      "Word: medical, Deprel: amod, Head: journal\n",
      "Word: journal, Deprel: nsubj, Head: called\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: Friday, Deprel: obl:tmod, Head: called\n",
      "Word: for, Deprel: case, Head: ban\n",
      "Word: a, Deprel: det, Head: ban\n",
      "Word: complete, Deprel: amod, Head: ban\n",
      "Word: ban, Deprel: obl, Head: called\n",
      "Word: on, Deprel: case, Head: tobacco\n",
      "Word: tobacco, Deprel: nmod, Head: ban\n",
      "Word: prompting, Deprel: acl, Head: ban\n",
      "Word: outrage, Deprel: obj, Head: prompting\n",
      "Word: from, Deprel: case, Head: groups\n",
      "Word: smokers, Deprel: compound, Head: groups\n",
      "Word: groups, Deprel: obl, Head: prompting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shares of McDonald s rose 1.83 or 8.3 percent to close at the day s high of 23.89'\n",
      "Word: Shares, Deprel: nsubj, Head: rose\n",
      "Word: of, Deprel: case, Head: McDonald\n",
      "Word: McDonald, Deprel: nmod, Head: Shares\n",
      "Word: s, Deprel: case, Head: McDonald\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 1.83, Deprel: nummod, Head: percent\n",
      "Word: or, Deprel: cc, Head: 8.3\n",
      "Word: 8.3, Deprel: conj, Head: 1.83\n",
      "Word: percent, Deprel: obl:tmod, Head: rose\n",
      "Word: to, Deprel: case, Head: close\n",
      "Word: close, Deprel: obl, Head: rose\n",
      "Word: at, Deprel: case, Head: high\n",
      "Word: the, Deprel: det, Head: day\n",
      "Word: day, Deprel: nmod:poss, Head: high\n",
      "Word: s, Deprel: case, Head: day\n",
      "Word: high, Deprel: obl, Head: rose\n",
      "Word: of, Deprel: case, Head: 23.89\n",
      "Word: 23.89, Deprel: nmod, Head: high\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'McDonald s shares rose 1.83 to close Friday at 23.89 on the New York Stock Exchange'\n",
      "Word: McDonald, Deprel: nmod:poss, Head: shares\n",
      "Word: s, Deprel: case, Head: McDonald\n",
      "Word: shares, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 1.83, Deprel: obj, Head: rose\n",
      "Word: to, Deprel: case, Head: close\n",
      "Word: close, Deprel: obl, Head: rose\n",
      "Word: Friday, Deprel: obl:tmod, Head: rose\n",
      "Word: at, Deprel: case, Head: 23.89\n",
      "Word: 23.89, Deprel: obl, Head: rose\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'An incremental step reported by researchers at the University of California San Francisco is the latest in a decade-long effort'\n",
      "Word: An, Deprel: det, Head: step\n",
      "Word: incremental, Deprel: amod, Head: step\n",
      "Word: step, Deprel: nsubj, Head: latest\n",
      "Word: reported, Deprel: acl, Head: step\n",
      "Word: by, Deprel: case, Head: researchers\n",
      "Word: researchers, Deprel: obl, Head: reported\n",
      "Word: at, Deprel: case, Head: University\n",
      "Word: the, Deprel: det, Head: University\n",
      "Word: University, Deprel: obl, Head: reported\n",
      "Word: of, Deprel: case, Head: California\n",
      "Word: California, Deprel: nmod, Head: University\n",
      "Word: San, Deprel: appos, Head: University\n",
      "Word: Francisco, Deprel: flat, Head: San\n",
      "Word: is, Deprel: cop, Head: latest\n",
      "Word: the, Deprel: det, Head: latest\n",
      "Word: latest, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: effort\n",
      "Word: a, Deprel: det, Head: effort\n",
      "Word: decade-long, Deprel: amod, Head: effort\n",
      "Word: effort, Deprel: obl, Head: latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The incremental step reported by researchers at UC San Francisco is the latest in a decade-long effort to infect mice with the virus'\n",
      "Word: The, Deprel: det, Head: step\n",
      "Word: incremental, Deprel: amod, Head: step\n",
      "Word: step, Deprel: nsubj, Head: latest\n",
      "Word: reported, Deprel: acl, Head: step\n",
      "Word: by, Deprel: case, Head: researchers\n",
      "Word: researchers, Deprel: obl, Head: reported\n",
      "Word: at, Deprel: case, Head: San\n",
      "Word: UC, Deprel: compound, Head: San\n",
      "Word: San, Deprel: nmod, Head: researchers\n",
      "Word: Francisco, Deprel: flat, Head: San\n",
      "Word: is, Deprel: cop, Head: latest\n",
      "Word: the, Deprel: det, Head: latest\n",
      "Word: latest, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: effort\n",
      "Word: a, Deprel: det, Head: effort\n",
      "Word: decade-long, Deprel: amod, Head: effort\n",
      "Word: effort, Deprel: obl, Head: latest\n",
      "Word: to, Deprel: mark, Head: infect\n",
      "Word: infect, Deprel: acl, Head: effort\n",
      "Word: mice, Deprel: obj, Head: infect\n",
      "Word: with, Deprel: case, Head: virus\n",
      "Word: the, Deprel: det, Head: virus\n",
      "Word: virus, Deprel: obl, Head: infect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He said the FDA was hoping Congress and the courts would bring clarity to the situation and some financial relief to consumers'\n",
      "Word: He, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: FDA\n",
      "Word: FDA, Deprel: nsubj, Head: hoping\n",
      "Word: was, Deprel: aux, Head: hoping\n",
      "Word: hoping, Deprel: ccomp, Head: said\n",
      "Word: Congress, Deprel: nsubj, Head: bring\n",
      "Word: and, Deprel: cc, Head: courts\n",
      "Word: the, Deprel: det, Head: courts\n",
      "Word: courts, Deprel: conj, Head: Congress\n",
      "Word: would, Deprel: aux, Head: bring\n",
      "Word: bring, Deprel: ccomp, Head: hoping\n",
      "Word: clarity, Deprel: obj, Head: bring\n",
      "Word: to, Deprel: case, Head: situation\n",
      "Word: the, Deprel: det, Head: situation\n",
      "Word: situation, Deprel: obl, Head: bring\n",
      "Word: and, Deprel: cc, Head: relief\n",
      "Word: some, Deprel: det, Head: relief\n",
      "Word: financial, Deprel: amod, Head: relief\n",
      "Word: relief, Deprel: conj, Head: situation\n",
      "Word: to, Deprel: case, Head: consumers\n",
      "Word: consumers, Deprel: nmod, Head: relief\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He said FDA hopes Congress and the courts will bring clarity to the situation and some financial relief to consumers — perhaps before the 2004 elections'\n",
      "Word: He, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: FDA, Deprel: nsubj, Head: hopes\n",
      "Word: hopes, Deprel: ccomp, Head: said\n",
      "Word: Congress, Deprel: nsubj, Head: bring\n",
      "Word: and, Deprel: cc, Head: courts\n",
      "Word: the, Deprel: det, Head: courts\n",
      "Word: courts, Deprel: conj, Head: Congress\n",
      "Word: will, Deprel: aux, Head: bring\n",
      "Word: bring, Deprel: ccomp, Head: hopes\n",
      "Word: clarity, Deprel: obj, Head: bring\n",
      "Word: to, Deprel: case, Head: situation\n",
      "Word: the, Deprel: det, Head: situation\n",
      "Word: situation, Deprel: obl, Head: bring\n",
      "Word: and, Deprel: cc, Head: relief\n",
      "Word: some, Deprel: det, Head: relief\n",
      "Word: financial, Deprel: amod, Head: relief\n",
      "Word: relief, Deprel: conj, Head: situation\n",
      "Word: to, Deprel: case, Head: consumers\n",
      "Word: consumers, Deprel: nmod, Head: relief\n",
      "Word: —, Deprel: punct, Head: elections\n",
      "Word: perhaps, Deprel: advmod, Head: elections\n",
      "Word: before, Deprel: case, Head: elections\n",
      "Word: the, Deprel: det, Head: elections\n",
      "Word: 2004, Deprel: nummod, Head: elections\n",
      "Word: elections, Deprel: obl, Head: bring\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Ernst Young admitted no wrongdoing with the settlement'\n",
      "Word: Ernst, Deprel: nsubj, Head: admitted\n",
      "Word: Young, Deprel: flat, Head: Ernst\n",
      "Word: admitted, Deprel: root, Head: ROOT\n",
      "Word: no, Deprel: det, Head: wrongdoing\n",
      "Word: wrongdoing, Deprel: obj, Head: admitted\n",
      "Word: with, Deprel: case, Head: settlement\n",
      "Word: the, Deprel: det, Head: settlement\n",
      "Word: settlement, Deprel: nmod, Head: wrongdoing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Ernst Young spokesman Kenneth Kerrigan said the firm admits no wrongdoing'\n",
      "Word: Ernst, Deprel: compound, Head: spokesman\n",
      "Word: Young, Deprel: amod, Head: spokesman\n",
      "Word: spokesman, Deprel: compound, Head: Kenneth\n",
      "Word: Kenneth, Deprel: nsubj, Head: said\n",
      "Word: Kerrigan, Deprel: flat, Head: Kenneth\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: firm\n",
      "Word: firm, Deprel: nsubj, Head: admits\n",
      "Word: admits, Deprel: ccomp, Head: said\n",
      "Word: no, Deprel: det, Head: wrongdoing\n",
      "Word: wrongdoing, Deprel: obj, Head: admits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The driver of the truck escaped and is now being sought by the police Supoyo said'\n",
      "Word: The, Deprel: det, Head: driver\n",
      "Word: driver, Deprel: nsubj, Head: escaped\n",
      "Word: of, Deprel: case, Head: truck\n",
      "Word: the, Deprel: det, Head: truck\n",
      "Word: truck, Deprel: nmod, Head: driver\n",
      "Word: escaped, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: sought\n",
      "Word: is, Deprel: aux, Head: sought\n",
      "Word: now, Deprel: advmod, Head: sought\n",
      "Word: being, Deprel: aux:pass, Head: sought\n",
      "Word: sought, Deprel: conj, Head: escaped\n",
      "Word: by, Deprel: case, Head: police\n",
      "Word: the, Deprel: det, Head: police\n",
      "Word: police, Deprel: obl, Head: sought\n",
      "Word: Supoyo, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl, Head: police\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But police say the driver of the truck has not been found and is wanted for questioning'\n",
      "Word: But, Deprel: cc, Head: say\n",
      "Word: police, Deprel: nsubj, Head: say\n",
      "Word: say, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: driver\n",
      "Word: driver, Deprel: nsubj:pass, Head: found\n",
      "Word: of, Deprel: case, Head: truck\n",
      "Word: the, Deprel: det, Head: truck\n",
      "Word: truck, Deprel: nmod, Head: driver\n",
      "Word: has, Deprel: aux, Head: found\n",
      "Word: not, Deprel: advmod, Head: found\n",
      "Word: been, Deprel: aux:pass, Head: found\n",
      "Word: found, Deprel: ccomp, Head: say\n",
      "Word: and, Deprel: cc, Head: wanted\n",
      "Word: is, Deprel: aux:pass, Head: wanted\n",
      "Word: wanted, Deprel: conj, Head: found\n",
      "Word: for, Deprel: case, Head: questioning\n",
      "Word: questioning, Deprel: obl, Head: wanted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The witness a 27-year-old Kosovan parking attendant with criminal convictions for dishonesty was paid 10,000 by the News of the World'\n",
      "Word: The, Deprel: det, Head: witness\n",
      "Word: witness, Deprel: nsubj, Head: paid\n",
      "Word: a, Deprel: det, Head: attendant\n",
      "Word: 27-year-old, Deprel: amod, Head: attendant\n",
      "Word: Kosovan, Deprel: amod, Head: attendant\n",
      "Word: parking, Deprel: compound, Head: attendant\n",
      "Word: attendant, Deprel: appos, Head: witness\n",
      "Word: with, Deprel: case, Head: convictions\n",
      "Word: criminal, Deprel: amod, Head: convictions\n",
      "Word: convictions, Deprel: nmod, Head: attendant\n",
      "Word: for, Deprel: case, Head: dishonesty\n",
      "Word: dishonesty, Deprel: nmod, Head: convictions\n",
      "Word: was, Deprel: aux:pass, Head: paid\n",
      "Word: paid, Deprel: root, Head: ROOT\n",
      "Word: 10,000, Deprel: obj, Head: paid\n",
      "Word: by, Deprel: case, Head: News\n",
      "Word: the, Deprel: det, Head: News\n",
      "Word: News, Deprel: obl, Head: paid\n",
      "Word: of, Deprel: case, Head: World\n",
      "Word: the, Deprel: det, Head: World\n",
      "Word: World, Deprel: nmod, Head: News\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The witness was a 27-year-old Kosovan parking attendant who was paid by the News of the World the court heard'\n",
      "Word: The, Deprel: det, Head: witness\n",
      "Word: witness, Deprel: nsubj, Head: attendant\n",
      "Word: was, Deprel: cop, Head: attendant\n",
      "Word: a, Deprel: det, Head: attendant\n",
      "Word: 27-year-old, Deprel: amod, Head: attendant\n",
      "Word: Kosovan, Deprel: amod, Head: attendant\n",
      "Word: parking, Deprel: compound, Head: attendant\n",
      "Word: attendant, Deprel: root, Head: ROOT\n",
      "Word: who, Deprel: nsubj:pass, Head: paid\n",
      "Word: was, Deprel: aux:pass, Head: paid\n",
      "Word: paid, Deprel: acl:relcl, Head: attendant\n",
      "Word: by, Deprel: case, Head: News\n",
      "Word: the, Deprel: det, Head: News\n",
      "Word: News, Deprel: obl, Head: paid\n",
      "Word: of, Deprel: case, Head: World\n",
      "Word: the, Deprel: det, Head: World\n",
      "Word: World, Deprel: nmod, Head: News\n",
      "Word: the, Deprel: det, Head: court\n",
      "Word: court, Deprel: nsubj, Head: heard\n",
      "Word: heard, Deprel: acl:relcl, Head: News\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In so many different ways the artistry of black musicians has conveyed the experience of black Americans throughout our history Bush said'\n",
      "Word: In, Deprel: case, Head: ways\n",
      "Word: so, Deprel: advmod, Head: many\n",
      "Word: many, Deprel: amod, Head: ways\n",
      "Word: different, Deprel: amod, Head: ways\n",
      "Word: ways, Deprel: obl, Head: conveyed\n",
      "Word: the, Deprel: det, Head: artistry\n",
      "Word: artistry, Deprel: nsubj, Head: conveyed\n",
      "Word: of, Deprel: case, Head: musicians\n",
      "Word: black, Deprel: amod, Head: musicians\n",
      "Word: musicians, Deprel: nmod, Head: artistry\n",
      "Word: has, Deprel: aux, Head: conveyed\n",
      "Word: conveyed, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: experience\n",
      "Word: experience, Deprel: obj, Head: conveyed\n",
      "Word: of, Deprel: case, Head: Americans\n",
      "Word: black, Deprel: amod, Head: Americans\n",
      "Word: Americans, Deprel: nmod, Head: experience\n",
      "Word: throughout, Deprel: case, Head: history\n",
      "Word: our, Deprel: nmod:poss, Head: history\n",
      "Word: history, Deprel: obl, Head: conveyed\n",
      "Word: Bush, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Surrounded by singers from Harlem Bush said The artistry of black musicians has conveyed the experience of black Americans throughout our history'\n",
      "Word: Surrounded, Deprel: advcl, Head: said\n",
      "Word: by, Deprel: case, Head: singers\n",
      "Word: singers, Deprel: obl, Head: Surrounded\n",
      "Word: from, Deprel: case, Head: Harlem\n",
      "Word: Harlem, Deprel: nmod, Head: singers\n",
      "Word: Bush, Deprel: flat, Head: Harlem\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: The, Deprel: det, Head: artistry\n",
      "Word: artistry, Deprel: nsubj, Head: conveyed\n",
      "Word: of, Deprel: case, Head: musicians\n",
      "Word: black, Deprel: amod, Head: musicians\n",
      "Word: musicians, Deprel: nmod, Head: artistry\n",
      "Word: has, Deprel: aux, Head: conveyed\n",
      "Word: conveyed, Deprel: ccomp, Head: said\n",
      "Word: the, Deprel: det, Head: experience\n",
      "Word: experience, Deprel: obj, Head: conveyed\n",
      "Word: of, Deprel: case, Head: Americans\n",
      "Word: black, Deprel: amod, Head: Americans\n",
      "Word: Americans, Deprel: nmod, Head: experience\n",
      "Word: throughout, Deprel: case, Head: history\n",
      "Word: our, Deprel: nmod:poss, Head: history\n",
      "Word: history, Deprel: obl, Head: conveyed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The differences between Grassley and Thomas on energy and Medicare have become so pointed that other members say their angry personal relationship is embarrassing the party'\n",
      "Word: The, Deprel: det, Head: differences\n",
      "Word: differences, Deprel: nsubj, Head: become\n",
      "Word: between, Deprel: case, Head: Grassley\n",
      "Word: Grassley, Deprel: nmod, Head: differences\n",
      "Word: and, Deprel: cc, Head: Thomas\n",
      "Word: Thomas, Deprel: conj, Head: Grassley\n",
      "Word: on, Deprel: case, Head: energy\n",
      "Word: energy, Deprel: nmod, Head: differences\n",
      "Word: and, Deprel: cc, Head: Medicare\n",
      "Word: Medicare, Deprel: conj, Head: energy\n",
      "Word: have, Deprel: aux, Head: become\n",
      "Word: become, Deprel: root, Head: ROOT\n",
      "Word: so, Deprel: advmod, Head: pointed\n",
      "Word: pointed, Deprel: xcomp, Head: become\n",
      "Word: that, Deprel: mark, Head: say\n",
      "Word: other, Deprel: amod, Head: members\n",
      "Word: members, Deprel: nsubj, Head: say\n",
      "Word: say, Deprel: ccomp, Head: pointed\n",
      "Word: their, Deprel: nmod:poss, Head: relationship\n",
      "Word: angry, Deprel: amod, Head: relationship\n",
      "Word: personal, Deprel: amod, Head: relationship\n",
      "Word: relationship, Deprel: nsubj, Head: embarrassing\n",
      "Word: is, Deprel: cop, Head: embarrassing\n",
      "Word: embarrassing, Deprel: ccomp, Head: say\n",
      "Word: the, Deprel: det, Head: party\n",
      "Word: party, Deprel: obj, Head: embarrassing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Their differences on energy and Medicare have become so pointed other members say it is embarrassing to the party'\n",
      "Word: Their, Deprel: nmod:poss, Head: differences\n",
      "Word: differences, Deprel: nsubj, Head: become\n",
      "Word: on, Deprel: case, Head: energy\n",
      "Word: energy, Deprel: nmod, Head: differences\n",
      "Word: and, Deprel: cc, Head: Medicare\n",
      "Word: Medicare, Deprel: conj, Head: energy\n",
      "Word: have, Deprel: aux, Head: become\n",
      "Word: become, Deprel: root, Head: ROOT\n",
      "Word: so, Deprel: advmod, Head: pointed\n",
      "Word: pointed, Deprel: xcomp, Head: become\n",
      "Word: other, Deprel: amod, Head: members\n",
      "Word: members, Deprel: nsubj, Head: say\n",
      "Word: say, Deprel: ccomp, Head: pointed\n",
      "Word: it, Deprel: nsubj, Head: embarrassing\n",
      "Word: is, Deprel: cop, Head: embarrassing\n",
      "Word: embarrassing, Deprel: ccomp, Head: say\n",
      "Word: to, Deprel: case, Head: party\n",
      "Word: the, Deprel: det, Head: party\n",
      "Word: party, Deprel: obl, Head: embarrassing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Geraldine Andrews the pastor s daughter-in-law said Robinson recently took her daughter out of a mental health facility'\n",
      "Word: Geraldine, Deprel: nsubj, Head: said\n",
      "Word: Andrews, Deprel: flat, Head: Geraldine\n",
      "Word: the, Deprel: det, Head: pastor\n",
      "Word: pastor, Deprel: nmod:poss, Head: daughter-in-law\n",
      "Word: s, Deprel: case, Head: pastor\n",
      "Word: daughter-in-law, Deprel: appos, Head: Geraldine\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Robinson, Deprel: nsubj, Head: took\n",
      "Word: recently, Deprel: advmod, Head: took\n",
      "Word: took, Deprel: ccomp, Head: said\n",
      "Word: her, Deprel: nmod:poss, Head: daughter\n",
      "Word: daughter, Deprel: obj, Head: took\n",
      "Word: out, Deprel: case, Head: facility\n",
      "Word: of, Deprel: case, Head: facility\n",
      "Word: a, Deprel: det, Head: facility\n",
      "Word: mental, Deprel: amod, Head: health\n",
      "Word: health, Deprel: compound, Head: facility\n",
      "Word: facility, Deprel: obl, Head: took\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Geraldine Andrews Reynolds daughter-in-law and a friend of Wilson s family said Robinson had recently taken Wilson out of a mental health facility'\n",
      "Word: Geraldine, Deprel: nsubj, Head: said\n",
      "Word: Andrews, Deprel: flat, Head: Geraldine\n",
      "Word: Reynolds, Deprel: compound, Head: daughter-in-law\n",
      "Word: daughter-in-law, Deprel: appos, Head: Geraldine\n",
      "Word: and, Deprel: cc, Head: friend\n",
      "Word: a, Deprel: det, Head: friend\n",
      "Word: friend, Deprel: conj, Head: Geraldine\n",
      "Word: of, Deprel: case, Head: family\n",
      "Word: Wilson, Deprel: nmod:poss, Head: family\n",
      "Word: s, Deprel: case, Head: Wilson\n",
      "Word: family, Deprel: nmod, Head: friend\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Robinson, Deprel: nsubj, Head: taken\n",
      "Word: had, Deprel: aux, Head: taken\n",
      "Word: recently, Deprel: advmod, Head: taken\n",
      "Word: taken, Deprel: ccomp, Head: said\n",
      "Word: Wilson, Deprel: obj, Head: taken\n",
      "Word: out, Deprel: case, Head: facility\n",
      "Word: of, Deprel: case, Head: facility\n",
      "Word: a, Deprel: det, Head: facility\n",
      "Word: mental, Deprel: amod, Head: health\n",
      "Word: health, Deprel: compound, Head: facility\n",
      "Word: facility, Deprel: obl, Head: taken\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He wounded a security guard and then fled stabbing two passersby as he ran off along the promenade'\n",
      "Word: He, Deprel: nsubj, Head: wounded\n",
      "Word: wounded, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guard\n",
      "Word: security, Deprel: compound, Head: guard\n",
      "Word: guard, Deprel: obj, Head: wounded\n",
      "Word: and, Deprel: cc, Head: fled\n",
      "Word: then, Deprel: advmod, Head: fled\n",
      "Word: fled, Deprel: conj, Head: wounded\n",
      "Word: stabbing, Deprel: xcomp, Head: fled\n",
      "Word: two, Deprel: nummod, Head: passersby\n",
      "Word: passersby, Deprel: obj, Head: stabbing\n",
      "Word: as, Deprel: mark, Head: ran\n",
      "Word: he, Deprel: nsubj, Head: ran\n",
      "Word: ran, Deprel: advcl, Head: stabbing\n",
      "Word: off, Deprel: compound:prt, Head: ran\n",
      "Word: along, Deprel: case, Head: promenade\n",
      "Word: the, Deprel: det, Head: promenade\n",
      "Word: promenade, Deprel: obl, Head: ran\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He then stabbed two passersby as he fled along a promenade by the Mediterranean Sea'\n",
      "Word: He, Deprel: nsubj, Head: stabbed\n",
      "Word: then, Deprel: advmod, Head: stabbed\n",
      "Word: stabbed, Deprel: root, Head: ROOT\n",
      "Word: two, Deprel: nummod, Head: passersby\n",
      "Word: passersby, Deprel: obj, Head: stabbed\n",
      "Word: as, Deprel: mark, Head: fled\n",
      "Word: he, Deprel: nsubj, Head: fled\n",
      "Word: fled, Deprel: advcl, Head: stabbed\n",
      "Word: along, Deprel: case, Head: promenade\n",
      "Word: a, Deprel: det, Head: promenade\n",
      "Word: promenade, Deprel: obl, Head: fled\n",
      "Word: by, Deprel: case, Head: Sea\n",
      "Word: the, Deprel: det, Head: Sea\n",
      "Word: Mediterranean, Deprel: amod, Head: Sea\n",
      "Word: Sea, Deprel: nmod, Head: promenade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He and his colleagues attributed some of the communication gap to doctors feeling pressed for time'\n",
      "Word: He, Deprel: nsubj, Head: attributed\n",
      "Word: and, Deprel: cc, Head: colleagues\n",
      "Word: his, Deprel: nmod:poss, Head: colleagues\n",
      "Word: colleagues, Deprel: conj, Head: He\n",
      "Word: attributed, Deprel: root, Head: ROOT\n",
      "Word: some, Deprel: obj, Head: attributed\n",
      "Word: of, Deprel: case, Head: gap\n",
      "Word: the, Deprel: det, Head: gap\n",
      "Word: communication, Deprel: compound, Head: gap\n",
      "Word: gap, Deprel: nmod, Head: some\n",
      "Word: to, Deprel: case, Head: doctors\n",
      "Word: doctors, Deprel: nmod, Head: gap\n",
      "Word: feeling, Deprel: advcl, Head: attributed\n",
      "Word: pressed, Deprel: xcomp, Head: feeling\n",
      "Word: for, Deprel: case, Head: time\n",
      "Word: time, Deprel: obl, Head: pressed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He attributed some of the communication gap to doctors feeling pressed for time patients cited discomfort discussing financial issues'\n",
      "Word: He, Deprel: nsubj, Head: attributed\n",
      "Word: attributed, Deprel: root, Head: ROOT\n",
      "Word: some, Deprel: obj, Head: attributed\n",
      "Word: of, Deprel: case, Head: gap\n",
      "Word: the, Deprel: det, Head: gap\n",
      "Word: communication, Deprel: compound, Head: gap\n",
      "Word: gap, Deprel: nmod, Head: some\n",
      "Word: to, Deprel: case, Head: doctors\n",
      "Word: doctors, Deprel: obl, Head: attributed\n",
      "Word: feeling, Deprel: advcl, Head: attributed\n",
      "Word: pressed, Deprel: xcomp, Head: feeling\n",
      "Word: for, Deprel: mark, Head: cited\n",
      "Word: time, Deprel: compound, Head: patients\n",
      "Word: patients, Deprel: nsubj, Head: cited\n",
      "Word: cited, Deprel: advcl, Head: pressed\n",
      "Word: discomfort, Deprel: obj, Head: cited\n",
      "Word: discussing, Deprel: advcl, Head: cited\n",
      "Word: financial, Deprel: amod, Head: issues\n",
      "Word: issues, Deprel: obj, Head: discussing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'State police said as many as 30 workers were trapped immediately after the garage collapsed'\n",
      "Word: State, Deprel: compound, Head: police\n",
      "Word: police, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: advmod, Head: 30\n",
      "Word: many, Deprel: fixed, Head: as\n",
      "Word: as, Deprel: fixed, Head: as\n",
      "Word: 30, Deprel: nummod, Head: workers\n",
      "Word: workers, Deprel: nsubj:pass, Head: trapped\n",
      "Word: were, Deprel: aux:pass, Head: trapped\n",
      "Word: trapped, Deprel: ccomp, Head: said\n",
      "Word: immediately, Deprel: advmod, Head: trapped\n",
      "Word: after, Deprel: mark, Head: collapsed\n",
      "Word: the, Deprel: det, Head: garage\n",
      "Word: garage, Deprel: nsubj, Head: collapsed\n",
      "Word: collapsed, Deprel: advcl, Head: trapped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'As many as 30 people were believed to be trapped inside initially the state police said'\n",
      "Word: As, Deprel: advmod, Head: 30\n",
      "Word: many, Deprel: fixed, Head: As\n",
      "Word: as, Deprel: fixed, Head: As\n",
      "Word: 30, Deprel: nummod, Head: people\n",
      "Word: people, Deprel: nsubj:pass, Head: believed\n",
      "Word: were, Deprel: aux:pass, Head: believed\n",
      "Word: believed, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: trapped\n",
      "Word: be, Deprel: aux:pass, Head: trapped\n",
      "Word: trapped, Deprel: xcomp, Head: believed\n",
      "Word: inside, Deprel: case, Head: initially\n",
      "Word: initially, Deprel: obl, Head: trapped\n",
      "Word: the, Deprel: det, Head: police\n",
      "Word: state, Deprel: compound, Head: police\n",
      "Word: police, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: believed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Before Thursday s matinee Baker called a clubhouse meeting concerned that the controversy had distracted the Cubs'\n",
      "Word: Before, Deprel: case, Head: matinee\n",
      "Word: Thursday, Deprel: nmod:poss, Head: matinee\n",
      "Word: s, Deprel: case, Head: Thursday\n",
      "Word: matinee, Deprel: obl, Head: called\n",
      "Word: Baker, Deprel: nsubj, Head: called\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: meeting\n",
      "Word: clubhouse, Deprel: compound, Head: meeting\n",
      "Word: meeting, Deprel: obj, Head: called\n",
      "Word: concerned, Deprel: acl, Head: meeting\n",
      "Word: that, Deprel: mark, Head: distracted\n",
      "Word: the, Deprel: det, Head: controversy\n",
      "Word: controversy, Deprel: nsubj, Head: distracted\n",
      "Word: had, Deprel: aux, Head: distracted\n",
      "Word: distracted, Deprel: ccomp, Head: concerned\n",
      "Word: the, Deprel: det, Head: Cubs\n",
      "Word: Cubs, Deprel: obj, Head: distracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Baker called a pregame meeting believing the the corked-bat episode had distracted the team'\n",
      "Word: Baker, Deprel: nsubj, Head: called\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: meeting\n",
      "Word: pregame, Deprel: compound, Head: meeting\n",
      "Word: meeting, Deprel: obj, Head: called\n",
      "Word: believing, Deprel: acl, Head: meeting\n",
      "Word: the, Deprel: det, Head: episode\n",
      "Word: the, Deprel: det, Head: episode\n",
      "Word: corked-bat, Deprel: compound, Head: episode\n",
      "Word: episode, Deprel: nsubj, Head: distracted\n",
      "Word: had, Deprel: aux, Head: distracted\n",
      "Word: distracted, Deprel: ccomp, Head: believing\n",
      "Word: the, Deprel: det, Head: team\n",
      "Word: team, Deprel: obj, Head: distracted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'She was taken by ambulance to Charing Cross Hospital in Hammersmith'\n",
      "Word: She, Deprel: nsubj:pass, Head: taken\n",
      "Word: was, Deprel: aux:pass, Head: taken\n",
      "Word: taken, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: ambulance\n",
      "Word: ambulance, Deprel: obl, Head: taken\n",
      "Word: to, Deprel: case, Head: Hospital\n",
      "Word: Charing, Deprel: compound, Head: Cross\n",
      "Word: Cross, Deprel: compound, Head: Hospital\n",
      "Word: Hospital, Deprel: obl, Head: taken\n",
      "Word: in, Deprel: case, Head: Hammersmith\n",
      "Word: Hammersmith, Deprel: nmod, Head: Hospital\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'She was taken to Charing Cross Hospital where she remained critically ill last night'\n",
      "Word: She, Deprel: nsubj:pass, Head: taken\n",
      "Word: was, Deprel: aux:pass, Head: taken\n",
      "Word: taken, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Hospital\n",
      "Word: Charing, Deprel: compound, Head: Cross\n",
      "Word: Cross, Deprel: compound, Head: Hospital\n",
      "Word: Hospital, Deprel: obl, Head: taken\n",
      "Word: where, Deprel: advmod, Head: remained\n",
      "Word: she, Deprel: nsubj, Head: remained\n",
      "Word: remained, Deprel: advcl, Head: taken\n",
      "Word: critically, Deprel: advmod, Head: ill\n",
      "Word: ill, Deprel: xcomp, Head: remained\n",
      "Word: last, Deprel: amod, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: remained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bush turned out a statement yesterday thanking the commission for its work and said Our journey into space will go on'\n",
      "Word: Bush, Deprel: nsubj, Head: turned\n",
      "Word: turned, Deprel: root, Head: ROOT\n",
      "Word: out, Deprel: compound:prt, Head: turned\n",
      "Word: a, Deprel: det, Head: statement\n",
      "Word: statement, Deprel: obj, Head: turned\n",
      "Word: yesterday, Deprel: obl:tmod, Head: turned\n",
      "Word: thanking, Deprel: advcl, Head: turned\n",
      "Word: the, Deprel: det, Head: commission\n",
      "Word: commission, Deprel: obj, Head: thanking\n",
      "Word: for, Deprel: case, Head: work\n",
      "Word: its, Deprel: nmod:poss, Head: work\n",
      "Word: work, Deprel: obl, Head: thanking\n",
      "Word: and, Deprel: cc, Head: said\n",
      "Word: said, Deprel: conj, Head: turned\n",
      "Word: Our, Deprel: nmod:poss, Head: journey\n",
      "Word: journey, Deprel: nsubj, Head: go\n",
      "Word: into, Deprel: case, Head: space\n",
      "Word: space, Deprel: nmod, Head: journey\n",
      "Word: will, Deprel: aux, Head: go\n",
      "Word: go, Deprel: ccomp, Head: said\n",
      "Word: on, Deprel: advmod, Head: go\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Bush did not discuss this when he issued a brief statement yesterday thanking the commission for its work and saying Our journey into space will go on'\n",
      "Word: Mr, Deprel: nsubj, Head: discuss\n",
      "Word: Bush, Deprel: flat, Head: Mr\n",
      "Word: did, Deprel: aux, Head: discuss\n",
      "Word: not, Deprel: advmod, Head: discuss\n",
      "Word: discuss, Deprel: root, Head: ROOT\n",
      "Word: this, Deprel: obj, Head: discuss\n",
      "Word: when, Deprel: advmod, Head: issued\n",
      "Word: he, Deprel: nsubj, Head: issued\n",
      "Word: issued, Deprel: advcl, Head: discuss\n",
      "Word: a, Deprel: det, Head: statement\n",
      "Word: brief, Deprel: amod, Head: statement\n",
      "Word: statement, Deprel: obj, Head: issued\n",
      "Word: yesterday, Deprel: obl:tmod, Head: issued\n",
      "Word: thanking, Deprel: advcl, Head: issued\n",
      "Word: the, Deprel: det, Head: commission\n",
      "Word: commission, Deprel: obj, Head: thanking\n",
      "Word: for, Deprel: case, Head: work\n",
      "Word: its, Deprel: nmod:poss, Head: work\n",
      "Word: work, Deprel: obl, Head: thanking\n",
      "Word: and, Deprel: cc, Head: saying\n",
      "Word: saying, Deprel: conj, Head: thanking\n",
      "Word: Our, Deprel: nmod:poss, Head: journey\n",
      "Word: journey, Deprel: nsubj, Head: go\n",
      "Word: into, Deprel: case, Head: space\n",
      "Word: space, Deprel: nmod, Head: journey\n",
      "Word: will, Deprel: aux, Head: go\n",
      "Word: go, Deprel: ccomp, Head: saying\n",
      "Word: on, Deprel: advmod, Head: go\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'OS ANGELES The Hulk was a monster at the box office in its debut weekend taking in a June opening record of 62.6 million'\n",
      "Word: OS, Deprel: compound, Head: ANGELES\n",
      "Word: ANGELES, Deprel: obl, Head: monster\n",
      "Word: The, Deprel: det, Head: Hulk\n",
      "Word: Hulk, Deprel: nsubj, Head: monster\n",
      "Word: was, Deprel: cop, Head: monster\n",
      "Word: a, Deprel: det, Head: monster\n",
      "Word: monster, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: office\n",
      "Word: the, Deprel: det, Head: office\n",
      "Word: box, Deprel: compound, Head: office\n",
      "Word: office, Deprel: nmod, Head: monster\n",
      "Word: in, Deprel: case, Head: weekend\n",
      "Word: its, Deprel: nmod:poss, Head: weekend\n",
      "Word: debut, Deprel: compound, Head: weekend\n",
      "Word: weekend, Deprel: obl, Head: monster\n",
      "Word: taking, Deprel: advcl, Head: monster\n",
      "Word: in, Deprel: compound:prt, Head: taking\n",
      "Word: a, Deprel: det, Head: record\n",
      "Word: June, Deprel: compound, Head: record\n",
      "Word: opening, Deprel: compound, Head: record\n",
      "Word: record, Deprel: obj, Head: taking\n",
      "Word: of, Deprel: case, Head: million\n",
      "Word: 62.6, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: nmod, Head: record\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Hulk took in 62.6 million at the box office a monster opening and a new June record'\n",
      "Word: The, Deprel: det, Head: Hulk\n",
      "Word: Hulk, Deprel: nsubj, Head: took\n",
      "Word: took, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: advmod, Head: took\n",
      "Word: 62.6, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: took\n",
      "Word: at, Deprel: case, Head: office\n",
      "Word: the, Deprel: det, Head: office\n",
      "Word: box, Deprel: compound, Head: office\n",
      "Word: office, Deprel: obl, Head: took\n",
      "Word: a, Deprel: det, Head: opening\n",
      "Word: monster, Deprel: compound, Head: opening\n",
      "Word: opening, Deprel: obl:tmod, Head: took\n",
      "Word: and, Deprel: cc, Head: record\n",
      "Word: a, Deprel: det, Head: record\n",
      "Word: new, Deprel: amod, Head: June\n",
      "Word: June, Deprel: compound, Head: record\n",
      "Word: record, Deprel: conj, Head: took\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The governor is going to Jackson where 13 of the state s 16 fatalities were reported'\n",
      "Word: The, Deprel: det, Head: governor\n",
      "Word: governor, Deprel: nsubj, Head: going\n",
      "Word: is, Deprel: aux, Head: going\n",
      "Word: going, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Jackson\n",
      "Word: Jackson, Deprel: obl, Head: going\n",
      "Word: where, Deprel: advmod, Head: reported\n",
      "Word: 13, Deprel: nsubj:pass, Head: reported\n",
      "Word: of, Deprel: case, Head: fatalities\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: state, Deprel: nmod:poss, Head: fatalities\n",
      "Word: s, Deprel: case, Head: state\n",
      "Word: 16, Deprel: nummod, Head: fatalities\n",
      "Word: fatalities, Deprel: nmod, Head: 13\n",
      "Word: were, Deprel: aux:pass, Head: reported\n",
      "Word: reported, Deprel: acl:relcl, Head: Jackson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The governor is going to Jackson where 13 people were killed'\n",
      "Word: The, Deprel: det, Head: governor\n",
      "Word: governor, Deprel: nsubj, Head: going\n",
      "Word: is, Deprel: aux, Head: going\n",
      "Word: going, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: Jackson\n",
      "Word: Jackson, Deprel: obl, Head: going\n",
      "Word: where, Deprel: advmod, Head: killed\n",
      "Word: 13, Deprel: nummod, Head: people\n",
      "Word: people, Deprel: nsubj:pass, Head: killed\n",
      "Word: were, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: advcl, Head: going\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Congratulations on being named Time magazine s Person of the Year'\n",
      "Word: Congratulations, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: mark, Head: named\n",
      "Word: being, Deprel: aux:pass, Head: named\n",
      "Word: named, Deprel: acl, Head: Congratulations\n",
      "Word: Time, Deprel: compound, Head: magazine\n",
      "Word: magazine, Deprel: nmod:poss, Head: Person\n",
      "Word: s, Deprel: case, Head: magazine\n",
      "Word: Person, Deprel: xcomp, Head: named\n",
      "Word: of, Deprel: case, Head: Year\n",
      "Word: the, Deprel: det, Head: Year\n",
      "Word: Year, Deprel: nmod, Head: Person\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Time magazine named the American soldier its Person of the Year for 2003'\n",
      "Word: Time, Deprel: compound, Head: magazine\n",
      "Word: magazine, Deprel: nsubj, Head: named\n",
      "Word: named, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: soldier\n",
      "Word: American, Deprel: amod, Head: soldier\n",
      "Word: soldier, Deprel: obj, Head: named\n",
      "Word: its, Deprel: nmod:poss, Head: Person\n",
      "Word: Person, Deprel: appos, Head: soldier\n",
      "Word: of, Deprel: case, Head: Year\n",
      "Word: the, Deprel: det, Head: Year\n",
      "Word: Year, Deprel: nmod, Head: Person\n",
      "Word: for, Deprel: case, Head: 2003\n",
      "Word: 2003, Deprel: obl, Head: named\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Shortly after the opening bell the Dow Jones Industrial Average was up 11.13 to 9,228.48 while the S P 500 index gained 1.74 to 982.33'\n",
      "Word: Shortly, Deprel: advmod, Head: bell\n",
      "Word: after, Deprel: case, Head: bell\n",
      "Word: the, Deprel: det, Head: bell\n",
      "Word: opening, Deprel: amod, Head: bell\n",
      "Word: bell, Deprel: obl, Head: up\n",
      "Word: the, Deprel: det, Head: Average\n",
      "Word: Dow, Deprel: compound, Head: Jones\n",
      "Word: Jones, Deprel: compound, Head: Average\n",
      "Word: Industrial, Deprel: amod, Head: Average\n",
      "Word: Average, Deprel: nsubj, Head: up\n",
      "Word: was, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: 11.13, Deprel: obl:npmod, Head: up\n",
      "Word: to, Deprel: case, Head: 9,228.48\n",
      "Word: 9,228.48, Deprel: obl, Head: up\n",
      "Word: while, Deprel: mark, Head: gained\n",
      "Word: the, Deprel: det, Head: index\n",
      "Word: S, Deprel: compound, Head: 500\n",
      "Word: P, Deprel: compound, Head: 500\n",
      "Word: 500, Deprel: compound, Head: index\n",
      "Word: index, Deprel: nsubj, Head: gained\n",
      "Word: gained, Deprel: advcl, Head: up\n",
      "Word: 1.74, Deprel: obl:npmod, Head: gained\n",
      "Word: to, Deprel: case, Head: 982.33\n",
      "Word: 982.33, Deprel: nmod, Head: 1.74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'After a weak start the Dow Jones Industrial Average ended the day up 26.26 to 9,217.35 while the S P 500 index rose 3 to 980.59'\n",
      "Word: After, Deprel: case, Head: start\n",
      "Word: a, Deprel: det, Head: start\n",
      "Word: weak, Deprel: amod, Head: start\n",
      "Word: start, Deprel: obl, Head: ended\n",
      "Word: the, Deprel: det, Head: Average\n",
      "Word: Dow, Deprel: compound, Head: Average\n",
      "Word: Jones, Deprel: compound, Head: Average\n",
      "Word: Industrial, Deprel: amod, Head: Average\n",
      "Word: Average, Deprel: nsubj, Head: ended\n",
      "Word: ended, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: day\n",
      "Word: day, Deprel: obj, Head: ended\n",
      "Word: up, Deprel: advmod, Head: ended\n",
      "Word: 26.26, Deprel: obl:npmod, Head: ended\n",
      "Word: to, Deprel: case, Head: 9,217.35\n",
      "Word: 9,217.35, Deprel: nmod, Head: 26.26\n",
      "Word: while, Deprel: mark, Head: rose\n",
      "Word: the, Deprel: det, Head: index\n",
      "Word: S, Deprel: compound, Head: 500\n",
      "Word: P, Deprel: compound, Head: 500\n",
      "Word: 500, Deprel: compound, Head: index\n",
      "Word: index, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: advcl, Head: ended\n",
      "Word: 3, Deprel: obl:npmod, Head: rose\n",
      "Word: to, Deprel: case, Head: 980.59\n",
      "Word: 980.59, Deprel: nmod, Head: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The indictment said he attended important meetings to plan the attacks recruited fellow bombers and coordinated the operation'\n",
      "Word: The, Deprel: det, Head: indictment\n",
      "Word: indictment, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: attended\n",
      "Word: attended, Deprel: ccomp, Head: said\n",
      "Word: important, Deprel: amod, Head: meetings\n",
      "Word: meetings, Deprel: obj, Head: attended\n",
      "Word: to, Deprel: mark, Head: plan\n",
      "Word: plan, Deprel: advcl, Head: attended\n",
      "Word: the, Deprel: det, Head: attacks\n",
      "Word: attacks, Deprel: obj, Head: plan\n",
      "Word: recruited, Deprel: conj, Head: attended\n",
      "Word: fellow, Deprel: amod, Head: bombers\n",
      "Word: bombers, Deprel: obj, Head: recruited\n",
      "Word: and, Deprel: cc, Head: coordinated\n",
      "Word: coordinated, Deprel: conj, Head: recruited\n",
      "Word: the, Deprel: det, Head: operation\n",
      "Word: operation, Deprel: obj, Head: coordinated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Samudra not present in Bangkok the indictment said but attended a series of meetings before the attacks recruiting fellow bombers and coordinating the operation'\n",
      "Word: Samudra, Deprel: nsubj, Head: present\n",
      "Word: not, Deprel: advmod, Head: present\n",
      "Word: present, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: Bangkok\n",
      "Word: Bangkok, Deprel: obl, Head: present\n",
      "Word: the, Deprel: det, Head: indictment\n",
      "Word: indictment, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: present\n",
      "Word: but, Deprel: cc, Head: attended\n",
      "Word: attended, Deprel: conj, Head: said\n",
      "Word: a, Deprel: det, Head: series\n",
      "Word: series, Deprel: obj, Head: attended\n",
      "Word: of, Deprel: case, Head: meetings\n",
      "Word: meetings, Deprel: nmod, Head: series\n",
      "Word: before, Deprel: case, Head: attacks\n",
      "Word: the, Deprel: det, Head: attacks\n",
      "Word: attacks, Deprel: nmod, Head: meetings\n",
      "Word: recruiting, Deprel: acl, Head: attacks\n",
      "Word: fellow, Deprel: amod, Head: bombers\n",
      "Word: bombers, Deprel: obj, Head: recruiting\n",
      "Word: and, Deprel: cc, Head: coordinating\n",
      "Word: coordinating, Deprel: conj, Head: recruiting\n",
      "Word: the, Deprel: det, Head: operation\n",
      "Word: operation, Deprel: obj, Head: coordinating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In addition primary care trusts PCTs were given star ratings for the first time this year'\n",
      "Word: In, Deprel: case, Head: addition\n",
      "Word: addition, Deprel: obl, Head: given\n",
      "Word: primary, Deprel: amod, Head: care\n",
      "Word: care, Deprel: compound, Head: trusts\n",
      "Word: trusts, Deprel: compound, Head: PCTs\n",
      "Word: PCTs, Deprel: nsubj:pass, Head: given\n",
      "Word: were, Deprel: aux:pass, Head: given\n",
      "Word: given, Deprel: root, Head: ROOT\n",
      "Word: star, Deprel: compound, Head: ratings\n",
      "Word: ratings, Deprel: obj, Head: given\n",
      "Word: for, Deprel: case, Head: time\n",
      "Word: the, Deprel: det, Head: time\n",
      "Word: first, Deprel: amod, Head: time\n",
      "Word: time, Deprel: obl, Head: given\n",
      "Word: this, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: given\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Primary Care Trusts and Mental Health Trusts have also been formally rated for the first time this year'\n",
      "Word: Primary, Deprel: amod, Head: Care\n",
      "Word: Care, Deprel: compound, Head: Trusts\n",
      "Word: Trusts, Deprel: nsubj:pass, Head: rated\n",
      "Word: and, Deprel: cc, Head: Trusts\n",
      "Word: Mental, Deprel: amod, Head: Health\n",
      "Word: Health, Deprel: compound, Head: Trusts\n",
      "Word: Trusts, Deprel: conj, Head: Trusts\n",
      "Word: have, Deprel: aux, Head: rated\n",
      "Word: also, Deprel: advmod, Head: rated\n",
      "Word: been, Deprel: aux:pass, Head: rated\n",
      "Word: formally, Deprel: advmod, Head: rated\n",
      "Word: rated, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: time\n",
      "Word: the, Deprel: det, Head: time\n",
      "Word: first, Deprel: amod, Head: time\n",
      "Word: time, Deprel: obl, Head: rated\n",
      "Word: this, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: rated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It will also give Microsoft an opportunity to comment on remedies proposed by the Commission'\n",
      "Word: It, Deprel: nsubj, Head: give\n",
      "Word: will, Deprel: aux, Head: give\n",
      "Word: also, Deprel: advmod, Head: give\n",
      "Word: give, Deprel: root, Head: ROOT\n",
      "Word: Microsoft, Deprel: iobj, Head: give\n",
      "Word: an, Deprel: det, Head: opportunity\n",
      "Word: opportunity, Deprel: obj, Head: give\n",
      "Word: to, Deprel: mark, Head: comment\n",
      "Word: comment, Deprel: acl, Head: opportunity\n",
      "Word: on, Deprel: case, Head: remedies\n",
      "Word: remedies, Deprel: obl, Head: comment\n",
      "Word: proposed, Deprel: acl, Head: remedies\n",
      "Word: by, Deprel: case, Head: Commission\n",
      "Word: the, Deprel: det, Head: Commission\n",
      "Word: Commission, Deprel: obl:agent, Head: proposed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Among other things Microsoft is to comment on proposed remedies in its response'\n",
      "Word: Among, Deprel: case, Head: things\n",
      "Word: other, Deprel: amod, Head: things\n",
      "Word: things, Deprel: obl, Head: comment\n",
      "Word: Microsoft, Deprel: nsubj, Head: comment\n",
      "Word: is, Deprel: cop, Head: comment\n",
      "Word: to, Deprel: mark, Head: comment\n",
      "Word: comment, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: remedies\n",
      "Word: proposed, Deprel: amod, Head: remedies\n",
      "Word: remedies, Deprel: obl, Head: comment\n",
      "Word: in, Deprel: case, Head: response\n",
      "Word: its, Deprel: nmod:poss, Head: response\n",
      "Word: response, Deprel: nmod, Head: remedies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Texans saddled with skyrocketing homeowners premiums might finally be getting relief'\n",
      "Word: Texans, Deprel: nsubj, Head: getting\n",
      "Word: saddled, Deprel: acl, Head: Texans\n",
      "Word: with, Deprel: case, Head: premiums\n",
      "Word: skyrocketing, Deprel: amod, Head: premiums\n",
      "Word: homeowners, Deprel: compound, Head: premiums\n",
      "Word: premiums, Deprel: obl, Head: saddled\n",
      "Word: might, Deprel: aux, Head: getting\n",
      "Word: finally, Deprel: advmod, Head: getting\n",
      "Word: be, Deprel: aux, Head: getting\n",
      "Word: getting, Deprel: root, Head: ROOT\n",
      "Word: relief, Deprel: obj, Head: getting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Relief is in sight for Texans saddled with skyrocketing homeowners insurance premiums'\n",
      "Word: Relief, Deprel: nsubj, Head: sight\n",
      "Word: is, Deprel: cop, Head: sight\n",
      "Word: in, Deprel: case, Head: sight\n",
      "Word: sight, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: Texans\n",
      "Word: Texans, Deprel: obl, Head: sight\n",
      "Word: saddled, Deprel: acl, Head: Texans\n",
      "Word: with, Deprel: case, Head: premiums\n",
      "Word: skyrocketing, Deprel: amod, Head: premiums\n",
      "Word: homeowners, Deprel: compound, Head: premiums\n",
      "Word: insurance, Deprel: compound, Head: premiums\n",
      "Word: premiums, Deprel: obl, Head: saddled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Six Democrats are vying to succeed Jacques and have qualified for the Feb 3 primary ballot'\n",
      "Word: Six, Deprel: nummod, Head: Democrats\n",
      "Word: Democrats, Deprel: nsubj, Head: vying\n",
      "Word: are, Deprel: cop, Head: vying\n",
      "Word: vying, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: succeed\n",
      "Word: succeed, Deprel: xcomp, Head: vying\n",
      "Word: Jacques, Deprel: obj, Head: succeed\n",
      "Word: and, Deprel: cc, Head: qualified\n",
      "Word: have, Deprel: aux, Head: qualified\n",
      "Word: qualified, Deprel: conj, Head: vying\n",
      "Word: for, Deprel: case, Head: ballot\n",
      "Word: the, Deprel: det, Head: ballot\n",
      "Word: Feb, Deprel: compound, Head: ballot\n",
      "Word: 3, Deprel: nummod, Head: Feb\n",
      "Word: primary, Deprel: compound, Head: ballot\n",
      "Word: ballot, Deprel: obl, Head: qualified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Six Democrats and two Republicans are running for her seat and have qualified for the Feb 3 primary ballot'\n",
      "Word: Six, Deprel: nummod, Head: Democrats\n",
      "Word: Democrats, Deprel: nsubj, Head: running\n",
      "Word: and, Deprel: cc, Head: Republicans\n",
      "Word: two, Deprel: nummod, Head: Republicans\n",
      "Word: Republicans, Deprel: conj, Head: Democrats\n",
      "Word: are, Deprel: aux, Head: running\n",
      "Word: running, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: seat\n",
      "Word: her, Deprel: nmod:poss, Head: seat\n",
      "Word: seat, Deprel: obl, Head: running\n",
      "Word: and, Deprel: cc, Head: qualified\n",
      "Word: have, Deprel: aux, Head: qualified\n",
      "Word: qualified, Deprel: conj, Head: running\n",
      "Word: for, Deprel: case, Head: ballot\n",
      "Word: the, Deprel: det, Head: ballot\n",
      "Word: Feb, Deprel: compound, Head: ballot\n",
      "Word: 3, Deprel: nummod, Head: Feb\n",
      "Word: primary, Deprel: compound, Head: ballot\n",
      "Word: ballot, Deprel: obl, Head: qualified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index rose 3.42 points or 0.34 percent to 1,007.84'\n",
      "Word: The, Deprel: det, Head: Index\n",
      "Word: broader, Deprel: amod, Head: Index\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: compound, Head: Index\n",
      "Word: s, Deprel: compound, Head: 500\n",
      "Word: 500, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 3.42, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: rose\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.34, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,007.84\n",
      "Word: 1,007.84, Deprel: obl, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index IXIC was down 1.55 points or 0.09 percent at 1,744.91'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-laced, Deprel: amod, Head: IXIC\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: down\n",
      "Word: was, Deprel: cop, Head: down\n",
      "Word: down, Deprel: root, Head: ROOT\n",
      "Word: 1.55, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: down\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.09, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 1,744.91\n",
      "Word: 1,744.91, Deprel: obl, Head: down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Crews worked to install a new culvert and prepare the highway so motorists could use the eastbound lanes for travel as storm clouds threatened to dump more rain'\n",
      "Word: Crews, Deprel: nsubj, Head: worked\n",
      "Word: worked, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: install\n",
      "Word: install, Deprel: advcl, Head: worked\n",
      "Word: a, Deprel: det, Head: culvert\n",
      "Word: new, Deprel: amod, Head: culvert\n",
      "Word: culvert, Deprel: obj, Head: install\n",
      "Word: and, Deprel: cc, Head: prepare\n",
      "Word: prepare, Deprel: conj, Head: install\n",
      "Word: the, Deprel: det, Head: highway\n",
      "Word: highway, Deprel: obj, Head: prepare\n",
      "Word: so, Deprel: mark, Head: use\n",
      "Word: motorists, Deprel: nsubj, Head: use\n",
      "Word: could, Deprel: aux, Head: use\n",
      "Word: use, Deprel: advcl, Head: prepare\n",
      "Word: the, Deprel: det, Head: lanes\n",
      "Word: eastbound, Deprel: amod, Head: lanes\n",
      "Word: lanes, Deprel: obj, Head: use\n",
      "Word: for, Deprel: case, Head: travel\n",
      "Word: travel, Deprel: obl, Head: use\n",
      "Word: as, Deprel: mark, Head: threatened\n",
      "Word: storm, Deprel: compound, Head: clouds\n",
      "Word: clouds, Deprel: nsubj, Head: threatened\n",
      "Word: threatened, Deprel: advcl, Head: use\n",
      "Word: to, Deprel: mark, Head: dump\n",
      "Word: dump, Deprel: xcomp, Head: threatened\n",
      "Word: more, Deprel: amod, Head: rain\n",
      "Word: rain, Deprel: obj, Head: dump\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Crews worked to install a new culvert and repave the highway so motorists could use the eastbound lanes for travel'\n",
      "Word: Crews, Deprel: nsubj, Head: worked\n",
      "Word: worked, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: install\n",
      "Word: install, Deprel: advcl, Head: worked\n",
      "Word: a, Deprel: det, Head: culvert\n",
      "Word: new, Deprel: amod, Head: culvert\n",
      "Word: culvert, Deprel: obj, Head: install\n",
      "Word: and, Deprel: cc, Head: repave\n",
      "Word: repave, Deprel: conj, Head: install\n",
      "Word: the, Deprel: det, Head: highway\n",
      "Word: highway, Deprel: obj, Head: repave\n",
      "Word: so, Deprel: mark, Head: use\n",
      "Word: motorists, Deprel: nsubj, Head: use\n",
      "Word: could, Deprel: aux, Head: use\n",
      "Word: use, Deprel: advcl, Head: repave\n",
      "Word: the, Deprel: det, Head: lanes\n",
      "Word: eastbound, Deprel: amod, Head: lanes\n",
      "Word: lanes, Deprel: obj, Head: use\n",
      "Word: for, Deprel: case, Head: travel\n",
      "Word: travel, Deprel: obl, Head: use\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Halliburton on Tuesday reiterated its contention that KBR had delivered fuel to Iraq at the best value the best price and the best terms'\n",
      "Word: Halliburton, Deprel: nsubj, Head: reiterated\n",
      "Word: on, Deprel: case, Head: Tuesday\n",
      "Word: Tuesday, Deprel: obl, Head: reiterated\n",
      "Word: reiterated, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: contention\n",
      "Word: contention, Deprel: obj, Head: reiterated\n",
      "Word: that, Deprel: mark, Head: delivered\n",
      "Word: KBR, Deprel: nsubj, Head: delivered\n",
      "Word: had, Deprel: aux, Head: delivered\n",
      "Word: delivered, Deprel: acl, Head: contention\n",
      "Word: fuel, Deprel: obj, Head: delivered\n",
      "Word: to, Deprel: case, Head: Iraq\n",
      "Word: Iraq, Deprel: obl, Head: delivered\n",
      "Word: at, Deprel: case, Head: value\n",
      "Word: the, Deprel: det, Head: value\n",
      "Word: best, Deprel: amod, Head: value\n",
      "Word: value, Deprel: obl, Head: delivered\n",
      "Word: the, Deprel: det, Head: price\n",
      "Word: best, Deprel: amod, Head: price\n",
      "Word: price, Deprel: obj, Head: delivered\n",
      "Word: and, Deprel: cc, Head: terms\n",
      "Word: the, Deprel: det, Head: terms\n",
      "Word: best, Deprel: amod, Head: terms\n",
      "Word: terms, Deprel: conj, Head: price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We believe KBR delivered fuel to Iraq at the best value the best price and the best terms Halliburton spokeswoman Wendy Hall said'\n",
      "Word: We, Deprel: nsubj, Head: believe\n",
      "Word: believe, Deprel: root, Head: ROOT\n",
      "Word: KBR, Deprel: nsubj, Head: delivered\n",
      "Word: delivered, Deprel: ccomp, Head: believe\n",
      "Word: fuel, Deprel: obj, Head: delivered\n",
      "Word: to, Deprel: case, Head: Iraq\n",
      "Word: Iraq, Deprel: obl, Head: delivered\n",
      "Word: at, Deprel: case, Head: value\n",
      "Word: the, Deprel: det, Head: value\n",
      "Word: best, Deprel: amod, Head: value\n",
      "Word: value, Deprel: obl, Head: delivered\n",
      "Word: the, Deprel: det, Head: price\n",
      "Word: best, Deprel: amod, Head: price\n",
      "Word: price, Deprel: obj, Head: delivered\n",
      "Word: and, Deprel: cc, Head: terms\n",
      "Word: the, Deprel: det, Head: terms\n",
      "Word: best, Deprel: amod, Head: terms\n",
      "Word: terms, Deprel: conj, Head: price\n",
      "Word: Halliburton, Deprel: compound, Head: spokeswoman\n",
      "Word: spokeswoman, Deprel: nsubj, Head: said\n",
      "Word: Wendy, Deprel: nsubj, Head: said\n",
      "Word: Hall, Deprel: flat, Head: Wendy\n",
      "Word: said, Deprel: acl:relcl, Head: terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Elecia Battle of Cleveland told police she dropped her purse as she left the Quick Shop Food Mart last week after buying the ticket'\n",
      "Word: Elecia, Deprel: compound, Head: Battle\n",
      "Word: Battle, Deprel: nsubj, Head: told\n",
      "Word: of, Deprel: case, Head: Cleveland\n",
      "Word: Cleveland, Deprel: nmod, Head: Battle\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: police, Deprel: iobj, Head: told\n",
      "Word: she, Deprel: nsubj, Head: dropped\n",
      "Word: dropped, Deprel: ccomp, Head: told\n",
      "Word: her, Deprel: nmod:poss, Head: purse\n",
      "Word: purse, Deprel: obj, Head: dropped\n",
      "Word: as, Deprel: mark, Head: left\n",
      "Word: she, Deprel: nsubj, Head: left\n",
      "Word: left, Deprel: advcl, Head: dropped\n",
      "Word: the, Deprel: det, Head: Mart\n",
      "Word: Quick, Deprel: amod, Head: Shop\n",
      "Word: Shop, Deprel: compound, Head: Mart\n",
      "Word: Food, Deprel: compound, Head: Mart\n",
      "Word: Mart, Deprel: obj, Head: left\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: left\n",
      "Word: after, Deprel: mark, Head: buying\n",
      "Word: buying, Deprel: advcl, Head: left\n",
      "Word: the, Deprel: det, Head: ticket\n",
      "Word: ticket, Deprel: obj, Head: buying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Elecia Battle dropped her purse after buying the Mega Millions Lottery ticket last week and believes the ticket blew away'\n",
      "Word: Elecia, Deprel: compound, Head: Battle\n",
      "Word: Battle, Deprel: nsubj, Head: dropped\n",
      "Word: dropped, Deprel: root, Head: ROOT\n",
      "Word: her, Deprel: nmod:poss, Head: purse\n",
      "Word: purse, Deprel: obj, Head: dropped\n",
      "Word: after, Deprel: mark, Head: buying\n",
      "Word: buying, Deprel: advcl, Head: dropped\n",
      "Word: the, Deprel: det, Head: ticket\n",
      "Word: Mega, Deprel: compound, Head: Millions\n",
      "Word: Millions, Deprel: compound, Head: Lottery\n",
      "Word: Lottery, Deprel: compound, Head: ticket\n",
      "Word: ticket, Deprel: obj, Head: buying\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: buying\n",
      "Word: and, Deprel: cc, Head: believes\n",
      "Word: believes, Deprel: conj, Head: dropped\n",
      "Word: the, Deprel: det, Head: ticket\n",
      "Word: ticket, Deprel: nsubj, Head: blew\n",
      "Word: blew, Deprel: ccomp, Head: believes\n",
      "Word: away, Deprel: advmod, Head: blew\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Customers include Mitsubishi Siemens DBTel Dell HP Palm Philips Sharp and Sony'\n",
      "Word: Customers, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: Mitsubishi, Deprel: compound, Head: Siemens\n",
      "Word: Siemens, Deprel: compound, Head: Sharp\n",
      "Word: DBTel, Deprel: compound, Head: Sharp\n",
      "Word: Dell, Deprel: compound, Head: HP\n",
      "Word: HP, Deprel: compound, Head: Sharp\n",
      "Word: Palm, Deprel: compound, Head: Philips\n",
      "Word: Philips, Deprel: compound, Head: Sharp\n",
      "Word: Sharp, Deprel: obj, Head: include\n",
      "Word: and, Deprel: cc, Head: Sony\n",
      "Word: Sony, Deprel: conj, Head: Sharp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'MediaQ s customers include major handheld makers Mitsubishi Siemens Palm Sharp Philips Dell and Sony'\n",
      "Word: MediaQ, Deprel: nmod:poss, Head: customers\n",
      "Word: s, Deprel: case, Head: MediaQ\n",
      "Word: customers, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: major, Deprel: amod, Head: makers\n",
      "Word: handheld, Deprel: compound, Head: makers\n",
      "Word: makers, Deprel: compound, Head: Dell\n",
      "Word: Mitsubishi, Deprel: compound, Head: Siemens\n",
      "Word: Siemens, Deprel: compound, Head: Dell\n",
      "Word: Palm, Deprel: compound, Head: Sharp\n",
      "Word: Sharp, Deprel: compound, Head: Philips\n",
      "Word: Philips, Deprel: compound, Head: Dell\n",
      "Word: Dell, Deprel: obj, Head: include\n",
      "Word: and, Deprel: cc, Head: Sony\n",
      "Word: Sony, Deprel: conj, Head: Dell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Cleveland Cavaliers won the right to draft James by winning the NBA s annual lottery Thursday night'\n",
      "Word: The, Deprel: det, Head: Cavaliers\n",
      "Word: Cleveland, Deprel: compound, Head: Cavaliers\n",
      "Word: Cavaliers, Deprel: nsubj, Head: won\n",
      "Word: won, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: right\n",
      "Word: right, Deprel: obj, Head: won\n",
      "Word: to, Deprel: mark, Head: draft\n",
      "Word: draft, Deprel: acl, Head: right\n",
      "Word: James, Deprel: obj, Head: draft\n",
      "Word: by, Deprel: mark, Head: winning\n",
      "Word: winning, Deprel: advcl, Head: draft\n",
      "Word: the, Deprel: det, Head: NBA\n",
      "Word: NBA, Deprel: nmod:poss, Head: lottery\n",
      "Word: s, Deprel: case, Head: NBA\n",
      "Word: annual, Deprel: amod, Head: lottery\n",
      "Word: lottery, Deprel: obj, Head: winning\n",
      "Word: Thursday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: winning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Such was the case Thursday night when the Cleveland Cavaliers won the LeBron James Lottery otherwise known as the NBA draft lottery'\n",
      "Word: Such, Deprel: nsubj, Head: case\n",
      "Word: was, Deprel: cop, Head: case\n",
      "Word: the, Deprel: det, Head: case\n",
      "Word: case, Deprel: root, Head: ROOT\n",
      "Word: Thursday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: case\n",
      "Word: when, Deprel: advmod, Head: won\n",
      "Word: the, Deprel: det, Head: Cavaliers\n",
      "Word: Cleveland, Deprel: compound, Head: Cavaliers\n",
      "Word: Cavaliers, Deprel: nsubj, Head: won\n",
      "Word: won, Deprel: advcl, Head: case\n",
      "Word: the, Deprel: det, Head: Lottery\n",
      "Word: LeBron, Deprel: compound, Head: Lottery\n",
      "Word: James, Deprel: flat, Head: LeBron\n",
      "Word: Lottery, Deprel: obj, Head: won\n",
      "Word: otherwise, Deprel: advmod, Head: known\n",
      "Word: known, Deprel: advcl, Head: won\n",
      "Word: as, Deprel: case, Head: lottery\n",
      "Word: the, Deprel: det, Head: lottery\n",
      "Word: NBA, Deprel: compound, Head: lottery\n",
      "Word: draft, Deprel: compound, Head: lottery\n",
      "Word: lottery, Deprel: obl, Head: known\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Among the workers the researchers found short workers had worse hearing than expected for their age'\n",
      "Word: Among, Deprel: case, Head: workers\n",
      "Word: the, Deprel: det, Head: workers\n",
      "Word: workers, Deprel: obl, Head: found\n",
      "Word: the, Deprel: det, Head: researchers\n",
      "Word: researchers, Deprel: nsubj, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: short, Deprel: amod, Head: workers\n",
      "Word: workers, Deprel: nsubj, Head: had\n",
      "Word: had, Deprel: ccomp, Head: found\n",
      "Word: worse, Deprel: amod, Head: hearing\n",
      "Word: hearing, Deprel: obj, Head: had\n",
      "Word: than, Deprel: mark, Head: expected\n",
      "Word: expected, Deprel: advcl, Head: had\n",
      "Word: for, Deprel: case, Head: age\n",
      "Word: their, Deprel: nmod:poss, Head: age\n",
      "Word: age, Deprel: obl, Head: expected\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Short workers had worse hearing than expected by age three times more often than taller workers writes Barrenas'\n",
      "Word: Short, Deprel: amod, Head: workers\n",
      "Word: workers, Deprel: nsubj, Head: had\n",
      "Word: had, Deprel: root, Head: ROOT\n",
      "Word: worse, Deprel: amod, Head: hearing\n",
      "Word: hearing, Deprel: obj, Head: had\n",
      "Word: than, Deprel: mark, Head: expected\n",
      "Word: expected, Deprel: acl, Head: hearing\n",
      "Word: by, Deprel: case, Head: age\n",
      "Word: age, Deprel: obl, Head: expected\n",
      "Word: three, Deprel: nummod, Head: times\n",
      "Word: times, Deprel: obl:npmod, Head: often\n",
      "Word: more, Deprel: advmod, Head: often\n",
      "Word: often, Deprel: advmod, Head: had\n",
      "Word: than, Deprel: case, Head: workers\n",
      "Word: taller, Deprel: amod, Head: workers\n",
      "Word: workers, Deprel: obl, Head: often\n",
      "Word: writes, Deprel: advcl, Head: had\n",
      "Word: Barrenas, Deprel: obj, Head: writes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Colpin did not specify whether it was this system that was at the centre of the investigation'\n",
      "Word: Mr, Deprel: nsubj, Head: specify\n",
      "Word: Colpin, Deprel: flat, Head: Mr\n",
      "Word: did, Deprel: aux, Head: specify\n",
      "Word: not, Deprel: advmod, Head: specify\n",
      "Word: specify, Deprel: root, Head: ROOT\n",
      "Word: whether, Deprel: mark, Head: system\n",
      "Word: it, Deprel: nsubj, Head: system\n",
      "Word: was, Deprel: cop, Head: system\n",
      "Word: this, Deprel: det, Head: system\n",
      "Word: system, Deprel: ccomp, Head: specify\n",
      "Word: that, Deprel: nsubj, Head: was\n",
      "Word: was, Deprel: acl:relcl, Head: system\n",
      "Word: at, Deprel: case, Head: centre\n",
      "Word: the, Deprel: det, Head: centre\n",
      "Word: centre, Deprel: obl, Head: was\n",
      "Word: of, Deprel: case, Head: investigation\n",
      "Word: the, Deprel: det, Head: investigation\n",
      "Word: investigation, Deprel: nmod, Head: centre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Neither OLAF nor the Belgian prosecutors have specified if it was this system that was at the centre of the investigation'\n",
      "Word: Neither, Deprel: det, Head: OLAF\n",
      "Word: OLAF, Deprel: nsubj, Head: specified\n",
      "Word: nor, Deprel: cc, Head: prosecutors\n",
      "Word: the, Deprel: det, Head: prosecutors\n",
      "Word: Belgian, Deprel: amod, Head: prosecutors\n",
      "Word: prosecutors, Deprel: conj, Head: OLAF\n",
      "Word: have, Deprel: aux, Head: specified\n",
      "Word: specified, Deprel: root, Head: ROOT\n",
      "Word: if, Deprel: mark, Head: system\n",
      "Word: it, Deprel: nsubj, Head: system\n",
      "Word: was, Deprel: cop, Head: system\n",
      "Word: this, Deprel: det, Head: system\n",
      "Word: system, Deprel: ccomp, Head: specified\n",
      "Word: that, Deprel: nsubj, Head: was\n",
      "Word: was, Deprel: acl:relcl, Head: system\n",
      "Word: at, Deprel: case, Head: centre\n",
      "Word: the, Deprel: det, Head: centre\n",
      "Word: centre, Deprel: obl, Head: was\n",
      "Word: of, Deprel: case, Head: investigation\n",
      "Word: the, Deprel: det, Head: investigation\n",
      "Word: investigation, Deprel: nmod, Head: centre\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Until now sales of the entertainment-oriented PCs have been limited to the United States Canada and Korea'\n",
      "Word: Until, Deprel: mark, Head: now\n",
      "Word: now, Deprel: advmod, Head: limited\n",
      "Word: sales, Deprel: nsubj:pass, Head: limited\n",
      "Word: of, Deprel: case, Head: PCs\n",
      "Word: the, Deprel: det, Head: PCs\n",
      "Word: entertainment-oriented, Deprel: amod, Head: PCs\n",
      "Word: PCs, Deprel: nmod, Head: sales\n",
      "Word: have, Deprel: aux, Head: limited\n",
      "Word: been, Deprel: aux:pass, Head: limited\n",
      "Word: limited, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: States\n",
      "Word: the, Deprel: det, Head: States\n",
      "Word: United, Deprel: amod, Head: States\n",
      "Word: States, Deprel: obl, Head: limited\n",
      "Word: Canada, Deprel: appos, Head: States\n",
      "Word: and, Deprel: cc, Head: Korea\n",
      "Word: Korea, Deprel: conj, Head: Canada\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The computers are currently sold in Canada the United States and Korea'\n",
      "Word: The, Deprel: det, Head: computers\n",
      "Word: computers, Deprel: nsubj:pass, Head: sold\n",
      "Word: are, Deprel: aux:pass, Head: sold\n",
      "Word: currently, Deprel: advmod, Head: sold\n",
      "Word: sold, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: Canada\n",
      "Word: Canada, Deprel: obl, Head: sold\n",
      "Word: the, Deprel: det, Head: States\n",
      "Word: United, Deprel: amod, Head: States\n",
      "Word: States, Deprel: obj, Head: sold\n",
      "Word: and, Deprel: cc, Head: Korea\n",
      "Word: Korea, Deprel: conj, Head: States\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Ballmer has been vocal in the past warning that Linux is a threat to Microsoft'\n",
      "Word: Ballmer, Deprel: nsubj, Head: vocal\n",
      "Word: has, Deprel: aux, Head: vocal\n",
      "Word: been, Deprel: cop, Head: vocal\n",
      "Word: vocal, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: warning\n",
      "Word: the, Deprel: det, Head: warning\n",
      "Word: past, Deprel: amod, Head: warning\n",
      "Word: warning, Deprel: obl, Head: vocal\n",
      "Word: that, Deprel: mark, Head: threat\n",
      "Word: Linux, Deprel: nsubj, Head: threat\n",
      "Word: is, Deprel: cop, Head: threat\n",
      "Word: a, Deprel: det, Head: threat\n",
      "Word: threat, Deprel: acl, Head: warning\n",
      "Word: to, Deprel: case, Head: Microsoft\n",
      "Word: Microsoft, Deprel: nmod, Head: threat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In the memo Ballmer reiterated the open-source threat to Microsoft'\n",
      "Word: In, Deprel: case, Head: memo\n",
      "Word: the, Deprel: det, Head: memo\n",
      "Word: memo, Deprel: obl, Head: reiterated\n",
      "Word: Ballmer, Deprel: nsubj, Head: reiterated\n",
      "Word: reiterated, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: threat\n",
      "Word: open-source, Deprel: amod, Head: threat\n",
      "Word: threat, Deprel: obj, Head: reiterated\n",
      "Word: to, Deprel: case, Head: Microsoft\n",
      "Word: Microsoft, Deprel: nmod, Head: threat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broad Standard Poor s 500-stock index was up 4.83 points or 0.49 per cent to 980.76'\n",
      "Word: The, Deprel: det, Head: Poor\n",
      "Word: broad, Deprel: amod, Head: Poor\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: nmod:poss, Head: index\n",
      "Word: s, Deprel: case, Head: Poor\n",
      "Word: 500-stock, Deprel: compound, Head: index\n",
      "Word: index, Deprel: nsubj, Head: up\n",
      "Word: was, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: 4.83, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: up\n",
      "Word: or, Deprel: cc, Head: cent\n",
      "Word: 0.49, Deprel: nummod, Head: cent\n",
      "Word: per, Deprel: compound, Head: cent\n",
      "Word: cent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 980.76\n",
      "Word: 980.76, Deprel: obl, Head: up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Standard Poor s 500 stock index futures declined 4.40 points to 983.50 while Nasdaq futures fell 6.5 points to 1,206.50'\n",
      "Word: Standard, Deprel: amod, Head: Poor\n",
      "Word: Poor, Deprel: nmod:poss, Head: futures\n",
      "Word: s, Deprel: case, Head: Poor\n",
      "Word: 500, Deprel: nummod, Head: futures\n",
      "Word: stock, Deprel: compound, Head: index\n",
      "Word: index, Deprel: compound, Head: futures\n",
      "Word: futures, Deprel: nsubj, Head: declined\n",
      "Word: declined, Deprel: root, Head: ROOT\n",
      "Word: 4.40, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: declined\n",
      "Word: to, Deprel: case, Head: 983.50\n",
      "Word: 983.50, Deprel: obl, Head: declined\n",
      "Word: while, Deprel: mark, Head: fell\n",
      "Word: Nasdaq, Deprel: compound, Head: futures\n",
      "Word: futures, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: advcl, Head: declined\n",
      "Word: 6.5, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: fell\n",
      "Word: to, Deprel: case, Head: 1,206.50\n",
      "Word: 1,206.50, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Talabani told him the Governing Council would need UN assistance and advice in implementing the new decisions which have been taken'\n",
      "Word: Talabani, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: him, Deprel: iobj, Head: told\n",
      "Word: the, Deprel: det, Head: Council\n",
      "Word: Governing, Deprel: amod, Head: Council\n",
      "Word: Council, Deprel: nsubj, Head: need\n",
      "Word: would, Deprel: aux, Head: need\n",
      "Word: need, Deprel: ccomp, Head: told\n",
      "Word: UN, Deprel: compound, Head: assistance\n",
      "Word: assistance, Deprel: obj, Head: need\n",
      "Word: and, Deprel: cc, Head: advice\n",
      "Word: advice, Deprel: conj, Head: assistance\n",
      "Word: in, Deprel: mark, Head: implementing\n",
      "Word: implementing, Deprel: advcl, Head: need\n",
      "Word: the, Deprel: det, Head: decisions\n",
      "Word: new, Deprel: amod, Head: decisions\n",
      "Word: decisions, Deprel: obj, Head: implementing\n",
      "Word: which, Deprel: nsubj:pass, Head: taken\n",
      "Word: have, Deprel: aux, Head: taken\n",
      "Word: been, Deprel: aux:pass, Head: taken\n",
      "Word: taken, Deprel: acl:relcl, Head: decisions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Talabani told him Iraqi leaders would need U.N assistance and advice in implementing the new decisions which have been taken on organising an interim Iraqi government by June'\n",
      "Word: Talabani, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: him, Deprel: iobj, Head: told\n",
      "Word: Iraqi, Deprel: amod, Head: leaders\n",
      "Word: leaders, Deprel: nsubj, Head: need\n",
      "Word: would, Deprel: aux, Head: need\n",
      "Word: need, Deprel: ccomp, Head: told\n",
      "Word: U.N, Deprel: compound, Head: assistance\n",
      "Word: assistance, Deprel: obj, Head: need\n",
      "Word: and, Deprel: cc, Head: advice\n",
      "Word: advice, Deprel: conj, Head: assistance\n",
      "Word: in, Deprel: mark, Head: implementing\n",
      "Word: implementing, Deprel: advcl, Head: need\n",
      "Word: the, Deprel: det, Head: decisions\n",
      "Word: new, Deprel: amod, Head: decisions\n",
      "Word: decisions, Deprel: obj, Head: implementing\n",
      "Word: which, Deprel: nsubj:pass, Head: taken\n",
      "Word: have, Deprel: aux, Head: taken\n",
      "Word: been, Deprel: aux:pass, Head: taken\n",
      "Word: taken, Deprel: acl:relcl, Head: decisions\n",
      "Word: on, Deprel: mark, Head: organising\n",
      "Word: organising, Deprel: advcl, Head: taken\n",
      "Word: an, Deprel: det, Head: government\n",
      "Word: interim, Deprel: amod, Head: government\n",
      "Word: Iraqi, Deprel: amod, Head: government\n",
      "Word: government, Deprel: obj, Head: organising\n",
      "Word: by, Deprel: case, Head: June\n",
      "Word: June, Deprel: obl, Head: organising\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Stanford 46-15 plays South Carolina 44-20 today in a first-round game at Rosenblatt Stadium in Omaha Neb'\n",
      "Word: Stanford, Deprel: nsubj, Head: plays\n",
      "Word: 46-15, Deprel: flat, Head: Stanford\n",
      "Word: plays, Deprel: root, Head: ROOT\n",
      "Word: South, Deprel: compound, Head: Carolina\n",
      "Word: Carolina, Deprel: obj, Head: plays\n",
      "Word: 44-20, Deprel: obl:tmod, Head: plays\n",
      "Word: today, Deprel: obl:tmod, Head: plays\n",
      "Word: in, Deprel: case, Head: game\n",
      "Word: a, Deprel: det, Head: game\n",
      "Word: first-round, Deprel: amod, Head: game\n",
      "Word: game, Deprel: obl, Head: plays\n",
      "Word: at, Deprel: case, Head: Stadium\n",
      "Word: Rosenblatt, Deprel: compound, Head: Stadium\n",
      "Word: Stadium, Deprel: nmod, Head: game\n",
      "Word: in, Deprel: case, Head: Neb\n",
      "Word: Omaha, Deprel: compound, Head: Neb\n",
      "Word: Neb, Deprel: nmod, Head: Stadium\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Stanford 46-15 plays South Carolina 44-20 on Friday in the opening game of the double-elimination tournament'\n",
      "Word: Stanford, Deprel: nsubj, Head: plays\n",
      "Word: 46-15, Deprel: flat, Head: Stanford\n",
      "Word: plays, Deprel: root, Head: ROOT\n",
      "Word: South, Deprel: compound, Head: Carolina\n",
      "Word: Carolina, Deprel: obj, Head: plays\n",
      "Word: 44-20, Deprel: obl:tmod, Head: plays\n",
      "Word: on, Deprel: case, Head: Friday\n",
      "Word: Friday, Deprel: obl, Head: plays\n",
      "Word: in, Deprel: case, Head: game\n",
      "Word: the, Deprel: det, Head: game\n",
      "Word: opening, Deprel: amod, Head: game\n",
      "Word: game, Deprel: obl, Head: plays\n",
      "Word: of, Deprel: case, Head: tournament\n",
      "Word: the, Deprel: det, Head: tournament\n",
      "Word: double-elimination, Deprel: amod, Head: tournament\n",
      "Word: tournament, Deprel: nmod, Head: game\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The same survey a month ago had Street leading Katz 42 percent to 34 percent with 21 percent undecided'\n",
      "Word: The, Deprel: det, Head: survey\n",
      "Word: same, Deprel: amod, Head: survey\n",
      "Word: survey, Deprel: nsubj, Head: had\n",
      "Word: a, Deprel: det, Head: month\n",
      "Word: month, Deprel: obl:npmod, Head: ago\n",
      "Word: ago, Deprel: advmod, Head: had\n",
      "Word: had, Deprel: root, Head: ROOT\n",
      "Word: Street, Deprel: nsubj, Head: leading\n",
      "Word: leading, Deprel: xcomp, Head: had\n",
      "Word: Katz, Deprel: obj, Head: leading\n",
      "Word: 42, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: leading\n",
      "Word: to, Deprel: case, Head: percent\n",
      "Word: 34, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: leading\n",
      "Word: with, Deprel: mark, Head: undecided\n",
      "Word: 21, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:npmod, Head: undecided\n",
      "Word: undecided, Deprel: obl, Head: leading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'One month ago in the same poll Katz was leading 46 to 40 percent'\n",
      "Word: One, Deprel: nummod, Head: month\n",
      "Word: month, Deprel: obl:tmod, Head: ago\n",
      "Word: ago, Deprel: advmod, Head: leading\n",
      "Word: in, Deprel: case, Head: poll\n",
      "Word: the, Deprel: det, Head: poll\n",
      "Word: same, Deprel: amod, Head: poll\n",
      "Word: poll, Deprel: obl, Head: leading\n",
      "Word: Katz, Deprel: nsubj, Head: leading\n",
      "Word: was, Deprel: aux, Head: leading\n",
      "Word: leading, Deprel: root, Head: ROOT\n",
      "Word: 46, Deprel: nummod, Head: percent\n",
      "Word: to, Deprel: case, Head: 40\n",
      "Word: 40, Deprel: nmod, Head: 46\n",
      "Word: percent, Deprel: obl:tmod, Head: leading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broad Standard Poor s 500 Index SPX advanced 11 points or 1.25 percent to 931'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broad, Deprel: amod, Head: s\n",
      "Word: Standard, Deprel: compound, Head: s\n",
      "Word: Poor, Deprel: amod, Head: s\n",
      "Word: s, Deprel: compound, Head: SPX\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: advanced\n",
      "Word: advanced, Deprel: root, Head: ROOT\n",
      "Word: 11, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: advanced\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.25, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 931\n",
      "Word: 931, Deprel: obl, Head: advanced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Standard Poor s 500 Index gained 10.89 or 1.2 percent to 931.12 as of 12:01 p.m in New York'\n",
      "Word: The, Deprel: det, Head: Poor\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: nmod:poss, Head: Index\n",
      "Word: s, Deprel: case, Head: Poor\n",
      "Word: 500, Deprel: nummod, Head: Index\n",
      "Word: Index, Deprel: nsubj, Head: gained\n",
      "Word: gained, Deprel: root, Head: ROOT\n",
      "Word: 10.89, Deprel: nummod, Head: percent\n",
      "Word: or, Deprel: cc, Head: 1.2\n",
      "Word: 1.2, Deprel: conj, Head: 10.89\n",
      "Word: percent, Deprel: obj, Head: gained\n",
      "Word: to, Deprel: case, Head: 931.12\n",
      "Word: 931.12, Deprel: obl, Head: gained\n",
      "Word: as, Deprel: case, Head: p.m\n",
      "Word: of, Deprel: fixed, Head: as\n",
      "Word: 12:01, Deprel: nummod, Head: p.m\n",
      "Word: p.m, Deprel: obl, Head: gained\n",
      "Word: in, Deprel: case, Head: York\n",
      "Word: New, Deprel: amod, Head: York\n",
      "Word: York, Deprel: nmod, Head: p.m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We are expending all available resources toward the investigation said Assistant U.S Attorney Todd Greenberg a counterterrorism prosecutor in Seattle'\n",
      "Word: We, Deprel: nsubj, Head: expending\n",
      "Word: are, Deprel: aux, Head: expending\n",
      "Word: expending, Deprel: root, Head: ROOT\n",
      "Word: all, Deprel: det, Head: resources\n",
      "Word: available, Deprel: amod, Head: resources\n",
      "Word: resources, Deprel: obj, Head: expending\n",
      "Word: toward, Deprel: case, Head: investigation\n",
      "Word: the, Deprel: det, Head: investigation\n",
      "Word: investigation, Deprel: nmod, Head: resources\n",
      "Word: said, Deprel: parataxis, Head: expending\n",
      "Word: Assistant, Deprel: compound, Head: Attorney\n",
      "Word: U.S, Deprel: compound, Head: Attorney\n",
      "Word: Attorney, Deprel: obj, Head: said\n",
      "Word: Todd, Deprel: flat, Head: Attorney\n",
      "Word: Greenberg, Deprel: flat, Head: Attorney\n",
      "Word: a, Deprel: det, Head: prosecutor\n",
      "Word: counterterrorism, Deprel: compound, Head: prosecutor\n",
      "Word: prosecutor, Deprel: appos, Head: Attorney\n",
      "Word: in, Deprel: case, Head: Seattle\n",
      "Word: Seattle, Deprel: nmod, Head: prosecutor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We are aware of the situation said Assistant US Attorney Todd Greenberg a counter-terrorism prosecutor in Seattle'\n",
      "Word: We, Deprel: nsubj, Head: aware\n",
      "Word: are, Deprel: cop, Head: aware\n",
      "Word: aware, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: situation\n",
      "Word: the, Deprel: det, Head: situation\n",
      "Word: situation, Deprel: obl, Head: aware\n",
      "Word: said, Deprel: parataxis, Head: aware\n",
      "Word: Assistant, Deprel: compound, Head: Attorney\n",
      "Word: US, Deprel: compound, Head: Attorney\n",
      "Word: Attorney, Deprel: obj, Head: said\n",
      "Word: Todd, Deprel: flat, Head: Attorney\n",
      "Word: Greenberg, Deprel: flat, Head: Attorney\n",
      "Word: a, Deprel: det, Head: prosecutor\n",
      "Word: counter-terrorism, Deprel: compound, Head: prosecutor\n",
      "Word: prosecutor, Deprel: appos, Head: Attorney\n",
      "Word: in, Deprel: case, Head: Seattle\n",
      "Word: Seattle, Deprel: nmod, Head: prosecutor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But they don ’ t realize that until it ’ s too late of course because they ’ re potential victims in a horror movie'\n",
      "Word: But, Deprel: cc, Head: realize\n",
      "Word: they, Deprel: nsubj, Head: realize\n",
      "Word: don, Deprel: aux, Head: realize\n",
      "Word: ’, Deprel: advmod, Head: realize\n",
      "Word: t, Deprel: advmod, Head: realize\n",
      "Word: realize, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: late\n",
      "Word: until, Deprel: mark, Head: it\n",
      "Word: it, Deprel: nsubj, Head: late\n",
      "Word: ’, Deprel: punct, Head: late\n",
      "Word: s, Deprel: cop, Head: late\n",
      "Word: too, Deprel: advmod, Head: late\n",
      "Word: late, Deprel: ccomp, Head: realize\n",
      "Word: of, Deprel: advmod, Head: late\n",
      "Word: course, Deprel: fixed, Head: of\n",
      "Word: because, Deprel: mark, Head: victims\n",
      "Word: they, Deprel: nsubj, Head: victims\n",
      "Word: ’, Deprel: case, Head: they\n",
      "Word: re, Deprel: case, Head: victims\n",
      "Word: potential, Deprel: amod, Head: victims\n",
      "Word: victims, Deprel: obl, Head: late\n",
      "Word: in, Deprel: case, Head: movie\n",
      "Word: a, Deprel: det, Head: movie\n",
      "Word: horror, Deprel: compound, Head: movie\n",
      "Word: movie, Deprel: nmod, Head: victims\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But they do n't realize that until it s too late of course because they re potential victims'\n",
      "Word: But, Deprel: cc, Head: realize\n",
      "Word: they, Deprel: nsubj, Head: realize\n",
      "Word: do, Deprel: aux, Head: realize\n",
      "Word: n't, Deprel: advmod, Head: realize\n",
      "Word: realize, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: late\n",
      "Word: until, Deprel: mark, Head: late\n",
      "Word: it, Deprel: nsubj, Head: late\n",
      "Word: s, Deprel: cop, Head: late\n",
      "Word: too, Deprel: advmod, Head: late\n",
      "Word: late, Deprel: advcl, Head: realize\n",
      "Word: of, Deprel: advmod, Head: late\n",
      "Word: course, Deprel: fixed, Head: of\n",
      "Word: because, Deprel: mark, Head: victims\n",
      "Word: they, Deprel: nsubj, Head: victims\n",
      "Word: re, Deprel: cop, Head: victims\n",
      "Word: potential, Deprel: amod, Head: victims\n",
      "Word: victims, Deprel: advcl, Head: late\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Arthur Benson attorney for the case s plaintiff schoolchildren said he will appeal'\n",
      "Word: Arthur, Deprel: compound, Head: attorney\n",
      "Word: Benson, Deprel: flat, Head: Arthur\n",
      "Word: attorney, Deprel: nsubj, Head: said\n",
      "Word: for, Deprel: case, Head: schoolchildren\n",
      "Word: the, Deprel: det, Head: case\n",
      "Word: case, Deprel: nmod:poss, Head: schoolchildren\n",
      "Word: s, Deprel: case, Head: case\n",
      "Word: plaintiff, Deprel: compound, Head: schoolchildren\n",
      "Word: schoolchildren, Deprel: nmod, Head: attorney\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: appeal\n",
      "Word: will, Deprel: aux, Head: appeal\n",
      "Word: appeal, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'An attorney for plaintiff schoolchildren said he plans to appeal'\n",
      "Word: An, Deprel: det, Head: attorney\n",
      "Word: attorney, Deprel: nsubj, Head: said\n",
      "Word: for, Deprel: case, Head: schoolchildren\n",
      "Word: plaintiff, Deprel: compound, Head: schoolchildren\n",
      "Word: schoolchildren, Deprel: nmod, Head: attorney\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: he, Deprel: nsubj, Head: plans\n",
      "Word: plans, Deprel: ccomp, Head: said\n",
      "Word: to, Deprel: mark, Head: appeal\n",
      "Word: appeal, Deprel: xcomp, Head: plans\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The euro has slipped nearly four percent since matching a record peak of around 1.1935 only last week and hitting an all-time high of 140.90 yen in late May'\n",
      "Word: The, Deprel: det, Head: euro\n",
      "Word: euro, Deprel: nsubj, Head: slipped\n",
      "Word: has, Deprel: aux, Head: slipped\n",
      "Word: slipped, Deprel: root, Head: ROOT\n",
      "Word: nearly, Deprel: advmod, Head: four\n",
      "Word: four, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: slipped\n",
      "Word: since, Deprel: mark, Head: matching\n",
      "Word: matching, Deprel: advcl, Head: slipped\n",
      "Word: a, Deprel: det, Head: peak\n",
      "Word: record, Deprel: amod, Head: peak\n",
      "Word: peak, Deprel: obj, Head: matching\n",
      "Word: of, Deprel: case, Head: 1.1935\n",
      "Word: around, Deprel: advmod, Head: 1.1935\n",
      "Word: 1.1935, Deprel: nmod, Head: peak\n",
      "Word: only, Deprel: advmod, Head: week\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: matching\n",
      "Word: and, Deprel: cc, Head: hitting\n",
      "Word: hitting, Deprel: conj, Head: matching\n",
      "Word: an, Deprel: det, Head: high\n",
      "Word: all-time, Deprel: amod, Head: high\n",
      "Word: high, Deprel: obj, Head: hitting\n",
      "Word: of, Deprel: case, Head: yen\n",
      "Word: 140.90, Deprel: nummod, Head: yen\n",
      "Word: yen, Deprel: nmod, Head: high\n",
      "Word: in, Deprel: case, Head: May\n",
      "Word: late, Deprel: amod, Head: May\n",
      "Word: May, Deprel: obl, Head: hitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The euro has slipped as much as four cents since matching a record peak near 1.1935 last week and hitting a record high of 140.90 yen in late May'\n",
      "Word: The, Deprel: det, Head: euro\n",
      "Word: euro, Deprel: nsubj, Head: slipped\n",
      "Word: has, Deprel: aux, Head: slipped\n",
      "Word: slipped, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: advmod, Head: four\n",
      "Word: much, Deprel: fixed, Head: as\n",
      "Word: as, Deprel: fixed, Head: as\n",
      "Word: four, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obj, Head: slipped\n",
      "Word: since, Deprel: mark, Head: matching\n",
      "Word: matching, Deprel: advcl, Head: slipped\n",
      "Word: a, Deprel: det, Head: peak\n",
      "Word: record, Deprel: amod, Head: peak\n",
      "Word: peak, Deprel: obj, Head: matching\n",
      "Word: near, Deprel: case, Head: 1.1935\n",
      "Word: 1.1935, Deprel: obl, Head: matching\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: matching\n",
      "Word: and, Deprel: cc, Head: hitting\n",
      "Word: hitting, Deprel: conj, Head: matching\n",
      "Word: a, Deprel: det, Head: high\n",
      "Word: record, Deprel: amod, Head: high\n",
      "Word: high, Deprel: obj, Head: hitting\n",
      "Word: of, Deprel: case, Head: yen\n",
      "Word: 140.90, Deprel: nummod, Head: yen\n",
      "Word: yen, Deprel: nmod, Head: high\n",
      "Word: in, Deprel: case, Head: May\n",
      "Word: late, Deprel: amod, Head: May\n",
      "Word: May, Deprel: obl, Head: hitting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Pennsylvania which has the most aggressive treatment program is treating 548 of 8,030 inmates'\n",
      "Word: Pennsylvania, Deprel: nsubj, Head: treating\n",
      "Word: which, Deprel: nsubj, Head: has\n",
      "Word: has, Deprel: acl:relcl, Head: Pennsylvania\n",
      "Word: the, Deprel: det, Head: program\n",
      "Word: most, Deprel: advmod, Head: aggressive\n",
      "Word: aggressive, Deprel: amod, Head: program\n",
      "Word: treatment, Deprel: compound, Head: program\n",
      "Word: program, Deprel: obj, Head: has\n",
      "Word: is, Deprel: aux, Head: treating\n",
      "Word: treating, Deprel: root, Head: ROOT\n",
      "Word: 548, Deprel: obj, Head: treating\n",
      "Word: of, Deprel: case, Head: inmates\n",
      "Word: 8,030, Deprel: nummod, Head: inmates\n",
      "Word: inmates, Deprel: nmod, Head: 548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Texas which has more than three times Michigan s inmate population is treating 328 of its 16,298 infected inmates'\n",
      "Word: Texas, Deprel: nsubj, Head: treating\n",
      "Word: which, Deprel: nsubj, Head: has\n",
      "Word: has, Deprel: acl:relcl, Head: Texas\n",
      "Word: more, Deprel: advmod, Head: three\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: three, Deprel: nummod, Head: times\n",
      "Word: times, Deprel: compound, Head: population\n",
      "Word: Michigan, Deprel: nmod:poss, Head: population\n",
      "Word: s, Deprel: case, Head: Michigan\n",
      "Word: inmate, Deprel: compound, Head: population\n",
      "Word: population, Deprel: obj, Head: has\n",
      "Word: is, Deprel: aux, Head: treating\n",
      "Word: treating, Deprel: root, Head: ROOT\n",
      "Word: 328, Deprel: obj, Head: treating\n",
      "Word: of, Deprel: case, Head: inmates\n",
      "Word: its, Deprel: nmod:poss, Head: inmates\n",
      "Word: 16,298, Deprel: nummod, Head: inmates\n",
      "Word: infected, Deprel: amod, Head: inmates\n",
      "Word: inmates, Deprel: nmod, Head: 328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The tech-loaded Nasdaq composite rose 20.96 points to 1595.91 to end at its highest level for 12 months'\n",
      "Word: The, Deprel: det, Head: composite\n",
      "Word: tech-loaded, Deprel: amod, Head: composite\n",
      "Word: Nasdaq, Deprel: compound, Head: composite\n",
      "Word: composite, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 20.96, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:tmod, Head: rose\n",
      "Word: to, Deprel: case, Head: 1595.91\n",
      "Word: 1595.91, Deprel: obl, Head: rose\n",
      "Word: to, Deprel: mark, Head: end\n",
      "Word: end, Deprel: advcl, Head: rose\n",
      "Word: at, Deprel: case, Head: level\n",
      "Word: its, Deprel: nmod:poss, Head: level\n",
      "Word: highest, Deprel: amod, Head: level\n",
      "Word: level, Deprel: obl, Head: end\n",
      "Word: for, Deprel: case, Head: months\n",
      "Word: 12, Deprel: nummod, Head: months\n",
      "Word: months, Deprel: obl, Head: end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index IXIC climbed 19.11 points or 1.2 percent to 1,615.02'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-laced, Deprel: amod, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: climbed\n",
      "Word: climbed, Deprel: root, Head: ROOT\n",
      "Word: 19.11, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: climbed\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.2, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,615.02\n",
      "Word: 1,615.02, Deprel: obl, Head: climbed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index IXIC shed 15 points or 0.98 percent to 1,492'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-laced, Deprel: amod, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: shed\n",
      "Word: shed, Deprel: root, Head: ROOT\n",
      "Word: 15, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: shed\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.98, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 1,492\n",
      "Word: 1,492, Deprel: obl, Head: shed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index SPX edged down 9 points or 0.98 percent to 921'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broader, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: s\n",
      "Word: Poor, Deprel: amod, Head: s\n",
      "Word: s, Deprel: compound, Head: SPX\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: edged\n",
      "Word: edged, Deprel: root, Head: ROOT\n",
      "Word: down, Deprel: advmod, Head: edged\n",
      "Word: 9, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: edged\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0.98, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: to, Deprel: case, Head: 921\n",
      "Word: 921, Deprel: obl, Head: edged\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'With the Expose feature all open windows shrink to fit on the screen but are still clear enough to identify'\n",
      "Word: With, Deprel: case, Head: feature\n",
      "Word: the, Deprel: det, Head: feature\n",
      "Word: Expose, Deprel: compound, Head: feature\n",
      "Word: feature, Deprel: obl, Head: shrink\n",
      "Word: all, Deprel: det, Head: windows\n",
      "Word: open, Deprel: amod, Head: windows\n",
      "Word: windows, Deprel: nsubj, Head: shrink\n",
      "Word: shrink, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: fit\n",
      "Word: fit, Deprel: advcl, Head: shrink\n",
      "Word: on, Deprel: case, Head: screen\n",
      "Word: the, Deprel: det, Head: screen\n",
      "Word: screen, Deprel: obl, Head: fit\n",
      "Word: but, Deprel: cc, Head: clear\n",
      "Word: are, Deprel: cop, Head: clear\n",
      "Word: still, Deprel: advmod, Head: clear\n",
      "Word: clear, Deprel: conj, Head: shrink\n",
      "Word: enough, Deprel: advmod, Head: clear\n",
      "Word: to, Deprel: mark, Head: identify\n",
      "Word: identify, Deprel: advcl, Head: clear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'With the Expose ex-poh-SAY feature all the open windows on the desktop immediately shrink to fit on the screen but are still clear enough to identify'\n",
      "Word: With, Deprel: case, Head: feature\n",
      "Word: the, Deprel: det, Head: feature\n",
      "Word: Expose, Deprel: compound, Head: feature\n",
      "Word: ex-poh-SAY, Deprel: compound, Head: feature\n",
      "Word: feature, Deprel: obl, Head: shrink\n",
      "Word: all, Deprel: det:predet, Head: windows\n",
      "Word: the, Deprel: det, Head: windows\n",
      "Word: open, Deprel: amod, Head: windows\n",
      "Word: windows, Deprel: nsubj, Head: shrink\n",
      "Word: on, Deprel: case, Head: desktop\n",
      "Word: the, Deprel: det, Head: desktop\n",
      "Word: desktop, Deprel: nmod, Head: windows\n",
      "Word: immediately, Deprel: advmod, Head: shrink\n",
      "Word: shrink, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: fit\n",
      "Word: fit, Deprel: advcl, Head: shrink\n",
      "Word: on, Deprel: case, Head: screen\n",
      "Word: the, Deprel: det, Head: screen\n",
      "Word: screen, Deprel: obl, Head: fit\n",
      "Word: but, Deprel: cc, Head: clear\n",
      "Word: are, Deprel: cop, Head: clear\n",
      "Word: still, Deprel: advmod, Head: clear\n",
      "Word: clear, Deprel: conj, Head: shrink\n",
      "Word: enough, Deprel: advmod, Head: clear\n",
      "Word: to, Deprel: mark, Head: identify\n",
      "Word: identify, Deprel: advcl, Head: clear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Instead prosecutors dismissed charges and Rucker left the courtroom a free man'\n",
      "Word: Instead, Deprel: advmod, Head: dismissed\n",
      "Word: prosecutors, Deprel: nsubj, Head: dismissed\n",
      "Word: dismissed, Deprel: root, Head: ROOT\n",
      "Word: charges, Deprel: obj, Head: dismissed\n",
      "Word: and, Deprel: cc, Head: left\n",
      "Word: Rucker, Deprel: nsubj, Head: left\n",
      "Word: left, Deprel: conj, Head: dismissed\n",
      "Word: the, Deprel: det, Head: courtroom\n",
      "Word: courtroom, Deprel: obj, Head: left\n",
      "Word: a, Deprel: det, Head: man\n",
      "Word: free, Deprel: amod, Head: man\n",
      "Word: man, Deprel: obj, Head: left\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Instead he left the courtroom a free man after authorities dismissed criminal charges'\n",
      "Word: Instead, Deprel: advmod, Head: left\n",
      "Word: he, Deprel: nsubj, Head: left\n",
      "Word: left, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: courtroom\n",
      "Word: courtroom, Deprel: obj, Head: left\n",
      "Word: a, Deprel: det, Head: man\n",
      "Word: free, Deprel: amod, Head: man\n",
      "Word: man, Deprel: obj, Head: left\n",
      "Word: after, Deprel: mark, Head: dismissed\n",
      "Word: authorities, Deprel: nsubj, Head: dismissed\n",
      "Word: dismissed, Deprel: advcl, Head: left\n",
      "Word: criminal, Deprel: amod, Head: charges\n",
      "Word: charges, Deprel: obj, Head: dismissed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This case was both mentally challenging and emotionally exhausting said the foreman Jim Wolfcale a 41-year-old minister'\n",
      "Word: This, Deprel: det, Head: case\n",
      "Word: case, Deprel: nsubj, Head: challenging\n",
      "Word: was, Deprel: cop, Head: challenging\n",
      "Word: both, Deprel: cc:preconj, Head: challenging\n",
      "Word: mentally, Deprel: advmod, Head: challenging\n",
      "Word: challenging, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: exhausting\n",
      "Word: emotionally, Deprel: advmod, Head: exhausting\n",
      "Word: exhausting, Deprel: conj, Head: challenging\n",
      "Word: said, Deprel: conj, Head: challenging\n",
      "Word: the, Deprel: det, Head: foreman\n",
      "Word: foreman, Deprel: obj, Head: said\n",
      "Word: Jim, Deprel: appos, Head: foreman\n",
      "Word: Wolfcale, Deprel: flat, Head: Jim\n",
      "Word: a, Deprel: det, Head: minister\n",
      "Word: 41-year-old, Deprel: amod, Head: minister\n",
      "Word: minister, Deprel: appos, Head: foreman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Jim Wolfcale the jury foreman and a minister said This case was both mentally challenging and emotionally exhausting'\n",
      "Word: Jim, Deprel: nsubj, Head: said\n",
      "Word: Wolfcale, Deprel: flat, Head: Jim\n",
      "Word: the, Deprel: det, Head: foreman\n",
      "Word: jury, Deprel: compound, Head: foreman\n",
      "Word: foreman, Deprel: appos, Head: Jim\n",
      "Word: and, Deprel: cc, Head: minister\n",
      "Word: a, Deprel: det, Head: minister\n",
      "Word: minister, Deprel: conj, Head: foreman\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: This, Deprel: det, Head: case\n",
      "Word: case, Deprel: nsubj, Head: challenging\n",
      "Word: was, Deprel: cop, Head: challenging\n",
      "Word: both, Deprel: cc:preconj, Head: challenging\n",
      "Word: mentally, Deprel: advmod, Head: challenging\n",
      "Word: challenging, Deprel: ccomp, Head: said\n",
      "Word: and, Deprel: cc, Head: exhausting\n",
      "Word: emotionally, Deprel: advmod, Head: exhausting\n",
      "Word: exhausting, Deprel: conj, Head: challenging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He arrives later this week on the first state visit by a US President'\n",
      "Word: He, Deprel: nsubj, Head: arrives\n",
      "Word: arrives, Deprel: root, Head: ROOT\n",
      "Word: later, Deprel: advmod, Head: week\n",
      "Word: this, Deprel: det, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: arrives\n",
      "Word: on, Deprel: case, Head: visit\n",
      "Word: the, Deprel: det, Head: visit\n",
      "Word: first, Deprel: amod, Head: visit\n",
      "Word: state, Deprel: compound, Head: visit\n",
      "Word: visit, Deprel: obl, Head: arrives\n",
      "Word: by, Deprel: case, Head: President\n",
      "Word: a, Deprel: det, Head: President\n",
      "Word: US, Deprel: compound, Head: President\n",
      "Word: President, Deprel: nmod, Head: visit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Bush arrives on Tuesday on the first state visit by an American President'\n",
      "Word: Mr, Deprel: nsubj, Head: arrives\n",
      "Word: Bush, Deprel: flat, Head: Mr\n",
      "Word: arrives, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: Tuesday\n",
      "Word: Tuesday, Deprel: obl, Head: arrives\n",
      "Word: on, Deprel: case, Head: visit\n",
      "Word: the, Deprel: det, Head: visit\n",
      "Word: first, Deprel: amod, Head: visit\n",
      "Word: state, Deprel: compound, Head: visit\n",
      "Word: visit, Deprel: obl, Head: arrives\n",
      "Word: by, Deprel: case, Head: President\n",
      "Word: an, Deprel: det, Head: President\n",
      "Word: American, Deprel: amod, Head: President\n",
      "Word: President, Deprel: nmod, Head: visit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The deal approved by both companies board of directors is expected to be completed in the third quarter of Nvidia s fiscal third quarter'\n",
      "Word: The, Deprel: det, Head: deal\n",
      "Word: deal, Deprel: nsubj:pass, Head: expected\n",
      "Word: approved, Deprel: acl, Head: deal\n",
      "Word: by, Deprel: case, Head: board\n",
      "Word: both, Deprel: det, Head: board\n",
      "Word: companies, Deprel: compound, Head: board\n",
      "Word: board, Deprel: obl, Head: approved\n",
      "Word: of, Deprel: case, Head: directors\n",
      "Word: directors, Deprel: nmod, Head: board\n",
      "Word: is, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: completed\n",
      "Word: be, Deprel: aux:pass, Head: completed\n",
      "Word: completed, Deprel: xcomp, Head: expected\n",
      "Word: in, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: third, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: completed\n",
      "Word: of, Deprel: case, Head: quarter\n",
      "Word: Nvidia, Deprel: nmod:poss, Head: quarter\n",
      "Word: s, Deprel: case, Head: Nvidia\n",
      "Word: fiscal, Deprel: amod, Head: quarter\n",
      "Word: third, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: nmod, Head: quarter\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The acquisition has been approved by both companies board of directors and is expected to close in the third quarter this year'\n",
      "Word: The, Deprel: det, Head: acquisition\n",
      "Word: acquisition, Deprel: nsubj:pass, Head: approved\n",
      "Word: has, Deprel: aux, Head: approved\n",
      "Word: been, Deprel: aux:pass, Head: approved\n",
      "Word: approved, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: board\n",
      "Word: both, Deprel: det, Head: board\n",
      "Word: companies, Deprel: compound, Head: board\n",
      "Word: board, Deprel: obl, Head: approved\n",
      "Word: of, Deprel: case, Head: directors\n",
      "Word: directors, Deprel: nmod, Head: board\n",
      "Word: and, Deprel: cc, Head: expected\n",
      "Word: is, Deprel: aux:pass, Head: expected\n",
      "Word: expected, Deprel: conj, Head: approved\n",
      "Word: to, Deprel: mark, Head: close\n",
      "Word: close, Deprel: xcomp, Head: expected\n",
      "Word: in, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: third, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: close\n",
      "Word: this, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: close\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The research firm earlier had forecast an increase of 4.9 percent'\n",
      "Word: The, Deprel: det, Head: firm\n",
      "Word: research, Deprel: compound, Head: firm\n",
      "Word: firm, Deprel: nsubj, Head: forecast\n",
      "Word: earlier, Deprel: advmod, Head: forecast\n",
      "Word: had, Deprel: aux, Head: forecast\n",
      "Word: forecast, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: increase\n",
      "Word: increase, Deprel: obj, Head: forecast\n",
      "Word: of, Deprel: case, Head: percent\n",
      "Word: 4.9, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: nmod, Head: increase\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The firm had predicted earlier this year a 4.9 percent increase'\n",
      "Word: The, Deprel: det, Head: firm\n",
      "Word: firm, Deprel: nsubj, Head: predicted\n",
      "Word: had, Deprel: aux, Head: predicted\n",
      "Word: predicted, Deprel: root, Head: ROOT\n",
      "Word: earlier, Deprel: advmod, Head: year\n",
      "Word: this, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: predicted\n",
      "Word: a, Deprel: det, Head: increase\n",
      "Word: 4.9, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: increase\n",
      "Word: increase, Deprel: obj, Head: predicted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The volatile mix could drag the session beyond the four days allotted by Bush said Senate President Jim King'\n",
      "Word: The, Deprel: det, Head: mix\n",
      "Word: volatile, Deprel: amod, Head: mix\n",
      "Word: mix, Deprel: nsubj, Head: drag\n",
      "Word: could, Deprel: aux, Head: drag\n",
      "Word: drag, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: session\n",
      "Word: session, Deprel: obj, Head: drag\n",
      "Word: beyond, Deprel: case, Head: days\n",
      "Word: the, Deprel: det, Head: days\n",
      "Word: four, Deprel: nummod, Head: days\n",
      "Word: days, Deprel: obl, Head: drag\n",
      "Word: allotted, Deprel: acl, Head: days\n",
      "Word: by, Deprel: case, Head: Bush\n",
      "Word: Bush, Deprel: obl:agent, Head: allotted\n",
      "Word: said, Deprel: advcl, Head: drag\n",
      "Word: Senate, Deprel: compound, Head: President\n",
      "Word: President, Deprel: nsubj, Head: said\n",
      "Word: Jim, Deprel: flat, Head: President\n",
      "Word: King, Deprel: flat, Head: President\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Senate might support capping noneconomic damages beyond the 250,000 Gov Jeb Bush proposes said Senate President Jim King'\n",
      "Word: The, Deprel: det, Head: Senate\n",
      "Word: Senate, Deprel: nsubj, Head: support\n",
      "Word: might, Deprel: aux, Head: support\n",
      "Word: support, Deprel: root, Head: ROOT\n",
      "Word: capping, Deprel: amod, Head: damages\n",
      "Word: noneconomic, Deprel: amod, Head: damages\n",
      "Word: damages, Deprel: obj, Head: support\n",
      "Word: beyond, Deprel: case, Head: Gov\n",
      "Word: the, Deprel: det, Head: Gov\n",
      "Word: 250,000, Deprel: nummod, Head: Gov\n",
      "Word: Gov, Deprel: nmod, Head: damages\n",
      "Word: Jeb, Deprel: nsubj, Head: proposes\n",
      "Word: Bush, Deprel: flat, Head: Jeb\n",
      "Word: proposes, Deprel: acl:relcl, Head: Gov\n",
      "Word: said, Deprel: parataxis, Head: support\n",
      "Word: Senate, Deprel: compound, Head: President\n",
      "Word: President, Deprel: obj, Head: said\n",
      "Word: Jim, Deprel: flat, Head: President\n",
      "Word: King, Deprel: flat, Head: President\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'More than 100 police officers were involved in the busts that were the culmination of a two-year operation investigating the cocaine importing and money laundering gang'\n",
      "Word: More, Deprel: advmod, Head: 100\n",
      "Word: than, Deprel: fixed, Head: More\n",
      "Word: 100, Deprel: nummod, Head: officers\n",
      "Word: police, Deprel: compound, Head: officers\n",
      "Word: officers, Deprel: nsubj:pass, Head: involved\n",
      "Word: were, Deprel: aux:pass, Head: involved\n",
      "Word: involved, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: busts\n",
      "Word: the, Deprel: det, Head: busts\n",
      "Word: busts, Deprel: obl, Head: involved\n",
      "Word: that, Deprel: nsubj, Head: culmination\n",
      "Word: were, Deprel: cop, Head: culmination\n",
      "Word: the, Deprel: det, Head: culmination\n",
      "Word: culmination, Deprel: acl:relcl, Head: busts\n",
      "Word: of, Deprel: case, Head: operation\n",
      "Word: a, Deprel: det, Head: operation\n",
      "Word: two-year, Deprel: amod, Head: operation\n",
      "Word: operation, Deprel: nmod, Head: culmination\n",
      "Word: investigating, Deprel: acl, Head: operation\n",
      "Word: the, Deprel: det, Head: gang\n",
      "Word: cocaine, Deprel: compound, Head: importing\n",
      "Word: importing, Deprel: compound, Head: gang\n",
      "Word: and, Deprel: cc, Head: laundering\n",
      "Word: money, Deprel: compound, Head: laundering\n",
      "Word: laundering, Deprel: conj, Head: importing\n",
      "Word: gang, Deprel: obj, Head: investigating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'More than 100 officers launched the London raids in the final phase of a two-year operation investigating a cocaine and money laundering ring'\n",
      "Word: More, Deprel: advmod, Head: 100\n",
      "Word: than, Deprel: fixed, Head: More\n",
      "Word: 100, Deprel: nummod, Head: officers\n",
      "Word: officers, Deprel: nsubj, Head: launched\n",
      "Word: launched, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: raids\n",
      "Word: London, Deprel: compound, Head: raids\n",
      "Word: raids, Deprel: obj, Head: launched\n",
      "Word: in, Deprel: case, Head: phase\n",
      "Word: the, Deprel: det, Head: phase\n",
      "Word: final, Deprel: amod, Head: phase\n",
      "Word: phase, Deprel: obl, Head: launched\n",
      "Word: of, Deprel: case, Head: operation\n",
      "Word: a, Deprel: det, Head: operation\n",
      "Word: two-year, Deprel: amod, Head: operation\n",
      "Word: operation, Deprel: nmod, Head: phase\n",
      "Word: investigating, Deprel: acl, Head: operation\n",
      "Word: a, Deprel: det, Head: ring\n",
      "Word: cocaine, Deprel: compound, Head: ring\n",
      "Word: and, Deprel: cc, Head: money\n",
      "Word: money, Deprel: conj, Head: cocaine\n",
      "Word: laundering, Deprel: compound, Head: ring\n",
      "Word: ring, Deprel: obj, Head: investigating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Stripping out the extraordinary items fourth-quarter earnings were 64 cents a share compared to 25 cents a share in the prior year'\n",
      "Word: Stripping, Deprel: csubj, Head: cents\n",
      "Word: out, Deprel: compound:prt, Head: Stripping\n",
      "Word: the, Deprel: det, Head: earnings\n",
      "Word: extraordinary, Deprel: amod, Head: earnings\n",
      "Word: items, Deprel: compound, Head: earnings\n",
      "Word: fourth-quarter, Deprel: compound, Head: earnings\n",
      "Word: earnings, Deprel: nsubj, Head: cents\n",
      "Word: were, Deprel: cop, Head: cents\n",
      "Word: 64, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:tmod, Head: cents\n",
      "Word: compared, Deprel: acl, Head: cents\n",
      "Word: to, Deprel: case, Head: cents\n",
      "Word: 25, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl, Head: compared\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:tmod, Head: cents\n",
      "Word: in, Deprel: case, Head: year\n",
      "Word: the, Deprel: det, Head: year\n",
      "Word: prior, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl, Head: compared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Earnings were 59 cents a share for the three months ended May 25 compared with 15 cents a share a year earlier'\n",
      "Word: Earnings, Deprel: nsubj, Head: cents\n",
      "Word: were, Deprel: cop, Head: cents\n",
      "Word: 59, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:npmod, Head: cents\n",
      "Word: for, Deprel: case, Head: months\n",
      "Word: the, Deprel: det, Head: months\n",
      "Word: three, Deprel: nummod, Head: months\n",
      "Word: months, Deprel: nmod, Head: cents\n",
      "Word: ended, Deprel: acl, Head: months\n",
      "Word: May, Deprel: appos, Head: ended\n",
      "Word: 25, Deprel: nummod, Head: May\n",
      "Word: compared, Deprel: case, Head: cents\n",
      "Word: with, Deprel: case, Head: cents\n",
      "Word: 15, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: nmod, Head: cents\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:tmod, Head: cents\n",
      "Word: a, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:npmod, Head: earlier\n",
      "Word: earlier, Deprel: advmod, Head: cents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But at age 15 she had reached 260 pounds and a difficult decision It was time to try surgery'\n",
      "Word: But, Deprel: cc, Head: reached\n",
      "Word: at, Deprel: case, Head: age\n",
      "Word: age, Deprel: obl, Head: reached\n",
      "Word: 15, Deprel: nummod, Head: age\n",
      "Word: she, Deprel: nsubj, Head: reached\n",
      "Word: had, Deprel: aux, Head: reached\n",
      "Word: reached, Deprel: root, Head: ROOT\n",
      "Word: 260, Deprel: nummod, Head: pounds\n",
      "Word: pounds, Deprel: obj, Head: reached\n",
      "Word: and, Deprel: cc, Head: decision\n",
      "Word: a, Deprel: det, Head: decision\n",
      "Word: difficult, Deprel: amod, Head: decision\n",
      "Word: decision, Deprel: conj, Head: pounds\n",
      "Word: It, Deprel: nsubj, Head: time\n",
      "Word: was, Deprel: cop, Head: time\n",
      "Word: time, Deprel: acl:relcl, Head: decision\n",
      "Word: to, Deprel: mark, Head: try\n",
      "Word: try, Deprel: acl, Head: time\n",
      "Word: surgery, Deprel: obj, Head: try\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But at the age of 15 she weighed a whopping 117kg and came to a difficult decision it was time to try surgery'\n",
      "Word: But, Deprel: cc, Head: weighed\n",
      "Word: at, Deprel: case, Head: age\n",
      "Word: the, Deprel: det, Head: age\n",
      "Word: age, Deprel: obl, Head: weighed\n",
      "Word: of, Deprel: case, Head: 15\n",
      "Word: 15, Deprel: nmod, Head: age\n",
      "Word: she, Deprel: nsubj, Head: weighed\n",
      "Word: weighed, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: 117kg\n",
      "Word: whopping, Deprel: amod, Head: 117kg\n",
      "Word: 117kg, Deprel: obj, Head: weighed\n",
      "Word: and, Deprel: cc, Head: came\n",
      "Word: came, Deprel: conj, Head: weighed\n",
      "Word: to, Deprel: case, Head: decision\n",
      "Word: a, Deprel: det, Head: decision\n",
      "Word: difficult, Deprel: amod, Head: decision\n",
      "Word: decision, Deprel: obl, Head: came\n",
      "Word: it, Deprel: nsubj, Head: time\n",
      "Word: was, Deprel: cop, Head: time\n",
      "Word: time, Deprel: ccomp, Head: came\n",
      "Word: to, Deprel: mark, Head: try\n",
      "Word: try, Deprel: acl, Head: time\n",
      "Word: surgery, Deprel: obj, Head: try\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'PeopleSoft will commit 863 million in cash and issue 52.6 million new shares the companies said'\n",
      "Word: PeopleSoft, Deprel: nsubj, Head: commit\n",
      "Word: will, Deprel: aux, Head: commit\n",
      "Word: commit, Deprel: root, Head: ROOT\n",
      "Word: 863, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: commit\n",
      "Word: in, Deprel: case, Head: cash\n",
      "Word: cash, Deprel: obl, Head: commit\n",
      "Word: and, Deprel: cc, Head: issue\n",
      "Word: issue, Deprel: conj, Head: commit\n",
      "Word: 52.6, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: nummod, Head: shares\n",
      "Word: new, Deprel: amod, Head: shares\n",
      "Word: shares, Deprel: obj, Head: issue\n",
      "Word: the, Deprel: det, Head: companies\n",
      "Word: companies, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: shares\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new deal would be valued at 1.75 billion including 863 million in cash and 52.6 million PeopleSoft shares'\n",
      "Word: The, Deprel: det, Head: deal\n",
      "Word: new, Deprel: amod, Head: deal\n",
      "Word: deal, Deprel: nsubj:pass, Head: valued\n",
      "Word: would, Deprel: aux, Head: valued\n",
      "Word: be, Deprel: aux:pass, Head: valued\n",
      "Word: valued, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: billion\n",
      "Word: 1.75, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obl, Head: valued\n",
      "Word: including, Deprel: case, Head: million\n",
      "Word: 863, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: nmod, Head: billion\n",
      "Word: in, Deprel: case, Head: cash\n",
      "Word: cash, Deprel: nmod, Head: million\n",
      "Word: and, Deprel: cc, Head: shares\n",
      "Word: 52.6, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: shares\n",
      "Word: PeopleSoft, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: conj, Head: billion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'If we could do that throughout the world we could end terrorism he said'\n",
      "Word: If, Deprel: mark, Head: do\n",
      "Word: we, Deprel: nsubj, Head: do\n",
      "Word: could, Deprel: aux, Head: do\n",
      "Word: do, Deprel: advcl, Head: end\n",
      "Word: that, Deprel: obj, Head: do\n",
      "Word: throughout, Deprel: case, Head: world\n",
      "Word: the, Deprel: det, Head: world\n",
      "Word: world, Deprel: obl, Head: do\n",
      "Word: we, Deprel: nsubj, Head: end\n",
      "Word: could, Deprel: aux, Head: end\n",
      "Word: end, Deprel: root, Head: ROOT\n",
      "Word: terrorism, Deprel: obj, Head: end\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'This is a hospital that treats everybody as people and if we could do that throughout the world we could end terrorism'\n",
      "Word: This, Deprel: nsubj, Head: hospital\n",
      "Word: is, Deprel: cop, Head: hospital\n",
      "Word: a, Deprel: det, Head: hospital\n",
      "Word: hospital, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: nsubj, Head: treats\n",
      "Word: treats, Deprel: acl:relcl, Head: hospital\n",
      "Word: everybody, Deprel: obj, Head: treats\n",
      "Word: as, Deprel: case, Head: people\n",
      "Word: people, Deprel: obl, Head: treats\n",
      "Word: and, Deprel: cc, Head: end\n",
      "Word: if, Deprel: mark, Head: do\n",
      "Word: we, Deprel: nsubj, Head: do\n",
      "Word: could, Deprel: aux, Head: do\n",
      "Word: do, Deprel: advcl, Head: end\n",
      "Word: that, Deprel: obj, Head: do\n",
      "Word: throughout, Deprel: case, Head: world\n",
      "Word: the, Deprel: det, Head: world\n",
      "Word: world, Deprel: obl, Head: do\n",
      "Word: we, Deprel: nsubj, Head: end\n",
      "Word: could, Deprel: aux, Head: end\n",
      "Word: end, Deprel: conj, Head: hospital\n",
      "Word: terrorism, Deprel: obj, Head: end\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Buoyed by some of the advice imparted by Nicklaus Howell shot an 8-under 64 for a one-stroke lead over Kenny Perry'\n",
      "Word: Buoyed, Deprel: csubj, Head: shot\n",
      "Word: by, Deprel: case, Head: some\n",
      "Word: some, Deprel: obl, Head: Buoyed\n",
      "Word: of, Deprel: case, Head: advice\n",
      "Word: the, Deprel: det, Head: advice\n",
      "Word: advice, Deprel: nmod, Head: some\n",
      "Word: imparted, Deprel: acl, Head: advice\n",
      "Word: by, Deprel: case, Head: Nicklaus\n",
      "Word: Nicklaus, Deprel: obl, Head: imparted\n",
      "Word: Howell, Deprel: flat, Head: Nicklaus\n",
      "Word: shot, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: 64\n",
      "Word: 8-under, Deprel: compound, Head: 64\n",
      "Word: 64, Deprel: obj, Head: shot\n",
      "Word: for, Deprel: case, Head: lead\n",
      "Word: a, Deprel: det, Head: lead\n",
      "Word: one-stroke, Deprel: amod, Head: lead\n",
      "Word: lead, Deprel: obl, Head: shot\n",
      "Word: over, Deprel: case, Head: Kenny\n",
      "Word: Kenny, Deprel: obl, Head: shot\n",
      "Word: Perry, Deprel: flat, Head: Kenny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Buoyed by advice imparted by Nicklaus Howell shot an 8-under 64 on Thursday to enter today s round with a one-stroke lead over Kenny Perry'\n",
      "Word: Buoyed, Deprel: csubj, Head: shot\n",
      "Word: by, Deprel: case, Head: advice\n",
      "Word: advice, Deprel: obl, Head: Buoyed\n",
      "Word: imparted, Deprel: acl, Head: advice\n",
      "Word: by, Deprel: case, Head: Nicklaus\n",
      "Word: Nicklaus, Deprel: obl, Head: imparted\n",
      "Word: Howell, Deprel: flat, Head: Nicklaus\n",
      "Word: shot, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: 64\n",
      "Word: 8-under, Deprel: compound, Head: 64\n",
      "Word: 64, Deprel: obj, Head: shot\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: shot\n",
      "Word: to, Deprel: mark, Head: enter\n",
      "Word: enter, Deprel: advcl, Head: shot\n",
      "Word: today, Deprel: nmod:poss, Head: round\n",
      "Word: s, Deprel: case, Head: today\n",
      "Word: round, Deprel: obj, Head: enter\n",
      "Word: with, Deprel: case, Head: lead\n",
      "Word: a, Deprel: det, Head: lead\n",
      "Word: one-stroke, Deprel: amod, Head: lead\n",
      "Word: lead, Deprel: obl, Head: enter\n",
      "Word: over, Deprel: case, Head: Kenny\n",
      "Word: Kenny, Deprel: nmod, Head: lead\n",
      "Word: Perry, Deprel: flat, Head: Kenny\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'So in his State of the Union address in January Bush declared that the British government has learned that Saddam Hussein recently sought significant quantities of uranium from Africa'\n",
      "Word: So, Deprel: advmod, Head: declared\n",
      "Word: in, Deprel: case, Head: address\n",
      "Word: his, Deprel: nmod:poss, Head: address\n",
      "Word: State, Deprel: compound, Head: address\n",
      "Word: of, Deprel: case, Head: Union\n",
      "Word: the, Deprel: det, Head: Union\n",
      "Word: Union, Deprel: nmod, Head: State\n",
      "Word: address, Deprel: obl, Head: declared\n",
      "Word: in, Deprel: case, Head: January\n",
      "Word: January, Deprel: nmod, Head: address\n",
      "Word: Bush, Deprel: nsubj, Head: declared\n",
      "Word: declared, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: learned\n",
      "Word: the, Deprel: det, Head: government\n",
      "Word: British, Deprel: amod, Head: government\n",
      "Word: government, Deprel: nsubj, Head: learned\n",
      "Word: has, Deprel: aux, Head: learned\n",
      "Word: learned, Deprel: ccomp, Head: declared\n",
      "Word: that, Deprel: mark, Head: sought\n",
      "Word: Saddam, Deprel: nsubj, Head: sought\n",
      "Word: Hussein, Deprel: flat, Head: Saddam\n",
      "Word: recently, Deprel: advmod, Head: sought\n",
      "Word: sought, Deprel: ccomp, Head: learned\n",
      "Word: significant, Deprel: amod, Head: quantities\n",
      "Word: quantities, Deprel: obj, Head: sought\n",
      "Word: of, Deprel: case, Head: uranium\n",
      "Word: uranium, Deprel: nmod, Head: quantities\n",
      "Word: from, Deprel: case, Head: Africa\n",
      "Word: Africa, Deprel: obl, Head: sought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In his Jan 28 State of the Union message Bush said The British government has learned that Saddam Hussein recently sought significant quantities of uranium from Africa'\n",
      "Word: In, Deprel: case, Head: message\n",
      "Word: his, Deprel: nmod:poss, Head: message\n",
      "Word: Jan, Deprel: compound, Head: message\n",
      "Word: 28, Deprel: nummod, Head: Jan\n",
      "Word: State, Deprel: compound, Head: message\n",
      "Word: of, Deprel: case, Head: Union\n",
      "Word: the, Deprel: det, Head: Union\n",
      "Word: Union, Deprel: nmod, Head: State\n",
      "Word: message, Deprel: obl, Head: said\n",
      "Word: Bush, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: The, Deprel: det, Head: government\n",
      "Word: British, Deprel: amod, Head: government\n",
      "Word: government, Deprel: nsubj, Head: learned\n",
      "Word: has, Deprel: aux, Head: learned\n",
      "Word: learned, Deprel: ccomp, Head: said\n",
      "Word: that, Deprel: mark, Head: sought\n",
      "Word: Saddam, Deprel: nsubj, Head: sought\n",
      "Word: Hussein, Deprel: flat, Head: Saddam\n",
      "Word: recently, Deprel: advmod, Head: sought\n",
      "Word: sought, Deprel: ccomp, Head: learned\n",
      "Word: significant, Deprel: amod, Head: quantities\n",
      "Word: quantities, Deprel: obj, Head: sought\n",
      "Word: of, Deprel: case, Head: uranium\n",
      "Word: uranium, Deprel: nmod, Head: quantities\n",
      "Word: from, Deprel: case, Head: Africa\n",
      "Word: Africa, Deprel: obl, Head: sought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Net revenue rose to 3.99 billion from 3.85 billion during the same quarter last year'\n",
      "Word: Net, Deprel: amod, Head: revenue\n",
      "Word: revenue, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: billion\n",
      "Word: 3.99, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obl, Head: rose\n",
      "Word: from, Deprel: case, Head: billion\n",
      "Word: 3.85, Deprel: nummod, Head: billion\n",
      "Word: billion, Deprel: nmod, Head: billion\n",
      "Word: during, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: same, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: rose\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'That is up from 1.14 billion during the same quarter last year'\n",
      "Word: That, Deprel: nsubj, Head: up\n",
      "Word: is, Deprel: cop, Head: up\n",
      "Word: up, Deprel: root, Head: ROOT\n",
      "Word: from, Deprel: case, Head: billion\n",
      "Word: 1.14, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: obl, Head: up\n",
      "Word: during, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: same, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: up\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'If it s a Bill Gates Comdex keynote it must be time for new Tablet PCs'\n",
      "Word: If, Deprel: mark, Head: keynote\n",
      "Word: it, Deprel: nsubj, Head: keynote\n",
      "Word: s, Deprel: cop, Head: keynote\n",
      "Word: a, Deprel: det, Head: keynote\n",
      "Word: Bill, Deprel: compound, Head: keynote\n",
      "Word: Gates, Deprel: flat, Head: Bill\n",
      "Word: Comdex, Deprel: compound, Head: keynote\n",
      "Word: keynote, Deprel: advcl, Head: time\n",
      "Word: it, Deprel: nsubj, Head: time\n",
      "Word: must, Deprel: aux, Head: time\n",
      "Word: be, Deprel: cop, Head: time\n",
      "Word: time, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: PCs\n",
      "Word: new, Deprel: amod, Head: PCs\n",
      "Word: Tablet, Deprel: compound, Head: PCs\n",
      "Word: PCs, Deprel: nmod, Head: time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'If it s the Sunday night before Comdex it must be time for yet another Bill Gates keynote'\n",
      "Word: If, Deprel: mark, Head: night\n",
      "Word: it, Deprel: nsubj, Head: night\n",
      "Word: s, Deprel: cop, Head: night\n",
      "Word: the, Deprel: det, Head: night\n",
      "Word: Sunday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: advcl, Head: time\n",
      "Word: before, Deprel: case, Head: Comdex\n",
      "Word: Comdex, Deprel: nmod, Head: night\n",
      "Word: it, Deprel: nsubj, Head: time\n",
      "Word: must, Deprel: aux, Head: time\n",
      "Word: be, Deprel: cop, Head: time\n",
      "Word: time, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: keynote\n",
      "Word: yet, Deprel: advmod, Head: keynote\n",
      "Word: another, Deprel: det, Head: keynote\n",
      "Word: Bill, Deprel: compound, Head: keynote\n",
      "Word: Gates, Deprel: compound, Head: keynote\n",
      "Word: keynote, Deprel: nmod, Head: time\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'According to reports Knight allegedly punched a parking attendant outside a Los Angeles nightclub'\n",
      "Word: According, Deprel: case, Head: reports\n",
      "Word: to, Deprel: fixed, Head: According\n",
      "Word: reports, Deprel: obl, Head: punched\n",
      "Word: Knight, Deprel: nsubj, Head: punched\n",
      "Word: allegedly, Deprel: advmod, Head: punched\n",
      "Word: punched, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: attendant\n",
      "Word: parking, Deprel: compound, Head: attendant\n",
      "Word: attendant, Deprel: obj, Head: punched\n",
      "Word: outside, Deprel: case, Head: nightclub\n",
      "Word: a, Deprel: det, Head: nightclub\n",
      "Word: Los, Deprel: compound, Head: nightclub\n",
      "Word: Angeles, Deprel: flat, Head: Los\n",
      "Word: nightclub, Deprel: obl, Head: punched\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He was arrested last week for allegedly punching a parking attendant outside a nightclub in LA'\n",
      "Word: He, Deprel: nsubj:pass, Head: arrested\n",
      "Word: was, Deprel: aux:pass, Head: arrested\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: arrested\n",
      "Word: for, Deprel: mark, Head: punching\n",
      "Word: allegedly, Deprel: advmod, Head: punching\n",
      "Word: punching, Deprel: advcl, Head: arrested\n",
      "Word: a, Deprel: det, Head: attendant\n",
      "Word: parking, Deprel: compound, Head: attendant\n",
      "Word: attendant, Deprel: obj, Head: punching\n",
      "Word: outside, Deprel: case, Head: nightclub\n",
      "Word: a, Deprel: det, Head: nightclub\n",
      "Word: nightclub, Deprel: obl, Head: punching\n",
      "Word: in, Deprel: case, Head: LA\n",
      "Word: LA, Deprel: nmod, Head: nightclub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Among those waiting a turn was Jodie Singer a sixth-grader from Washington D.C'\n",
      "Word: Among, Deprel: case, Head: those\n",
      "Word: those, Deprel: root, Head: ROOT\n",
      "Word: waiting, Deprel: acl, Head: those\n",
      "Word: a, Deprel: det, Head: turn\n",
      "Word: turn, Deprel: obj, Head: waiting\n",
      "Word: was, Deprel: cop, Head: those\n",
      "Word: Jodie, Deprel: nsubj, Head: those\n",
      "Word: Singer, Deprel: flat, Head: Jodie\n",
      "Word: a, Deprel: det, Head: sixth-grader\n",
      "Word: sixth-grader, Deprel: appos, Head: Jodie\n",
      "Word: from, Deprel: case, Head: Washington\n",
      "Word: Washington, Deprel: nmod, Head: sixth-grader\n",
      "Word: D.C, Deprel: flat, Head: Washington\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Jodie Singer a sixth-grader from Washington D.C anxiously awaited her turn at the microphone'\n",
      "Word: Jodie, Deprel: nsubj, Head: awaited\n",
      "Word: Singer, Deprel: flat, Head: Jodie\n",
      "Word: a, Deprel: det, Head: sixth-grader\n",
      "Word: sixth-grader, Deprel: appos, Head: Jodie\n",
      "Word: from, Deprel: case, Head: D.C\n",
      "Word: Washington, Deprel: compound, Head: D.C\n",
      "Word: D.C, Deprel: nmod, Head: sixth-grader\n",
      "Word: anxiously, Deprel: advmod, Head: awaited\n",
      "Word: awaited, Deprel: root, Head: ROOT\n",
      "Word: her, Deprel: nmod:poss, Head: turn\n",
      "Word: turn, Deprel: obj, Head: awaited\n",
      "Word: at, Deprel: case, Head: microphone\n",
      "Word: the, Deprel: det, Head: microphone\n",
      "Word: microphone, Deprel: obl, Head: awaited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But the cancer society said its study had been misused'\n",
      "Word: But, Deprel: cc, Head: said\n",
      "Word: the, Deprel: det, Head: society\n",
      "Word: cancer, Deprel: compound, Head: society\n",
      "Word: society, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: its, Deprel: nmod:poss, Head: study\n",
      "Word: study, Deprel: nsubj:pass, Head: misused\n",
      "Word: had, Deprel: aux, Head: misused\n",
      "Word: been, Deprel: aux:pass, Head: misused\n",
      "Word: misused, Deprel: ccomp, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The American Cancer Society and several scientists said the study was flawed in several ways'\n",
      "Word: The, Deprel: det, Head: Society\n",
      "Word: American, Deprel: amod, Head: Society\n",
      "Word: Cancer, Deprel: compound, Head: Society\n",
      "Word: Society, Deprel: nsubj, Head: said\n",
      "Word: and, Deprel: cc, Head: scientists\n",
      "Word: several, Deprel: amod, Head: scientists\n",
      "Word: scientists, Deprel: conj, Head: Society\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: study\n",
      "Word: study, Deprel: nsubj, Head: flawed\n",
      "Word: was, Deprel: cop, Head: flawed\n",
      "Word: flawed, Deprel: ccomp, Head: said\n",
      "Word: in, Deprel: case, Head: ways\n",
      "Word: several, Deprel: amod, Head: ways\n",
      "Word: ways, Deprel: obl, Head: flawed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Both are being held in the Armstrong County Jail'\n",
      "Word: Both, Deprel: nsubj:pass, Head: held\n",
      "Word: are, Deprel: aux, Head: held\n",
      "Word: being, Deprel: aux:pass, Head: held\n",
      "Word: held, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: Jail\n",
      "Word: the, Deprel: det, Head: Jail\n",
      "Word: Armstrong, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: Jail\n",
      "Word: Jail, Deprel: obl, Head: held\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Tatar was being held without bail in Armstrong County Prison today'\n",
      "Word: Tatar, Deprel: nsubj:pass, Head: held\n",
      "Word: was, Deprel: aux, Head: held\n",
      "Word: being, Deprel: aux:pass, Head: held\n",
      "Word: held, Deprel: root, Head: ROOT\n",
      "Word: without, Deprel: case, Head: bail\n",
      "Word: bail, Deprel: obl, Head: held\n",
      "Word: in, Deprel: case, Head: Prison\n",
      "Word: Armstrong, Deprel: compound, Head: County\n",
      "Word: County, Deprel: compound, Head: Prison\n",
      "Word: Prison, Deprel: obl, Head: held\n",
      "Word: today, Deprel: obl:tmod, Head: held\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A few miles further east is Tehuacan where corn may first have been domesticated 4,000 years ago'\n",
      "Word: A, Deprel: det, Head: miles\n",
      "Word: few, Deprel: amod, Head: miles\n",
      "Word: miles, Deprel: obl:npmod, Head: further\n",
      "Word: further, Deprel: advmod, Head: east\n",
      "Word: east, Deprel: advmod, Head: Tehuacan\n",
      "Word: is, Deprel: cop, Head: Tehuacan\n",
      "Word: Tehuacan, Deprel: root, Head: ROOT\n",
      "Word: where, Deprel: advmod, Head: domesticated\n",
      "Word: corn, Deprel: nsubj:pass, Head: domesticated\n",
      "Word: may, Deprel: aux, Head: domesticated\n",
      "Word: first, Deprel: advmod, Head: domesticated\n",
      "Word: have, Deprel: aux, Head: domesticated\n",
      "Word: been, Deprel: aux:pass, Head: domesticated\n",
      "Word: domesticated, Deprel: acl:relcl, Head: Tehuacan\n",
      "Word: 4,000, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl:npmod, Head: ago\n",
      "Word: ago, Deprel: advmod, Head: domesticated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A few miles west are the pyramids of Teotihuacan where corn may first have been domesticated 4,000 years ago'\n",
      "Word: A, Deprel: det, Head: miles\n",
      "Word: few, Deprel: amod, Head: miles\n",
      "Word: miles, Deprel: obl:tmod, Head: west\n",
      "Word: west, Deprel: root, Head: ROOT\n",
      "Word: are, Deprel: cop, Head: west\n",
      "Word: the, Deprel: det, Head: pyramids\n",
      "Word: pyramids, Deprel: nsubj, Head: west\n",
      "Word: of, Deprel: case, Head: Teotihuacan\n",
      "Word: Teotihuacan, Deprel: nmod, Head: pyramids\n",
      "Word: where, Deprel: advmod, Head: domesticated\n",
      "Word: corn, Deprel: nsubj:pass, Head: domesticated\n",
      "Word: may, Deprel: aux, Head: domesticated\n",
      "Word: first, Deprel: advmod, Head: domesticated\n",
      "Word: have, Deprel: aux, Head: domesticated\n",
      "Word: been, Deprel: aux:pass, Head: domesticated\n",
      "Word: domesticated, Deprel: acl:relcl, Head: pyramids\n",
      "Word: 4,000, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl:npmod, Head: ago\n",
      "Word: ago, Deprel: advmod, Head: domesticated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The confusion capped a tumultuous week for the list which is intended to block about 80 percent of telemarketing calls'\n",
      "Word: The, Deprel: det, Head: confusion\n",
      "Word: confusion, Deprel: nsubj, Head: capped\n",
      "Word: capped, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: week\n",
      "Word: tumultuous, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obj, Head: capped\n",
      "Word: for, Deprel: case, Head: list\n",
      "Word: the, Deprel: det, Head: list\n",
      "Word: list, Deprel: obl, Head: capped\n",
      "Word: which, Deprel: nsubj:pass, Head: intended\n",
      "Word: is, Deprel: aux:pass, Head: intended\n",
      "Word: intended, Deprel: acl:relcl, Head: list\n",
      "Word: to, Deprel: mark, Head: block\n",
      "Word: block, Deprel: xcomp, Head: intended\n",
      "Word: about, Deprel: advmod, Head: 80\n",
      "Word: 80, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: block\n",
      "Word: of, Deprel: case, Head: calls\n",
      "Word: telemarketing, Deprel: compound, Head: calls\n",
      "Word: calls, Deprel: nmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The free service was originally intended to block about 80 percent of telemarketer calls'\n",
      "Word: The, Deprel: det, Head: service\n",
      "Word: free, Deprel: amod, Head: service\n",
      "Word: service, Deprel: nsubj:pass, Head: intended\n",
      "Word: was, Deprel: aux:pass, Head: intended\n",
      "Word: originally, Deprel: advmod, Head: intended\n",
      "Word: intended, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: block\n",
      "Word: block, Deprel: advcl, Head: intended\n",
      "Word: about, Deprel: advmod, Head: 80\n",
      "Word: 80, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: block\n",
      "Word: of, Deprel: case, Head: calls\n",
      "Word: telemarketer, Deprel: compound, Head: calls\n",
      "Word: calls, Deprel: nmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The other 24 members are split between representatives of the securities industry and so-called public board members'\n",
      "Word: The, Deprel: det, Head: members\n",
      "Word: other, Deprel: amod, Head: members\n",
      "Word: 24, Deprel: nummod, Head: members\n",
      "Word: members, Deprel: nsubj, Head: split\n",
      "Word: are, Deprel: aux:pass, Head: split\n",
      "Word: split, Deprel: root, Head: ROOT\n",
      "Word: between, Deprel: case, Head: representatives\n",
      "Word: representatives, Deprel: obl, Head: split\n",
      "Word: of, Deprel: case, Head: industry\n",
      "Word: the, Deprel: det, Head: industry\n",
      "Word: securities, Deprel: compound, Head: industry\n",
      "Word: industry, Deprel: nmod, Head: representatives\n",
      "Word: and, Deprel: cc, Head: members\n",
      "Word: so-called, Deprel: amod, Head: members\n",
      "Word: public, Deprel: amod, Head: board\n",
      "Word: board, Deprel: compound, Head: members\n",
      "Word: members, Deprel: conj, Head: industry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Of the 24 directors who are not exchange executives half are representatives of the securities industry and half are designated public members'\n",
      "Word: Of, Deprel: case, Head: directors\n",
      "Word: the, Deprel: det, Head: directors\n",
      "Word: 24, Deprel: nummod, Head: directors\n",
      "Word: directors, Deprel: obl, Head: representatives\n",
      "Word: who, Deprel: nsubj, Head: executives\n",
      "Word: are, Deprel: cop, Head: executives\n",
      "Word: not, Deprel: advmod, Head: executives\n",
      "Word: exchange, Deprel: compound, Head: executives\n",
      "Word: executives, Deprel: acl:relcl, Head: directors\n",
      "Word: half, Deprel: nsubj, Head: representatives\n",
      "Word: are, Deprel: cop, Head: representatives\n",
      "Word: representatives, Deprel: root, Head: ROOT\n",
      "Word: of, Deprel: case, Head: industry\n",
      "Word: the, Deprel: det, Head: industry\n",
      "Word: securities, Deprel: compound, Head: industry\n",
      "Word: industry, Deprel: nmod, Head: representatives\n",
      "Word: and, Deprel: cc, Head: members\n",
      "Word: half, Deprel: nsubj, Head: members\n",
      "Word: are, Deprel: cop, Head: members\n",
      "Word: designated, Deprel: amod, Head: members\n",
      "Word: public, Deprel: amod, Head: members\n",
      "Word: members, Deprel: conj, Head: representatives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Our strong preference is to achieve a financial restructuring out of court and we remain hopeful we can do so chief executive Marce Fuller said'\n",
      "Word: Our, Deprel: nmod:poss, Head: preference\n",
      "Word: strong, Deprel: amod, Head: preference\n",
      "Word: preference, Deprel: nsubj:outer, Head: achieve\n",
      "Word: is, Deprel: cop, Head: achieve\n",
      "Word: to, Deprel: mark, Head: achieve\n",
      "Word: achieve, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: restructuring\n",
      "Word: financial, Deprel: amod, Head: restructuring\n",
      "Word: restructuring, Deprel: obj, Head: achieve\n",
      "Word: out, Deprel: case, Head: court\n",
      "Word: of, Deprel: case, Head: court\n",
      "Word: court, Deprel: obl, Head: achieve\n",
      "Word: and, Deprel: cc, Head: remain\n",
      "Word: we, Deprel: nsubj, Head: remain\n",
      "Word: remain, Deprel: conj, Head: achieve\n",
      "Word: hopeful, Deprel: xcomp, Head: remain\n",
      "Word: we, Deprel: nsubj, Head: do\n",
      "Word: can, Deprel: aux, Head: do\n",
      "Word: do, Deprel: ccomp, Head: hopeful\n",
      "Word: so, Deprel: advmod, Head: do\n",
      "Word: chief, Deprel: amod, Head: executive\n",
      "Word: executive, Deprel: obj, Head: do\n",
      "Word: Marce, Deprel: flat, Head: executive\n",
      "Word: Fuller, Deprel: flat, Head: executive\n",
      "Word: said, Deprel: advcl, Head: do\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Our strong preference is to achieve a financial restructuring out of court Mirant CEO Marce Fuller said in a prepared statement early Friday'\n",
      "Word: Our, Deprel: nmod:poss, Head: preference\n",
      "Word: strong, Deprel: amod, Head: preference\n",
      "Word: preference, Deprel: nsubj:outer, Head: achieve\n",
      "Word: is, Deprel: cop, Head: achieve\n",
      "Word: to, Deprel: mark, Head: achieve\n",
      "Word: achieve, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: restructuring\n",
      "Word: financial, Deprel: amod, Head: restructuring\n",
      "Word: restructuring, Deprel: obj, Head: achieve\n",
      "Word: out, Deprel: case, Head: court\n",
      "Word: of, Deprel: case, Head: court\n",
      "Word: court, Deprel: nmod, Head: restructuring\n",
      "Word: Mirant, Deprel: compound, Head: CEO\n",
      "Word: CEO, Deprel: compound, Head: Marce\n",
      "Word: Marce, Deprel: nsubj, Head: said\n",
      "Word: Fuller, Deprel: flat, Head: Marce\n",
      "Word: said, Deprel: parataxis, Head: achieve\n",
      "Word: in, Deprel: case, Head: statement\n",
      "Word: a, Deprel: det, Head: statement\n",
      "Word: prepared, Deprel: amod, Head: statement\n",
      "Word: statement, Deprel: obl, Head: said\n",
      "Word: early, Deprel: amod, Head: Friday\n",
      "Word: Friday, Deprel: obl:tmod, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Named in the complaint were former chief executive officers Paul A Allaire and G Richard Thoman and former CFO Barry D Romeril'\n",
      "Word: Named, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: complaint\n",
      "Word: the, Deprel: det, Head: complaint\n",
      "Word: complaint, Deprel: obl, Head: Named\n",
      "Word: were, Deprel: aux:pass, Head: Named\n",
      "Word: former, Deprel: amod, Head: officers\n",
      "Word: chief, Deprel: amod, Head: executive\n",
      "Word: executive, Deprel: compound, Head: officers\n",
      "Word: officers, Deprel: nsubj:pass, Head: Named\n",
      "Word: Paul, Deprel: appos, Head: officers\n",
      "Word: A, Deprel: flat, Head: Paul\n",
      "Word: Allaire, Deprel: flat, Head: Paul\n",
      "Word: and, Deprel: cc, Head: G\n",
      "Word: G, Deprel: conj, Head: Paul\n",
      "Word: Richard, Deprel: flat, Head: G\n",
      "Word: Thoman, Deprel: flat, Head: G\n",
      "Word: and, Deprel: cc, Head: CFO\n",
      "Word: former, Deprel: amod, Head: CFO\n",
      "Word: CFO, Deprel: conj, Head: G\n",
      "Word: Barry, Deprel: flat, Head: CFO\n",
      "Word: D, Deprel: flat, Head: Barry\n",
      "Word: Romeril, Deprel: flat, Head: Barry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The executives fined included former Chief Executives Paul A Allaire and G Richard Thoman as well as former Chief Financial Officer Barry Romeril'\n",
      "Word: The, Deprel: det, Head: executives\n",
      "Word: executives, Deprel: nsubj, Head: included\n",
      "Word: fined, Deprel: acl, Head: executives\n",
      "Word: included, Deprel: root, Head: ROOT\n",
      "Word: former, Deprel: amod, Head: Executives\n",
      "Word: Chief, Deprel: amod, Head: Executives\n",
      "Word: Executives, Deprel: obj, Head: included\n",
      "Word: Paul, Deprel: appos, Head: Executives\n",
      "Word: A, Deprel: flat, Head: Paul\n",
      "Word: Allaire, Deprel: flat, Head: Paul\n",
      "Word: and, Deprel: cc, Head: G\n",
      "Word: G, Deprel: conj, Head: Executives\n",
      "Word: Richard, Deprel: flat, Head: G\n",
      "Word: Thoman, Deprel: flat, Head: G\n",
      "Word: as, Deprel: cc, Head: Barry\n",
      "Word: well, Deprel: fixed, Head: as\n",
      "Word: as, Deprel: fixed, Head: as\n",
      "Word: former, Deprel: amod, Head: Officer\n",
      "Word: Chief, Deprel: amod, Head: Officer\n",
      "Word: Financial, Deprel: amod, Head: Officer\n",
      "Word: Officer, Deprel: conj, Head: Executives\n",
      "Word: Barry, Deprel: conj, Head: Executives\n",
      "Word: Romeril, Deprel: flat, Head: Barry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Episcopal Diocese of Central Florida became one of the first in the nation Saturday to officially reject the national denomination s policies on homosexuality'\n",
      "Word: The, Deprel: det, Head: Diocese\n",
      "Word: Episcopal, Deprel: compound, Head: Diocese\n",
      "Word: Diocese, Deprel: nsubj, Head: became\n",
      "Word: of, Deprel: case, Head: Florida\n",
      "Word: Central, Deprel: amod, Head: Florida\n",
      "Word: Florida, Deprel: nmod, Head: Diocese\n",
      "Word: became, Deprel: root, Head: ROOT\n",
      "Word: one, Deprel: xcomp, Head: became\n",
      "Word: of, Deprel: case, Head: first\n",
      "Word: the, Deprel: det, Head: first\n",
      "Word: first, Deprel: nmod, Head: one\n",
      "Word: in, Deprel: case, Head: nation\n",
      "Word: the, Deprel: det, Head: nation\n",
      "Word: nation, Deprel: obl, Head: first\n",
      "Word: Saturday, Deprel: obl:tmod, Head: first\n",
      "Word: to, Deprel: mark, Head: reject\n",
      "Word: officially, Deprel: advmod, Head: reject\n",
      "Word: reject, Deprel: advcl, Head: became\n",
      "Word: the, Deprel: det, Head: denomination\n",
      "Word: national, Deprel: amod, Head: denomination\n",
      "Word: denomination, Deprel: nmod:poss, Head: policies\n",
      "Word: s, Deprel: case, Head: denomination\n",
      "Word: policies, Deprel: obj, Head: reject\n",
      "Word: on, Deprel: case, Head: homosexuality\n",
      "Word: homosexuality, Deprel: nmod, Head: policies\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Episcopal Diocese of Central Florida voted Saturday to repudiate a decision by the denomination s national convention to confirm a gay man as bishop'\n",
      "Word: The, Deprel: det, Head: Diocese\n",
      "Word: Episcopal, Deprel: amod, Head: Diocese\n",
      "Word: Diocese, Deprel: nsubj, Head: voted\n",
      "Word: of, Deprel: case, Head: Florida\n",
      "Word: Central, Deprel: amod, Head: Florida\n",
      "Word: Florida, Deprel: nmod, Head: Diocese\n",
      "Word: voted, Deprel: root, Head: ROOT\n",
      "Word: Saturday, Deprel: obl:tmod, Head: voted\n",
      "Word: to, Deprel: mark, Head: repudiate\n",
      "Word: repudiate, Deprel: advcl, Head: voted\n",
      "Word: a, Deprel: det, Head: decision\n",
      "Word: decision, Deprel: obj, Head: repudiate\n",
      "Word: by, Deprel: case, Head: convention\n",
      "Word: the, Deprel: det, Head: denomination\n",
      "Word: denomination, Deprel: nmod:poss, Head: convention\n",
      "Word: s, Deprel: case, Head: denomination\n",
      "Word: national, Deprel: amod, Head: convention\n",
      "Word: convention, Deprel: nmod, Head: decision\n",
      "Word: to, Deprel: mark, Head: confirm\n",
      "Word: confirm, Deprel: advcl, Head: repudiate\n",
      "Word: a, Deprel: det, Head: man\n",
      "Word: gay, Deprel: amod, Head: man\n",
      "Word: man, Deprel: obj, Head: confirm\n",
      "Word: as, Deprel: case, Head: bishop\n",
      "Word: bishop, Deprel: obl, Head: confirm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Chera Larkins 32 of Manhattan charged with three sham marriages is also charged with perjury and filing a false instrument'\n",
      "Word: Chera, Deprel: nsubj:pass, Head: charged\n",
      "Word: Larkins, Deprel: flat, Head: Chera\n",
      "Word: 32, Deprel: appos, Head: Chera\n",
      "Word: of, Deprel: case, Head: Manhattan\n",
      "Word: Manhattan, Deprel: nmod, Head: Chera\n",
      "Word: charged, Deprel: acl, Head: Manhattan\n",
      "Word: with, Deprel: case, Head: marriages\n",
      "Word: three, Deprel: nummod, Head: marriages\n",
      "Word: sham, Deprel: compound, Head: marriages\n",
      "Word: marriages, Deprel: obl, Head: charged\n",
      "Word: is, Deprel: aux:pass, Head: charged\n",
      "Word: also, Deprel: advmod, Head: charged\n",
      "Word: charged, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: perjury\n",
      "Word: perjury, Deprel: obl, Head: charged\n",
      "Word: and, Deprel: cc, Head: filing\n",
      "Word: filing, Deprel: conj, Head: charged\n",
      "Word: a, Deprel: det, Head: instrument\n",
      "Word: false, Deprel: amod, Head: instrument\n",
      "Word: instrument, Deprel: obj, Head: filing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Chera Larkins 32 of Manhattan charged with perjury and filing a false instrument in three marriage applications'\n",
      "Word: Chera, Deprel: root, Head: ROOT\n",
      "Word: Larkins, Deprel: flat, Head: Chera\n",
      "Word: 32, Deprel: dep, Head: Chera\n",
      "Word: of, Deprel: case, Head: Manhattan\n",
      "Word: Manhattan, Deprel: nmod, Head: Chera\n",
      "Word: charged, Deprel: acl, Head: Chera\n",
      "Word: with, Deprel: case, Head: perjury\n",
      "Word: perjury, Deprel: obl, Head: charged\n",
      "Word: and, Deprel: cc, Head: filing\n",
      "Word: filing, Deprel: conj, Head: charged\n",
      "Word: a, Deprel: det, Head: instrument\n",
      "Word: false, Deprel: amod, Head: instrument\n",
      "Word: instrument, Deprel: obj, Head: filing\n",
      "Word: in, Deprel: case, Head: applications\n",
      "Word: three, Deprel: nummod, Head: applications\n",
      "Word: marriage, Deprel: compound, Head: applications\n",
      "Word: applications, Deprel: obl, Head: filing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It estimated on Thursday it has a 51 percent market share in Europe'\n",
      "Word: It, Deprel: nsubj, Head: estimated\n",
      "Word: estimated, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: estimated\n",
      "Word: it, Deprel: nsubj, Head: has\n",
      "Word: has, Deprel: ccomp, Head: estimated\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: 51, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: compound, Head: share\n",
      "Word: market, Deprel: compound, Head: share\n",
      "Word: share, Deprel: obj, Head: has\n",
      "Word: in, Deprel: case, Head: Europe\n",
      "Word: Europe, Deprel: nmod, Head: share\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Boston Scientific said it has gained 51 percent of the coated-stent market in Europe'\n",
      "Word: Boston, Deprel: compound, Head: Scientific\n",
      "Word: Scientific, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: it, Deprel: nsubj, Head: gained\n",
      "Word: has, Deprel: aux, Head: gained\n",
      "Word: gained, Deprel: ccomp, Head: said\n",
      "Word: 51, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: gained\n",
      "Word: of, Deprel: case, Head: market\n",
      "Word: the, Deprel: det, Head: market\n",
      "Word: coated-stent, Deprel: amod, Head: market\n",
      "Word: market, Deprel: nmod, Head: percent\n",
      "Word: in, Deprel: case, Head: Europe\n",
      "Word: Europe, Deprel: obl, Head: gained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Senate Banking Committee is scheduled to hold a hearing on Tuesday where Donaldson is scheduled to testify on hedge and mutual funds'\n",
      "Word: The, Deprel: det, Head: Committee\n",
      "Word: Senate, Deprel: compound, Head: Banking\n",
      "Word: Banking, Deprel: compound, Head: Committee\n",
      "Word: Committee, Deprel: nsubj:pass, Head: scheduled\n",
      "Word: is, Deprel: aux:pass, Head: scheduled\n",
      "Word: scheduled, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: hold\n",
      "Word: hold, Deprel: xcomp, Head: scheduled\n",
      "Word: a, Deprel: det, Head: hearing\n",
      "Word: hearing, Deprel: obj, Head: hold\n",
      "Word: on, Deprel: case, Head: Tuesday\n",
      "Word: Tuesday, Deprel: obl, Head: hold\n",
      "Word: where, Deprel: advmod, Head: scheduled\n",
      "Word: Donaldson, Deprel: nsubj:pass, Head: scheduled\n",
      "Word: is, Deprel: aux:pass, Head: scheduled\n",
      "Word: scheduled, Deprel: acl:relcl, Head: Tuesday\n",
      "Word: to, Deprel: mark, Head: testify\n",
      "Word: testify, Deprel: xcomp, Head: scheduled\n",
      "Word: on, Deprel: case, Head: hedge\n",
      "Word: hedge, Deprel: obl, Head: testify\n",
      "Word: and, Deprel: cc, Head: mutual\n",
      "Word: mutual, Deprel: amod, Head: funds\n",
      "Word: funds, Deprel: conj, Head: hedge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Senate Banking Committee is scheduled to hold a hearing on Tuesday when Donaldson will be questioned about hedge and mutual funds'\n",
      "Word: The, Deprel: det, Head: Committee\n",
      "Word: Senate, Deprel: compound, Head: Banking\n",
      "Word: Banking, Deprel: compound, Head: Committee\n",
      "Word: Committee, Deprel: nsubj:pass, Head: scheduled\n",
      "Word: is, Deprel: aux:pass, Head: scheduled\n",
      "Word: scheduled, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: hold\n",
      "Word: hold, Deprel: xcomp, Head: scheduled\n",
      "Word: a, Deprel: det, Head: hearing\n",
      "Word: hearing, Deprel: obj, Head: hold\n",
      "Word: on, Deprel: case, Head: Tuesday\n",
      "Word: Tuesday, Deprel: obl, Head: hold\n",
      "Word: when, Deprel: advmod, Head: questioned\n",
      "Word: Donaldson, Deprel: nsubj:pass, Head: questioned\n",
      "Word: will, Deprel: aux, Head: questioned\n",
      "Word: be, Deprel: aux:pass, Head: questioned\n",
      "Word: questioned, Deprel: advcl, Head: hold\n",
      "Word: about, Deprel: case, Head: funds\n",
      "Word: hedge, Deprel: compound, Head: funds\n",
      "Word: and, Deprel: cc, Head: mutual\n",
      "Word: mutual, Deprel: conj, Head: hedge\n",
      "Word: funds, Deprel: obl, Head: questioned\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The tech-heavy Nasdaq Composite Index IXIC was off 0.11 percent or 1.78 points at 1,594.13'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: tech-heavy, Deprel: amod, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: off\n",
      "Word: was, Deprel: cop, Head: off\n",
      "Word: off, Deprel: root, Head: ROOT\n",
      "Word: 0.11, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: off\n",
      "Word: or, Deprel: cc, Head: points\n",
      "Word: 1.78, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: conj, Head: percent\n",
      "Word: at, Deprel: case, Head: 1,594.13\n",
      "Word: 1,594.13, Deprel: obl, Head: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index SPX was down 0.04 points or 0 percent at 971.52'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broader, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: s\n",
      "Word: Poor, Deprel: amod, Head: s\n",
      "Word: s, Deprel: compound, Head: Index\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: down\n",
      "Word: was, Deprel: cop, Head: down\n",
      "Word: down, Deprel: root, Head: ROOT\n",
      "Word: 0.04, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: down\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 0, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 971.52\n",
      "Word: 971.52, Deprel: obl, Head: down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'These men are entitled to respect for their private lives Kennedy said'\n",
      "Word: These, Deprel: det, Head: men\n",
      "Word: men, Deprel: nsubj:pass, Head: entitled\n",
      "Word: are, Deprel: aux:pass, Head: entitled\n",
      "Word: entitled, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: respect\n",
      "Word: respect, Deprel: xcomp, Head: entitled\n",
      "Word: for, Deprel: case, Head: lives\n",
      "Word: their, Deprel: nmod:poss, Head: lives\n",
      "Word: private, Deprel: amod, Head: lives\n",
      "Word: lives, Deprel: obl, Head: respect\n",
      "Word: Kennedy, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: lives\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The petitioners are entitled to respect for their private lives'\n",
      "Word: The, Deprel: det, Head: petitioners\n",
      "Word: petitioners, Deprel: nsubj:pass, Head: entitled\n",
      "Word: are, Deprel: aux:pass, Head: entitled\n",
      "Word: entitled, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: respect\n",
      "Word: respect, Deprel: xcomp, Head: entitled\n",
      "Word: for, Deprel: case, Head: lives\n",
      "Word: their, Deprel: nmod:poss, Head: lives\n",
      "Word: private, Deprel: amod, Head: lives\n",
      "Word: lives, Deprel: obl, Head: respect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Morse is charged with assault and Mr Darvish is charged with filing a false report'\n",
      "Word: Mr, Deprel: nsubj:pass, Head: charged\n",
      "Word: Morse, Deprel: flat, Head: Mr\n",
      "Word: is, Deprel: aux:pass, Head: charged\n",
      "Word: charged, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: assault\n",
      "Word: assault, Deprel: obl, Head: charged\n",
      "Word: and, Deprel: cc, Head: charged\n",
      "Word: Mr, Deprel: nsubj:pass, Head: charged\n",
      "Word: Darvish, Deprel: flat, Head: Mr\n",
      "Word: is, Deprel: aux:pass, Head: charged\n",
      "Word: charged, Deprel: conj, Head: charged\n",
      "Word: with, Deprel: mark, Head: filing\n",
      "Word: filing, Deprel: advcl, Head: charged\n",
      "Word: a, Deprel: det, Head: report\n",
      "Word: false, Deprel: amod, Head: report\n",
      "Word: report, Deprel: obj, Head: filing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'His partner Bijan Darvish is charged with filing a false police report'\n",
      "Word: His, Deprel: nmod:poss, Head: partner\n",
      "Word: partner, Deprel: compound, Head: Bijan\n",
      "Word: Bijan, Deprel: nsubj:pass, Head: charged\n",
      "Word: Darvish, Deprel: flat, Head: Bijan\n",
      "Word: is, Deprel: aux:pass, Head: charged\n",
      "Word: charged, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: mark, Head: filing\n",
      "Word: filing, Deprel: advcl, Head: charged\n",
      "Word: a, Deprel: det, Head: report\n",
      "Word: false, Deprel: amod, Head: report\n",
      "Word: police, Deprel: compound, Head: report\n",
      "Word: report, Deprel: obj, Head: filing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The mock explosion the first event in the drill occurred in a car in industrial south Seattle'\n",
      "Word: The, Deprel: det, Head: explosion\n",
      "Word: mock, Deprel: compound, Head: explosion\n",
      "Word: explosion, Deprel: nsubj, Head: occurred\n",
      "Word: the, Deprel: det, Head: event\n",
      "Word: first, Deprel: amod, Head: event\n",
      "Word: event, Deprel: appos, Head: explosion\n",
      "Word: in, Deprel: case, Head: drill\n",
      "Word: the, Deprel: det, Head: drill\n",
      "Word: drill, Deprel: nmod, Head: event\n",
      "Word: occurred, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: car\n",
      "Word: a, Deprel: det, Head: car\n",
      "Word: car, Deprel: obl, Head: occurred\n",
      "Word: in, Deprel: case, Head: Seattle\n",
      "Word: industrial, Deprel: amod, Head: Seattle\n",
      "Word: south, Deprel: compound, Head: Seattle\n",
      "Word: Seattle, Deprel: nmod, Head: car\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The mock explosion of a radioactive dirty bomb the first event in the weeklong drill occurred on several acres in the south Seattle industrial area'\n",
      "Word: The, Deprel: det, Head: explosion\n",
      "Word: mock, Deprel: amod, Head: explosion\n",
      "Word: explosion, Deprel: nsubj, Head: occurred\n",
      "Word: of, Deprel: case, Head: bomb\n",
      "Word: a, Deprel: det, Head: bomb\n",
      "Word: radioactive, Deprel: amod, Head: bomb\n",
      "Word: dirty, Deprel: amod, Head: bomb\n",
      "Word: bomb, Deprel: nmod, Head: explosion\n",
      "Word: the, Deprel: det, Head: event\n",
      "Word: first, Deprel: amod, Head: event\n",
      "Word: event, Deprel: nmod:tmod, Head: explosion\n",
      "Word: in, Deprel: case, Head: drill\n",
      "Word: the, Deprel: det, Head: drill\n",
      "Word: weeklong, Deprel: compound, Head: drill\n",
      "Word: drill, Deprel: nmod, Head: event\n",
      "Word: occurred, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: acres\n",
      "Word: several, Deprel: amod, Head: acres\n",
      "Word: acres, Deprel: obl, Head: occurred\n",
      "Word: in, Deprel: case, Head: area\n",
      "Word: the, Deprel: det, Head: area\n",
      "Word: south, Deprel: amod, Head: area\n",
      "Word: Seattle, Deprel: compound, Head: area\n",
      "Word: industrial, Deprel: amod, Head: area\n",
      "Word: area, Deprel: nmod, Head: acres\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The third appointment was to a new job executive vice president and chief staff officer'\n",
      "Word: The, Deprel: det, Head: appointment\n",
      "Word: third, Deprel: amod, Head: appointment\n",
      "Word: appointment, Deprel: nsubj, Head: job\n",
      "Word: was, Deprel: cop, Head: job\n",
      "Word: to, Deprel: case, Head: job\n",
      "Word: a, Deprel: det, Head: job\n",
      "Word: new, Deprel: amod, Head: job\n",
      "Word: job, Deprel: root, Head: ROOT\n",
      "Word: executive, Deprel: amod, Head: president\n",
      "Word: vice, Deprel: compound, Head: president\n",
      "Word: president, Deprel: appos, Head: job\n",
      "Word: and, Deprel: cc, Head: officer\n",
      "Word: chief, Deprel: amod, Head: officer\n",
      "Word: staff, Deprel: compound, Head: officer\n",
      "Word: officer, Deprel: conj, Head: president\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Bruce N Hawthorne 53 was named executive vice president and chief staff officer'\n",
      "Word: Bruce, Deprel: nsubj:pass, Head: named\n",
      "Word: N, Deprel: flat, Head: Bruce\n",
      "Word: Hawthorne, Deprel: flat, Head: Bruce\n",
      "Word: 53, Deprel: amod, Head: Bruce\n",
      "Word: was, Deprel: aux:pass, Head: named\n",
      "Word: named, Deprel: root, Head: ROOT\n",
      "Word: executive, Deprel: amod, Head: president\n",
      "Word: vice, Deprel: compound, Head: president\n",
      "Word: president, Deprel: xcomp, Head: named\n",
      "Word: and, Deprel: cc, Head: officer\n",
      "Word: chief, Deprel: amod, Head: officer\n",
      "Word: staff, Deprel: compound, Head: officer\n",
      "Word: officer, Deprel: conj, Head: president\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The commission dropped charges that Patton improperly appointed Conner to the Kentucky Lottery Board and that he improperly appointed Conner s then-husband Seth to the Agriculture Development Board'\n",
      "Word: The, Deprel: det, Head: commission\n",
      "Word: commission, Deprel: nsubj, Head: dropped\n",
      "Word: dropped, Deprel: root, Head: ROOT\n",
      "Word: charges, Deprel: obj, Head: dropped\n",
      "Word: that, Deprel: mark, Head: appointed\n",
      "Word: Patton, Deprel: nsubj, Head: appointed\n",
      "Word: improperly, Deprel: advmod, Head: appointed\n",
      "Word: appointed, Deprel: acl, Head: charges\n",
      "Word: Conner, Deprel: obj, Head: appointed\n",
      "Word: to, Deprel: case, Head: Board\n",
      "Word: the, Deprel: det, Head: Board\n",
      "Word: Kentucky, Deprel: compound, Head: Board\n",
      "Word: Lottery, Deprel: compound, Head: Board\n",
      "Word: Board, Deprel: obl, Head: appointed\n",
      "Word: and, Deprel: cc, Head: appointed\n",
      "Word: that, Deprel: mark, Head: appointed\n",
      "Word: he, Deprel: nsubj, Head: appointed\n",
      "Word: improperly, Deprel: advmod, Head: appointed\n",
      "Word: appointed, Deprel: conj, Head: appointed\n",
      "Word: Conner, Deprel: nmod:poss, Head: then-husband\n",
      "Word: s, Deprel: case, Head: Conner\n",
      "Word: then-husband, Deprel: obj, Head: appointed\n",
      "Word: Seth, Deprel: flat, Head: then-husband\n",
      "Word: to, Deprel: case, Head: Board\n",
      "Word: the, Deprel: det, Head: Board\n",
      "Word: Agriculture, Deprel: compound, Head: Board\n",
      "Word: Development, Deprel: compound, Head: Board\n",
      "Word: Board, Deprel: obl, Head: appointed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Patton also appointed Conner to the Kentucky Lottery Board and appointed Seth Conner to the Agriculture Development Board the commission says'\n",
      "Word: Patton, Deprel: nsubj, Head: appointed\n",
      "Word: also, Deprel: advmod, Head: appointed\n",
      "Word: appointed, Deprel: root, Head: ROOT\n",
      "Word: Conner, Deprel: obj, Head: appointed\n",
      "Word: to, Deprel: case, Head: Board\n",
      "Word: the, Deprel: det, Head: Board\n",
      "Word: Kentucky, Deprel: compound, Head: Board\n",
      "Word: Lottery, Deprel: compound, Head: Board\n",
      "Word: Board, Deprel: obl, Head: appointed\n",
      "Word: and, Deprel: cc, Head: appointed\n",
      "Word: appointed, Deprel: conj, Head: appointed\n",
      "Word: Seth, Deprel: obj, Head: appointed\n",
      "Word: Conner, Deprel: flat, Head: Seth\n",
      "Word: to, Deprel: case, Head: Board\n",
      "Word: the, Deprel: det, Head: Board\n",
      "Word: Agriculture, Deprel: compound, Head: Board\n",
      "Word: Development, Deprel: compound, Head: Board\n",
      "Word: Board, Deprel: obl, Head: appointed\n",
      "Word: the, Deprel: det, Head: commission\n",
      "Word: commission, Deprel: nsubj, Head: says\n",
      "Word: says, Deprel: acl:relcl, Head: Board\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'McGill also detailed the hole that had been cut in the Caprice s trunk'\n",
      "Word: McGill, Deprel: nsubj, Head: detailed\n",
      "Word: also, Deprel: advmod, Head: detailed\n",
      "Word: detailed, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: hole\n",
      "Word: hole, Deprel: obj, Head: detailed\n",
      "Word: that, Deprel: nsubj:pass, Head: cut\n",
      "Word: had, Deprel: aux, Head: cut\n",
      "Word: been, Deprel: aux:pass, Head: cut\n",
      "Word: cut, Deprel: acl:relcl, Head: hole\n",
      "Word: in, Deprel: case, Head: trunk\n",
      "Word: the, Deprel: det, Head: Caprice\n",
      "Word: Caprice, Deprel: nmod:poss, Head: trunk\n",
      "Word: s, Deprel: case, Head: Caprice\n",
      "Word: trunk, Deprel: obl, Head: cut\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'McGill also said a dark glove was stuffed into a hole that had been cut in the Caprice s trunk'\n",
      "Word: McGill, Deprel: nsubj, Head: said\n",
      "Word: also, Deprel: advmod, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: glove\n",
      "Word: dark, Deprel: amod, Head: glove\n",
      "Word: glove, Deprel: nsubj:pass, Head: stuffed\n",
      "Word: was, Deprel: aux:pass, Head: stuffed\n",
      "Word: stuffed, Deprel: ccomp, Head: said\n",
      "Word: into, Deprel: case, Head: hole\n",
      "Word: a, Deprel: det, Head: hole\n",
      "Word: hole, Deprel: obl, Head: stuffed\n",
      "Word: that, Deprel: nsubj:pass, Head: cut\n",
      "Word: had, Deprel: aux, Head: cut\n",
      "Word: been, Deprel: aux:pass, Head: cut\n",
      "Word: cut, Deprel: acl:relcl, Head: hole\n",
      "Word: in, Deprel: case, Head: trunk\n",
      "Word: the, Deprel: det, Head: Caprice\n",
      "Word: Caprice, Deprel: nmod:poss, Head: trunk\n",
      "Word: s, Deprel: case, Head: Caprice\n",
      "Word: trunk, Deprel: obl, Head: cut\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Analysts had been expecting a net loss of 54 cents a share according to Thomson First Call'\n",
      "Word: Analysts, Deprel: nsubj, Head: expecting\n",
      "Word: had, Deprel: aux, Head: expecting\n",
      "Word: been, Deprel: aux, Head: expecting\n",
      "Word: expecting, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: loss\n",
      "Word: net, Deprel: compound, Head: loss\n",
      "Word: loss, Deprel: obj, Head: expecting\n",
      "Word: of, Deprel: case, Head: cents\n",
      "Word: 54, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: nmod, Head: loss\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:tmod, Head: cents\n",
      "Word: according, Deprel: case, Head: Call\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: Thomson, Deprel: compound, Head: Call\n",
      "Word: First, Deprel: amod, Head: Call\n",
      "Word: Call, Deprel: obl, Head: expecting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Analysts had forecast second quarter sales of 614 million according to the Thomson First Call Web site'\n",
      "Word: Analysts, Deprel: nsubj, Head: forecast\n",
      "Word: had, Deprel: aux, Head: forecast\n",
      "Word: forecast, Deprel: root, Head: ROOT\n",
      "Word: second, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: compound, Head: sales\n",
      "Word: sales, Deprel: obj, Head: forecast\n",
      "Word: of, Deprel: case, Head: million\n",
      "Word: 614, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: nmod, Head: sales\n",
      "Word: according, Deprel: case, Head: site\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: the, Deprel: det, Head: site\n",
      "Word: Thomson, Deprel: compound, Head: Call\n",
      "Word: First, Deprel: amod, Head: Call\n",
      "Word: Call, Deprel: compound, Head: site\n",
      "Word: Web, Deprel: compound, Head: site\n",
      "Word: site, Deprel: obl, Head: forecast\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The district also sent letters yesterday informing parents of the situation'\n",
      "Word: The, Deprel: det, Head: district\n",
      "Word: district, Deprel: nsubj, Head: sent\n",
      "Word: also, Deprel: advmod, Head: sent\n",
      "Word: sent, Deprel: root, Head: ROOT\n",
      "Word: letters, Deprel: obj, Head: sent\n",
      "Word: yesterday, Deprel: obl:tmod, Head: sent\n",
      "Word: informing, Deprel: advcl, Head: sent\n",
      "Word: parents, Deprel: iobj, Head: informing\n",
      "Word: of, Deprel: case, Head: situation\n",
      "Word: the, Deprel: det, Head: situation\n",
      "Word: situation, Deprel: nmod, Head: parents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Parents received letters informing them of the possible contamination yesterday'\n",
      "Word: Parents, Deprel: nsubj, Head: received\n",
      "Word: received, Deprel: root, Head: ROOT\n",
      "Word: letters, Deprel: obj, Head: received\n",
      "Word: informing, Deprel: acl, Head: letters\n",
      "Word: them, Deprel: iobj, Head: informing\n",
      "Word: of, Deprel: case, Head: contamination\n",
      "Word: the, Deprel: det, Head: contamination\n",
      "Word: possible, Deprel: amod, Head: contamination\n",
      "Word: contamination, Deprel: obl, Head: informing\n",
      "Word: yesterday, Deprel: nmod:tmod, Head: contamination\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Richard Grasso quit as chairman last week after losing the support of his board amid public furor over his 140 million pay package'\n",
      "Word: Richard, Deprel: nsubj, Head: quit\n",
      "Word: Grasso, Deprel: flat, Head: Richard\n",
      "Word: quit, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: case, Head: chairman\n",
      "Word: chairman, Deprel: obl, Head: quit\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: quit\n",
      "Word: after, Deprel: mark, Head: losing\n",
      "Word: losing, Deprel: advcl, Head: quit\n",
      "Word: the, Deprel: det, Head: support\n",
      "Word: support, Deprel: obj, Head: losing\n",
      "Word: of, Deprel: case, Head: board\n",
      "Word: his, Deprel: nmod:poss, Head: board\n",
      "Word: board, Deprel: nmod, Head: support\n",
      "Word: amid, Deprel: case, Head: furor\n",
      "Word: public, Deprel: amod, Head: furor\n",
      "Word: furor, Deprel: obl, Head: losing\n",
      "Word: over, Deprel: case, Head: package\n",
      "Word: his, Deprel: nmod:poss, Head: package\n",
      "Word: 140, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: package\n",
      "Word: pay, Deprel: compound, Head: package\n",
      "Word: package, Deprel: nmod, Head: furor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Grasso quit last week in the wake of a firestorm of criticism over his 140 million compensation package'\n",
      "Word: Grasso, Deprel: nsubj, Head: quit\n",
      "Word: quit, Deprel: root, Head: ROOT\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: quit\n",
      "Word: in, Deprel: case, Head: wake\n",
      "Word: the, Deprel: det, Head: wake\n",
      "Word: wake, Deprel: obl, Head: quit\n",
      "Word: of, Deprel: case, Head: firestorm\n",
      "Word: a, Deprel: det, Head: firestorm\n",
      "Word: firestorm, Deprel: nmod, Head: wake\n",
      "Word: of, Deprel: case, Head: criticism\n",
      "Word: criticism, Deprel: nmod, Head: firestorm\n",
      "Word: over, Deprel: case, Head: package\n",
      "Word: his, Deprel: nmod:poss, Head: package\n",
      "Word: 140, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: package\n",
      "Word: compensation, Deprel: compound, Head: package\n",
      "Word: package, Deprel: nmod, Head: criticism\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new servers will run either Linux or the x86 version of Solaris he said'\n",
      "Word: The, Deprel: det, Head: servers\n",
      "Word: new, Deprel: amod, Head: servers\n",
      "Word: servers, Deprel: nsubj, Head: run\n",
      "Word: will, Deprel: aux, Head: run\n",
      "Word: run, Deprel: root, Head: ROOT\n",
      "Word: either, Deprel: cc:preconj, Head: Linux\n",
      "Word: Linux, Deprel: obj, Head: run\n",
      "Word: or, Deprel: cc, Head: version\n",
      "Word: the, Deprel: det, Head: version\n",
      "Word: x86, Deprel: compound, Head: version\n",
      "Word: version, Deprel: conj, Head: Linux\n",
      "Word: of, Deprel: case, Head: Solaris\n",
      "Word: Solaris, Deprel: nmod, Head: version\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: Linux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The servers can run Solaris x86 operating system or the standard Linux operating system'\n",
      "Word: The, Deprel: det, Head: servers\n",
      "Word: servers, Deprel: nsubj, Head: run\n",
      "Word: can, Deprel: aux, Head: run\n",
      "Word: run, Deprel: root, Head: ROOT\n",
      "Word: Solaris, Deprel: compound, Head: system\n",
      "Word: x86, Deprel: compound, Head: system\n",
      "Word: operating, Deprel: compound, Head: system\n",
      "Word: system, Deprel: obj, Head: run\n",
      "Word: or, Deprel: cc, Head: system\n",
      "Word: the, Deprel: det, Head: system\n",
      "Word: standard, Deprel: amod, Head: system\n",
      "Word: Linux, Deprel: compound, Head: system\n",
      "Word: operating, Deprel: compound, Head: system\n",
      "Word: system, Deprel: conj, Head: system\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Sliding down the ice Moriarty and Carella hit the spongy rocky floor of the river and immediately felt the pull'\n",
      "Word: Sliding, Deprel: csubj, Head: hit\n",
      "Word: down, Deprel: case, Head: Moriarty\n",
      "Word: the, Deprel: det, Head: Moriarty\n",
      "Word: ice, Deprel: compound, Head: Moriarty\n",
      "Word: Moriarty, Deprel: obl, Head: Sliding\n",
      "Word: and, Deprel: cc, Head: Carella\n",
      "Word: Carella, Deprel: conj, Head: Moriarty\n",
      "Word: hit, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: floor\n",
      "Word: spongy, Deprel: amod, Head: floor\n",
      "Word: rocky, Deprel: amod, Head: floor\n",
      "Word: floor, Deprel: obj, Head: hit\n",
      "Word: of, Deprel: case, Head: river\n",
      "Word: the, Deprel: det, Head: river\n",
      "Word: river, Deprel: nmod, Head: floor\n",
      "Word: and, Deprel: cc, Head: felt\n",
      "Word: immediately, Deprel: advmod, Head: felt\n",
      "Word: felt, Deprel: conj, Head: hit\n",
      "Word: the, Deprel: det, Head: pull\n",
      "Word: pull, Deprel: obj, Head: felt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Sliding down the embankment the two rescuers hit the spongy rocky floor of the river and immediately felt the pull'\n",
      "Word: Sliding, Deprel: advcl, Head: hit\n",
      "Word: down, Deprel: case, Head: embankment\n",
      "Word: the, Deprel: det, Head: embankment\n",
      "Word: embankment, Deprel: obl, Head: Sliding\n",
      "Word: the, Deprel: det, Head: rescuers\n",
      "Word: two, Deprel: nummod, Head: rescuers\n",
      "Word: rescuers, Deprel: nsubj, Head: hit\n",
      "Word: hit, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: floor\n",
      "Word: spongy, Deprel: amod, Head: floor\n",
      "Word: rocky, Deprel: amod, Head: floor\n",
      "Word: floor, Deprel: obj, Head: hit\n",
      "Word: of, Deprel: case, Head: river\n",
      "Word: the, Deprel: det, Head: river\n",
      "Word: river, Deprel: nmod, Head: floor\n",
      "Word: and, Deprel: cc, Head: felt\n",
      "Word: immediately, Deprel: advmod, Head: felt\n",
      "Word: felt, Deprel: conj, Head: hit\n",
      "Word: the, Deprel: det, Head: pull\n",
      "Word: pull, Deprel: obj, Head: felt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Cadbury Schweppes plc plans to cut 5500 jobs and shut factories after a 4.9 billion A11.9 billion acquisition spree over the past three years inflated costs'\n",
      "Word: Cadbury, Deprel: compound, Head: plc\n",
      "Word: Schweppes, Deprel: compound, Head: plc\n",
      "Word: plc, Deprel: nsubj, Head: plans\n",
      "Word: plans, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: cut\n",
      "Word: cut, Deprel: xcomp, Head: plans\n",
      "Word: 5500, Deprel: nummod, Head: jobs\n",
      "Word: jobs, Deprel: obj, Head: cut\n",
      "Word: and, Deprel: cc, Head: shut\n",
      "Word: shut, Deprel: conj, Head: cut\n",
      "Word: factories, Deprel: obj, Head: shut\n",
      "Word: after, Deprel: case, Head: spree\n",
      "Word: a, Deprel: det, Head: spree\n",
      "Word: 4.9, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: nummod, Head: spree\n",
      "Word: A11.9, Deprel: compound, Head: billion\n",
      "Word: billion, Deprel: nmod, Head: billion\n",
      "Word: acquisition, Deprel: compound, Head: spree\n",
      "Word: spree, Deprel: obl, Head: shut\n",
      "Word: over, Deprel: case, Head: years\n",
      "Word: the, Deprel: det, Head: years\n",
      "Word: past, Deprel: amod, Head: years\n",
      "Word: three, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: nmod, Head: spree\n",
      "Word: inflated, Deprel: amod, Head: costs\n",
      "Word: costs, Deprel: obl, Head: shut\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Cadbury Schweppes has unveiled plans to slash 5,500 jobs and 20 percent of its factories over four years to cut costs brought about by an acquisition spree'\n",
      "Word: Cadbury, Deprel: compound, Head: Schweppes\n",
      "Word: Schweppes, Deprel: nsubj, Head: unveiled\n",
      "Word: has, Deprel: aux, Head: unveiled\n",
      "Word: unveiled, Deprel: root, Head: ROOT\n",
      "Word: plans, Deprel: obj, Head: unveiled\n",
      "Word: to, Deprel: mark, Head: slash\n",
      "Word: slash, Deprel: acl, Head: plans\n",
      "Word: 5,500, Deprel: nummod, Head: jobs\n",
      "Word: jobs, Deprel: obj, Head: slash\n",
      "Word: and, Deprel: cc, Head: percent\n",
      "Word: 20, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: jobs\n",
      "Word: of, Deprel: case, Head: factories\n",
      "Word: its, Deprel: nmod:poss, Head: factories\n",
      "Word: factories, Deprel: nmod, Head: percent\n",
      "Word: over, Deprel: advmod, Head: four\n",
      "Word: four, Deprel: nummod, Head: years\n",
      "Word: years, Deprel: obl:tmod, Head: slash\n",
      "Word: to, Deprel: mark, Head: cut\n",
      "Word: cut, Deprel: advcl, Head: slash\n",
      "Word: costs, Deprel: obj, Head: cut\n",
      "Word: brought, Deprel: acl, Head: costs\n",
      "Word: about, Deprel: compound:prt, Head: brought\n",
      "Word: by, Deprel: case, Head: spree\n",
      "Word: an, Deprel: det, Head: spree\n",
      "Word: acquisition, Deprel: compound, Head: spree\n",
      "Word: spree, Deprel: obl:agent, Head: brought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Mr Sweeney outlined plans for the campaign in a speech last night in Philadelphia at the annual meeting of the American Political Science Association'\n",
      "Word: Mr, Deprel: nsubj, Head: outlined\n",
      "Word: Sweeney, Deprel: flat, Head: Mr\n",
      "Word: outlined, Deprel: root, Head: ROOT\n",
      "Word: plans, Deprel: obj, Head: outlined\n",
      "Word: for, Deprel: case, Head: campaign\n",
      "Word: the, Deprel: det, Head: campaign\n",
      "Word: campaign, Deprel: nmod, Head: plans\n",
      "Word: in, Deprel: case, Head: speech\n",
      "Word: a, Deprel: det, Head: speech\n",
      "Word: speech, Deprel: nmod, Head: campaign\n",
      "Word: last, Deprel: amod, Head: night\n",
      "Word: night, Deprel: obl:tmod, Head: outlined\n",
      "Word: in, Deprel: case, Head: Philadelphia\n",
      "Word: Philadelphia, Deprel: obl, Head: outlined\n",
      "Word: at, Deprel: case, Head: meeting\n",
      "Word: the, Deprel: det, Head: meeting\n",
      "Word: annual, Deprel: amod, Head: meeting\n",
      "Word: meeting, Deprel: obl, Head: outlined\n",
      "Word: of, Deprel: case, Head: Association\n",
      "Word: the, Deprel: det, Head: Association\n",
      "Word: American, Deprel: amod, Head: Association\n",
      "Word: Political, Deprel: amod, Head: Science\n",
      "Word: Science, Deprel: compound, Head: Association\n",
      "Word: Association, Deprel: nmod, Head: meeting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Sweeney was to outline plans for the campaign in a speech on Saturday night at the annual meeting of the American Political Science Association'\n",
      "Word: Sweeney, Deprel: nsubj, Head: outline\n",
      "Word: was, Deprel: aux, Head: outline\n",
      "Word: to, Deprel: mark, Head: outline\n",
      "Word: outline, Deprel: root, Head: ROOT\n",
      "Word: plans, Deprel: obj, Head: outline\n",
      "Word: for, Deprel: case, Head: campaign\n",
      "Word: the, Deprel: det, Head: campaign\n",
      "Word: campaign, Deprel: nmod, Head: plans\n",
      "Word: in, Deprel: case, Head: speech\n",
      "Word: a, Deprel: det, Head: speech\n",
      "Word: speech, Deprel: nmod, Head: campaign\n",
      "Word: on, Deprel: case, Head: night\n",
      "Word: Saturday, Deprel: compound, Head: night\n",
      "Word: night, Deprel: nmod, Head: speech\n",
      "Word: at, Deprel: case, Head: meeting\n",
      "Word: the, Deprel: det, Head: meeting\n",
      "Word: annual, Deprel: amod, Head: meeting\n",
      "Word: meeting, Deprel: obl, Head: outline\n",
      "Word: of, Deprel: case, Head: Association\n",
      "Word: the, Deprel: det, Head: Association\n",
      "Word: American, Deprel: amod, Head: Association\n",
      "Word: Political, Deprel: amod, Head: Science\n",
      "Word: Science, Deprel: compound, Head: Association\n",
      "Word: Association, Deprel: nmod, Head: meeting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It seemed like an isolated incident said Ariel Dean of Washington D.C who earned a degree in political science'\n",
      "Word: It, Deprel: expl, Head: seemed\n",
      "Word: seemed, Deprel: root, Head: ROOT\n",
      "Word: like, Deprel: case, Head: incident\n",
      "Word: an, Deprel: det, Head: incident\n",
      "Word: isolated, Deprel: amod, Head: incident\n",
      "Word: incident, Deprel: obl, Head: seemed\n",
      "Word: said, Deprel: advcl, Head: seemed\n",
      "Word: Ariel, Deprel: obj, Head: said\n",
      "Word: Dean, Deprel: flat, Head: Ariel\n",
      "Word: of, Deprel: case, Head: D.C\n",
      "Word: Washington, Deprel: compound, Head: D.C\n",
      "Word: D.C, Deprel: nmod, Head: Ariel\n",
      "Word: who, Deprel: nsubj, Head: earned\n",
      "Word: earned, Deprel: acl:relcl, Head: Ariel\n",
      "Word: a, Deprel: det, Head: degree\n",
      "Word: degree, Deprel: obj, Head: earned\n",
      "Word: in, Deprel: case, Head: science\n",
      "Word: political, Deprel: amod, Head: science\n",
      "Word: science, Deprel: nmod, Head: degree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It seemed like an isolated incident said graduate Ariel Dean of Washington D.C'\n",
      "Word: It, Deprel: nsubj, Head: seemed\n",
      "Word: seemed, Deprel: root, Head: ROOT\n",
      "Word: like, Deprel: case, Head: incident\n",
      "Word: an, Deprel: det, Head: incident\n",
      "Word: isolated, Deprel: amod, Head: incident\n",
      "Word: incident, Deprel: obl, Head: seemed\n",
      "Word: said, Deprel: advcl, Head: seemed\n",
      "Word: graduate, Deprel: obj, Head: said\n",
      "Word: Ariel, Deprel: flat, Head: graduate\n",
      "Word: Dean, Deprel: flat, Head: Ariel\n",
      "Word: of, Deprel: case, Head: Washington\n",
      "Word: Washington, Deprel: nmod, Head: graduate\n",
      "Word: D.C, Deprel: flat, Head: Washington\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The jury awarded TVT about 23 million in compensatory damages and roughly 108 million in punitive damages'\n",
      "Word: The, Deprel: det, Head: jury\n",
      "Word: jury, Deprel: nsubj, Head: awarded\n",
      "Word: awarded, Deprel: root, Head: ROOT\n",
      "Word: TVT, Deprel: iobj, Head: awarded\n",
      "Word: about, Deprel: advmod, Head: 23\n",
      "Word: 23, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: awarded\n",
      "Word: in, Deprel: case, Head: damages\n",
      "Word: compensatory, Deprel: amod, Head: damages\n",
      "Word: damages, Deprel: nmod, Head: million\n",
      "Word: and, Deprel: cc, Head: million\n",
      "Word: roughly, Deprel: advmod, Head: 108\n",
      "Word: 108, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: conj, Head: awarded\n",
      "Word: in, Deprel: case, Head: damages\n",
      "Word: punitive, Deprel: amod, Head: damages\n",
      "Word: damages, Deprel: nmod, Head: million\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'TVT Records sought 360 million in punitive damages and 30 million in compensatory damages officials said'\n",
      "Word: TVT, Deprel: compound, Head: Records\n",
      "Word: Records, Deprel: nsubj, Head: sought\n",
      "Word: sought, Deprel: root, Head: ROOT\n",
      "Word: 360, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: sought\n",
      "Word: in, Deprel: case, Head: damages\n",
      "Word: punitive, Deprel: amod, Head: damages\n",
      "Word: damages, Deprel: obl, Head: sought\n",
      "Word: and, Deprel: cc, Head: million\n",
      "Word: 30, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: conj, Head: million\n",
      "Word: in, Deprel: case, Head: officials\n",
      "Word: compensatory, Deprel: amod, Head: damages\n",
      "Word: damages, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: nmod, Head: million\n",
      "Word: said, Deprel: parataxis, Head: sought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'TVT Records sought 360 million in punitive damages and 30 million in compensatory damages officials said'\n",
      "Word: TVT, Deprel: compound, Head: Records\n",
      "Word: Records, Deprel: nsubj, Head: sought\n",
      "Word: sought, Deprel: root, Head: ROOT\n",
      "Word: 360, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: sought\n",
      "Word: in, Deprel: case, Head: damages\n",
      "Word: punitive, Deprel: amod, Head: damages\n",
      "Word: damages, Deprel: obl, Head: sought\n",
      "Word: and, Deprel: cc, Head: million\n",
      "Word: 30, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: conj, Head: million\n",
      "Word: in, Deprel: case, Head: officials\n",
      "Word: compensatory, Deprel: amod, Head: damages\n",
      "Word: damages, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: nmod, Head: million\n",
      "Word: said, Deprel: parataxis, Head: sought\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The damages included 24 million in compensatory damages and 52 million in punitive damages for IDJ'\n",
      "Word: The, Deprel: det, Head: damages\n",
      "Word: damages, Deprel: nsubj, Head: included\n",
      "Word: included, Deprel: root, Head: ROOT\n",
      "Word: 24, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: included\n",
      "Word: in, Deprel: case, Head: damages\n",
      "Word: compensatory, Deprel: amod, Head: damages\n",
      "Word: damages, Deprel: nmod, Head: million\n",
      "Word: and, Deprel: cc, Head: million\n",
      "Word: 52, Deprel: nummod, Head: million\n",
      "Word: million, Deprel: conj, Head: million\n",
      "Word: in, Deprel: case, Head: damages\n",
      "Word: punitive, Deprel: amod, Head: damages\n",
      "Word: damages, Deprel: nmod, Head: million\n",
      "Word: for, Deprel: case, Head: IDJ\n",
      "Word: IDJ, Deprel: nmod, Head: million\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The two Democrats on the five-member FCC panel held a news conference to sway opinion against Powell'\n",
      "Word: The, Deprel: det, Head: Democrats\n",
      "Word: two, Deprel: nummod, Head: Democrats\n",
      "Word: Democrats, Deprel: nsubj, Head: held\n",
      "Word: on, Deprel: case, Head: panel\n",
      "Word: the, Deprel: det, Head: panel\n",
      "Word: five-member, Deprel: amod, Head: panel\n",
      "Word: FCC, Deprel: compound, Head: panel\n",
      "Word: panel, Deprel: nmod, Head: Democrats\n",
      "Word: held, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: conference\n",
      "Word: news, Deprel: compound, Head: conference\n",
      "Word: conference, Deprel: obj, Head: held\n",
      "Word: to, Deprel: mark, Head: sway\n",
      "Word: sway, Deprel: advcl, Head: held\n",
      "Word: opinion, Deprel: obj, Head: sway\n",
      "Word: against, Deprel: case, Head: Powell\n",
      "Word: Powell, Deprel: nmod, Head: opinion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The two Democrats on the five-member FCC held a news conference to sway opinion against Powell and the panel s two other Republicans'\n",
      "Word: The, Deprel: det, Head: Democrats\n",
      "Word: two, Deprel: nummod, Head: Democrats\n",
      "Word: Democrats, Deprel: nsubj, Head: held\n",
      "Word: on, Deprel: case, Head: FCC\n",
      "Word: the, Deprel: det, Head: FCC\n",
      "Word: five-member, Deprel: amod, Head: FCC\n",
      "Word: FCC, Deprel: nmod, Head: Democrats\n",
      "Word: held, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: conference\n",
      "Word: news, Deprel: compound, Head: conference\n",
      "Word: conference, Deprel: obj, Head: held\n",
      "Word: to, Deprel: mark, Head: sway\n",
      "Word: sway, Deprel: acl, Head: conference\n",
      "Word: opinion, Deprel: obj, Head: sway\n",
      "Word: against, Deprel: case, Head: Powell\n",
      "Word: Powell, Deprel: nmod, Head: opinion\n",
      "Word: and, Deprel: cc, Head: Republicans\n",
      "Word: the, Deprel: det, Head: panel\n",
      "Word: panel, Deprel: nmod:poss, Head: Republicans\n",
      "Word: s, Deprel: case, Head: panel\n",
      "Word: two, Deprel: nummod, Head: Republicans\n",
      "Word: other, Deprel: amod, Head: Republicans\n",
      "Word: Republicans, Deprel: conj, Head: opinion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Unit volumes also set a record as notebooks accounted for more than 40 percent of sales'\n",
      "Word: Unit, Deprel: compound, Head: volumes\n",
      "Word: volumes, Deprel: nsubj, Head: set\n",
      "Word: also, Deprel: advmod, Head: set\n",
      "Word: set, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: record\n",
      "Word: record, Deprel: obj, Head: set\n",
      "Word: as, Deprel: mark, Head: accounted\n",
      "Word: notebooks, Deprel: nsubj, Head: accounted\n",
      "Word: accounted, Deprel: advcl, Head: set\n",
      "Word: for, Deprel: case, Head: percent\n",
      "Word: more, Deprel: advmod, Head: 40\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: 40, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: accounted\n",
      "Word: of, Deprel: case, Head: sales\n",
      "Word: sales, Deprel: nmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In May 2002 LCDs accounted for only 22 percent of monitor sales'\n",
      "Word: In, Deprel: case, Head: May\n",
      "Word: May, Deprel: obl, Head: accounted\n",
      "Word: 2002, Deprel: nummod, Head: May\n",
      "Word: LCDs, Deprel: nsubj, Head: accounted\n",
      "Word: accounted, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: percent\n",
      "Word: only, Deprel: advmod, Head: 22\n",
      "Word: 22, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: accounted\n",
      "Word: of, Deprel: case, Head: sales\n",
      "Word: monitor, Deprel: compound, Head: sales\n",
      "Word: sales, Deprel: nmod, Head: percent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Besides battling its sales slump Siebel also has been sparring with some investors upset about huge stock option windfalls company managers have pocketed'\n",
      "Word: Besides, Deprel: mark, Head: battling\n",
      "Word: battling, Deprel: advcl, Head: sparring\n",
      "Word: its, Deprel: nmod:poss, Head: slump\n",
      "Word: sales, Deprel: compound, Head: slump\n",
      "Word: slump, Deprel: obj, Head: battling\n",
      "Word: Siebel, Deprel: nsubj, Head: sparring\n",
      "Word: also, Deprel: advmod, Head: sparring\n",
      "Word: has, Deprel: aux, Head: sparring\n",
      "Word: been, Deprel: aux, Head: sparring\n",
      "Word: sparring, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: investors\n",
      "Word: some, Deprel: det, Head: investors\n",
      "Word: investors, Deprel: obl, Head: sparring\n",
      "Word: upset, Deprel: amod, Head: investors\n",
      "Word: about, Deprel: case, Head: windfalls\n",
      "Word: huge, Deprel: amod, Head: windfalls\n",
      "Word: stock, Deprel: compound, Head: option\n",
      "Word: option, Deprel: compound, Head: windfalls\n",
      "Word: windfalls, Deprel: obl, Head: upset\n",
      "Word: company, Deprel: compound, Head: managers\n",
      "Word: managers, Deprel: nsubj, Head: pocketed\n",
      "Word: have, Deprel: aux, Head: pocketed\n",
      "Word: pocketed, Deprel: acl:relcl, Head: windfalls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Besides a sales slump Siebel is sparring with some shareholders over management stock option windfalls'\n",
      "Word: Besides, Deprel: case, Head: slump\n",
      "Word: a, Deprel: det, Head: slump\n",
      "Word: sales, Deprel: compound, Head: slump\n",
      "Word: slump, Deprel: obl, Head: sparring\n",
      "Word: Siebel, Deprel: nsubj, Head: sparring\n",
      "Word: is, Deprel: aux, Head: sparring\n",
      "Word: sparring, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: shareholders\n",
      "Word: some, Deprel: det, Head: shareholders\n",
      "Word: shareholders, Deprel: obl, Head: sparring\n",
      "Word: over, Deprel: case, Head: windfalls\n",
      "Word: management, Deprel: compound, Head: windfalls\n",
      "Word: stock, Deprel: compound, Head: option\n",
      "Word: option, Deprel: compound, Head: windfalls\n",
      "Word: windfalls, Deprel: nmod, Head: shareholders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'That compared with a year-earlier profit of 102 million or 13 cents a share'\n",
      "Word: That, Deprel: nsubj, Head: compared\n",
      "Word: compared, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: profit\n",
      "Word: a, Deprel: det, Head: profit\n",
      "Word: year-earlier, Deprel: amod, Head: profit\n",
      "Word: profit, Deprel: obl, Head: compared\n",
      "Word: of, Deprel: case, Head: million\n",
      "Word: 102, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nmod, Head: profit\n",
      "Word: or, Deprel: cc, Head: cents\n",
      "Word: 13, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: conj, Head: million\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: nmod:npmod, Head: cents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'That was more than double the 102 million or 13 cents a share for the year-earlier quarter'\n",
      "Word: That, Deprel: nsubj, Head: cents\n",
      "Word: was, Deprel: cop, Head: cents\n",
      "Word: more, Deprel: advmod, Head: million\n",
      "Word: than, Deprel: fixed, Head: more\n",
      "Word: double, Deprel: advmod, Head: cents\n",
      "Word: the, Deprel: det, Head: cents\n",
      "Word: 102, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: cents\n",
      "Word: or, Deprel: cc, Head: 13\n",
      "Word: 13, Deprel: conj, Head: million\n",
      "Word: cents, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: share\n",
      "Word: share, Deprel: appos, Head: cents\n",
      "Word: for, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: year-earlier, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: nmod, Head: cents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Stanford 51-17 and Rice 57-12 will play for the national championship tonight'\n",
      "Word: Stanford, Deprel: nsubj, Head: play\n",
      "Word: 51-17, Deprel: nummod, Head: Stanford\n",
      "Word: and, Deprel: cc, Head: Rice\n",
      "Word: Rice, Deprel: conj, Head: Stanford\n",
      "Word: 57-12, Deprel: nummod, Head: Rice\n",
      "Word: will, Deprel: aux, Head: play\n",
      "Word: play, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: championship\n",
      "Word: the, Deprel: det, Head: championship\n",
      "Word: national, Deprel: amod, Head: championship\n",
      "Word: championship, Deprel: obl, Head: play\n",
      "Word: tonight, Deprel: obl:tmod, Head: play\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Rice 57-12 and Stanford 51-17 will meet in a winner-take-all matchup at 6:05 p.m Monday'\n",
      "Word: Rice, Deprel: nsubj, Head: meet\n",
      "Word: 57-12, Deprel: nummod, Head: Rice\n",
      "Word: and, Deprel: cc, Head: Stanford\n",
      "Word: Stanford, Deprel: conj, Head: Rice\n",
      "Word: 51-17, Deprel: nummod, Head: Stanford\n",
      "Word: will, Deprel: aux, Head: meet\n",
      "Word: meet, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: matchup\n",
      "Word: a, Deprel: det, Head: matchup\n",
      "Word: winner-take-all, Deprel: amod, Head: matchup\n",
      "Word: matchup, Deprel: obl, Head: meet\n",
      "Word: at, Deprel: case, Head: p.m\n",
      "Word: 6:05, Deprel: nummod, Head: p.m\n",
      "Word: p.m, Deprel: obl, Head: meet\n",
      "Word: Monday, Deprel: nmod:npmod, Head: p.m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The economy nonetheless has yet to exhibit sustainable growth'\n",
      "Word: The, Deprel: det, Head: economy\n",
      "Word: economy, Deprel: nsubj, Head: has\n",
      "Word: nonetheless, Deprel: advmod, Head: has\n",
      "Word: has, Deprel: root, Head: ROOT\n",
      "Word: yet, Deprel: advmod, Head: has\n",
      "Word: to, Deprel: mark, Head: exhibit\n",
      "Word: exhibit, Deprel: xcomp, Head: has\n",
      "Word: sustainable, Deprel: amod, Head: growth\n",
      "Word: growth, Deprel: obj, Head: exhibit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But the economy has n't shown signs of sustainable growth'\n",
      "Word: But, Deprel: cc, Head: shown\n",
      "Word: the, Deprel: det, Head: economy\n",
      "Word: economy, Deprel: nsubj, Head: shown\n",
      "Word: has, Deprel: aux, Head: shown\n",
      "Word: n't, Deprel: advmod, Head: shown\n",
      "Word: shown, Deprel: root, Head: ROOT\n",
      "Word: signs, Deprel: obj, Head: shown\n",
      "Word: of, Deprel: case, Head: growth\n",
      "Word: sustainable, Deprel: amod, Head: growth\n",
      "Word: growth, Deprel: nmod, Head: signs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A 32-count indictment strikes at one of the very top targets in the drug trafficking world U.S Attorney Marcos Jimenez said'\n",
      "Word: A, Deprel: det, Head: strikes\n",
      "Word: 32-count, Deprel: amod, Head: indictment\n",
      "Word: indictment, Deprel: compound, Head: strikes\n",
      "Word: strikes, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: one\n",
      "Word: one, Deprel: nmod, Head: strikes\n",
      "Word: of, Deprel: case, Head: targets\n",
      "Word: the, Deprel: det, Head: targets\n",
      "Word: very, Deprel: advmod, Head: top\n",
      "Word: top, Deprel: amod, Head: targets\n",
      "Word: targets, Deprel: nmod, Head: one\n",
      "Word: in, Deprel: case, Head: world\n",
      "Word: the, Deprel: det, Head: world\n",
      "Word: drug, Deprel: compound, Head: trafficking\n",
      "Word: trafficking, Deprel: compound, Head: world\n",
      "Word: world, Deprel: nmod, Head: targets\n",
      "Word: U.S, Deprel: compound, Head: Attorney\n",
      "Word: Attorney, Deprel: appos, Head: world\n",
      "Word: Marcos, Deprel: flat, Head: Attorney\n",
      "Word: Jimenez, Deprel: flat, Head: Marcos\n",
      "Word: said, Deprel: parataxis, Head: strikes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The newly unsealed 32-count indictment alleges money laundering and conspiracy and strikes at one of the very top targets in the drug-trafficking world Jiménez said'\n",
      "Word: The, Deprel: det, Head: indictment\n",
      "Word: newly, Deprel: advmod, Head: unsealed\n",
      "Word: unsealed, Deprel: amod, Head: indictment\n",
      "Word: 32-count, Deprel: amod, Head: indictment\n",
      "Word: indictment, Deprel: nsubj, Head: alleges\n",
      "Word: alleges, Deprel: root, Head: ROOT\n",
      "Word: money, Deprel: compound, Head: laundering\n",
      "Word: laundering, Deprel: obj, Head: alleges\n",
      "Word: and, Deprel: cc, Head: conspiracy\n",
      "Word: conspiracy, Deprel: conj, Head: laundering\n",
      "Word: and, Deprel: cc, Head: strikes\n",
      "Word: strikes, Deprel: conj, Head: laundering\n",
      "Word: at, Deprel: case, Head: one\n",
      "Word: one, Deprel: nmod, Head: laundering\n",
      "Word: of, Deprel: case, Head: targets\n",
      "Word: the, Deprel: det, Head: targets\n",
      "Word: very, Deprel: advmod, Head: top\n",
      "Word: top, Deprel: amod, Head: targets\n",
      "Word: targets, Deprel: nmod, Head: one\n",
      "Word: in, Deprel: case, Head: world\n",
      "Word: the, Deprel: det, Head: world\n",
      "Word: drug-trafficking, Deprel: amod, Head: world\n",
      "Word: world, Deprel: nmod, Head: targets\n",
      "Word: Jiménez, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: alleges\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A soldier was killed Monday and another wounded when their convoy was ambushed in northern Iraq'\n",
      "Word: A, Deprel: det, Head: soldier\n",
      "Word: soldier, Deprel: nsubj:pass, Head: killed\n",
      "Word: was, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: root, Head: ROOT\n",
      "Word: Monday, Deprel: obl:tmod, Head: killed\n",
      "Word: and, Deprel: cc, Head: wounded\n",
      "Word: another, Deprel: nsubj, Head: wounded\n",
      "Word: wounded, Deprel: conj, Head: killed\n",
      "Word: when, Deprel: advmod, Head: ambushed\n",
      "Word: their, Deprel: nmod:poss, Head: convoy\n",
      "Word: convoy, Deprel: nsubj:pass, Head: ambushed\n",
      "Word: was, Deprel: aux:pass, Head: ambushed\n",
      "Word: ambushed, Deprel: advcl, Head: wounded\n",
      "Word: in, Deprel: case, Head: Iraq\n",
      "Word: northern, Deprel: amod, Head: Iraq\n",
      "Word: Iraq, Deprel: obl, Head: ambushed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'On Sunday a U.S soldier was killed and another injured when a munitions dump they were guarding exploded in southern Iraq'\n",
      "Word: On, Deprel: case, Head: Sunday\n",
      "Word: Sunday, Deprel: obl, Head: killed\n",
      "Word: a, Deprel: det, Head: soldier\n",
      "Word: U.S, Deprel: compound, Head: soldier\n",
      "Word: soldier, Deprel: nsubj:pass, Head: killed\n",
      "Word: was, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: injured\n",
      "Word: another, Deprel: nsubj, Head: injured\n",
      "Word: injured, Deprel: conj, Head: killed\n",
      "Word: when, Deprel: advmod, Head: exploded\n",
      "Word: a, Deprel: det, Head: dump\n",
      "Word: munitions, Deprel: compound, Head: dump\n",
      "Word: dump, Deprel: nsubj, Head: exploded\n",
      "Word: they, Deprel: nsubj, Head: guarding\n",
      "Word: were, Deprel: aux, Head: guarding\n",
      "Word: guarding, Deprel: acl:relcl, Head: dump\n",
      "Word: exploded, Deprel: advcl, Head: killed\n",
      "Word: in, Deprel: case, Head: Iraq\n",
      "Word: southern, Deprel: amod, Head: Iraq\n",
      "Word: Iraq, Deprel: obl, Head: exploded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The commission estimated California lost 937 million to corporate tax shelters in 2001'\n",
      "Word: The, Deprel: det, Head: commission\n",
      "Word: commission, Deprel: nsubj, Head: estimated\n",
      "Word: estimated, Deprel: root, Head: ROOT\n",
      "Word: California, Deprel: nsubj, Head: lost\n",
      "Word: lost, Deprel: ccomp, Head: estimated\n",
      "Word: 937, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obj, Head: lost\n",
      "Word: to, Deprel: case, Head: shelters\n",
      "Word: corporate, Deprel: amod, Head: shelters\n",
      "Word: tax, Deprel: compound, Head: shelters\n",
      "Word: shelters, Deprel: obl, Head: lost\n",
      "Word: in, Deprel: case, Head: 2001\n",
      "Word: 2001, Deprel: obl, Head: lost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'California s lost tax revenue was mostly due to international corporate tax shelters'\n",
      "Word: California, Deprel: nmod:poss, Head: revenue\n",
      "Word: s, Deprel: case, Head: California\n",
      "Word: lost, Deprel: amod, Head: revenue\n",
      "Word: tax, Deprel: compound, Head: revenue\n",
      "Word: revenue, Deprel: nsubj, Head: due\n",
      "Word: was, Deprel: cop, Head: due\n",
      "Word: mostly, Deprel: advmod, Head: due\n",
      "Word: due, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: shelters\n",
      "Word: international, Deprel: amod, Head: shelters\n",
      "Word: corporate, Deprel: amod, Head: shelters\n",
      "Word: tax, Deprel: compound, Head: shelters\n",
      "Word: shelters, Deprel: obl, Head: due\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In other markets U.S Treasuries started off on Monday weaker as stocks rose early'\n",
      "Word: In, Deprel: case, Head: markets\n",
      "Word: other, Deprel: amod, Head: markets\n",
      "Word: markets, Deprel: obl, Head: started\n",
      "Word: U.S, Deprel: compound, Head: Treasuries\n",
      "Word: Treasuries, Deprel: nsubj, Head: started\n",
      "Word: started, Deprel: root, Head: ROOT\n",
      "Word: off, Deprel: compound:prt, Head: started\n",
      "Word: on, Deprel: case, Head: Monday\n",
      "Word: Monday, Deprel: obl, Head: started\n",
      "Word: weaker, Deprel: advcl, Head: started\n",
      "Word: as, Deprel: mark, Head: rose\n",
      "Word: stocks, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: advcl, Head: started\n",
      "Word: early, Deprel: advmod, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In other markets U.S Treasuries inched higher as declining stocks raised the appeal of safe-haven debt'\n",
      "Word: In, Deprel: case, Head: markets\n",
      "Word: other, Deprel: amod, Head: markets\n",
      "Word: markets, Deprel: obl, Head: inched\n",
      "Word: U.S, Deprel: compound, Head: Treasuries\n",
      "Word: Treasuries, Deprel: nsubj, Head: inched\n",
      "Word: inched, Deprel: root, Head: ROOT\n",
      "Word: higher, Deprel: advmod, Head: inched\n",
      "Word: as, Deprel: mark, Head: raised\n",
      "Word: declining, Deprel: amod, Head: stocks\n",
      "Word: stocks, Deprel: nsubj, Head: raised\n",
      "Word: raised, Deprel: advcl, Head: inched\n",
      "Word: the, Deprel: det, Head: appeal\n",
      "Word: appeal, Deprel: obj, Head: raised\n",
      "Word: of, Deprel: case, Head: debt\n",
      "Word: safe-haven, Deprel: amod, Head: debt\n",
      "Word: debt, Deprel: nmod, Head: appeal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A cost analysis is under way said Michael Rebell CFE s executive director'\n",
      "Word: A, Deprel: det, Head: analysis\n",
      "Word: cost, Deprel: compound, Head: analysis\n",
      "Word: analysis, Deprel: nsubj, Head: said\n",
      "Word: is, Deprel: cop, Head: way\n",
      "Word: under, Deprel: case, Head: way\n",
      "Word: way, Deprel: ccomp, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: Michael, Deprel: nsubj, Head: said\n",
      "Word: Rebell, Deprel: flat, Head: Michael\n",
      "Word: CFE, Deprel: nmod:poss, Head: director\n",
      "Word: s, Deprel: case, Head: CFE\n",
      "Word: executive, Deprel: amod, Head: director\n",
      "Word: director, Deprel: appos, Head: Michael\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We re not looking for a Robin Hood remedy said Michael Rebell the campaign s executive director'\n",
      "Word: We, Deprel: nsubj, Head: looking\n",
      "Word: re, Deprel: aux, Head: looking\n",
      "Word: not, Deprel: advmod, Head: looking\n",
      "Word: looking, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: remedy\n",
      "Word: a, Deprel: det, Head: remedy\n",
      "Word: Robin, Deprel: compound, Head: Hood\n",
      "Word: Hood, Deprel: compound, Head: remedy\n",
      "Word: remedy, Deprel: obl, Head: looking\n",
      "Word: said, Deprel: advcl, Head: looking\n",
      "Word: Michael, Deprel: obj, Head: said\n",
      "Word: Rebell, Deprel: flat, Head: Michael\n",
      "Word: the, Deprel: det, Head: campaign\n",
      "Word: campaign, Deprel: nmod:poss, Head: director\n",
      "Word: s, Deprel: case, Head: campaign\n",
      "Word: executive, Deprel: amod, Head: director\n",
      "Word: director, Deprel: appos, Head: Michael\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I was going to the court believing I could do this only if I played my best tennis'\n",
      "Word: I, Deprel: nsubj, Head: going\n",
      "Word: was, Deprel: aux, Head: going\n",
      "Word: going, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: court\n",
      "Word: the, Deprel: det, Head: court\n",
      "Word: court, Deprel: obl, Head: going\n",
      "Word: believing, Deprel: advcl, Head: going\n",
      "Word: I, Deprel: nsubj, Head: do\n",
      "Word: could, Deprel: aux, Head: do\n",
      "Word: do, Deprel: ccomp, Head: believing\n",
      "Word: this, Deprel: obj, Head: do\n",
      "Word: only, Deprel: advmod, Head: played\n",
      "Word: if, Deprel: mark, Head: played\n",
      "Word: I, Deprel: nsubj, Head: played\n",
      "Word: played, Deprel: advcl, Head: do\n",
      "Word: my, Deprel: nmod:poss, Head: tennis\n",
      "Word: best, Deprel: amod, Head: tennis\n",
      "Word: tennis, Deprel: obj, Head: played\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'I was believing that I was confident I could do this but only in the case I would play my best tennis'\n",
      "Word: I, Deprel: nsubj, Head: believing\n",
      "Word: was, Deprel: aux, Head: believing\n",
      "Word: believing, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: confident\n",
      "Word: I, Deprel: nsubj, Head: confident\n",
      "Word: was, Deprel: cop, Head: confident\n",
      "Word: confident, Deprel: ccomp, Head: believing\n",
      "Word: I, Deprel: nsubj, Head: do\n",
      "Word: could, Deprel: aux, Head: do\n",
      "Word: do, Deprel: ccomp, Head: confident\n",
      "Word: this, Deprel: obj, Head: do\n",
      "Word: but, Deprel: cc, Head: play\n",
      "Word: only, Deprel: advmod, Head: case\n",
      "Word: in, Deprel: case, Head: case\n",
      "Word: the, Deprel: det, Head: case\n",
      "Word: case, Deprel: obl, Head: play\n",
      "Word: I, Deprel: nsubj, Head: play\n",
      "Word: would, Deprel: aux, Head: play\n",
      "Word: play, Deprel: conj, Head: believing\n",
      "Word: my, Deprel: nmod:poss, Head: tennis\n",
      "Word: best, Deprel: amod, Head: tennis\n",
      "Word: tennis, Deprel: obj, Head: play\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dotson told FBI agents that he shot Dennehy after the player tried to shoot him according to the arrest warrant affidavit'\n",
      "Word: Dotson, Deprel: nsubj, Head: told\n",
      "Word: told, Deprel: root, Head: ROOT\n",
      "Word: FBI, Deprel: compound, Head: agents\n",
      "Word: agents, Deprel: iobj, Head: told\n",
      "Word: that, Deprel: mark, Head: shot\n",
      "Word: he, Deprel: nsubj, Head: shot\n",
      "Word: shot, Deprel: ccomp, Head: told\n",
      "Word: Dennehy, Deprel: obj, Head: shot\n",
      "Word: after, Deprel: mark, Head: tried\n",
      "Word: the, Deprel: det, Head: player\n",
      "Word: player, Deprel: nsubj, Head: tried\n",
      "Word: tried, Deprel: advcl, Head: shot\n",
      "Word: to, Deprel: mark, Head: shoot\n",
      "Word: shoot, Deprel: xcomp, Head: tried\n",
      "Word: him, Deprel: obj, Head: shoot\n",
      "Word: according, Deprel: case, Head: affidavit\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: the, Deprel: det, Head: affidavit\n",
      "Word: arrest, Deprel: compound, Head: warrant\n",
      "Word: warrant, Deprel: compound, Head: affidavit\n",
      "Word: affidavit, Deprel: obl, Head: shoot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dotson was arrested July 21 after telling FBI agents he shot Dennehy when Dennehy tried to shoot him according to the arrest warrant affidavit'\n",
      "Word: Dotson, Deprel: nsubj:pass, Head: arrested\n",
      "Word: was, Deprel: aux:pass, Head: arrested\n",
      "Word: arrested, Deprel: root, Head: ROOT\n",
      "Word: July, Deprel: obl:tmod, Head: arrested\n",
      "Word: 21, Deprel: nummod, Head: July\n",
      "Word: after, Deprel: mark, Head: telling\n",
      "Word: telling, Deprel: advcl, Head: arrested\n",
      "Word: FBI, Deprel: compound, Head: agents\n",
      "Word: agents, Deprel: iobj, Head: telling\n",
      "Word: he, Deprel: nsubj, Head: shot\n",
      "Word: shot, Deprel: ccomp, Head: telling\n",
      "Word: Dennehy, Deprel: obj, Head: shot\n",
      "Word: when, Deprel: advmod, Head: tried\n",
      "Word: Dennehy, Deprel: nsubj, Head: tried\n",
      "Word: tried, Deprel: advcl, Head: shot\n",
      "Word: to, Deprel: mark, Head: shoot\n",
      "Word: shoot, Deprel: xcomp, Head: tried\n",
      "Word: him, Deprel: obj, Head: shoot\n",
      "Word: according, Deprel: case, Head: affidavit\n",
      "Word: to, Deprel: fixed, Head: according\n",
      "Word: the, Deprel: det, Head: affidavit\n",
      "Word: arrest, Deprel: compound, Head: warrant\n",
      "Word: warrant, Deprel: compound, Head: affidavit\n",
      "Word: affidavit, Deprel: obl, Head: shoot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dogs he said are second only to humans in the thoroughness of medical understanding and research'\n",
      "Word: Dogs, Deprel: nsubj, Head: second\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: Dogs\n",
      "Word: are, Deprel: cop, Head: second\n",
      "Word: second, Deprel: root, Head: ROOT\n",
      "Word: only, Deprel: advmod, Head: humans\n",
      "Word: to, Deprel: case, Head: humans\n",
      "Word: humans, Deprel: obl, Head: second\n",
      "Word: in, Deprel: case, Head: thoroughness\n",
      "Word: the, Deprel: det, Head: thoroughness\n",
      "Word: thoroughness, Deprel: obl, Head: second\n",
      "Word: of, Deprel: case, Head: understanding\n",
      "Word: medical, Deprel: amod, Head: understanding\n",
      "Word: understanding, Deprel: nmod, Head: thoroughness\n",
      "Word: and, Deprel: cc, Head: research\n",
      "Word: research, Deprel: conj, Head: understanding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He said that dogs are second only to humans in terms of being the subject of medical research'\n",
      "Word: He, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: second\n",
      "Word: dogs, Deprel: nsubj, Head: second\n",
      "Word: are, Deprel: cop, Head: second\n",
      "Word: second, Deprel: ccomp, Head: said\n",
      "Word: only, Deprel: advmod, Head: humans\n",
      "Word: to, Deprel: case, Head: humans\n",
      "Word: humans, Deprel: obl, Head: second\n",
      "Word: in, Deprel: case, Head: terms\n",
      "Word: terms, Deprel: obl, Head: second\n",
      "Word: of, Deprel: mark, Head: subject\n",
      "Word: being, Deprel: cop, Head: subject\n",
      "Word: the, Deprel: det, Head: subject\n",
      "Word: subject, Deprel: acl, Head: terms\n",
      "Word: of, Deprel: case, Head: research\n",
      "Word: medical, Deprel: amod, Head: research\n",
      "Word: research, Deprel: nmod, Head: subject\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The stock rose 2.11 or about 11 percent to close on Friday at 21.51 on the New York Stock Exchange'\n",
      "Word: The, Deprel: det, Head: stock\n",
      "Word: stock, Deprel: nsubj, Head: rose\n",
      "Word: rose, Deprel: root, Head: ROOT\n",
      "Word: 2.11, Deprel: nummod, Head: percent\n",
      "Word: or, Deprel: cc, Head: about\n",
      "Word: about, Deprel: conj, Head: 2.11\n",
      "Word: 11, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: rose\n",
      "Word: to, Deprel: mark, Head: close\n",
      "Word: close, Deprel: advcl, Head: rose\n",
      "Word: on, Deprel: case, Head: Friday\n",
      "Word: Friday, Deprel: obl, Head: close\n",
      "Word: at, Deprel: case, Head: 21.51\n",
      "Word: 21.51, Deprel: obl, Head: close\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: compound, Head: Exchange\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: rose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'PG E Corp shares jumped 1.63 or 8 percent to 21.03 on the New York Stock Exchange on Friday'\n",
      "Word: PG, Deprel: compound, Head: shares\n",
      "Word: E, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: compound, Head: shares\n",
      "Word: shares, Deprel: nsubj, Head: jumped\n",
      "Word: jumped, Deprel: root, Head: ROOT\n",
      "Word: 1.63, Deprel: nummod, Head: percent\n",
      "Word: or, Deprel: cc, Head: 8\n",
      "Word: 8, Deprel: conj, Head: 1.63\n",
      "Word: percent, Deprel: obl:tmod, Head: jumped\n",
      "Word: to, Deprel: case, Head: 21.03\n",
      "Word: 21.03, Deprel: obl, Head: jumped\n",
      "Word: on, Deprel: case, Head: Exchange\n",
      "Word: the, Deprel: det, Head: Exchange\n",
      "Word: New, Deprel: compound, Head: Exchange\n",
      "Word: York, Deprel: flat, Head: New\n",
      "Word: Stock, Deprel: compound, Head: Exchange\n",
      "Word: Exchange, Deprel: obl, Head: jumped\n",
      "Word: on, Deprel: case, Head: Friday\n",
      "Word: Friday, Deprel: nmod, Head: Exchange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Eric Gagne earned his 17th save in as many opportunities as he struck out three in the ninth and allowed only an infield single by Greg Norton'\n",
      "Word: Eric, Deprel: nsubj, Head: earned\n",
      "Word: Gagne, Deprel: flat, Head: Eric\n",
      "Word: earned, Deprel: root, Head: ROOT\n",
      "Word: his, Deprel: nmod:poss, Head: save\n",
      "Word: 17th, Deprel: amod, Head: save\n",
      "Word: save, Deprel: obj, Head: earned\n",
      "Word: in, Deprel: case, Head: opportunities\n",
      "Word: as, Deprel: advmod, Head: many\n",
      "Word: many, Deprel: amod, Head: opportunities\n",
      "Word: opportunities, Deprel: obl, Head: earned\n",
      "Word: as, Deprel: mark, Head: struck\n",
      "Word: he, Deprel: nsubj, Head: struck\n",
      "Word: struck, Deprel: advcl, Head: earned\n",
      "Word: out, Deprel: compound:prt, Head: struck\n",
      "Word: three, Deprel: obj, Head: struck\n",
      "Word: in, Deprel: case, Head: ninth\n",
      "Word: the, Deprel: det, Head: ninth\n",
      "Word: ninth, Deprel: obl, Head: struck\n",
      "Word: and, Deprel: cc, Head: allowed\n",
      "Word: allowed, Deprel: conj, Head: struck\n",
      "Word: only, Deprel: advmod, Head: single\n",
      "Word: an, Deprel: det, Head: single\n",
      "Word: infield, Deprel: compound, Head: single\n",
      "Word: single, Deprel: obj, Head: allowed\n",
      "Word: by, Deprel: case, Head: Greg\n",
      "Word: Greg, Deprel: nmod, Head: single\n",
      "Word: Norton, Deprel: flat, Head: Greg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Closer Eric Gagne earned his 17th save in as many opportunities as he struck out three of the four batters he faced in the ninth'\n",
      "Word: Closer, Deprel: amod, Head: Eric\n",
      "Word: Eric, Deprel: nsubj, Head: earned\n",
      "Word: Gagne, Deprel: flat, Head: Eric\n",
      "Word: earned, Deprel: root, Head: ROOT\n",
      "Word: his, Deprel: nmod:poss, Head: save\n",
      "Word: 17th, Deprel: amod, Head: save\n",
      "Word: save, Deprel: obj, Head: earned\n",
      "Word: in, Deprel: case, Head: opportunities\n",
      "Word: as, Deprel: advmod, Head: many\n",
      "Word: many, Deprel: amod, Head: opportunities\n",
      "Word: opportunities, Deprel: obl, Head: earned\n",
      "Word: as, Deprel: mark, Head: struck\n",
      "Word: he, Deprel: nsubj, Head: struck\n",
      "Word: struck, Deprel: advcl, Head: earned\n",
      "Word: out, Deprel: compound:prt, Head: struck\n",
      "Word: three, Deprel: obj, Head: struck\n",
      "Word: of, Deprel: case, Head: batters\n",
      "Word: the, Deprel: det, Head: batters\n",
      "Word: four, Deprel: nummod, Head: batters\n",
      "Word: batters, Deprel: nmod, Head: three\n",
      "Word: he, Deprel: nsubj, Head: faced\n",
      "Word: faced, Deprel: acl:relcl, Head: batters\n",
      "Word: in, Deprel: case, Head: ninth\n",
      "Word: the, Deprel: det, Head: ninth\n",
      "Word: ninth, Deprel: obl, Head: faced\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Blair s government included the charge that Saddam sought uranium from Niger in a September 2002 dossier setting out the case for military action'\n",
      "Word: Blair, Deprel: nmod:poss, Head: government\n",
      "Word: s, Deprel: case, Head: Blair\n",
      "Word: government, Deprel: nsubj, Head: included\n",
      "Word: included, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: charge\n",
      "Word: charge, Deprel: obj, Head: included\n",
      "Word: that, Deprel: mark, Head: sought\n",
      "Word: Saddam, Deprel: nsubj, Head: sought\n",
      "Word: sought, Deprel: acl, Head: charge\n",
      "Word: uranium, Deprel: obj, Head: sought\n",
      "Word: from, Deprel: case, Head: Niger\n",
      "Word: Niger, Deprel: obl, Head: sought\n",
      "Word: in, Deprel: case, Head: dossier\n",
      "Word: a, Deprel: det, Head: dossier\n",
      "Word: September, Deprel: compound, Head: dossier\n",
      "Word: 2002, Deprel: nummod, Head: September\n",
      "Word: dossier, Deprel: obl, Head: sought\n",
      "Word: setting, Deprel: advcl, Head: sought\n",
      "Word: out, Deprel: compound:prt, Head: setting\n",
      "Word: the, Deprel: det, Head: case\n",
      "Word: case, Deprel: obj, Head: setting\n",
      "Word: for, Deprel: case, Head: action\n",
      "Word: military, Deprel: amod, Head: action\n",
      "Word: action, Deprel: nmod, Head: case\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Britain included the accusation in a September 2002 dossier setting out the case for war in Iraq'\n",
      "Word: Britain, Deprel: nsubj, Head: included\n",
      "Word: included, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: accusation\n",
      "Word: accusation, Deprel: obj, Head: included\n",
      "Word: in, Deprel: case, Head: dossier\n",
      "Word: a, Deprel: det, Head: dossier\n",
      "Word: September, Deprel: compound, Head: dossier\n",
      "Word: 2002, Deprel: nummod, Head: September\n",
      "Word: dossier, Deprel: nmod, Head: accusation\n",
      "Word: setting, Deprel: acl, Head: dossier\n",
      "Word: out, Deprel: compound:prt, Head: setting\n",
      "Word: the, Deprel: det, Head: case\n",
      "Word: case, Deprel: obj, Head: setting\n",
      "Word: for, Deprel: case, Head: war\n",
      "Word: war, Deprel: nmod, Head: case\n",
      "Word: in, Deprel: case, Head: Iraq\n",
      "Word: Iraq, Deprel: nmod, Head: war\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Not counting energy prices wholesale prices were down 0.9 percent'\n",
      "Word: Not, Deprel: advmod, Head: counting\n",
      "Word: counting, Deprel: advcl, Head: percent\n",
      "Word: energy, Deprel: compound, Head: prices\n",
      "Word: prices, Deprel: obj, Head: counting\n",
      "Word: wholesale, Deprel: compound, Head: prices\n",
      "Word: prices, Deprel: nsubj, Head: percent\n",
      "Word: were, Deprel: cop, Head: percent\n",
      "Word: down, Deprel: advmod, Head: percent\n",
      "Word: 0.9, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Energy prices dropped by 8.6 percent the biggest decline since July 1986'\n",
      "Word: Energy, Deprel: compound, Head: prices\n",
      "Word: prices, Deprel: nsubj, Head: dropped\n",
      "Word: dropped, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: percent\n",
      "Word: 8.6, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: dropped\n",
      "Word: the, Deprel: det, Head: decline\n",
      "Word: biggest, Deprel: amod, Head: decline\n",
      "Word: decline, Deprel: obj, Head: dropped\n",
      "Word: since, Deprel: case, Head: July\n",
      "Word: July, Deprel: obl, Head: dropped\n",
      "Word: 1986, Deprel: nummod, Head: July\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The spacecraft is scheduled to blast off as early as tomorrow or as late as Friday from the Jiuquan launching site in the Gobi Desert'\n",
      "Word: The, Deprel: det, Head: spacecraft\n",
      "Word: spacecraft, Deprel: nsubj:pass, Head: scheduled\n",
      "Word: is, Deprel: aux:pass, Head: scheduled\n",
      "Word: scheduled, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: blast\n",
      "Word: blast, Deprel: xcomp, Head: scheduled\n",
      "Word: off, Deprel: compound:prt, Head: blast\n",
      "Word: as, Deprel: advmod, Head: early\n",
      "Word: early, Deprel: advmod, Head: blast\n",
      "Word: as, Deprel: case, Head: tomorrow\n",
      "Word: tomorrow, Deprel: obl, Head: early\n",
      "Word: or, Deprel: cc, Head: late\n",
      "Word: as, Deprel: advmod, Head: late\n",
      "Word: late, Deprel: conj, Head: early\n",
      "Word: as, Deprel: case, Head: Friday\n",
      "Word: Friday, Deprel: obl, Head: late\n",
      "Word: from, Deprel: case, Head: site\n",
      "Word: the, Deprel: det, Head: site\n",
      "Word: Jiuquan, Deprel: compound, Head: site\n",
      "Word: launching, Deprel: compound, Head: site\n",
      "Word: site, Deprel: obl, Head: late\n",
      "Word: in, Deprel: case, Head: Desert\n",
      "Word: the, Deprel: det, Head: Desert\n",
      "Word: Gobi, Deprel: compound, Head: Desert\n",
      "Word: Desert, Deprel: nmod, Head: site\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The spacecraft is scheduled to blast off between next Wednesday and Friday from a launching site in the Gobi Desert'\n",
      "Word: The, Deprel: det, Head: spacecraft\n",
      "Word: spacecraft, Deprel: nsubj:pass, Head: scheduled\n",
      "Word: is, Deprel: aux:pass, Head: scheduled\n",
      "Word: scheduled, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: blast\n",
      "Word: blast, Deprel: xcomp, Head: scheduled\n",
      "Word: off, Deprel: compound:prt, Head: blast\n",
      "Word: between, Deprel: case, Head: Wednesday\n",
      "Word: next, Deprel: amod, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: blast\n",
      "Word: and, Deprel: cc, Head: Friday\n",
      "Word: Friday, Deprel: conj, Head: Wednesday\n",
      "Word: from, Deprel: case, Head: site\n",
      "Word: a, Deprel: det, Head: site\n",
      "Word: launching, Deprel: compound, Head: site\n",
      "Word: site, Deprel: obl, Head: blast\n",
      "Word: in, Deprel: case, Head: Desert\n",
      "Word: the, Deprel: det, Head: Desert\n",
      "Word: Gobi, Deprel: compound, Head: Desert\n",
      "Word: Desert, Deprel: nmod, Head: site\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hong Kong was flat Australia Singapore and South Korea lost 0.2-0.4 percent'\n",
      "Word: Hong, Deprel: compound, Head: Kong\n",
      "Word: Kong, Deprel: nsubj, Head: Singapore\n",
      "Word: was, Deprel: cop, Head: Singapore\n",
      "Word: flat, Deprel: amod, Head: Singapore\n",
      "Word: Australia, Deprel: compound, Head: Singapore\n",
      "Word: Singapore, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: lost\n",
      "Word: South, Deprel: compound, Head: Korea\n",
      "Word: Korea, Deprel: nsubj, Head: lost\n",
      "Word: lost, Deprel: conj, Head: Singapore\n",
      "Word: 0.2-0.4, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: lost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Australia was flat Singapore was down 0.3 percent by midday and South Korea added 0.2 percent'\n",
      "Word: Australia, Deprel: nsubj, Head: flat\n",
      "Word: was, Deprel: cop, Head: flat\n",
      "Word: flat, Deprel: root, Head: ROOT\n",
      "Word: Singapore, Deprel: nsubj, Head: down\n",
      "Word: was, Deprel: cop, Head: down\n",
      "Word: down, Deprel: ccomp, Head: flat\n",
      "Word: 0.3, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: down\n",
      "Word: by, Deprel: case, Head: midday\n",
      "Word: midday, Deprel: obl, Head: down\n",
      "Word: and, Deprel: cc, Head: added\n",
      "Word: South, Deprel: compound, Head: Korea\n",
      "Word: Korea, Deprel: nsubj, Head: added\n",
      "Word: added, Deprel: conj, Head: down\n",
      "Word: 0.2, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'SUVs parked on residential streets in Monrovia were tagged with ELF and other slogans and another was set ablaze in front of a house Sgt Tom Wright said'\n",
      "Word: SUVs, Deprel: nsubj:pass, Head: tagged\n",
      "Word: parked, Deprel: acl, Head: SUVs\n",
      "Word: on, Deprel: case, Head: streets\n",
      "Word: residential, Deprel: amod, Head: streets\n",
      "Word: streets, Deprel: obl, Head: parked\n",
      "Word: in, Deprel: case, Head: Monrovia\n",
      "Word: Monrovia, Deprel: nmod, Head: streets\n",
      "Word: were, Deprel: aux:pass, Head: tagged\n",
      "Word: tagged, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: ELF\n",
      "Word: ELF, Deprel: obl, Head: tagged\n",
      "Word: and, Deprel: cc, Head: slogans\n",
      "Word: other, Deprel: amod, Head: slogans\n",
      "Word: slogans, Deprel: conj, Head: ELF\n",
      "Word: and, Deprel: cc, Head: set\n",
      "Word: another, Deprel: nsubj:pass, Head: set\n",
      "Word: was, Deprel: aux:pass, Head: set\n",
      "Word: set, Deprel: conj, Head: tagged\n",
      "Word: ablaze, Deprel: xcomp, Head: set\n",
      "Word: in, Deprel: case, Head: front\n",
      "Word: front, Deprel: obl, Head: set\n",
      "Word: of, Deprel: case, Head: house\n",
      "Word: a, Deprel: det, Head: house\n",
      "Word: house, Deprel: nmod, Head: front\n",
      "Word: Sgt, Deprel: appos, Head: house\n",
      "Word: Tom, Deprel: flat, Head: Sgt\n",
      "Word: Wright, Deprel: flat, Head: Sgt\n",
      "Word: said, Deprel: acl:relcl, Head: house\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Several SUVs parked on residential streets in Monrovia were tagged with ELF and other slogans said Sgt Tom Wright'\n",
      "Word: Several, Deprel: amod, Head: SUVs\n",
      "Word: SUVs, Deprel: nsubj:pass, Head: tagged\n",
      "Word: parked, Deprel: acl, Head: SUVs\n",
      "Word: on, Deprel: case, Head: streets\n",
      "Word: residential, Deprel: amod, Head: streets\n",
      "Word: streets, Deprel: obl, Head: parked\n",
      "Word: in, Deprel: case, Head: Monrovia\n",
      "Word: Monrovia, Deprel: nmod, Head: streets\n",
      "Word: were, Deprel: aux:pass, Head: tagged\n",
      "Word: tagged, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: ELF\n",
      "Word: ELF, Deprel: obl, Head: tagged\n",
      "Word: and, Deprel: cc, Head: slogans\n",
      "Word: other, Deprel: amod, Head: slogans\n",
      "Word: slogans, Deprel: conj, Head: ELF\n",
      "Word: said, Deprel: parataxis, Head: tagged\n",
      "Word: Sgt, Deprel: obj, Head: said\n",
      "Word: Tom, Deprel: flat, Head: Sgt\n",
      "Word: Wright, Deprel: flat, Head: Sgt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The technology-laced Nasdaq Composite Index IXIC was down 25.36 points or 1.53 percent at 1,628.26'\n",
      "Word: The, Deprel: det, Head: IXIC\n",
      "Word: technology-laced, Deprel: amod, Head: Index\n",
      "Word: Nasdaq, Deprel: compound, Head: Composite\n",
      "Word: Composite, Deprel: compound, Head: Index\n",
      "Word: Index, Deprel: compound, Head: IXIC\n",
      "Word: IXIC, Deprel: nsubj, Head: down\n",
      "Word: was, Deprel: cop, Head: down\n",
      "Word: down, Deprel: root, Head: ROOT\n",
      "Word: 25.36, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obl:npmod, Head: down\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.53, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 1,628.26\n",
      "Word: 1,628.26, Deprel: obl, Head: down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The broader Standard Poor s 500 Index SPX gave up 11.91 points or 1.19 percent at 986.60'\n",
      "Word: The, Deprel: det, Head: SPX\n",
      "Word: broader, Deprel: amod, Head: SPX\n",
      "Word: Standard, Deprel: compound, Head: Poor\n",
      "Word: Poor, Deprel: amod, Head: s\n",
      "Word: s, Deprel: compound, Head: SPX\n",
      "Word: 500, Deprel: nummod, Head: s\n",
      "Word: Index, Deprel: compound, Head: SPX\n",
      "Word: SPX, Deprel: nsubj, Head: gave\n",
      "Word: gave, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: gave\n",
      "Word: 11.91, Deprel: nummod, Head: points\n",
      "Word: points, Deprel: obj, Head: gave\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 1.19, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: points\n",
      "Word: at, Deprel: case, Head: 986.60\n",
      "Word: 986.60, Deprel: obl, Head: gave\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'At least 11 more cases in Indiana and three in Illinois are suspected'\n",
      "Word: At, Deprel: case, Head: least\n",
      "Word: least, Deprel: nmod, Head: 11\n",
      "Word: 11, Deprel: nummod, Head: cases\n",
      "Word: more, Deprel: amod, Head: cases\n",
      "Word: cases, Deprel: nsubj, Head: suspected\n",
      "Word: in, Deprel: case, Head: Indiana\n",
      "Word: Indiana, Deprel: nmod, Head: cases\n",
      "Word: and, Deprel: cc, Head: three\n",
      "Word: three, Deprel: conj, Head: Indiana\n",
      "Word: in, Deprel: case, Head: Illinois\n",
      "Word: Illinois, Deprel: nmod, Head: three\n",
      "Word: are, Deprel: cop, Head: suspected\n",
      "Word: suspected, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'There ’ s also at least three suspected cases in Illinois and 11 in Indiana'\n",
      "Word: There, Deprel: expl, Head: s\n",
      "Word: ’, Deprel: aux, Head: s\n",
      "Word: s, Deprel: root, Head: ROOT\n",
      "Word: also, Deprel: advmod, Head: s\n",
      "Word: at, Deprel: case, Head: least\n",
      "Word: least, Deprel: nmod, Head: three\n",
      "Word: three, Deprel: nummod, Head: cases\n",
      "Word: suspected, Deprel: amod, Head: cases\n",
      "Word: cases, Deprel: nsubj, Head: s\n",
      "Word: in, Deprel: case, Head: Illinois\n",
      "Word: Illinois, Deprel: nmod, Head: cases\n",
      "Word: and, Deprel: cc, Head: 11\n",
      "Word: 11, Deprel: conj, Head: Illinois\n",
      "Word: in, Deprel: case, Head: Indiana\n",
      "Word: Indiana, Deprel: nmod, Head: cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The pill which they call the polypill would contain aspirin a cholesterol-lowering drug three blood pressure-lowering drugs at half the standard dose and folic acid'\n",
      "Word: The, Deprel: det, Head: pill\n",
      "Word: pill, Deprel: nsubj, Head: contain\n",
      "Word: which, Deprel: obj, Head: call\n",
      "Word: they, Deprel: nsubj, Head: call\n",
      "Word: call, Deprel: acl:relcl, Head: pill\n",
      "Word: the, Deprel: det, Head: polypill\n",
      "Word: polypill, Deprel: obj, Head: call\n",
      "Word: would, Deprel: aux, Head: contain\n",
      "Word: contain, Deprel: root, Head: ROOT\n",
      "Word: aspirin, Deprel: obj, Head: contain\n",
      "Word: a, Deprel: det, Head: drugs\n",
      "Word: cholesterol-lowering, Deprel: amod, Head: drugs\n",
      "Word: drug, Deprel: compound, Head: drugs\n",
      "Word: three, Deprel: nummod, Head: drugs\n",
      "Word: blood, Deprel: compound, Head: pressure-lowering\n",
      "Word: pressure-lowering, Deprel: amod, Head: drugs\n",
      "Word: drugs, Deprel: obj, Head: contain\n",
      "Word: at, Deprel: case, Head: dose\n",
      "Word: half, Deprel: det:predet, Head: dose\n",
      "Word: the, Deprel: det, Head: dose\n",
      "Word: standard, Deprel: amod, Head: dose\n",
      "Word: dose, Deprel: obl, Head: contain\n",
      "Word: and, Deprel: cc, Head: acid\n",
      "Word: folic, Deprel: compound, Head: acid\n",
      "Word: acid, Deprel: conj, Head: dose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The ingredients of such a polypill would contain aspirin a cholesterol-lowering statin three blood pressure-lowering agents in half dose and folic acid'\n",
      "Word: The, Deprel: det, Head: ingredients\n",
      "Word: ingredients, Deprel: nsubj, Head: contain\n",
      "Word: of, Deprel: case, Head: polypill\n",
      "Word: such, Deprel: det:predet, Head: polypill\n",
      "Word: a, Deprel: det, Head: polypill\n",
      "Word: polypill, Deprel: nmod, Head: ingredients\n",
      "Word: would, Deprel: aux, Head: contain\n",
      "Word: contain, Deprel: root, Head: ROOT\n",
      "Word: aspirin, Deprel: obj, Head: contain\n",
      "Word: a, Deprel: det, Head: statin\n",
      "Word: cholesterol-lowering, Deprel: amod, Head: statin\n",
      "Word: statin, Deprel: obj, Head: contain\n",
      "Word: three, Deprel: nummod, Head: agents\n",
      "Word: blood, Deprel: compound, Head: pressure-lowering\n",
      "Word: pressure-lowering, Deprel: amod, Head: agents\n",
      "Word: agents, Deprel: obj, Head: contain\n",
      "Word: in, Deprel: case, Head: dose\n",
      "Word: half, Deprel: compound, Head: dose\n",
      "Word: dose, Deprel: nmod, Head: agents\n",
      "Word: and, Deprel: cc, Head: acid\n",
      "Word: folic, Deprel: compound, Head: acid\n",
      "Word: acid, Deprel: conj, Head: dose\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'They drive around in their cars while people are being killed 500 metres away he said on Sunday'\n",
      "Word: They, Deprel: nsubj, Head: drive\n",
      "Word: drive, Deprel: root, Head: ROOT\n",
      "Word: around, Deprel: advmod, Head: drive\n",
      "Word: in, Deprel: case, Head: cars\n",
      "Word: their, Deprel: nmod:poss, Head: cars\n",
      "Word: cars, Deprel: obl, Head: drive\n",
      "Word: while, Deprel: mark, Head: killed\n",
      "Word: people, Deprel: nsubj:pass, Head: killed\n",
      "Word: are, Deprel: aux, Head: killed\n",
      "Word: being, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: advcl, Head: drive\n",
      "Word: 500, Deprel: nummod, Head: metres\n",
      "Word: metres, Deprel: obl:npmod, Head: away\n",
      "Word: away, Deprel: advmod, Head: killed\n",
      "Word: he, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: parataxis, Head: drive\n",
      "Word: on, Deprel: case, Head: Sunday\n",
      "Word: Sunday, Deprel: obl, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'What they are doing right now is they drive around in their cars while people are being killed 500 metres away'\n",
      "Word: What, Deprel: nsubj:outer, Head: drive\n",
      "Word: they, Deprel: nsubj, Head: doing\n",
      "Word: are, Deprel: aux, Head: doing\n",
      "Word: doing, Deprel: acl:relcl, Head: What\n",
      "Word: right, Deprel: advmod, Head: now\n",
      "Word: now, Deprel: advmod, Head: doing\n",
      "Word: is, Deprel: cop, Head: drive\n",
      "Word: they, Deprel: nsubj, Head: drive\n",
      "Word: drive, Deprel: root, Head: ROOT\n",
      "Word: around, Deprel: advmod, Head: drive\n",
      "Word: in, Deprel: case, Head: cars\n",
      "Word: their, Deprel: nmod:poss, Head: cars\n",
      "Word: cars, Deprel: obl, Head: drive\n",
      "Word: while, Deprel: mark, Head: killed\n",
      "Word: people, Deprel: nsubj:pass, Head: killed\n",
      "Word: are, Deprel: aux, Head: killed\n",
      "Word: being, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: advcl, Head: drive\n",
      "Word: 500, Deprel: nummod, Head: metres\n",
      "Word: metres, Deprel: obl:npmod, Head: away\n",
      "Word: away, Deprel: advmod, Head: killed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'At Tuesday s arraignment hearing Marsh pleaded not guilty to 122 counts of burial service fraud and 47 counts of making false statements'\n",
      "Word: At, Deprel: case, Head: hearing\n",
      "Word: Tuesday, Deprel: nmod:poss, Head: hearing\n",
      "Word: s, Deprel: case, Head: Tuesday\n",
      "Word: arraignment, Deprel: compound, Head: hearing\n",
      "Word: hearing, Deprel: obl, Head: pleaded\n",
      "Word: Marsh, Deprel: nsubj, Head: pleaded\n",
      "Word: pleaded, Deprel: root, Head: ROOT\n",
      "Word: not, Deprel: advmod, Head: guilty\n",
      "Word: guilty, Deprel: obj, Head: pleaded\n",
      "Word: to, Deprel: case, Head: counts\n",
      "Word: 122, Deprel: nummod, Head: counts\n",
      "Word: counts, Deprel: obl, Head: pleaded\n",
      "Word: of, Deprel: case, Head: fraud\n",
      "Word: burial, Deprel: compound, Head: service\n",
      "Word: service, Deprel: compound, Head: fraud\n",
      "Word: fraud, Deprel: nmod, Head: counts\n",
      "Word: and, Deprel: cc, Head: counts\n",
      "Word: 47, Deprel: nummod, Head: counts\n",
      "Word: counts, Deprel: conj, Head: counts\n",
      "Word: of, Deprel: mark, Head: making\n",
      "Word: making, Deprel: acl, Head: counts\n",
      "Word: false, Deprel: amod, Head: statements\n",
      "Word: statements, Deprel: obj, Head: making\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'At the hearing he pleaded not guilty to the burial service fraud and false statements charges'\n",
      "Word: At, Deprel: case, Head: hearing\n",
      "Word: the, Deprel: det, Head: hearing\n",
      "Word: hearing, Deprel: obl, Head: pleaded\n",
      "Word: he, Deprel: nsubj, Head: pleaded\n",
      "Word: pleaded, Deprel: root, Head: ROOT\n",
      "Word: not, Deprel: advmod, Head: guilty\n",
      "Word: guilty, Deprel: obj, Head: pleaded\n",
      "Word: to, Deprel: case, Head: fraud\n",
      "Word: the, Deprel: det, Head: fraud\n",
      "Word: burial, Deprel: compound, Head: service\n",
      "Word: service, Deprel: compound, Head: fraud\n",
      "Word: fraud, Deprel: obl, Head: pleaded\n",
      "Word: and, Deprel: cc, Head: charges\n",
      "Word: false, Deprel: amod, Head: statements\n",
      "Word: statements, Deprel: compound, Head: charges\n",
      "Word: charges, Deprel: conj, Head: fraud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Still revenues from the extra premiums would not be huge'\n",
      "Word: Still, Deprel: advmod, Head: huge\n",
      "Word: revenues, Deprel: nsubj, Head: huge\n",
      "Word: from, Deprel: case, Head: premiums\n",
      "Word: the, Deprel: det, Head: premiums\n",
      "Word: extra, Deprel: amod, Head: premiums\n",
      "Word: premiums, Deprel: nmod, Head: revenues\n",
      "Word: would, Deprel: aux, Head: huge\n",
      "Word: not, Deprel: advmod, Head: huge\n",
      "Word: be, Deprel: cop, Head: huge\n",
      "Word: huge, Deprel: root, Head: ROOT\n",
      "\n",
      "Dependencies for Sentence: 'How would the extra premiums be collected'\n",
      "Word: How, Deprel: advmod, Head: collected\n",
      "Word: would, Deprel: aux, Head: collected\n",
      "Word: the, Deprel: det, Head: premiums\n",
      "Word: extra, Deprel: amod, Head: premiums\n",
      "Word: premiums, Deprel: nsubj:pass, Head: collected\n",
      "Word: be, Deprel: aux:pass, Head: collected\n",
      "Word: collected, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Pentagon had hoped to retain control of the postwar effort so the decision is a victory for Secretary of State Colin L Powell'\n",
      "Word: The, Deprel: det, Head: Pentagon\n",
      "Word: Pentagon, Deprel: nsubj, Head: hoped\n",
      "Word: had, Deprel: aux, Head: hoped\n",
      "Word: hoped, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: retain\n",
      "Word: retain, Deprel: xcomp, Head: hoped\n",
      "Word: control, Deprel: obj, Head: retain\n",
      "Word: of, Deprel: case, Head: effort\n",
      "Word: the, Deprel: det, Head: effort\n",
      "Word: postwar, Deprel: amod, Head: effort\n",
      "Word: effort, Deprel: nmod, Head: control\n",
      "Word: so, Deprel: mark, Head: victory\n",
      "Word: the, Deprel: det, Head: decision\n",
      "Word: decision, Deprel: nsubj, Head: victory\n",
      "Word: is, Deprel: cop, Head: victory\n",
      "Word: a, Deprel: det, Head: victory\n",
      "Word: victory, Deprel: advcl, Head: hoped\n",
      "Word: for, Deprel: case, Head: Colin\n",
      "Word: Secretary, Deprel: compound, Head: Colin\n",
      "Word: of, Deprel: case, Head: State\n",
      "Word: State, Deprel: nmod, Head: Secretary\n",
      "Word: Colin, Deprel: nmod, Head: victory\n",
      "Word: L, Deprel: flat, Head: Colin\n",
      "Word: Powell, Deprel: flat, Head: Colin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Pentagon had hoped to retain control of the postwar effort so the decision was seen by some insiders as a victory for Powell and the State Department'\n",
      "Word: The, Deprel: det, Head: Pentagon\n",
      "Word: Pentagon, Deprel: nsubj, Head: hoped\n",
      "Word: had, Deprel: aux, Head: hoped\n",
      "Word: hoped, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: retain\n",
      "Word: retain, Deprel: xcomp, Head: hoped\n",
      "Word: control, Deprel: obj, Head: retain\n",
      "Word: of, Deprel: case, Head: effort\n",
      "Word: the, Deprel: det, Head: effort\n",
      "Word: postwar, Deprel: amod, Head: effort\n",
      "Word: effort, Deprel: nmod, Head: control\n",
      "Word: so, Deprel: mark, Head: seen\n",
      "Word: the, Deprel: det, Head: decision\n",
      "Word: decision, Deprel: nsubj:pass, Head: seen\n",
      "Word: was, Deprel: aux:pass, Head: seen\n",
      "Word: seen, Deprel: advcl, Head: retain\n",
      "Word: by, Deprel: case, Head: insiders\n",
      "Word: some, Deprel: det, Head: insiders\n",
      "Word: insiders, Deprel: obl:agent, Head: seen\n",
      "Word: as, Deprel: case, Head: victory\n",
      "Word: a, Deprel: det, Head: victory\n",
      "Word: victory, Deprel: obl, Head: seen\n",
      "Word: for, Deprel: case, Head: Powell\n",
      "Word: Powell, Deprel: nmod, Head: victory\n",
      "Word: and, Deprel: cc, Head: Department\n",
      "Word: the, Deprel: det, Head: Department\n",
      "Word: State, Deprel: compound, Head: Department\n",
      "Word: Department, Deprel: conj, Head: Powell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Aiken s study appears in the Sept 24 issue of the Journal of the American Medical Association'\n",
      "Word: Aiken, Deprel: nmod:poss, Head: study\n",
      "Word: s, Deprel: case, Head: Aiken\n",
      "Word: study, Deprel: nsubj, Head: appears\n",
      "Word: appears, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: issue\n",
      "Word: the, Deprel: det, Head: issue\n",
      "Word: Sept, Deprel: compound, Head: issue\n",
      "Word: 24, Deprel: nummod, Head: Sept\n",
      "Word: issue, Deprel: obl, Head: appears\n",
      "Word: of, Deprel: case, Head: Journal\n",
      "Word: the, Deprel: det, Head: Journal\n",
      "Word: Journal, Deprel: nmod, Head: issue\n",
      "Word: of, Deprel: case, Head: Association\n",
      "Word: the, Deprel: det, Head: Association\n",
      "Word: American, Deprel: amod, Head: Association\n",
      "Word: Medical, Deprel: amod, Head: Association\n",
      "Word: Association, Deprel: nmod, Head: Journal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The findings appear in Wednesday s Journal of the American Medical Association'\n",
      "Word: The, Deprel: det, Head: findings\n",
      "Word: findings, Deprel: nsubj, Head: appear\n",
      "Word: appear, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: Journal\n",
      "Word: Wednesday, Deprel: nmod:poss, Head: Journal\n",
      "Word: s, Deprel: case, Head: Wednesday\n",
      "Word: Journal, Deprel: obl, Head: appear\n",
      "Word: of, Deprel: case, Head: Association\n",
      "Word: the, Deprel: det, Head: Association\n",
      "Word: American, Deprel: amod, Head: Association\n",
      "Word: Medical, Deprel: amod, Head: Association\n",
      "Word: Association, Deprel: nmod, Head: Journal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Semiconductor giant Intel Corp said yesterday that its second-quarter profits doubled from a year ago as stronger-than-expected demand for computer microprocessors offset the weakness of its communications chip business'\n",
      "Word: Semiconductor, Deprel: compound, Head: giant\n",
      "Word: giant, Deprel: compound, Head: Corp\n",
      "Word: Intel, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: yesterday, Deprel: obl:tmod, Head: said\n",
      "Word: that, Deprel: mark, Head: doubled\n",
      "Word: its, Deprel: nmod:poss, Head: profits\n",
      "Word: second-quarter, Deprel: amod, Head: profits\n",
      "Word: profits, Deprel: nsubj, Head: doubled\n",
      "Word: doubled, Deprel: ccomp, Head: said\n",
      "Word: from, Deprel: case, Head: ago\n",
      "Word: a, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:npmod, Head: ago\n",
      "Word: ago, Deprel: advmod, Head: doubled\n",
      "Word: as, Deprel: mark, Head: offset\n",
      "Word: stronger-than-expected, Deprel: amod, Head: demand\n",
      "Word: demand, Deprel: nsubj, Head: offset\n",
      "Word: for, Deprel: case, Head: microprocessors\n",
      "Word: computer, Deprel: compound, Head: microprocessors\n",
      "Word: microprocessors, Deprel: nmod, Head: demand\n",
      "Word: offset, Deprel: advcl, Head: doubled\n",
      "Word: the, Deprel: det, Head: weakness\n",
      "Word: weakness, Deprel: obj, Head: offset\n",
      "Word: of, Deprel: case, Head: business\n",
      "Word: its, Deprel: nmod:poss, Head: business\n",
      "Word: communications, Deprel: compound, Head: chip\n",
      "Word: chip, Deprel: compound, Head: business\n",
      "Word: business, Deprel: nmod, Head: weakness\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Intel Corp s second-quarter profits doubled and revenues grew 8 percent from a year ago as the chip-making giant reported stronger-than-expected demand for personal computer microprocessors'\n",
      "Word: Intel, Deprel: compound, Head: Corp\n",
      "Word: Corp, Deprel: nmod:poss, Head: profits\n",
      "Word: s, Deprel: case, Head: Corp\n",
      "Word: second-quarter, Deprel: amod, Head: profits\n",
      "Word: profits, Deprel: nsubj, Head: doubled\n",
      "Word: doubled, Deprel: root, Head: ROOT\n",
      "Word: and, Deprel: cc, Head: grew\n",
      "Word: revenues, Deprel: nsubj, Head: grew\n",
      "Word: grew, Deprel: conj, Head: doubled\n",
      "Word: 8, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: grew\n",
      "Word: from, Deprel: case, Head: year\n",
      "Word: a, Deprel: det, Head: year\n",
      "Word: year, Deprel: obl:npmod, Head: ago\n",
      "Word: ago, Deprel: advmod, Head: grew\n",
      "Word: as, Deprel: mark, Head: reported\n",
      "Word: the, Deprel: det, Head: giant\n",
      "Word: chip-making, Deprel: compound, Head: giant\n",
      "Word: giant, Deprel: nsubj, Head: reported\n",
      "Word: reported, Deprel: advcl, Head: grew\n",
      "Word: stronger-than-expected, Deprel: amod, Head: demand\n",
      "Word: demand, Deprel: obj, Head: reported\n",
      "Word: for, Deprel: case, Head: microprocessors\n",
      "Word: personal, Deprel: amod, Head: microprocessors\n",
      "Word: computer, Deprel: compound, Head: microprocessors\n",
      "Word: microprocessors, Deprel: nmod, Head: demand\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A Merrill Lynch spokesman said we are pleased with the judge s decision'\n",
      "Word: A, Deprel: det, Head: spokesman\n",
      "Word: Merrill, Deprel: compound, Head: spokesman\n",
      "Word: Lynch, Deprel: flat, Head: Merrill\n",
      "Word: spokesman, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: we, Deprel: nsubj, Head: pleased\n",
      "Word: are, Deprel: cop, Head: pleased\n",
      "Word: pleased, Deprel: ccomp, Head: said\n",
      "Word: with, Deprel: case, Head: decision\n",
      "Word: the, Deprel: det, Head: judge\n",
      "Word: judge, Deprel: nmod:poss, Head: decision\n",
      "Word: s, Deprel: case, Head: judge\n",
      "Word: decision, Deprel: obl, Head: pleased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'We are very pleased with the judge s decision Merrill said yesterday'\n",
      "Word: We, Deprel: nsubj, Head: pleased\n",
      "Word: are, Deprel: cop, Head: pleased\n",
      "Word: very, Deprel: advmod, Head: pleased\n",
      "Word: pleased, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: decision\n",
      "Word: the, Deprel: det, Head: judge\n",
      "Word: judge, Deprel: nmod:poss, Head: decision\n",
      "Word: s, Deprel: case, Head: judge\n",
      "Word: decision, Deprel: obl, Head: pleased\n",
      "Word: Merrill, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: decision\n",
      "Word: yesterday, Deprel: obl:tmod, Head: said\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Trans fats are created when hydrogen is added to vegetable oil solidifying it and increasing the shelf life of certain food products'\n",
      "Word: Trans, Deprel: amod, Head: fats\n",
      "Word: fats, Deprel: nsubj:pass, Head: created\n",
      "Word: are, Deprel: aux:pass, Head: created\n",
      "Word: created, Deprel: root, Head: ROOT\n",
      "Word: when, Deprel: advmod, Head: added\n",
      "Word: hydrogen, Deprel: nsubj:pass, Head: added\n",
      "Word: is, Deprel: aux:pass, Head: added\n",
      "Word: added, Deprel: advcl, Head: created\n",
      "Word: to, Deprel: case, Head: oil\n",
      "Word: vegetable, Deprel: compound, Head: oil\n",
      "Word: oil, Deprel: obl, Head: added\n",
      "Word: solidifying, Deprel: advcl, Head: added\n",
      "Word: it, Deprel: obj, Head: solidifying\n",
      "Word: and, Deprel: cc, Head: increasing\n",
      "Word: increasing, Deprel: conj, Head: solidifying\n",
      "Word: the, Deprel: det, Head: life\n",
      "Word: shelf, Deprel: compound, Head: life\n",
      "Word: life, Deprel: obj, Head: increasing\n",
      "Word: of, Deprel: case, Head: products\n",
      "Word: certain, Deprel: amod, Head: products\n",
      "Word: food, Deprel: compound, Head: products\n",
      "Word: products, Deprel: nmod, Head: life\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Trans fats are created when vegetable oil has been partially hydrogenated solidifying it and increasing the shelf life of certain products'\n",
      "Word: Trans, Deprel: amod, Head: fats\n",
      "Word: fats, Deprel: nsubj:pass, Head: created\n",
      "Word: are, Deprel: aux:pass, Head: created\n",
      "Word: created, Deprel: root, Head: ROOT\n",
      "Word: when, Deprel: advmod, Head: hydrogenated\n",
      "Word: vegetable, Deprel: compound, Head: oil\n",
      "Word: oil, Deprel: nsubj:pass, Head: hydrogenated\n",
      "Word: has, Deprel: aux, Head: hydrogenated\n",
      "Word: been, Deprel: aux:pass, Head: hydrogenated\n",
      "Word: partially, Deprel: advmod, Head: hydrogenated\n",
      "Word: hydrogenated, Deprel: advcl, Head: created\n",
      "Word: solidifying, Deprel: advcl, Head: hydrogenated\n",
      "Word: it, Deprel: obj, Head: solidifying\n",
      "Word: and, Deprel: cc, Head: increasing\n",
      "Word: increasing, Deprel: conj, Head: solidifying\n",
      "Word: the, Deprel: det, Head: life\n",
      "Word: shelf, Deprel: compound, Head: life\n",
      "Word: life, Deprel: obj, Head: increasing\n",
      "Word: of, Deprel: case, Head: products\n",
      "Word: certain, Deprel: amod, Head: products\n",
      "Word: products, Deprel: nmod, Head: life\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Schroeder cancelled his Italian holiday after Stefani refused to apologise for the slurs which came after Berlusconi compared a German politician to a Nazi concentration camp guard'\n",
      "Word: Schroeder, Deprel: nsubj, Head: cancelled\n",
      "Word: cancelled, Deprel: root, Head: ROOT\n",
      "Word: his, Deprel: nmod:poss, Head: holiday\n",
      "Word: Italian, Deprel: amod, Head: holiday\n",
      "Word: holiday, Deprel: obj, Head: cancelled\n",
      "Word: after, Deprel: mark, Head: refused\n",
      "Word: Stefani, Deprel: nsubj, Head: refused\n",
      "Word: refused, Deprel: advcl, Head: cancelled\n",
      "Word: to, Deprel: mark, Head: apologise\n",
      "Word: apologise, Deprel: xcomp, Head: refused\n",
      "Word: for, Deprel: case, Head: slurs\n",
      "Word: the, Deprel: det, Head: slurs\n",
      "Word: slurs, Deprel: obl, Head: apologise\n",
      "Word: which, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: acl:relcl, Head: slurs\n",
      "Word: after, Deprel: mark, Head: compared\n",
      "Word: Berlusconi, Deprel: nsubj, Head: compared\n",
      "Word: compared, Deprel: advcl, Head: came\n",
      "Word: a, Deprel: det, Head: politician\n",
      "Word: German, Deprel: amod, Head: politician\n",
      "Word: politician, Deprel: obj, Head: compared\n",
      "Word: to, Deprel: case, Head: guard\n",
      "Word: a, Deprel: det, Head: guard\n",
      "Word: Nazi, Deprel: amod, Head: guard\n",
      "Word: concentration, Deprel: compound, Head: camp\n",
      "Word: camp, Deprel: compound, Head: guard\n",
      "Word: guard, Deprel: obl, Head: compared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Stefani s remarks further stoked tension after Italian Prime Minister Silvio Berlusconi last week compared a German member of the European Parliament to a Nazi concentration camp guard'\n",
      "Word: Stefani, Deprel: nmod:poss, Head: remarks\n",
      "Word: s, Deprel: case, Head: Stefani\n",
      "Word: remarks, Deprel: nsubj, Head: stoked\n",
      "Word: further, Deprel: advmod, Head: stoked\n",
      "Word: stoked, Deprel: root, Head: ROOT\n",
      "Word: tension, Deprel: obj, Head: stoked\n",
      "Word: after, Deprel: mark, Head: compared\n",
      "Word: Italian, Deprel: amod, Head: Minister\n",
      "Word: Prime, Deprel: amod, Head: Minister\n",
      "Word: Minister, Deprel: nsubj, Head: compared\n",
      "Word: Silvio, Deprel: flat, Head: Minister\n",
      "Word: Berlusconi, Deprel: flat, Head: Minister\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: compared\n",
      "Word: compared, Deprel: advcl, Head: stoked\n",
      "Word: a, Deprel: det, Head: member\n",
      "Word: German, Deprel: amod, Head: member\n",
      "Word: member, Deprel: obj, Head: compared\n",
      "Word: of, Deprel: case, Head: Parliament\n",
      "Word: the, Deprel: det, Head: Parliament\n",
      "Word: European, Deprel: amod, Head: Parliament\n",
      "Word: Parliament, Deprel: nmod, Head: member\n",
      "Word: to, Deprel: case, Head: guard\n",
      "Word: a, Deprel: det, Head: guard\n",
      "Word: Nazi, Deprel: amod, Head: guard\n",
      "Word: concentration, Deprel: compound, Head: camp\n",
      "Word: camp, Deprel: compound, Head: guard\n",
      "Word: guard, Deprel: obl, Head: compared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Dell s OpenManage software includes Dell Update Packages with SMS to help automate the management of server hardware applications and operating systems patches with a single tool'\n",
      "Word: Dell, Deprel: nmod:poss, Head: software\n",
      "Word: s, Deprel: case, Head: Dell\n",
      "Word: OpenManage, Deprel: compound, Head: software\n",
      "Word: software, Deprel: nsubj, Head: includes\n",
      "Word: includes, Deprel: root, Head: ROOT\n",
      "Word: Dell, Deprel: compound, Head: Packages\n",
      "Word: Update, Deprel: compound, Head: Packages\n",
      "Word: Packages, Deprel: obj, Head: includes\n",
      "Word: with, Deprel: case, Head: SMS\n",
      "Word: SMS, Deprel: nmod, Head: Packages\n",
      "Word: to, Deprel: mark, Head: help\n",
      "Word: help, Deprel: advcl, Head: includes\n",
      "Word: automate, Deprel: xcomp, Head: help\n",
      "Word: the, Deprel: det, Head: management\n",
      "Word: management, Deprel: obj, Head: automate\n",
      "Word: of, Deprel: case, Head: applications\n",
      "Word: server, Deprel: compound, Head: hardware\n",
      "Word: hardware, Deprel: compound, Head: applications\n",
      "Word: applications, Deprel: nmod, Head: management\n",
      "Word: and, Deprel: cc, Head: patches\n",
      "Word: operating, Deprel: compound, Head: systems\n",
      "Word: systems, Deprel: compound, Head: patches\n",
      "Word: patches, Deprel: conj, Head: applications\n",
      "Word: with, Deprel: case, Head: tool\n",
      "Word: a, Deprel: det, Head: tool\n",
      "Word: single, Deprel: amod, Head: tool\n",
      "Word: tool, Deprel: obl, Head: automate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The update packages help automate the management of server hardware applications and operating systems patches using one tool which is unpleasantly vague'\n",
      "Word: The, Deprel: det, Head: packages\n",
      "Word: update, Deprel: compound, Head: packages\n",
      "Word: packages, Deprel: nsubj, Head: help\n",
      "Word: help, Deprel: root, Head: ROOT\n",
      "Word: automate, Deprel: xcomp, Head: help\n",
      "Word: the, Deprel: det, Head: management\n",
      "Word: management, Deprel: obj, Head: automate\n",
      "Word: of, Deprel: case, Head: applications\n",
      "Word: server, Deprel: compound, Head: hardware\n",
      "Word: hardware, Deprel: compound, Head: applications\n",
      "Word: applications, Deprel: nmod, Head: management\n",
      "Word: and, Deprel: cc, Head: patches\n",
      "Word: operating, Deprel: compound, Head: systems\n",
      "Word: systems, Deprel: compound, Head: patches\n",
      "Word: patches, Deprel: conj, Head: applications\n",
      "Word: using, Deprel: advcl, Head: automate\n",
      "Word: one, Deprel: nummod, Head: tool\n",
      "Word: tool, Deprel: obj, Head: using\n",
      "Word: which, Deprel: nsubj, Head: vague\n",
      "Word: is, Deprel: cop, Head: vague\n",
      "Word: unpleasantly, Deprel: advmod, Head: vague\n",
      "Word: vague, Deprel: acl:relcl, Head: tool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'He ll be swept over any minute or just die of the cold Moriarty thought'\n",
      "Word: He, Deprel: nsubj:pass, Head: swept\n",
      "Word: ll, Deprel: aux, Head: swept\n",
      "Word: be, Deprel: aux:pass, Head: swept\n",
      "Word: swept, Deprel: root, Head: ROOT\n",
      "Word: over, Deprel: case, Head: minute\n",
      "Word: any, Deprel: det, Head: minute\n",
      "Word: minute, Deprel: obl, Head: swept\n",
      "Word: or, Deprel: cc, Head: die\n",
      "Word: just, Deprel: advmod, Head: die\n",
      "Word: die, Deprel: conj, Head: swept\n",
      "Word: of, Deprel: case, Head: cold\n",
      "Word: the, Deprel: det, Head: cold\n",
      "Word: cold, Deprel: obl, Head: die\n",
      "Word: Moriarty, Deprel: nsubj, Head: thought\n",
      "Word: thought, Deprel: parataxis, Head: swept\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'From the top of the embankment Moriarty thought He ll be swept over any minute or just die of the cold'\n",
      "Word: From, Deprel: case, Head: top\n",
      "Word: the, Deprel: det, Head: top\n",
      "Word: top, Deprel: obl, Head: thought\n",
      "Word: of, Deprel: case, Head: embankment\n",
      "Word: the, Deprel: det, Head: embankment\n",
      "Word: embankment, Deprel: nmod, Head: top\n",
      "Word: Moriarty, Deprel: nsubj, Head: thought\n",
      "Word: thought, Deprel: root, Head: ROOT\n",
      "Word: He, Deprel: nsubj:pass, Head: swept\n",
      "Word: ll, Deprel: aux, Head: swept\n",
      "Word: be, Deprel: aux:pass, Head: swept\n",
      "Word: swept, Deprel: ccomp, Head: thought\n",
      "Word: over, Deprel: case, Head: minute\n",
      "Word: any, Deprel: det, Head: minute\n",
      "Word: minute, Deprel: obl:tmod, Head: swept\n",
      "Word: or, Deprel: cc, Head: die\n",
      "Word: just, Deprel: advmod, Head: die\n",
      "Word: die, Deprel: conj, Head: swept\n",
      "Word: of, Deprel: case, Head: cold\n",
      "Word: the, Deprel: det, Head: cold\n",
      "Word: cold, Deprel: obl, Head: die\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'LURD s Ja'neh also called for an interim government and the deployment of a U.S.-led Western peacekeeping force'\n",
      "Word: LURD, Deprel: nmod:poss, Head: Ja'neh\n",
      "Word: s, Deprel: case, Head: LURD\n",
      "Word: Ja'neh, Deprel: nsubj, Head: called\n",
      "Word: also, Deprel: advmod, Head: called\n",
      "Word: called, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: government\n",
      "Word: an, Deprel: det, Head: government\n",
      "Word: interim, Deprel: amod, Head: government\n",
      "Word: government, Deprel: obl, Head: called\n",
      "Word: and, Deprel: cc, Head: deployment\n",
      "Word: the, Deprel: det, Head: deployment\n",
      "Word: deployment, Deprel: conj, Head: government\n",
      "Word: of, Deprel: case, Head: force\n",
      "Word: a, Deprel: det, Head: force\n",
      "Word: U.S.-led, Deprel: amod, Head: force\n",
      "Word: Western, Deprel: amod, Head: force\n",
      "Word: peacekeeping, Deprel: compound, Head: force\n",
      "Word: force, Deprel: nmod, Head: deployment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The rebels are also calling for the deployment of a U.S.-led peacekeeping force'\n",
      "Word: The, Deprel: det, Head: rebels\n",
      "Word: rebels, Deprel: nsubj, Head: calling\n",
      "Word: are, Deprel: aux, Head: calling\n",
      "Word: also, Deprel: advmod, Head: calling\n",
      "Word: calling, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: deployment\n",
      "Word: the, Deprel: det, Head: deployment\n",
      "Word: deployment, Deprel: obl, Head: calling\n",
      "Word: of, Deprel: case, Head: force\n",
      "Word: a, Deprel: det, Head: force\n",
      "Word: U.S.-led, Deprel: amod, Head: force\n",
      "Word: peacekeeping, Deprel: compound, Head: force\n",
      "Word: force, Deprel: nmod, Head: deployment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'KEDO Spokesman Roland Tricot said The executive board decided to refer this question to capitals'\n",
      "Word: KEDO, Deprel: compound, Head: Spokesman\n",
      "Word: Spokesman, Deprel: compound, Head: Roland\n",
      "Word: Roland, Deprel: nsubj, Head: said\n",
      "Word: Tricot, Deprel: flat, Head: Roland\n",
      "Word: said, Deprel: root, Head: ROOT\n",
      "Word: The, Deprel: det, Head: board\n",
      "Word: executive, Deprel: amod, Head: board\n",
      "Word: board, Deprel: nsubj, Head: decided\n",
      "Word: decided, Deprel: ccomp, Head: said\n",
      "Word: to, Deprel: mark, Head: refer\n",
      "Word: refer, Deprel: xcomp, Head: decided\n",
      "Word: this, Deprel: det, Head: question\n",
      "Word: question, Deprel: obj, Head: refer\n",
      "Word: to, Deprel: case, Head: capitals\n",
      "Word: capitals, Deprel: obl, Head: refer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The executive board decided to refer this to the capitals the Korean Energy Development Organization said'\n",
      "Word: The, Deprel: det, Head: board\n",
      "Word: executive, Deprel: amod, Head: board\n",
      "Word: board, Deprel: nsubj, Head: decided\n",
      "Word: decided, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: refer\n",
      "Word: refer, Deprel: xcomp, Head: decided\n",
      "Word: this, Deprel: obj, Head: refer\n",
      "Word: to, Deprel: case, Head: capitals\n",
      "Word: the, Deprel: det, Head: capitals\n",
      "Word: capitals, Deprel: obl, Head: refer\n",
      "Word: the, Deprel: det, Head: Organization\n",
      "Word: Korean, Deprel: amod, Head: Organization\n",
      "Word: Energy, Deprel: compound, Head: Organization\n",
      "Word: Development, Deprel: compound, Head: Organization\n",
      "Word: Organization, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: capitals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But skeptics are concerned about the ease with which vendors can use these hardware-based security features to set digital rights management policies'\n",
      "Word: But, Deprel: cc, Head: concerned\n",
      "Word: skeptics, Deprel: nsubj, Head: concerned\n",
      "Word: are, Deprel: cop, Head: concerned\n",
      "Word: concerned, Deprel: root, Head: ROOT\n",
      "Word: about, Deprel: case, Head: ease\n",
      "Word: the, Deprel: det, Head: ease\n",
      "Word: ease, Deprel: obl, Head: concerned\n",
      "Word: with, Deprel: case, Head: which\n",
      "Word: which, Deprel: obl, Head: use\n",
      "Word: vendors, Deprel: nsubj, Head: use\n",
      "Word: can, Deprel: aux, Head: use\n",
      "Word: use, Deprel: acl:relcl, Head: ease\n",
      "Word: these, Deprel: det, Head: features\n",
      "Word: hardware-based, Deprel: amod, Head: features\n",
      "Word: security, Deprel: compound, Head: features\n",
      "Word: features, Deprel: obj, Head: use\n",
      "Word: to, Deprel: mark, Head: set\n",
      "Word: set, Deprel: advcl, Head: use\n",
      "Word: digital, Deprel: amod, Head: rights\n",
      "Word: rights, Deprel: compound, Head: management\n",
      "Word: management, Deprel: compound, Head: policies\n",
      "Word: policies, Deprel: obj, Head: set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'But skeptics are concerned about the ease at which these hardware-based security features could be used to set digital rights management policies by vendors'\n",
      "Word: But, Deprel: cc, Head: concerned\n",
      "Word: skeptics, Deprel: nsubj, Head: concerned\n",
      "Word: are, Deprel: cop, Head: concerned\n",
      "Word: concerned, Deprel: root, Head: ROOT\n",
      "Word: about, Deprel: case, Head: ease\n",
      "Word: the, Deprel: det, Head: ease\n",
      "Word: ease, Deprel: obl, Head: concerned\n",
      "Word: at, Deprel: case, Head: which\n",
      "Word: which, Deprel: obl, Head: used\n",
      "Word: these, Deprel: det, Head: features\n",
      "Word: hardware-based, Deprel: amod, Head: features\n",
      "Word: security, Deprel: compound, Head: features\n",
      "Word: features, Deprel: nsubj:pass, Head: used\n",
      "Word: could, Deprel: aux, Head: used\n",
      "Word: be, Deprel: aux:pass, Head: used\n",
      "Word: used, Deprel: acl:relcl, Head: ease\n",
      "Word: to, Deprel: mark, Head: set\n",
      "Word: set, Deprel: advcl, Head: used\n",
      "Word: digital, Deprel: amod, Head: rights\n",
      "Word: rights, Deprel: compound, Head: management\n",
      "Word: management, Deprel: compound, Head: policies\n",
      "Word: policies, Deprel: obj, Head: set\n",
      "Word: by, Deprel: case, Head: vendors\n",
      "Word: vendors, Deprel: obl, Head: set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Prof Sally Baldwin 63 from York fell into a cavity which opened up when the structure collapsed at Tiburtina station Italian railway officials said'\n",
      "Word: Prof, Deprel: nsubj, Head: fell\n",
      "Word: Sally, Deprel: flat, Head: Prof\n",
      "Word: Baldwin, Deprel: flat, Head: Prof\n",
      "Word: 63, Deprel: amod, Head: Prof\n",
      "Word: from, Deprel: case, Head: York\n",
      "Word: York, Deprel: nmod, Head: Prof\n",
      "Word: fell, Deprel: root, Head: ROOT\n",
      "Word: into, Deprel: case, Head: cavity\n",
      "Word: a, Deprel: det, Head: cavity\n",
      "Word: cavity, Deprel: obl, Head: fell\n",
      "Word: which, Deprel: nsubj, Head: opened\n",
      "Word: opened, Deprel: acl:relcl, Head: cavity\n",
      "Word: up, Deprel: compound:prt, Head: opened\n",
      "Word: when, Deprel: advmod, Head: collapsed\n",
      "Word: the, Deprel: det, Head: structure\n",
      "Word: structure, Deprel: nsubj, Head: collapsed\n",
      "Word: collapsed, Deprel: advcl, Head: opened\n",
      "Word: at, Deprel: case, Head: station\n",
      "Word: Tiburtina, Deprel: compound, Head: station\n",
      "Word: station, Deprel: obl, Head: collapsed\n",
      "Word: Italian, Deprel: amod, Head: officials\n",
      "Word: railway, Deprel: compound, Head: officials\n",
      "Word: officials, Deprel: nsubj, Head: said\n",
      "Word: said, Deprel: acl:relcl, Head: station\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Sally Baldwin from York was killed instantly when a walkway collapsed and she fell into the machinery at Tiburtina station'\n",
      "Word: Sally, Deprel: nsubj:pass, Head: killed\n",
      "Word: Baldwin, Deprel: flat, Head: Sally\n",
      "Word: from, Deprel: case, Head: York\n",
      "Word: York, Deprel: nmod, Head: Sally\n",
      "Word: was, Deprel: aux:pass, Head: killed\n",
      "Word: killed, Deprel: root, Head: ROOT\n",
      "Word: instantly, Deprel: advmod, Head: killed\n",
      "Word: when, Deprel: advmod, Head: collapsed\n",
      "Word: a, Deprel: det, Head: walkway\n",
      "Word: walkway, Deprel: nsubj, Head: collapsed\n",
      "Word: collapsed, Deprel: advcl, Head: killed\n",
      "Word: and, Deprel: cc, Head: fell\n",
      "Word: she, Deprel: nsubj, Head: fell\n",
      "Word: fell, Deprel: conj, Head: killed\n",
      "Word: into, Deprel: case, Head: machinery\n",
      "Word: the, Deprel: det, Head: machinery\n",
      "Word: machinery, Deprel: obl, Head: fell\n",
      "Word: at, Deprel: case, Head: station\n",
      "Word: Tiburtina, Deprel: compound, Head: station\n",
      "Word: station, Deprel: obl, Head: fell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It calls for the agency to plan an independent safety and engineering organization'\n",
      "Word: It, Deprel: nsubj, Head: calls\n",
      "Word: calls, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: mark, Head: plan\n",
      "Word: the, Deprel: det, Head: agency\n",
      "Word: agency, Deprel: nsubj, Head: plan\n",
      "Word: to, Deprel: mark, Head: plan\n",
      "Word: plan, Deprel: csubj, Head: calls\n",
      "Word: an, Deprel: det, Head: organization\n",
      "Word: independent, Deprel: amod, Head: organization\n",
      "Word: safety, Deprel: compound, Head: organization\n",
      "Word: and, Deprel: cc, Head: engineering\n",
      "Word: engineering, Deprel: conj, Head: safety\n",
      "Word: organization, Deprel: obj, Head: plan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The agency has yet to fully formulate a strategy for the creation of an independent engineering technical authority'\n",
      "Word: The, Deprel: det, Head: agency\n",
      "Word: agency, Deprel: nsubj, Head: has\n",
      "Word: has, Deprel: root, Head: ROOT\n",
      "Word: yet, Deprel: advmod, Head: has\n",
      "Word: to, Deprel: mark, Head: formulate\n",
      "Word: fully, Deprel: advmod, Head: formulate\n",
      "Word: formulate, Deprel: xcomp, Head: has\n",
      "Word: a, Deprel: det, Head: strategy\n",
      "Word: strategy, Deprel: obj, Head: formulate\n",
      "Word: for, Deprel: case, Head: creation\n",
      "Word: the, Deprel: det, Head: creation\n",
      "Word: creation, Deprel: nmod, Head: strategy\n",
      "Word: of, Deprel: case, Head: authority\n",
      "Word: an, Deprel: det, Head: authority\n",
      "Word: independent, Deprel: amod, Head: authority\n",
      "Word: engineering, Deprel: compound, Head: authority\n",
      "Word: technical, Deprel: amod, Head: authority\n",
      "Word: authority, Deprel: nmod, Head: creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'WorldCom s accounting problems came to light early last year and the company filed for bankruptcy in July 2002 citing massive accounting irregularities'\n",
      "Word: WorldCom, Deprel: nmod:poss, Head: problems\n",
      "Word: s, Deprel: case, Head: WorldCom\n",
      "Word: accounting, Deprel: compound, Head: problems\n",
      "Word: problems, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: light\n",
      "Word: light, Deprel: obl, Head: came\n",
      "Word: early, Deprel: advmod, Head: year\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: came\n",
      "Word: and, Deprel: cc, Head: filed\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: filed\n",
      "Word: filed, Deprel: conj, Head: came\n",
      "Word: for, Deprel: case, Head: bankruptcy\n",
      "Word: bankruptcy, Deprel: obl, Head: filed\n",
      "Word: in, Deprel: case, Head: July\n",
      "Word: July, Deprel: obl, Head: filed\n",
      "Word: 2002, Deprel: nummod, Head: July\n",
      "Word: citing, Deprel: advcl, Head: filed\n",
      "Word: massive, Deprel: amod, Head: irregularities\n",
      "Word: accounting, Deprel: compound, Head: irregularities\n",
      "Word: irregularities, Deprel: obj, Head: citing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'WorldCom s financial troubles came to light last year and the company subsequently filed for bankruptcy in July 2002'\n",
      "Word: WorldCom, Deprel: nmod:poss, Head: troubles\n",
      "Word: s, Deprel: case, Head: WorldCom\n",
      "Word: financial, Deprel: amod, Head: troubles\n",
      "Word: troubles, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: light\n",
      "Word: light, Deprel: obl, Head: came\n",
      "Word: last, Deprel: amod, Head: year\n",
      "Word: year, Deprel: obl:tmod, Head: came\n",
      "Word: and, Deprel: cc, Head: filed\n",
      "Word: the, Deprel: det, Head: company\n",
      "Word: company, Deprel: nsubj, Head: filed\n",
      "Word: subsequently, Deprel: advmod, Head: filed\n",
      "Word: filed, Deprel: conj, Head: came\n",
      "Word: for, Deprel: case, Head: bankruptcy\n",
      "Word: bankruptcy, Deprel: obl, Head: filed\n",
      "Word: in, Deprel: case, Head: July\n",
      "Word: July, Deprel: obl, Head: filed\n",
      "Word: 2002, Deprel: nummod, Head: July\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Benchmark Treasury 10-year notes gained 17/32 yielding 4.015 percent'\n",
      "Word: Benchmark, Deprel: compound, Head: notes\n",
      "Word: Treasury, Deprel: compound, Head: 10-year\n",
      "Word: 10-year, Deprel: compound, Head: notes\n",
      "Word: notes, Deprel: nsubj, Head: gained\n",
      "Word: gained, Deprel: root, Head: ROOT\n",
      "Word: 17/32, Deprel: nsubj, Head: yielding\n",
      "Word: yielding, Deprel: advcl, Head: gained\n",
      "Word: 4.015, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: yielding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The benchmark 10-year note was recently down 17/32 to yield 4.067 percent'\n",
      "Word: The, Deprel: det, Head: note\n",
      "Word: benchmark, Deprel: compound, Head: note\n",
      "Word: 10-year, Deprel: amod, Head: note\n",
      "Word: note, Deprel: nsubj, Head: down\n",
      "Word: was, Deprel: cop, Head: down\n",
      "Word: recently, Deprel: advmod, Head: down\n",
      "Word: down, Deprel: root, Head: ROOT\n",
      "Word: 17/32, Deprel: obl:npmod, Head: down\n",
      "Word: to, Deprel: case, Head: yield\n",
      "Word: yield, Deprel: nmod, Head: 17/32\n",
      "Word: 4.067, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl:tmod, Head: down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Prosecutors did an about-face in May and asked that the autopsy reports be unsealed after portions of Conner Peterson s autopsy report favorable to the defense were leaked to the media'\n",
      "Word: Prosecutors, Deprel: nsubj, Head: did\n",
      "Word: did, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: about-face\n",
      "Word: about-face, Deprel: obj, Head: did\n",
      "Word: in, Deprel: case, Head: May\n",
      "Word: May, Deprel: obl, Head: did\n",
      "Word: and, Deprel: cc, Head: asked\n",
      "Word: asked, Deprel: conj, Head: did\n",
      "Word: that, Deprel: mark, Head: unsealed\n",
      "Word: the, Deprel: det, Head: reports\n",
      "Word: autopsy, Deprel: compound, Head: reports\n",
      "Word: reports, Deprel: nsubj:pass, Head: unsealed\n",
      "Word: be, Deprel: aux:pass, Head: unsealed\n",
      "Word: unsealed, Deprel: ccomp, Head: asked\n",
      "Word: after, Deprel: mark, Head: leaked\n",
      "Word: portions, Deprel: nsubj, Head: leaked\n",
      "Word: of, Deprel: case, Head: report\n",
      "Word: Conner, Deprel: nmod:poss, Head: report\n",
      "Word: Peterson, Deprel: flat, Head: Conner\n",
      "Word: s, Deprel: case, Head: Conner\n",
      "Word: autopsy, Deprel: compound, Head: report\n",
      "Word: report, Deprel: nmod, Head: portions\n",
      "Word: favorable, Deprel: amod, Head: report\n",
      "Word: to, Deprel: case, Head: defense\n",
      "Word: the, Deprel: det, Head: defense\n",
      "Word: defense, Deprel: obl, Head: favorable\n",
      "Word: were, Deprel: aux:pass, Head: leaked\n",
      "Word: leaked, Deprel: advcl, Head: unsealed\n",
      "Word: to, Deprel: case, Head: media\n",
      "Word: the, Deprel: det, Head: media\n",
      "Word: media, Deprel: obl, Head: leaked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'They asked that the autopsy reports be unsealed after portions of the autopsy report on Peterson s unborn son that were favorable to the defense were leaked to the media'\n",
      "Word: They, Deprel: nsubj, Head: asked\n",
      "Word: asked, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: unsealed\n",
      "Word: the, Deprel: det, Head: reports\n",
      "Word: autopsy, Deprel: compound, Head: reports\n",
      "Word: reports, Deprel: nsubj:pass, Head: unsealed\n",
      "Word: be, Deprel: aux:pass, Head: unsealed\n",
      "Word: unsealed, Deprel: ccomp, Head: asked\n",
      "Word: after, Deprel: case, Head: portions\n",
      "Word: portions, Deprel: obl, Head: unsealed\n",
      "Word: of, Deprel: case, Head: report\n",
      "Word: the, Deprel: det, Head: report\n",
      "Word: autopsy, Deprel: compound, Head: report\n",
      "Word: report, Deprel: nmod, Head: portions\n",
      "Word: on, Deprel: case, Head: son\n",
      "Word: Peterson, Deprel: nmod:poss, Head: son\n",
      "Word: s, Deprel: case, Head: Peterson\n",
      "Word: unborn, Deprel: amod, Head: son\n",
      "Word: son, Deprel: nmod, Head: report\n",
      "Word: that, Deprel: nsubj, Head: favorable\n",
      "Word: were, Deprel: cop, Head: favorable\n",
      "Word: favorable, Deprel: acl:relcl, Head: son\n",
      "Word: to, Deprel: case, Head: defense\n",
      "Word: the, Deprel: det, Head: defense\n",
      "Word: defense, Deprel: obl, Head: favorable\n",
      "Word: were, Deprel: cop, Head: leaked\n",
      "Word: leaked, Deprel: ccomp, Head: asked\n",
      "Word: to, Deprel: case, Head: media\n",
      "Word: the, Deprel: det, Head: media\n",
      "Word: media, Deprel: obl, Head: leaked\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Volume was moderate at 827.68 million shares up from 798.95 million at the same point Tuesday'\n",
      "Word: Volume, Deprel: nsubj, Head: moderate\n",
      "Word: was, Deprel: cop, Head: moderate\n",
      "Word: moderate, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: shares\n",
      "Word: 827.68, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: shares\n",
      "Word: shares, Deprel: obl, Head: moderate\n",
      "Word: up, Deprel: advmod, Head: moderate\n",
      "Word: from, Deprel: case, Head: million\n",
      "Word: 798.95, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obl, Head: moderate\n",
      "Word: at, Deprel: case, Head: point\n",
      "Word: the, Deprel: det, Head: point\n",
      "Word: same, Deprel: amod, Head: point\n",
      "Word: point, Deprel: obl, Head: moderate\n",
      "Word: Tuesday, Deprel: nmod:npmod, Head: point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Volume came to 439.66 million shares below 450.39 million at the same point Wednesday'\n",
      "Word: Volume, Deprel: nsubj, Head: came\n",
      "Word: came, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: shares\n",
      "Word: 439.66, Deprel: compound, Head: million\n",
      "Word: million, Deprel: nummod, Head: shares\n",
      "Word: shares, Deprel: obl, Head: came\n",
      "Word: below, Deprel: case, Head: million\n",
      "Word: 450.39, Deprel: compound, Head: million\n",
      "Word: million, Deprel: obl, Head: came\n",
      "Word: at, Deprel: case, Head: point\n",
      "Word: the, Deprel: det, Head: point\n",
      "Word: same, Deprel: amod, Head: point\n",
      "Word: point, Deprel: obl, Head: came\n",
      "Word: Wednesday, Deprel: obl, Head: came\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Penn Traffic s stock closed at 36 cents per share on Wednesday on Nasdaq up two cents'\n",
      "Word: Penn, Deprel: compound, Head: Traffic\n",
      "Word: Traffic, Deprel: nmod:poss, Head: stock\n",
      "Word: s, Deprel: case, Head: Traffic\n",
      "Word: stock, Deprel: nsubj, Head: closed\n",
      "Word: closed, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: cents\n",
      "Word: 36, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl, Head: closed\n",
      "Word: per, Deprel: case, Head: share\n",
      "Word: share, Deprel: nmod, Head: cents\n",
      "Word: on, Deprel: case, Head: Wednesday\n",
      "Word: Wednesday, Deprel: obl, Head: closed\n",
      "Word: on, Deprel: case, Head: Nasdaq\n",
      "Word: Nasdaq, Deprel: obl, Head: closed\n",
      "Word: up, Deprel: advcl, Head: closed\n",
      "Word: two, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl, Head: closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Penn Traffic stock closed Wednesday at 36 cents up 2 cents or 6.2 percent from Tuesday s close'\n",
      "Word: Penn, Deprel: compound, Head: Traffic\n",
      "Word: Traffic, Deprel: compound, Head: stock\n",
      "Word: stock, Deprel: nsubj, Head: closed\n",
      "Word: closed, Deprel: root, Head: ROOT\n",
      "Word: Wednesday, Deprel: obl:tmod, Head: closed\n",
      "Word: at, Deprel: case, Head: cents\n",
      "Word: 36, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl, Head: closed\n",
      "Word: up, Deprel: advmod, Head: cents\n",
      "Word: 2, Deprel: nummod, Head: cents\n",
      "Word: cents, Deprel: obl:tmod, Head: up\n",
      "Word: or, Deprel: cc, Head: percent\n",
      "Word: 6.2, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: conj, Head: cents\n",
      "Word: from, Deprel: case, Head: close\n",
      "Word: Tuesday, Deprel: nmod:poss, Head: close\n",
      "Word: s, Deprel: case, Head: Tuesday\n",
      "Word: close, Deprel: obl, Head: up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hotly contested legislation that would change the state s takeover law and help a Michigan-based development company fend off a takeover cleared the state Senate on Thursday'\n",
      "Word: Hotly, Deprel: advmod, Head: contested\n",
      "Word: contested, Deprel: amod, Head: legislation\n",
      "Word: legislation, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: nsubj, Head: change\n",
      "Word: would, Deprel: aux, Head: change\n",
      "Word: change, Deprel: acl:relcl, Head: legislation\n",
      "Word: the, Deprel: det, Head: state\n",
      "Word: state, Deprel: nmod:poss, Head: law\n",
      "Word: s, Deprel: case, Head: state\n",
      "Word: takeover, Deprel: compound, Head: law\n",
      "Word: law, Deprel: obj, Head: change\n",
      "Word: and, Deprel: cc, Head: help\n",
      "Word: help, Deprel: conj, Head: change\n",
      "Word: a, Deprel: det, Head: company\n",
      "Word: Michigan-based, Deprel: amod, Head: company\n",
      "Word: development, Deprel: compound, Head: company\n",
      "Word: company, Deprel: obj, Head: help\n",
      "Word: fend, Deprel: xcomp, Head: help\n",
      "Word: off, Deprel: compound:prt, Head: fend\n",
      "Word: a, Deprel: det, Head: takeover\n",
      "Word: takeover, Deprel: obj, Head: fend\n",
      "Word: cleared, Deprel: acl, Head: takeover\n",
      "Word: the, Deprel: det, Head: Senate\n",
      "Word: state, Deprel: compound, Head: Senate\n",
      "Word: Senate, Deprel: obj, Head: cleared\n",
      "Word: on, Deprel: case, Head: Thursday\n",
      "Word: Thursday, Deprel: obl, Head: cleared\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Legislation that would change state takeover law and help Bloomfield Hills-based Taubman Centers Inc fend off a 1-billion takeover won committee approval Tuesday'\n",
      "Word: Legislation, Deprel: nsubj, Head: fend\n",
      "Word: that, Deprel: nsubj, Head: change\n",
      "Word: would, Deprel: aux, Head: change\n",
      "Word: change, Deprel: acl:relcl, Head: Legislation\n",
      "Word: state, Deprel: compound, Head: law\n",
      "Word: takeover, Deprel: compound, Head: law\n",
      "Word: law, Deprel: obj, Head: change\n",
      "Word: and, Deprel: cc, Head: help\n",
      "Word: help, Deprel: conj, Head: change\n",
      "Word: Bloomfield, Deprel: compound, Head: Hills-based\n",
      "Word: Hills-based, Deprel: compound, Head: Inc\n",
      "Word: Taubman, Deprel: compound, Head: Centers\n",
      "Word: Centers, Deprel: compound, Head: Inc\n",
      "Word: Inc, Deprel: obj, Head: help\n",
      "Word: fend, Deprel: root, Head: ROOT\n",
      "Word: off, Deprel: compound:prt, Head: fend\n",
      "Word: a, Deprel: det, Head: approval\n",
      "Word: 1-billion, Deprel: nummod, Head: takeover\n",
      "Word: takeover, Deprel: compound, Head: won\n",
      "Word: won, Deprel: amod, Head: approval\n",
      "Word: committee, Deprel: compound, Head: approval\n",
      "Word: approval, Deprel: obj, Head: fend\n",
      "Word: Tuesday, Deprel: obl:tmod, Head: fend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'However other unions including the powerful CGT remained opposed to the reform and demanded the government begin fresh negotiations with them'\n",
      "Word: However, Deprel: advmod, Head: remained\n",
      "Word: other, Deprel: amod, Head: unions\n",
      "Word: unions, Deprel: nsubj, Head: remained\n",
      "Word: including, Deprel: case, Head: CGT\n",
      "Word: the, Deprel: det, Head: CGT\n",
      "Word: powerful, Deprel: amod, Head: CGT\n",
      "Word: CGT, Deprel: nmod, Head: unions\n",
      "Word: remained, Deprel: root, Head: ROOT\n",
      "Word: opposed, Deprel: xcomp, Head: remained\n",
      "Word: to, Deprel: case, Head: reform\n",
      "Word: the, Deprel: det, Head: reform\n",
      "Word: reform, Deprel: obl, Head: opposed\n",
      "Word: and, Deprel: cc, Head: demanded\n",
      "Word: demanded, Deprel: conj, Head: remained\n",
      "Word: the, Deprel: det, Head: government\n",
      "Word: government, Deprel: obj, Head: demanded\n",
      "Word: begin, Deprel: xcomp, Head: demanded\n",
      "Word: fresh, Deprel: amod, Head: negotiations\n",
      "Word: negotiations, Deprel: obj, Head: begin\n",
      "Word: with, Deprel: case, Head: them\n",
      "Word: them, Deprel: nmod, Head: negotiations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The powerful CGT and other unions remained opposed to the plans however and demanded the government renegotiate the reform with them'\n",
      "Word: The, Deprel: det, Head: CGT\n",
      "Word: powerful, Deprel: amod, Head: CGT\n",
      "Word: CGT, Deprel: nsubj, Head: remained\n",
      "Word: and, Deprel: cc, Head: unions\n",
      "Word: other, Deprel: amod, Head: unions\n",
      "Word: unions, Deprel: conj, Head: CGT\n",
      "Word: remained, Deprel: root, Head: ROOT\n",
      "Word: opposed, Deprel: xcomp, Head: remained\n",
      "Word: to, Deprel: case, Head: plans\n",
      "Word: the, Deprel: det, Head: plans\n",
      "Word: plans, Deprel: obl, Head: opposed\n",
      "Word: however, Deprel: advmod, Head: opposed\n",
      "Word: and, Deprel: cc, Head: demanded\n",
      "Word: demanded, Deprel: conj, Head: remained\n",
      "Word: the, Deprel: det, Head: government\n",
      "Word: government, Deprel: obj, Head: demanded\n",
      "Word: renegotiate, Deprel: xcomp, Head: demanded\n",
      "Word: the, Deprel: det, Head: reform\n",
      "Word: reform, Deprel: obj, Head: renegotiate\n",
      "Word: with, Deprel: case, Head: them\n",
      "Word: them, Deprel: obl, Head: renegotiate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The family owns Cheetahs strip clubs here and in Las Vegas'\n",
      "Word: The, Deprel: det, Head: family\n",
      "Word: family, Deprel: nsubj, Head: owns\n",
      "Word: owns, Deprel: root, Head: ROOT\n",
      "Word: Cheetahs, Deprel: compound, Head: clubs\n",
      "Word: strip, Deprel: compound, Head: clubs\n",
      "Word: clubs, Deprel: obj, Head: owns\n",
      "Word: here, Deprel: advmod, Head: owns\n",
      "Word: and, Deprel: cc, Head: Las\n",
      "Word: in, Deprel: case, Head: Las\n",
      "Word: Las, Deprel: conj, Head: here\n",
      "Word: Vegas, Deprel: flat, Head: Las\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The searches were conducted simultaneously with raids on strip clubs in San Diego and Las Vegas'\n",
      "Word: The, Deprel: det, Head: searches\n",
      "Word: searches, Deprel: nsubj:pass, Head: conducted\n",
      "Word: were, Deprel: aux:pass, Head: conducted\n",
      "Word: conducted, Deprel: root, Head: ROOT\n",
      "Word: simultaneously, Deprel: advmod, Head: conducted\n",
      "Word: with, Deprel: case, Head: raids\n",
      "Word: raids, Deprel: obl, Head: conducted\n",
      "Word: on, Deprel: case, Head: clubs\n",
      "Word: strip, Deprel: compound, Head: clubs\n",
      "Word: clubs, Deprel: nmod, Head: raids\n",
      "Word: in, Deprel: case, Head: San\n",
      "Word: San, Deprel: nmod, Head: clubs\n",
      "Word: Diego, Deprel: flat, Head: San\n",
      "Word: and, Deprel: cc, Head: Las\n",
      "Word: Las, Deprel: conj, Head: San\n",
      "Word: Vegas, Deprel: flat, Head: Las\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The new bill would have Medicare cover 95 percent of drug costs over 5,100'\n",
      "Word: The, Deprel: det, Head: bill\n",
      "Word: new, Deprel: amod, Head: bill\n",
      "Word: bill, Deprel: nsubj, Head: have\n",
      "Word: would, Deprel: aux, Head: have\n",
      "Word: have, Deprel: root, Head: ROOT\n",
      "Word: Medicare, Deprel: obj, Head: have\n",
      "Word: cover, Deprel: xcomp, Head: have\n",
      "Word: 95, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obj, Head: cover\n",
      "Word: of, Deprel: case, Head: costs\n",
      "Word: drug, Deprel: compound, Head: costs\n",
      "Word: costs, Deprel: nmod, Head: percent\n",
      "Word: over, Deprel: case, Head: 5,100\n",
      "Word: 5,100, Deprel: obl, Head: cover\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Above that seniors would be responsible for 100 percent of drug costs until the out-of-pocket total reaches 3,600'\n",
      "Word: Above, Deprel: advmod, Head: responsible\n",
      "Word: that, Deprel: mark, Head: responsible\n",
      "Word: seniors, Deprel: nsubj, Head: responsible\n",
      "Word: would, Deprel: aux, Head: responsible\n",
      "Word: be, Deprel: cop, Head: responsible\n",
      "Word: responsible, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: percent\n",
      "Word: 100, Deprel: nummod, Head: percent\n",
      "Word: percent, Deprel: obl, Head: responsible\n",
      "Word: of, Deprel: case, Head: costs\n",
      "Word: drug, Deprel: compound, Head: costs\n",
      "Word: costs, Deprel: nmod, Head: percent\n",
      "Word: until, Deprel: mark, Head: reaches\n",
      "Word: the, Deprel: det, Head: total\n",
      "Word: out-of-pocket, Deprel: compound, Head: total\n",
      "Word: total, Deprel: nsubj, Head: reaches\n",
      "Word: reaches, Deprel: advcl, Head: responsible\n",
      "Word: 3,600, Deprel: obj, Head: reaches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Several thousand 3rd Infantry troops including the 3rd Brigade Combat Team based at Fort Benning in Columbus began returning last week'\n",
      "Word: Several, Deprel: amod, Head: thousand\n",
      "Word: thousand, Deprel: nummod, Head: troops\n",
      "Word: 3rd, Deprel: amod, Head: troops\n",
      "Word: Infantry, Deprel: compound, Head: troops\n",
      "Word: troops, Deprel: nsubj, Head: began\n",
      "Word: including, Deprel: case, Head: Team\n",
      "Word: the, Deprel: det, Head: Team\n",
      "Word: 3rd, Deprel: amod, Head: Brigade\n",
      "Word: Brigade, Deprel: compound, Head: Team\n",
      "Word: Combat, Deprel: compound, Head: Team\n",
      "Word: Team, Deprel: nmod, Head: troops\n",
      "Word: based, Deprel: acl, Head: Team\n",
      "Word: at, Deprel: case, Head: Fort\n",
      "Word: Fort, Deprel: obl, Head: based\n",
      "Word: Benning, Deprel: flat, Head: Fort\n",
      "Word: in, Deprel: case, Head: Columbus\n",
      "Word: Columbus, Deprel: obl, Head: based\n",
      "Word: began, Deprel: root, Head: ROOT\n",
      "Word: returning, Deprel: xcomp, Head: began\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: returning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A few thousand troops most from the division s 3rd Brigade Combat Team based at Fort Benning in Columbus began returning last week with flights continuing through Friday'\n",
      "Word: A, Deprel: det, Head: troops\n",
      "Word: few, Deprel: amod, Head: thousand\n",
      "Word: thousand, Deprel: nummod, Head: troops\n",
      "Word: troops, Deprel: nsubj, Head: began\n",
      "Word: most, Deprel: amod, Head: troops\n",
      "Word: from, Deprel: case, Head: Team\n",
      "Word: the, Deprel: det, Head: division\n",
      "Word: division, Deprel: nmod:poss, Head: Team\n",
      "Word: s, Deprel: case, Head: division\n",
      "Word: 3rd, Deprel: amod, Head: Brigade\n",
      "Word: Brigade, Deprel: compound, Head: Team\n",
      "Word: Combat, Deprel: compound, Head: Team\n",
      "Word: Team, Deprel: obl, Head: most\n",
      "Word: based, Deprel: acl, Head: Team\n",
      "Word: at, Deprel: case, Head: Fort\n",
      "Word: Fort, Deprel: obl, Head: based\n",
      "Word: Benning, Deprel: flat, Head: Fort\n",
      "Word: in, Deprel: case, Head: Columbus\n",
      "Word: Columbus, Deprel: obl, Head: based\n",
      "Word: began, Deprel: root, Head: ROOT\n",
      "Word: returning, Deprel: xcomp, Head: began\n",
      "Word: last, Deprel: amod, Head: week\n",
      "Word: week, Deprel: obl:tmod, Head: returning\n",
      "Word: with, Deprel: case, Head: flights\n",
      "Word: flights, Deprel: obl, Head: returning\n",
      "Word: continuing, Deprel: acl, Head: flights\n",
      "Word: through, Deprel: case, Head: Friday\n",
      "Word: Friday, Deprel: obl, Head: continuing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The study also found that consumer goods advertisers continued to spend the most dollars online representing 35 of all Web advertising'\n",
      "Word: The, Deprel: det, Head: study\n",
      "Word: study, Deprel: nsubj, Head: found\n",
      "Word: also, Deprel: advmod, Head: found\n",
      "Word: found, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: continued\n",
      "Word: consumer, Deprel: compound, Head: goods\n",
      "Word: goods, Deprel: compound, Head: advertisers\n",
      "Word: advertisers, Deprel: nsubj, Head: continued\n",
      "Word: continued, Deprel: ccomp, Head: found\n",
      "Word: to, Deprel: mark, Head: spend\n",
      "Word: spend, Deprel: xcomp, Head: continued\n",
      "Word: the, Deprel: det, Head: dollars\n",
      "Word: most, Deprel: amod, Head: dollars\n",
      "Word: dollars, Deprel: obj, Head: spend\n",
      "Word: online, Deprel: advmod, Head: spend\n",
      "Word: representing, Deprel: advcl, Head: spend\n",
      "Word: 35, Deprel: obj, Head: representing\n",
      "Word: of, Deprel: case, Head: advertising\n",
      "Word: all, Deprel: det, Head: advertising\n",
      "Word: Web, Deprel: compound, Head: advertising\n",
      "Word: advertising, Deprel: nmod, Head: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'In the second quarter consumer advertisers continued to spend the most online slightly increasing their share'\n",
      "Word: In, Deprel: case, Head: quarter\n",
      "Word: the, Deprel: det, Head: quarter\n",
      "Word: second, Deprel: amod, Head: quarter\n",
      "Word: quarter, Deprel: obl, Head: continued\n",
      "Word: consumer, Deprel: compound, Head: advertisers\n",
      "Word: advertisers, Deprel: nsubj, Head: continued\n",
      "Word: continued, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: spend\n",
      "Word: spend, Deprel: xcomp, Head: continued\n",
      "Word: the, Deprel: det, Head: most\n",
      "Word: most, Deprel: advmod, Head: online\n",
      "Word: online, Deprel: advmod, Head: spend\n",
      "Word: slightly, Deprel: advmod, Head: increasing\n",
      "Word: increasing, Deprel: advcl, Head: spend\n",
      "Word: their, Deprel: nmod:poss, Head: share\n",
      "Word: share, Deprel: obj, Head: increasing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Prairie dogs sold as exotic pets are believed to have been infected in an Illinois pet shop by a Gambian giant rat imported from Africa'\n",
      "Word: Prairie, Deprel: amod, Head: dogs\n",
      "Word: dogs, Deprel: nsubj, Head: sold\n",
      "Word: sold, Deprel: root, Head: ROOT\n",
      "Word: as, Deprel: mark, Head: believed\n",
      "Word: exotic, Deprel: amod, Head: pets\n",
      "Word: pets, Deprel: nsubj:pass, Head: believed\n",
      "Word: are, Deprel: aux:pass, Head: believed\n",
      "Word: believed, Deprel: advcl, Head: sold\n",
      "Word: to, Deprel: mark, Head: infected\n",
      "Word: have, Deprel: aux, Head: infected\n",
      "Word: been, Deprel: aux:pass, Head: infected\n",
      "Word: infected, Deprel: xcomp, Head: believed\n",
      "Word: in, Deprel: case, Head: shop\n",
      "Word: an, Deprel: det, Head: shop\n",
      "Word: Illinois, Deprel: compound, Head: shop\n",
      "Word: pet, Deprel: compound, Head: shop\n",
      "Word: shop, Deprel: obl, Head: infected\n",
      "Word: by, Deprel: case, Head: rat\n",
      "Word: a, Deprel: det, Head: rat\n",
      "Word: Gambian, Deprel: amod, Head: rat\n",
      "Word: giant, Deprel: compound, Head: rat\n",
      "Word: rat, Deprel: obl, Head: infected\n",
      "Word: imported, Deprel: acl, Head: rat\n",
      "Word: from, Deprel: case, Head: Africa\n",
      "Word: Africa, Deprel: obl, Head: imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Prairie dogs are believed to have become infected in a pet shop through a Gambian rat imported from Africa'\n",
      "Word: Prairie, Deprel: amod, Head: dogs\n",
      "Word: dogs, Deprel: nsubj:pass, Head: believed\n",
      "Word: are, Deprel: aux:pass, Head: believed\n",
      "Word: believed, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: mark, Head: become\n",
      "Word: have, Deprel: aux, Head: become\n",
      "Word: become, Deprel: xcomp, Head: believed\n",
      "Word: infected, Deprel: xcomp, Head: become\n",
      "Word: in, Deprel: case, Head: shop\n",
      "Word: a, Deprel: det, Head: shop\n",
      "Word: pet, Deprel: compound, Head: shop\n",
      "Word: shop, Deprel: obl, Head: infected\n",
      "Word: through, Deprel: case, Head: rat\n",
      "Word: a, Deprel: det, Head: rat\n",
      "Word: Gambian, Deprel: amod, Head: rat\n",
      "Word: rat, Deprel: obl, Head: infected\n",
      "Word: imported, Deprel: acl, Head: rat\n",
      "Word: from, Deprel: case, Head: Africa\n",
      "Word: Africa, Deprel: obl, Head: imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The defense can not appeal Roush s ruling until after the trial'\n",
      "Word: The, Deprel: det, Head: defense\n",
      "Word: defense, Deprel: nsubj, Head: appeal\n",
      "Word: can, Deprel: aux, Head: appeal\n",
      "Word: not, Deprel: advmod, Head: appeal\n",
      "Word: appeal, Deprel: root, Head: ROOT\n",
      "Word: Roush, Deprel: nmod:poss, Head: ruling\n",
      "Word: s, Deprel: case, Head: Roush\n",
      "Word: ruling, Deprel: obj, Head: appeal\n",
      "Word: until, Deprel: case, Head: trial\n",
      "Word: after, Deprel: case, Head: trial\n",
      "Word: the, Deprel: det, Head: trial\n",
      "Word: trial, Deprel: obl, Head: appeal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Defense lawyers can not appeal the ruling until after trial in the appellate courts'\n",
      "Word: Defense, Deprel: compound, Head: lawyers\n",
      "Word: lawyers, Deprel: nsubj, Head: appeal\n",
      "Word: can, Deprel: aux, Head: appeal\n",
      "Word: not, Deprel: advmod, Head: appeal\n",
      "Word: appeal, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: ruling\n",
      "Word: ruling, Deprel: obj, Head: appeal\n",
      "Word: until, Deprel: case, Head: trial\n",
      "Word: after, Deprel: case, Head: trial\n",
      "Word: trial, Deprel: obl, Head: appeal\n",
      "Word: in, Deprel: case, Head: courts\n",
      "Word: the, Deprel: det, Head: courts\n",
      "Word: appellate, Deprel: compound, Head: courts\n",
      "Word: courts, Deprel: nmod, Head: trial\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Crohn s disease causes inflammation of the intestine and symptoms include diarrhea pain weight loss and tiredness'\n",
      "Word: Crohn, Deprel: nmod:poss, Head: disease\n",
      "Word: s, Deprel: case, Head: Crohn\n",
      "Word: disease, Deprel: nsubj, Head: causes\n",
      "Word: causes, Deprel: root, Head: ROOT\n",
      "Word: inflammation, Deprel: obj, Head: causes\n",
      "Word: of, Deprel: case, Head: intestine\n",
      "Word: the, Deprel: det, Head: intestine\n",
      "Word: intestine, Deprel: nmod, Head: inflammation\n",
      "Word: and, Deprel: cc, Head: symptoms\n",
      "Word: symptoms, Deprel: conj, Head: intestine\n",
      "Word: include, Deprel: ccomp, Head: causes\n",
      "Word: diarrhea, Deprel: compound, Head: pain\n",
      "Word: pain, Deprel: compound, Head: loss\n",
      "Word: weight, Deprel: compound, Head: loss\n",
      "Word: loss, Deprel: obj, Head: include\n",
      "Word: and, Deprel: cc, Head: tiredness\n",
      "Word: tiredness, Deprel: conj, Head: loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Symptoms include chronic diarrhoea abdominal pain weight loss and extreme tiredness'\n",
      "Word: Symptoms, Deprel: nsubj, Head: include\n",
      "Word: include, Deprel: root, Head: ROOT\n",
      "Word: chronic, Deprel: amod, Head: diarrhoea\n",
      "Word: diarrhoea, Deprel: obj, Head: include\n",
      "Word: abdominal, Deprel: amod, Head: pain\n",
      "Word: pain, Deprel: compound, Head: loss\n",
      "Word: weight, Deprel: compound, Head: loss\n",
      "Word: loss, Deprel: conj, Head: diarrhoea\n",
      "Word: and, Deprel: cc, Head: tiredness\n",
      "Word: extreme, Deprel: amod, Head: tiredness\n",
      "Word: tiredness, Deprel: conj, Head: loss\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The committee was appointed by Defense Secretary Donald Rumsfeld under orders from Congress'\n",
      "Word: The, Deprel: det, Head: committee\n",
      "Word: committee, Deprel: nsubj:pass, Head: appointed\n",
      "Word: was, Deprel: aux:pass, Head: appointed\n",
      "Word: appointed, Deprel: root, Head: ROOT\n",
      "Word: by, Deprel: case, Head: Secretary\n",
      "Word: Defense, Deprel: compound, Head: Secretary\n",
      "Word: Secretary, Deprel: obl:agent, Head: appointed\n",
      "Word: Donald, Deprel: flat, Head: Secretary\n",
      "Word: Rumsfeld, Deprel: flat, Head: Secretary\n",
      "Word: under, Deprel: case, Head: orders\n",
      "Word: orders, Deprel: obl, Head: appointed\n",
      "Word: from, Deprel: case, Head: Congress\n",
      "Word: Congress, Deprel: nmod, Head: orders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The public hearing is the second for the panel created by Defense Secretary Donald Rumsfeld under pressure from Congress'\n",
      "Word: The, Deprel: det, Head: hearing\n",
      "Word: public, Deprel: amod, Head: hearing\n",
      "Word: hearing, Deprel: nsubj, Head: second\n",
      "Word: is, Deprel: cop, Head: second\n",
      "Word: the, Deprel: det, Head: second\n",
      "Word: second, Deprel: root, Head: ROOT\n",
      "Word: for, Deprel: case, Head: panel\n",
      "Word: the, Deprel: det, Head: panel\n",
      "Word: panel, Deprel: nmod, Head: second\n",
      "Word: created, Deprel: acl, Head: panel\n",
      "Word: by, Deprel: case, Head: Secretary\n",
      "Word: Defense, Deprel: compound, Head: Secretary\n",
      "Word: Secretary, Deprel: obl:agent, Head: created\n",
      "Word: Donald, Deprel: flat, Head: Secretary\n",
      "Word: Rumsfeld, Deprel: flat, Head: Secretary\n",
      "Word: under, Deprel: case, Head: pressure\n",
      "Word: pressure, Deprel: obl, Head: created\n",
      "Word: from, Deprel: case, Head: Congress\n",
      "Word: Congress, Deprel: nmod, Head: pressure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Authorities identified the tipster as Richard Powell who is imprisoned for killing his landlady in 1982'\n",
      "Word: Authorities, Deprel: nsubj, Head: identified\n",
      "Word: identified, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: tipster\n",
      "Word: tipster, Deprel: obj, Head: identified\n",
      "Word: as, Deprel: case, Head: Richard\n",
      "Word: Richard, Deprel: obl, Head: identified\n",
      "Word: Powell, Deprel: flat, Head: Richard\n",
      "Word: who, Deprel: nsubj:pass, Head: imprisoned\n",
      "Word: is, Deprel: aux:pass, Head: imprisoned\n",
      "Word: imprisoned, Deprel: acl:relcl, Head: Richard\n",
      "Word: for, Deprel: mark, Head: killing\n",
      "Word: killing, Deprel: advcl, Head: imprisoned\n",
      "Word: his, Deprel: nmod:poss, Head: landlady\n",
      "Word: landlady, Deprel: obj, Head: killing\n",
      "Word: in, Deprel: case, Head: 1982\n",
      "Word: 1982, Deprel: obl, Head: killing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Powell is serving time in a different case killing his landlady in 1982'\n",
      "Word: Powell, Deprel: nsubj, Head: serving\n",
      "Word: is, Deprel: aux, Head: serving\n",
      "Word: serving, Deprel: root, Head: ROOT\n",
      "Word: time, Deprel: obj, Head: serving\n",
      "Word: in, Deprel: case, Head: case\n",
      "Word: a, Deprel: det, Head: case\n",
      "Word: different, Deprel: amod, Head: case\n",
      "Word: case, Deprel: obl, Head: serving\n",
      "Word: killing, Deprel: advcl, Head: serving\n",
      "Word: his, Deprel: nmod:poss, Head: landlady\n",
      "Word: landlady, Deprel: obj, Head: killing\n",
      "Word: in, Deprel: case, Head: 1982\n",
      "Word: 1982, Deprel: obl, Head: killing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Kiernan testified that Seifert had received a gunshot wound to the back'\n",
      "Word: Kiernan, Deprel: nsubj, Head: testified\n",
      "Word: testified, Deprel: root, Head: ROOT\n",
      "Word: that, Deprel: mark, Head: received\n",
      "Word: Seifert, Deprel: nsubj, Head: received\n",
      "Word: had, Deprel: aux, Head: received\n",
      "Word: received, Deprel: ccomp, Head: testified\n",
      "Word: a, Deprel: det, Head: wound\n",
      "Word: gunshot, Deprel: compound, Head: wound\n",
      "Word: wound, Deprel: obj, Head: received\n",
      "Word: to, Deprel: case, Head: back\n",
      "Word: the, Deprel: det, Head: back\n",
      "Word: back, Deprel: obl, Head: received\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Seifert he testified had a gunshot wound in the back'\n",
      "Word: Seifert, Deprel: nsubj, Head: had\n",
      "Word: he, Deprel: nsubj, Head: testified\n",
      "Word: testified, Deprel: acl:relcl, Head: Seifert\n",
      "Word: had, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: wound\n",
      "Word: gunshot, Deprel: compound, Head: wound\n",
      "Word: wound, Deprel: obj, Head: had\n",
      "Word: in, Deprel: case, Head: back\n",
      "Word: the, Deprel: det, Head: back\n",
      "Word: back, Deprel: nmod, Head: wound\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Former Indiana Rep Frank McCloskey 64 died Sunday in Bloomington after a battle with bladder cancer'\n",
      "Word: Former, Deprel: amod, Head: Rep\n",
      "Word: Indiana, Deprel: compound, Head: Rep\n",
      "Word: Rep, Deprel: nsubj, Head: died\n",
      "Word: Frank, Deprel: flat, Head: Rep\n",
      "Word: McCloskey, Deprel: flat, Head: Frank\n",
      "Word: 64, Deprel: nummod, Head: Rep\n",
      "Word: died, Deprel: root, Head: ROOT\n",
      "Word: Sunday, Deprel: obl:tmod, Head: died\n",
      "Word: in, Deprel: case, Head: Bloomington\n",
      "Word: Bloomington, Deprel: obl, Head: died\n",
      "Word: after, Deprel: case, Head: battle\n",
      "Word: a, Deprel: det, Head: battle\n",
      "Word: battle, Deprel: obl, Head: died\n",
      "Word: with, Deprel: case, Head: cancer\n",
      "Word: bladder, Deprel: compound, Head: cancer\n",
      "Word: cancer, Deprel: nmod, Head: battle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'McCloskey died Sunday afternoon in his home after a year-long battle with bladder cancer'\n",
      "Word: McCloskey, Deprel: nsubj, Head: died\n",
      "Word: died, Deprel: root, Head: ROOT\n",
      "Word: Sunday, Deprel: compound, Head: afternoon\n",
      "Word: afternoon, Deprel: obl:tmod, Head: died\n",
      "Word: in, Deprel: case, Head: home\n",
      "Word: his, Deprel: nmod:poss, Head: home\n",
      "Word: home, Deprel: obl, Head: died\n",
      "Word: after, Deprel: case, Head: battle\n",
      "Word: a, Deprel: det, Head: battle\n",
      "Word: year-long, Deprel: amod, Head: battle\n",
      "Word: battle, Deprel: obl, Head: died\n",
      "Word: with, Deprel: case, Head: cancer\n",
      "Word: bladder, Deprel: compound, Head: cancer\n",
      "Word: cancer, Deprel: nmod, Head: battle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Hospitals and the Red Cross appealed to blood donors yesterday'\n",
      "Word: Hospitals, Deprel: nsubj, Head: appealed\n",
      "Word: and, Deprel: cc, Head: Cross\n",
      "Word: the, Deprel: det, Head: Cross\n",
      "Word: Red, Deprel: amod, Head: Cross\n",
      "Word: Cross, Deprel: conj, Head: Hospitals\n",
      "Word: appealed, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: donors\n",
      "Word: blood, Deprel: compound, Head: donors\n",
      "Word: donors, Deprel: obl, Head: appealed\n",
      "Word: yesterday, Deprel: obl:tmod, Head: appealed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The Connecticut Hospital Association joined the Red Cross Monday in calling for more blood donors'\n",
      "Word: The, Deprel: det, Head: Association\n",
      "Word: Connecticut, Deprel: compound, Head: Association\n",
      "Word: Hospital, Deprel: compound, Head: Association\n",
      "Word: Association, Deprel: nsubj, Head: joined\n",
      "Word: joined, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: Cross\n",
      "Word: Red, Deprel: amod, Head: Cross\n",
      "Word: Cross, Deprel: obj, Head: joined\n",
      "Word: Monday, Deprel: obl:tmod, Head: joined\n",
      "Word: in, Deprel: mark, Head: calling\n",
      "Word: calling, Deprel: advcl, Head: joined\n",
      "Word: for, Deprel: case, Head: donors\n",
      "Word: more, Deprel: amod, Head: donors\n",
      "Word: blood, Deprel: compound, Head: donors\n",
      "Word: donors, Deprel: obl, Head: calling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It is priced at 5,995 for an unlimited number of users tapping into the single processor or 195 per user with a minimum of five users'\n",
      "Word: It, Deprel: nsubj:pass, Head: priced\n",
      "Word: is, Deprel: aux:pass, Head: priced\n",
      "Word: priced, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: 5,995\n",
      "Word: 5,995, Deprel: obl, Head: priced\n",
      "Word: for, Deprel: case, Head: number\n",
      "Word: an, Deprel: det, Head: number\n",
      "Word: unlimited, Deprel: amod, Head: number\n",
      "Word: number, Deprel: obl, Head: priced\n",
      "Word: of, Deprel: case, Head: users\n",
      "Word: users, Deprel: nmod, Head: number\n",
      "Word: tapping, Deprel: acl, Head: users\n",
      "Word: into, Deprel: case, Head: processor\n",
      "Word: the, Deprel: det, Head: processor\n",
      "Word: single, Deprel: amod, Head: processor\n",
      "Word: processor, Deprel: obl, Head: tapping\n",
      "Word: or, Deprel: cc, Head: 195\n",
      "Word: 195, Deprel: conj, Head: processor\n",
      "Word: per, Deprel: case, Head: user\n",
      "Word: user, Deprel: nmod, Head: 195\n",
      "Word: with, Deprel: case, Head: minimum\n",
      "Word: a, Deprel: det, Head: minimum\n",
      "Word: minimum, Deprel: obl, Head: tapping\n",
      "Word: of, Deprel: case, Head: users\n",
      "Word: five, Deprel: nummod, Head: users\n",
      "Word: users, Deprel: nmod, Head: minimum\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'It is priced at 5,995 or 195 on a per user licensing plan with a minimum of five users'\n",
      "Word: It, Deprel: nsubj:pass, Head: priced\n",
      "Word: is, Deprel: aux:pass, Head: priced\n",
      "Word: priced, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: 5,995\n",
      "Word: 5,995, Deprel: obl, Head: priced\n",
      "Word: or, Deprel: cc, Head: 195\n",
      "Word: 195, Deprel: conj, Head: 5,995\n",
      "Word: on, Deprel: case, Head: plan\n",
      "Word: a, Deprel: det, Head: plan\n",
      "Word: per, Deprel: case, Head: user\n",
      "Word: user, Deprel: compound, Head: licensing\n",
      "Word: licensing, Deprel: compound, Head: plan\n",
      "Word: plan, Deprel: obl, Head: priced\n",
      "Word: with, Deprel: case, Head: minimum\n",
      "Word: a, Deprel: det, Head: minimum\n",
      "Word: minimum, Deprel: obl, Head: priced\n",
      "Word: of, Deprel: case, Head: users\n",
      "Word: five, Deprel: nummod, Head: users\n",
      "Word: users, Deprel: nmod, Head: minimum\n",
      "\n",
      "Dependencies for Sentence: 'A man is riding a bicycle'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: riding\n",
      "Word: is, Deprel: aux, Head: riding\n",
      "Word: riding, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: bicycle\n",
      "Word: bicycle, Deprel: obj, Head: riding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is riding a bike'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: riding\n",
      "Word: is, Deprel: aux, Head: riding\n",
      "Word: riding, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: bike\n",
      "Word: bike, Deprel: obj, Head: riding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman and man are dancing in the rain'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: dancing\n",
      "Word: and, Deprel: cc, Head: man\n",
      "Word: man, Deprel: conj, Head: woman\n",
      "Word: are, Deprel: aux, Head: dancing\n",
      "Word: dancing, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: rain\n",
      "Word: the, Deprel: det, Head: rain\n",
      "Word: rain, Deprel: obl, Head: dancing\n",
      "\n",
      "Dependencies for Sentence: 'A man and woman are dancing in rain'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: dancing\n",
      "Word: and, Deprel: cc, Head: woman\n",
      "Word: woman, Deprel: conj, Head: man\n",
      "Word: are, Deprel: aux, Head: dancing\n",
      "Word: dancing, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: rain\n",
      "Word: rain, Deprel: obl, Head: dancing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Someone is drawing'\n",
      "Word: Someone, Deprel: nsubj, Head: drawing\n",
      "Word: is, Deprel: aux, Head: drawing\n",
      "Word: drawing, Deprel: root, Head: ROOT\n",
      "\n",
      "Dependencies for Sentence: 'Someone is dancing'\n",
      "Word: Someone, Deprel: nsubj, Head: dancing\n",
      "Word: is, Deprel: aux, Head: dancing\n",
      "Word: dancing, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man and a woman are kissing each other'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: kissing\n",
      "Word: and, Deprel: cc, Head: woman\n",
      "Word: a, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: conj, Head: man\n",
      "Word: are, Deprel: aux, Head: kissing\n",
      "Word: kissing, Deprel: root, Head: ROOT\n",
      "Word: each, Deprel: det, Head: other\n",
      "Word: other, Deprel: advmod, Head: kissing\n",
      "\n",
      "Dependencies for Sentence: 'A man and a woman are talking to each other'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: talking\n",
      "Word: and, Deprel: cc, Head: woman\n",
      "Word: a, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: conj, Head: man\n",
      "Word: are, Deprel: aux, Head: talking\n",
      "Word: talking, Deprel: root, Head: ROOT\n",
      "Word: to, Deprel: case, Head: other\n",
      "Word: each, Deprel: det, Head: other\n",
      "Word: other, Deprel: obl, Head: talking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is slicing an onion'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: onion\n",
      "Word: onion, Deprel: obj, Head: slicing\n",
      "\n",
      "Dependencies for Sentence: 'A woman is cutting an onion'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: cutting\n",
      "Word: is, Deprel: aux, Head: cutting\n",
      "Word: cutting, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: onion\n",
      "Word: onion, Deprel: obj, Head: cutting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A person is peeling shrimp'\n",
      "Word: A, Deprel: det, Head: person\n",
      "Word: person, Deprel: nsubj, Head: peeling\n",
      "Word: is, Deprel: aux, Head: peeling\n",
      "Word: peeling, Deprel: root, Head: ROOT\n",
      "Word: shrimp, Deprel: obj, Head: peeling\n",
      "\n",
      "Dependencies for Sentence: 'A person is preparing shrimp'\n",
      "Word: A, Deprel: det, Head: person\n",
      "Word: person, Deprel: nsubj, Head: preparing\n",
      "Word: is, Deprel: aux, Head: preparing\n",
      "Word: preparing, Deprel: root, Head: ROOT\n",
      "Word: shrimp, Deprel: obj, Head: preparing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is cutting broccoli'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: cutting\n",
      "Word: is, Deprel: aux, Head: cutting\n",
      "Word: cutting, Deprel: root, Head: ROOT\n",
      "Word: broccoli, Deprel: obj, Head: cutting\n",
      "\n",
      "Dependencies for Sentence: 'A woman is slicing broccoli'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: broccoli, Deprel: obj, Head: slicing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A woman is playing the guitar'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Two men are fistfighting in a ring'\n",
      "Word: Two, Deprel: nummod, Head: men\n",
      "Word: men, Deprel: nsubj, Head: fistfighting\n",
      "Word: are, Deprel: aux, Head: fistfighting\n",
      "Word: fistfighting, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: ring\n",
      "Word: a, Deprel: det, Head: ring\n",
      "Word: ring, Deprel: obl, Head: fistfighting\n",
      "\n",
      "Dependencies for Sentence: 'Two men fistfight in a ring'\n",
      "Word: Two, Deprel: nummod, Head: men\n",
      "Word: men, Deprel: nsubj, Head: fistfight\n",
      "Word: fistfight, Deprel: root, Head: ROOT\n",
      "Word: in, Deprel: case, Head: ring\n",
      "Word: a, Deprel: det, Head: ring\n",
      "Word: ring, Deprel: obl, Head: fistfight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A small boy is playing with a dog'\n",
      "Word: A, Deprel: det, Head: boy\n",
      "Word: small, Deprel: amod, Head: boy\n",
      "Word: boy, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: dog\n",
      "Word: a, Deprel: det, Head: dog\n",
      "Word: dog, Deprel: obl, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A baby is playing with a dog'\n",
      "Word: A, Deprel: det, Head: baby\n",
      "Word: baby, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: dog\n",
      "Word: a, Deprel: det, Head: dog\n",
      "Word: dog, Deprel: obl, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The man is drawing'\n",
      "Word: The, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: drawing\n",
      "Word: is, Deprel: aux, Head: drawing\n",
      "Word: drawing, Deprel: root, Head: ROOT\n",
      "\n",
      "Dependencies for Sentence: 'A man is drawing'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: drawing\n",
      "Word: is, Deprel: aux, Head: drawing\n",
      "Word: drawing, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is cutting a potato'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: cutting\n",
      "Word: is, Deprel: aux, Head: cutting\n",
      "Word: cutting, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: cutting\n",
      "\n",
      "Dependencies for Sentence: 'A woman is cutting a tomato'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: cutting\n",
      "Word: is, Deprel: aux, Head: cutting\n",
      "Word: cutting, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: tomato\n",
      "Word: tomato, Deprel: obj, Head: cutting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A small dog laying on the bed'\n",
      "Word: A, Deprel: det, Head: dog\n",
      "Word: small, Deprel: amod, Head: dog\n",
      "Word: dog, Deprel: root, Head: ROOT\n",
      "Word: laying, Deprel: acl, Head: dog\n",
      "Word: on, Deprel: case, Head: bed\n",
      "Word: the, Deprel: det, Head: bed\n",
      "Word: bed, Deprel: obl, Head: laying\n",
      "\n",
      "Dependencies for Sentence: 'A small dog is laying on a bed'\n",
      "Word: A, Deprel: det, Head: dog\n",
      "Word: small, Deprel: amod, Head: dog\n",
      "Word: dog, Deprel: nsubj, Head: laying\n",
      "Word: is, Deprel: aux, Head: laying\n",
      "Word: laying, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: bed\n",
      "Word: a, Deprel: det, Head: bed\n",
      "Word: bed, Deprel: obl, Head: laying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A person wipes butter on a tray'\n",
      "Word: A, Deprel: det, Head: person\n",
      "Word: person, Deprel: nsubj, Head: wipes\n",
      "Word: wipes, Deprel: root, Head: ROOT\n",
      "Word: butter, Deprel: obj, Head: wipes\n",
      "Word: on, Deprel: case, Head: tray\n",
      "Word: a, Deprel: det, Head: tray\n",
      "Word: tray, Deprel: obl, Head: wipes\n",
      "\n",
      "Dependencies for Sentence: 'A person is buttering a tray'\n",
      "Word: A, Deprel: det, Head: person\n",
      "Word: person, Deprel: nsubj, Head: buttering\n",
      "Word: is, Deprel: aux, Head: buttering\n",
      "Word: buttering, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: tray\n",
      "Word: tray, Deprel: obj, Head: buttering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Two men are playing football'\n",
      "Word: Two, Deprel: nummod, Head: men\n",
      "Word: men, Deprel: nsubj, Head: playing\n",
      "Word: are, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: football, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'Two men are practicing football'\n",
      "Word: Two, Deprel: nummod, Head: men\n",
      "Word: men, Deprel: nsubj, Head: practicing\n",
      "Word: are, Deprel: aux, Head: practicing\n",
      "Word: practicing, Deprel: root, Head: ROOT\n",
      "Word: football, Deprel: obj, Head: practicing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The man is playing the guitar'\n",
      "Word: The, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'The girl is playing the guitar'\n",
      "Word: The, Deprel: det, Head: girl\n",
      "Word: girl, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The man is slicing a potato'\n",
      "Word: The, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: slicing\n",
      "\n",
      "Dependencies for Sentence: 'A man is slicing potato'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: potato, Deprel: obj, Head: slicing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A boy is playing a guitar'\n",
      "Word: A, Deprel: det, Head: boy\n",
      "Word: boy, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A kid is playing a guitar'\n",
      "Word: A, Deprel: det, Head: kid\n",
      "Word: kid, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'The man is slicing a potato'\n",
      "Word: The, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: slicing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is slicing potato'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: potato, Deprel: obj, Head: slicing\n",
      "\n",
      "Dependencies for Sentence: 'A man is peeling a potato'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: peeling\n",
      "Word: is, Deprel: aux, Head: peeling\n",
      "Word: peeling, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: peeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is slicing a potato'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: slicing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is stabbing a potato with a fork'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: stabbing\n",
      "Word: is, Deprel: aux, Head: stabbing\n",
      "Word: stabbing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: stabbing\n",
      "Word: with, Deprel: case, Head: fork\n",
      "Word: a, Deprel: det, Head: fork\n",
      "Word: fork, Deprel: obl, Head: stabbing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is puncturing a potato with a fork'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: puncturing\n",
      "Word: is, Deprel: aux, Head: puncturing\n",
      "Word: puncturing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: puncturing\n",
      "Word: with, Deprel: case, Head: fork\n",
      "Word: a, Deprel: det, Head: fork\n",
      "Word: fork, Deprel: obl, Head: puncturing\n",
      "\n",
      "Dependencies for Sentence: 'A child is waking up'\n",
      "Word: A, Deprel: det, Head: child\n",
      "Word: child, Deprel: nsubj, Head: waking\n",
      "Word: is, Deprel: aux, Head: waking\n",
      "Word: waking, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: waking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A girl is waking up'\n",
      "Word: A, Deprel: det, Head: girl\n",
      "Word: girl, Deprel: nsubj, Head: waking\n",
      "Word: is, Deprel: aux, Head: waking\n",
      "Word: waking, Deprel: root, Head: ROOT\n",
      "Word: up, Deprel: compound:prt, Head: waking\n",
      "\n",
      "Dependencies for Sentence: 'A boy is playing a key-board'\n",
      "Word: A, Deprel: det, Head: boy\n",
      "Word: boy, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: key-board\n",
      "Word: key-board, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A little boy is playing a keyboard'\n",
      "Word: A, Deprel: det, Head: boy\n",
      "Word: little, Deprel: amod, Head: boy\n",
      "Word: boy, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: keyboard\n",
      "Word: keyboard, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A woman is cutting an onion'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: cutting\n",
      "Word: is, Deprel: aux, Head: cutting\n",
      "Word: cutting, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: onion\n",
      "Word: onion, Deprel: obj, Head: cutting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is cutting through an onion'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: cutting\n",
      "Word: is, Deprel: aux, Head: cutting\n",
      "Word: cutting, Deprel: root, Head: ROOT\n",
      "Word: through, Deprel: case, Head: onion\n",
      "Word: an, Deprel: det, Head: onion\n",
      "Word: onion, Deprel: obl, Head: cutting\n",
      "\n",
      "Dependencies for Sentence: 'A toy train is striking a toy car'\n",
      "Word: A, Deprel: det, Head: train\n",
      "Word: toy, Deprel: compound, Head: train\n",
      "Word: train, Deprel: nsubj, Head: striking\n",
      "Word: is, Deprel: aux, Head: striking\n",
      "Word: striking, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: car\n",
      "Word: toy, Deprel: compound, Head: car\n",
      "Word: car, Deprel: obj, Head: striking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A toy train strikes a toy car'\n",
      "Word: A, Deprel: det, Head: train\n",
      "Word: toy, Deprel: compound, Head: train\n",
      "Word: train, Deprel: nsubj, Head: strikes\n",
      "Word: strikes, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: car\n",
      "Word: toy, Deprel: compound, Head: car\n",
      "Word: car, Deprel: obj, Head: strikes\n",
      "\n",
      "Dependencies for Sentence: 'A man is playing the guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing the flute'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: flute\n",
      "Word: flute, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A cat opens a drawer and climbs inside'\n",
      "Word: A, Deprel: det, Head: cat\n",
      "Word: cat, Deprel: nsubj, Head: opens\n",
      "Word: opens, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: drawer\n",
      "Word: drawer, Deprel: obj, Head: opens\n",
      "Word: and, Deprel: cc, Head: climbs\n",
      "Word: climbs, Deprel: conj, Head: opens\n",
      "Word: inside, Deprel: advmod, Head: climbs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A cat is opening a drawer and climbing inside'\n",
      "Word: A, Deprel: det, Head: cat\n",
      "Word: cat, Deprel: nsubj, Head: opening\n",
      "Word: is, Deprel: aux, Head: opening\n",
      "Word: opening, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: drawer\n",
      "Word: drawer, Deprel: obj, Head: opening\n",
      "Word: and, Deprel: cc, Head: climbing\n",
      "Word: climbing, Deprel: conj, Head: opening\n",
      "Word: inside, Deprel: advmod, Head: climbing\n",
      "\n",
      "Dependencies for Sentence: 'A woman is frying a food'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: frying\n",
      "Word: is, Deprel: aux, Head: frying\n",
      "Word: frying, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: food\n",
      "Word: food, Deprel: obj, Head: frying\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is deep frying food'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: food\n",
      "Word: is, Deprel: cop, Head: food\n",
      "Word: deep, Deprel: amod, Head: food\n",
      "Word: frying, Deprel: amod, Head: food\n",
      "Word: food, Deprel: root, Head: ROOT\n",
      "\n",
      "Dependencies for Sentence: 'A woman plays the flute'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: plays\n",
      "Word: plays, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: flute\n",
      "Word: flute, Deprel: obj, Head: plays\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is playing the flute'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: flute\n",
      "Word: flute, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A man is dicing an onion'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: dicing\n",
      "Word: is, Deprel: aux, Head: dicing\n",
      "Word: dicing, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: onion\n",
      "Word: onion, Deprel: obj, Head: dicing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is cutting an onion'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: cutting\n",
      "Word: is, Deprel: aux, Head: cutting\n",
      "Word: cutting, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: onion\n",
      "Word: onion, Deprel: obj, Head: cutting\n",
      "\n",
      "Dependencies for Sentence: 'A girl is playing a guitar'\n",
      "Word: A, Deprel: det, Head: girl\n",
      "Word: girl, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A girl is singing on stage'\n",
      "Word: A, Deprel: det, Head: girl\n",
      "Word: girl, Deprel: nsubj, Head: singing\n",
      "Word: is, Deprel: aux, Head: singing\n",
      "Word: singing, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: stage\n",
      "Word: stage, Deprel: obl, Head: singing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is singing on stage'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: singing\n",
      "Word: is, Deprel: aux, Head: singing\n",
      "Word: singing, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: stage\n",
      "Word: stage, Deprel: obl, Head: singing\n",
      "\n",
      "Dependencies for Sentence: 'A woman is riding a horse'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: riding\n",
      "Word: is, Deprel: aux, Head: riding\n",
      "Word: riding, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: horse\n",
      "Word: horse, Deprel: obj, Head: riding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is riding a donkey'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: riding\n",
      "Word: is, Deprel: aux, Head: riding\n",
      "Word: riding, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: donkey\n",
      "Word: donkey, Deprel: obj, Head: riding\n",
      "\n",
      "Dependencies for Sentence: 'A girl is playing a guitar'\n",
      "Word: A, Deprel: det, Head: girl\n",
      "Word: girl, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A woman is brushing some shrimp'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: brushing\n",
      "Word: is, Deprel: aux, Head: brushing\n",
      "Word: brushing, Deprel: root, Head: ROOT\n",
      "Word: some, Deprel: det, Head: shrimp\n",
      "Word: shrimp, Deprel: obj, Head: brushing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman brushes some shrimp'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: brushes\n",
      "Word: brushes, Deprel: root, Head: ROOT\n",
      "Word: some, Deprel: det, Head: shrimp\n",
      "Word: shrimp, Deprel: obj, Head: brushes\n",
      "\n",
      "Dependencies for Sentence: 'A man is dancing on the ceiling'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: dancing\n",
      "Word: is, Deprel: aux, Head: dancing\n",
      "Word: dancing, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: ceiling\n",
      "Word: the, Deprel: det, Head: ceiling\n",
      "Word: ceiling, Deprel: obl, Head: dancing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is dancing on the ceiling of a room'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: dancing\n",
      "Word: is, Deprel: aux, Head: dancing\n",
      "Word: dancing, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: ceiling\n",
      "Word: the, Deprel: det, Head: ceiling\n",
      "Word: ceiling, Deprel: obl, Head: dancing\n",
      "Word: of, Deprel: case, Head: room\n",
      "Word: a, Deprel: det, Head: room\n",
      "Word: room, Deprel: nmod, Head: ceiling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is playing an electric guitar'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: guitar\n",
      "Word: electric, Deprel: amod, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing an acoustic guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: guitar\n",
      "Word: acoustic, Deprel: amod, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman thinly slices an onion with a large knife'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: slices\n",
      "Word: thinly, Deprel: advmod, Head: slices\n",
      "Word: slices, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: onion\n",
      "Word: onion, Deprel: obj, Head: slices\n",
      "Word: with, Deprel: case, Head: knife\n",
      "Word: a, Deprel: det, Head: knife\n",
      "Word: large, Deprel: amod, Head: knife\n",
      "Word: knife, Deprel: obl, Head: slices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is slicing onions with a large knife'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: onions, Deprel: obj, Head: slicing\n",
      "Word: with, Deprel: case, Head: knife\n",
      "Word: a, Deprel: det, Head: knife\n",
      "Word: large, Deprel: amod, Head: knife\n",
      "Word: knife, Deprel: obl, Head: slicing\n",
      "\n",
      "Dependencies for Sentence: 'A man is playing a keyboard'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: keyboard\n",
      "Word: keyboard, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man plays a keyboard'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: plays\n",
      "Word: plays, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: keyboard\n",
      "Word: keyboard, Deprel: obj, Head: plays\n",
      "\n",
      "Dependencies for Sentence: 'A man plays the guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: plays\n",
      "Word: plays, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: plays\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing the guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A woman is peeling a potato'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: peeling\n",
      "Word: is, Deprel: aux, Head: peeling\n",
      "Word: peeling, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: peeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman peels a potato'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: peels\n",
      "Word: peels, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: peels\n",
      "\n",
      "Dependencies for Sentence: 'A woman is handling a frog'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: handling\n",
      "Word: is, Deprel: aux, Head: handling\n",
      "Word: handling, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: frog\n",
      "Word: frog, Deprel: obj, Head: handling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is holding a frog'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: holding\n",
      "Word: is, Deprel: aux, Head: holding\n",
      "Word: holding, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: frog\n",
      "Word: frog, Deprel: obj, Head: holding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A person is peeling shrimp'\n",
      "Word: A, Deprel: det, Head: person\n",
      "Word: person, Deprel: nsubj, Head: peeling\n",
      "Word: is, Deprel: aux, Head: peeling\n",
      "Word: peeling, Deprel: root, Head: ROOT\n",
      "Word: shrimp, Deprel: obj, Head: peeling\n",
      "\n",
      "Dependencies for Sentence: 'A man is peeling shrimp'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: peeling\n",
      "Word: is, Deprel: aux, Head: peeling\n",
      "Word: peeling, Deprel: compound, Head: shrimp\n",
      "Word: shrimp, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing a flute'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: flute\n",
      "Word: flute, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A man is playing a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing a flute'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: flute\n",
      "Word: flute, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A man is playing a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A man is playing a flute'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: flute\n",
      "Word: flute, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing a piano'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: piano\n",
      "Word: piano, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A man is playing a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A man is playing a piano'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: piano\n",
      "Word: piano, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing a flute'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: flute\n",
      "Word: flute, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A man is playing a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is playing a flute'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: flute\n",
      "Word: flute, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A man is playing a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Two women are on a couch'\n",
      "Word: Two, Deprel: nummod, Head: women\n",
      "Word: women, Deprel: nsubj, Head: couch\n",
      "Word: are, Deprel: cop, Head: couch\n",
      "Word: on, Deprel: case, Head: couch\n",
      "Word: a, Deprel: det, Head: couch\n",
      "Word: couch, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Two women are hugging on a couch'\n",
      "Word: Two, Deprel: nummod, Head: women\n",
      "Word: women, Deprel: nsubj, Head: hugging\n",
      "Word: are, Deprel: aux, Head: hugging\n",
      "Word: hugging, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: couch\n",
      "Word: a, Deprel: det, Head: couch\n",
      "Word: couch, Deprel: obl, Head: hugging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Someone is slicing a cucumber'\n",
      "Word: Someone, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: cucumber\n",
      "Word: cucumber, Deprel: obj, Head: slicing\n",
      "\n",
      "Dependencies for Sentence: 'A man is slicing a cucumber'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: cucumber\n",
      "Word: cucumber, Deprel: obj, Head: slicing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A kitten is playing with a blue rope toy'\n",
      "Word: A, Deprel: det, Head: kitten\n",
      "Word: kitten, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: toy\n",
      "Word: a, Deprel: det, Head: toy\n",
      "Word: blue, Deprel: amod, Head: toy\n",
      "Word: rope, Deprel: compound, Head: toy\n",
      "Word: toy, Deprel: obl, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A kitten is playing with a toy'\n",
      "Word: A, Deprel: det, Head: kitten\n",
      "Word: kitten, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: with, Deprel: case, Head: toy\n",
      "Word: a, Deprel: det, Head: toy\n",
      "Word: toy, Deprel: obl, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A group of people are sweeping water out of a house'\n",
      "Word: A, Deprel: det, Head: group\n",
      "Word: group, Deprel: nsubj, Head: sweeping\n",
      "Word: of, Deprel: case, Head: people\n",
      "Word: people, Deprel: nmod, Head: group\n",
      "Word: are, Deprel: aux, Head: sweeping\n",
      "Word: sweeping, Deprel: root, Head: ROOT\n",
      "Word: water, Deprel: obj, Head: sweeping\n",
      "Word: out, Deprel: case, Head: house\n",
      "Word: of, Deprel: case, Head: house\n",
      "Word: a, Deprel: det, Head: house\n",
      "Word: house, Deprel: obl, Head: sweeping\n",
      "\n",
      "Dependencies for Sentence: 'People are sweeping water out of a house'\n",
      "Word: People, Deprel: nsubj, Head: sweeping\n",
      "Word: are, Deprel: aux, Head: sweeping\n",
      "Word: sweeping, Deprel: root, Head: ROOT\n",
      "Word: water, Deprel: obj, Head: sweeping\n",
      "Word: out, Deprel: case, Head: house\n",
      "Word: of, Deprel: case, Head: house\n",
      "Word: a, Deprel: det, Head: house\n",
      "Word: house, Deprel: obl, Head: sweeping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The dog is barking at the toy'\n",
      "Word: The, Deprel: det, Head: dog\n",
      "Word: dog, Deprel: nsubj, Head: barking\n",
      "Word: is, Deprel: aux, Head: barking\n",
      "Word: barking, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: toy\n",
      "Word: the, Deprel: det, Head: toy\n",
      "Word: toy, Deprel: obl, Head: barking\n",
      "\n",
      "Dependencies for Sentence: 'A dog is barking at a toy'\n",
      "Word: A, Deprel: det, Head: dog\n",
      "Word: dog, Deprel: nsubj, Head: barking\n",
      "Word: is, Deprel: aux, Head: barking\n",
      "Word: barking, Deprel: root, Head: ROOT\n",
      "Word: at, Deprel: case, Head: toy\n",
      "Word: a, Deprel: det, Head: toy\n",
      "Word: toy, Deprel: obl, Head: barking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A person folds a tortilla'\n",
      "Word: A, Deprel: det, Head: person\n",
      "Word: person, Deprel: nsubj, Head: folds\n",
      "Word: folds, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: tortilla\n",
      "Word: tortilla, Deprel: obj, Head: folds\n",
      "\n",
      "Dependencies for Sentence: 'A man folds a tortilla'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: folds\n",
      "Word: folds, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: tortilla\n",
      "Word: tortilla, Deprel: obj, Head: folds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A cat is drinking milk'\n",
      "Word: A, Deprel: det, Head: cat\n",
      "Word: cat, Deprel: nsubj, Head: drinking\n",
      "Word: is, Deprel: aux, Head: drinking\n",
      "Word: drinking, Deprel: root, Head: ROOT\n",
      "Word: milk, Deprel: obj, Head: drinking\n",
      "\n",
      "Dependencies for Sentence: 'A kitten is drinking milk'\n",
      "Word: A, Deprel: det, Head: kitten\n",
      "Word: kitten, Deprel: nsubj, Head: drinking\n",
      "Word: is, Deprel: aux, Head: drinking\n",
      "Word: drinking, Deprel: amod, Head: milk\n",
      "Word: milk, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A person is driving a car'\n",
      "Word: A, Deprel: det, Head: person\n",
      "Word: person, Deprel: nsubj, Head: driving\n",
      "Word: is, Deprel: aux, Head: driving\n",
      "Word: driving, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: car\n",
      "Word: car, Deprel: obj, Head: driving\n",
      "\n",
      "Dependencies for Sentence: 'A man is driving a car'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: driving\n",
      "Word: is, Deprel: aux, Head: driving\n",
      "Word: driving, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: car\n",
      "Word: car, Deprel: obj, Head: driving\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A turtle is walking'\n",
      "Word: A, Deprel: det, Head: turtle\n",
      "Word: turtle, Deprel: nsubj, Head: walking\n",
      "Word: is, Deprel: cop, Head: walking\n",
      "Word: walking, Deprel: root, Head: ROOT\n",
      "\n",
      "Dependencies for Sentence: 'A tortoise is walking'\n",
      "Word: A, Deprel: det, Head: tortoise\n",
      "Word: tortoise, Deprel: nsubj, Head: walking\n",
      "Word: is, Deprel: cop, Head: walking\n",
      "Word: walking, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A cow is eating grass'\n",
      "Word: A, Deprel: det, Head: cow\n",
      "Word: cow, Deprel: nsubj, Head: eating\n",
      "Word: is, Deprel: aux, Head: eating\n",
      "Word: eating, Deprel: root, Head: ROOT\n",
      "Word: grass, Deprel: obj, Head: eating\n",
      "\n",
      "Dependencies for Sentence: 'A cow is eating hay'\n",
      "Word: A, Deprel: det, Head: cow\n",
      "Word: cow, Deprel: nsubj, Head: eating\n",
      "Word: is, Deprel: aux, Head: eating\n",
      "Word: eating, Deprel: root, Head: ROOT\n",
      "Word: hay, Deprel: obj, Head: eating\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is chopping broccoli'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: broccoli\n",
      "Word: is, Deprel: cop, Head: broccoli\n",
      "Word: chopping, Deprel: amod, Head: broccoli\n",
      "Word: broccoli, Deprel: root, Head: ROOT\n",
      "\n",
      "Dependencies for Sentence: 'A woman is chopping garlic'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: garlic\n",
      "Word: is, Deprel: cop, Head: garlic\n",
      "Word: chopping, Deprel: amod, Head: garlic\n",
      "Word: garlic, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is crying'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: crying\n",
      "Word: is, Deprel: cop, Head: crying\n",
      "Word: crying, Deprel: root, Head: ROOT\n",
      "\n",
      "Dependencies for Sentence: 'A man is screaming'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: screaming\n",
      "Word: is, Deprel: cop, Head: screaming\n",
      "Word: screaming, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is putting on sun glasses'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: putting\n",
      "Word: is, Deprel: aux, Head: putting\n",
      "Word: putting, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: compound:prt, Head: putting\n",
      "Word: sun, Deprel: compound, Head: glasses\n",
      "Word: glasses, Deprel: obj, Head: putting\n",
      "\n",
      "Dependencies for Sentence: 'A woman puts on sunglasses'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: puts\n",
      "Word: puts, Deprel: root, Head: ROOT\n",
      "Word: on, Deprel: case, Head: puts\n",
      "Word: sunglasses, Deprel: obl, Head: puts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'The man is playing the guitar'\n",
      "Word: The, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: the, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n",
      "\n",
      "Dependencies for Sentence: 'A man is playing guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is cutting an onion'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: cutting\n",
      "Word: is, Deprel: aux, Head: cutting\n",
      "Word: cutting, Deprel: root, Head: ROOT\n",
      "Word: an, Deprel: det, Head: onion\n",
      "Word: onion, Deprel: obj, Head: cutting\n",
      "\n",
      "Dependencies for Sentence: 'A man is cutting a plantain'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: cutting\n",
      "Word: is, Deprel: aux, Head: cutting\n",
      "Word: cutting, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: plantain\n",
      "Word: plantain, Deprel: obj, Head: cutting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is slicing a potato'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: slicing\n",
      "\n",
      "Dependencies for Sentence: 'A woman is peeling a potato'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: peeling\n",
      "Word: is, Deprel: aux, Head: peeling\n",
      "Word: peeling, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: peeling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is slicing a potato'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: potato\n",
      "Word: potato, Deprel: obj, Head: slicing\n",
      "\n",
      "Dependencies for Sentence: 'A woman is slicing carrot'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: slicing\n",
      "Word: is, Deprel: aux, Head: slicing\n",
      "Word: slicing, Deprel: root, Head: ROOT\n",
      "Word: carrot, Deprel: obj, Head: slicing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man plays a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: plays\n",
      "Word: plays, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: plays\n",
      "\n",
      "Dependencies for Sentence: 'A man is playing a guitar'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: playing\n",
      "Word: is, Deprel: aux, Head: playing\n",
      "Word: playing, Deprel: root, Head: ROOT\n",
      "Word: a, Deprel: det, Head: guitar\n",
      "Word: guitar, Deprel: obj, Head: playing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Women are running'\n",
      "Word: Women, Deprel: nsubj, Head: running\n",
      "Word: are, Deprel: cop, Head: running\n",
      "Word: running, Deprel: root, Head: ROOT\n",
      "\n",
      "Dependencies for Sentence: 'Two women are running'\n",
      "Word: Two, Deprel: nummod, Head: women\n",
      "Word: women, Deprel: nsubj, Head: running\n",
      "Word: are, Deprel: cop, Head: running\n",
      "Word: running, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is tapping her fingers on a table'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: tapping\n",
      "Word: is, Deprel: aux, Head: tapping\n",
      "Word: tapping, Deprel: root, Head: ROOT\n",
      "Word: her, Deprel: nmod:poss, Head: fingers\n",
      "Word: fingers, Deprel: obj, Head: tapping\n",
      "Word: on, Deprel: case, Head: table\n",
      "Word: a, Deprel: det, Head: table\n",
      "Word: table, Deprel: obl, Head: tapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A woman is tapping her fingers'\n",
      "Word: A, Deprel: det, Head: woman\n",
      "Word: woman, Deprel: nsubj, Head: tapping\n",
      "Word: is, Deprel: aux, Head: tapping\n",
      "Word: tapping, Deprel: root, Head: ROOT\n",
      "Word: her, Deprel: nmod:poss, Head: fingers\n",
      "Word: fingers, Deprel: obj, Head: tapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Someone is boiling okra in a pot'\n",
      "Word: Someone, Deprel: nsubj, Head: boiling\n",
      "Word: is, Deprel: aux, Head: boiling\n",
      "Word: boiling, Deprel: root, Head: ROOT\n",
      "Word: okra, Deprel: obj, Head: boiling\n",
      "Word: in, Deprel: case, Head: pot\n",
      "Word: a, Deprel: det, Head: pot\n",
      "Word: pot, Deprel: obl, Head: boiling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'Someone is cooking okra in a pan'\n",
      "Word: Someone, Deprel: nsubj, Head: cooking\n",
      "Word: is, Deprel: aux, Head: cooking\n",
      "Word: cooking, Deprel: root, Head: ROOT\n",
      "Word: okra, Deprel: obj, Head: cooking\n",
      "Word: in, Deprel: case, Head: pan\n",
      "Word: a, Deprel: det, Head: pan\n",
      "Word: pan, Deprel: obl, Head: cooking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dependencies for Sentence: 'A man is smoking'\n",
      "Word: A, Deprel: det, Head: man\n",
      "Word: man, Deprel: nsubj, Head: smoking\n",
      "Word: is, Deprel: cop, Head: smoking\n",
      "Word: smoking, Deprel: root, Head: ROOT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maric\\AppData\\Local\\Temp\\ipykernel_11204\\4154973064.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Classify the words into p, s, o\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     roles_df[k,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m classify_syntactic_roles(nlp_stanza([train_df\u001b[38;5;241m.\u001b[39mloc[k,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m]]))\n\u001b[1;32m----> 6\u001b[0m     roles_df[k,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m classify_syntactic_roles(\u001b[43mnlp_stanza\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m roles_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\stanza\\pipeline\\core.py:480\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[1;34m(self, doc, processors)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, doc, processors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\stanza\\pipeline\\core.py:431\u001b[0m, in \u001b[0;36mPipeline.process\u001b[1;34m(self, doc, processors)\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors\u001b[38;5;241m.\u001b[39mget(processor_name):\n\u001b[0;32m    430\u001b[0m         process \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors[processor_name]\u001b[38;5;241m.\u001b[39mbulk_process \u001b[38;5;28;01mif\u001b[39;00m bulk \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessors[processor_name]\u001b[38;5;241m.\u001b[39mprocess\n\u001b[1;32m--> 431\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m doc\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\stanza\\pipeline\\depparse_processor.py:65\u001b[0m, in \u001b[0;36mDepparseProcessor.process\u001b[1;34m(self, document)\u001b[0m\n\u001b[0;32m     63\u001b[0m     preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch):\n\u001b[1;32m---> 65\u001b[0m         preds \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mdata_orig_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     preds \u001b[38;5;241m=\u001b[39m unsort(preds, batch\u001b[38;5;241m.\u001b[39mdata_orig_idx)\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\stanza\\models\\depparse\\trainer.py:149\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[1;34m(self, batch, unsort)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    148\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m word\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 149\u001b[0m _, preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordchars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordchars_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufeats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlemma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeprel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_orig_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msentlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwordlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m head_seqs \u001b[38;5;241m=\u001b[39m [chuliu_edmonds_one_root(adj[:l, :l])[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m adj, l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(preds[\u001b[38;5;241m0\u001b[39m], sentlens)] \u001b[38;5;66;03m# remove attachment for the root\u001b[39;00m\n\u001b[0;32m    151\u001b[0m deprel_seqs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeprel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munmap([preds[\u001b[38;5;241m1\u001b[39m][i][j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][h] \u001b[38;5;28;01mfor\u001b[39;00m j, h \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(hs)]) \u001b[38;5;28;01mfor\u001b[39;00m i, hs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(head_seqs)]\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\stanza\\models\\depparse\\model.py:176\u001b[0m, in \u001b[0;36mParser.forward\u001b[1;34m(self, word, word_mask, wordchars, wordchars_mask, upos, xpos, ufeats, pretrained, lemma, head, deprel, word_orig_idx, sentlens, wordlens, text)\u001b[0m\n\u001b[0;32m    174\u001b[0m all_forward_chars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharmodel_forward\u001b[38;5;241m.\u001b[39mbuild_char_representation(charlm_text)\n\u001b[0;32m    175\u001b[0m all_forward_chars \u001b[38;5;241m=\u001b[39m pack(pad_sequence(all_forward_chars, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m--> 176\u001b[0m all_backward_chars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharmodel_backward\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_char_representation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcharlm_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m all_backward_chars \u001b[38;5;241m=\u001b[39m pack(pad_sequence(all_backward_chars, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m    178\u001b[0m inputs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [all_forward_chars, all_backward_chars]\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\stanza\\models\\common\\char_model.py:222\u001b[0m, in \u001b[0;36mCharacterLanguageModel.build_char_representation\u001b[1;34m(self, sentences)\u001b[0m\n\u001b[0;32m    219\u001b[0m chars \u001b[38;5;241m=\u001b[39m get_long_tensor(chars, \u001b[38;5;28mlen\u001b[39m(all_data), pad_id\u001b[38;5;241m=\u001b[39mvocab\u001b[38;5;241m.\u001b[39munit2id(CHARLM_END))\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 222\u001b[0m     output, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchar_lens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m     res \u001b[38;5;241m=\u001b[39m [output[i, offsets] \u001b[38;5;28;01mfor\u001b[39;00m i, offsets \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(char_offsets)]\n\u001b[0;32m    224\u001b[0m     res \u001b[38;5;241m=\u001b[39m unsort(res, orig_idx)\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\stanza\\models\\common\\char_model.py:153\u001b[0m, in \u001b[0;36mCharacterLanguageModel.forward\u001b[1;34m(self, chars, charlens, hidden)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hidden \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \n\u001b[0;32m    151\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharlstm_h_init\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchar_num_layers\u001b[39m\u001b[38;5;124m'\u001b[39m], batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchar_hidden_dim\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcontiguous(),\n\u001b[0;32m    152\u001b[0m               \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcharlstm_c_init\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchar_num_layers\u001b[39m\u001b[38;5;124m'\u001b[39m], batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchar_hidden_dim\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcontiguous())\n\u001b[1;32m--> 153\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcharlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43membs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcharlens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pad_packed_sequence(output, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    155\u001b[0m decoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(output)\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\stanza\\models\\common\\packed_lstm.py:22\u001b[0m, in \u001b[0;36mPackedLSTM.forward\u001b[1;34m(self, input, lengths, hx)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28minput\u001b[39m, PackedSequence):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m pack_padded_sequence(\u001b[38;5;28minput\u001b[39m, lengths, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n\u001b[1;32m---> 22\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpad:\n\u001b[0;32m     24\u001b[0m     res \u001b[38;5;241m=\u001b[39m (pad_packed_sequence(res[\u001b[38;5;241m0\u001b[39m], batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)[\u001b[38;5;241m0\u001b[39m], res[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\maric\\Documents\\MASTERS\\PrimerSemestre\\IHLT\\FinalProject_versionantiguaconflictos\\IHLT\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:1135\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1123\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1124\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1125\u001b[0m         hx,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first,\n\u001b[0;32m   1133\u001b[0m     )\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1135\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1136\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1137\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1146\u001b[0m output \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1147\u001b[0m hidden \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;241m1\u001b[39m:]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# chunks\n",
    "\n",
    "roles_df = pd.DataFrame(columns=['0','1'], index=range(2234))\n",
    "\n",
    "for k in range(n):\n",
    "# Classify the words into p, s, o\n",
    "    roles_df[k,'0'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'0']]))\n",
    "    roles_df[k,'1'] = classify_syntactic_roles(nlp_stanza([train_df.loc[k,'1']]))\n",
    "\n",
    "roles_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IHLT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
