{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\maric\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import ast\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from nltk.metrics import jaccard_distance\n",
    "from nltk.util import ngrams\n",
    "from typing import List, Set\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "\n",
    "# dir_nltk_data = 'c:\\\\Users\\\\maric\\\\Documents\\\\MASTERS\\\\PrimerSemestre\\\\IHLT\\\\FinalProject\\\\IHLT\\\\Lib\\\\site-packages\\\\nltk\\\\tag'\n",
    "\n",
    "# Download required resource\n",
    "nltk.download('averaged_perceptron_tagger_eng')# , download_dir=dir_nltk_data)\n",
    "\n",
    "# Add the project directory to the Python path\n",
    "project_dir = Path.cwd().parent\n",
    "sys.path.append(str(project_dir))\n",
    "\n",
    "from Preprocessing.preprocessingUtils import TextPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>gs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['But', 'other', 'sources', 'close', 'to', 'th...</td>\n",
       "      <td>['But', 'other', 'sources', 'close', 'to', 'th...</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['Micron', 'has', 'declared', 'its', 'first', ...</td>\n",
       "      <td>['Micron', \"'s\", 'numbers', 'also', 'marked', ...</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['The', 'fines', 'are', 'part', 'of', 'failed'...</td>\n",
       "      <td>['Perry', 'said', 'he', 'backs', 'the', 'Senat...</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['The', 'American', 'Anglican', 'Council', ','...</td>\n",
       "      <td>['The', 'American', 'Anglican', 'Council', ','...</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['The', 'tech-loaded', 'Nasdaq', 'composite', ...</td>\n",
       "      <td>['The', 'technology-laced', 'Nasdaq', 'Composi...</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  ['But', 'other', 'sources', 'close', 'to', 'th...   \n",
       "1  ['Micron', 'has', 'declared', 'its', 'first', ...   \n",
       "2  ['The', 'fines', 'are', 'part', 'of', 'failed'...   \n",
       "3  ['The', 'American', 'Anglican', 'Council', ','...   \n",
       "4  ['The', 'tech-loaded', 'Nasdaq', 'composite', ...   \n",
       "\n",
       "                                                   1    gs  \n",
       "0  ['But', 'other', 'sources', 'close', 'to', 'th...  4.00  \n",
       "1  ['Micron', \"'s\", 'numbers', 'also', 'marked', ...  3.75  \n",
       "2  ['Perry', 'said', 'he', 'backs', 'the', 'Senat...  2.80  \n",
       "3  ['The', 'American', 'Anglican', 'Council', ','...  3.40  \n",
       "4  ['The', 'technology-laced', 'Nasdaq', 'Composi...  2.40  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "train_df = pd.read_csv('../Preprocessing/STS_train.csv')\n",
    "\n",
    "# Display the DataFrame\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>gs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[But, other, sources, close, to, the, sale, sa...</td>\n",
       "      <td>[But, other, sources, close, to, the, sale, sa...</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Micron, has, declared, its, first, quarterly,...</td>\n",
       "      <td>[Micron, 's, numbers, also, marked, the, first...</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, fines, are, part, of, failed, Republican...</td>\n",
       "      <td>[Perry, said, he, backs, the, Senate, 's, effo...</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, tech-loaded, Nasdaq, composite, rose, 20...</td>\n",
       "      <td>[The, technology-laced, Nasdaq, Composite, Ind...</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [But, other, sources, close, to, the, sale, sa...   \n",
       "1  [Micron, has, declared, its, first, quarterly,...   \n",
       "2  [The, fines, are, part, of, failed, Republican...   \n",
       "3  [The, American, Anglican, Council, ,, which, r...   \n",
       "4  [The, tech-loaded, Nasdaq, composite, rose, 20...   \n",
       "\n",
       "                                                   1    gs  \n",
       "0  [But, other, sources, close, to, the, sale, sa...  4.00  \n",
       "1  [Micron, 's, numbers, also, marked, the, first...  3.75  \n",
       "2  [Perry, said, he, backs, the, Senate, 's, effo...  2.80  \n",
       "3  [The, American, Anglican, Council, ,, which, r...  3.40  \n",
       "4  [The, technology-laced, Nasdaq, Composite, Ind...  2.40  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Turn the 2 first columns from strings to actual lists of strings\n",
    "train_df.iloc[:, :2] = train_df.iloc[:, :2].map(ast.literal_eval)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(But, CC), (other, JJ), (sources, NNS), (clos...</td>\n",
       "      <td>[(But, CC), (other, JJ), (sources, NNS), (clos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(Micron, NNP), (has, VBZ), (declared, VBN), (...</td>\n",
       "      <td>[(Micron, NNP), (s, NN), (numbers, NNS), (also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(The, DT), (fines, NNS), (are, VBP), (part, N...</td>\n",
       "      <td>[(Perry, NNP), (said, VBD), (he, PRP), (backs,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(The, DT), (American, JJ), (Anglican, NNP), (...</td>\n",
       "      <td>[(The, DT), (American, JJ), (Anglican, NNP), (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(The, DT), (tech-loaded, JJ), (Nasdaq, NNP), ...</td>\n",
       "      <td>[(The, DT), (technology-laced, JJ), (Nasdaq, N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [(But, CC), (other, JJ), (sources, NNS), (clos...   \n",
       "1  [(Micron, NNP), (has, VBZ), (declared, VBN), (...   \n",
       "2  [(The, DT), (fines, NNS), (are, VBP), (part, N...   \n",
       "3  [(The, DT), (American, JJ), (Anglican, NNP), (...   \n",
       "4  [(The, DT), (tech-loaded, JJ), (Nasdaq, NNP), ...   \n",
       "\n",
       "                                                   1  \n",
       "0  [(But, CC), (other, JJ), (sources, NNS), (clos...  \n",
       "1  [(Micron, NNP), (s, NN), (numbers, NNS), (also...  \n",
       "2  [(Perry, NNP), (said, VBD), (he, PRP), (backs,...  \n",
       "3  [(The, DT), (American, JJ), (Anglican, NNP), (...  \n",
       "4  [(The, DT), (technology-laced, JJ), (Nasdaq, N...  "
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the TextPreprocessor\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "# Remove punctuation\n",
    "train_df = preprocessor.remove_punctuation(train_df)\n",
    "train_df = preprocessor.remove_empty_strings(train_df)\n",
    "\n",
    "# POS-tagging the words\n",
    "\n",
    "n=len(train_df)\n",
    "train_df_POS = pd.DataFrame(columns=['0','1'])\n",
    "\n",
    "function_words_tag = {'IN', 'CC', 'DT', 'PDT', 'WDT'}\n",
    "\n",
    "for i in range(n):\n",
    "    train_df_POS.loc[i,'0'] = nltk.pos_tag(train_df.loc[i,'0']) \n",
    "    train_df_POS.loc[i,'1'] = nltk.pos_tag(train_df.loc[i,'1']) \n",
    "\n",
    "train_df_POS.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(other, JJ), (sources, NNS), (close, RB), (to...</td>\n",
       "      <td>[(other, JJ), (sources, NNS), (close, RB), (to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(Micron, NNP), (has, VBZ), (declared, VBN), (...</td>\n",
       "      <td>[(Micron, NNP), (s, NN), (numbers, NNS), (also...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(fines, NNS), (are, VBP), (part, NN), (failed...</td>\n",
       "      <td>[(Perry, NNP), (said, VBD), (he, PRP), (backs,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(American, JJ), (Anglican, NNP), (Council, NN...</td>\n",
       "      <td>[(American, JJ), (Anglican, NNP), (Council, NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(tech-loaded, JJ), (Nasdaq, NNP), (composite,...</td>\n",
       "      <td>[(technology-laced, JJ), (Nasdaq, NNP), (Compo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [(other, JJ), (sources, NNS), (close, RB), (to...   \n",
       "1  [(Micron, NNP), (has, VBZ), (declared, VBN), (...   \n",
       "2  [(fines, NNS), (are, VBP), (part, NN), (failed...   \n",
       "3  [(American, JJ), (Anglican, NNP), (Council, NN...   \n",
       "4  [(tech-loaded, JJ), (Nasdaq, NNP), (composite,...   \n",
       "\n",
       "                                                   1  \n",
       "0  [(other, JJ), (sources, NNS), (close, RB), (to...  \n",
       "1  [(Micron, NNP), (s, NN), (numbers, NNS), (also...  \n",
       "2  [(Perry, NNP), (said, VBD), (he, PRP), (backs,...  \n",
       "3  [(American, JJ), (Anglican, NNP), (Council, NN...  \n",
       "4  [(technology-laced, JJ), (Nasdaq, NNP), (Compo...  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the function words (prepositions, conjunctions, articles) carry less semantics than content words and thus removing them might eliminate\n",
    "# the noise and provide a more accurate estimate of semantic similarity.\n",
    "\n",
    "function_words_tag = {'IN', 'CC', 'DT', 'PDT', 'WDT'}\n",
    "\n",
    "for i in range(n):\n",
    "    for tag in function_words_tag:\n",
    "        j=0\n",
    "        while j < (len(train_df_POS.loc[i,'0'])):\n",
    "            if train_df_POS.loc[i,'0'][j][1]==tag:\n",
    "                train_df_POS.loc[i,'0'].pop(j)\n",
    "            j=j+1\n",
    "        j=0\n",
    "        while j < (len(train_df_POS.loc[i,'1'])):\n",
    "            if train_df_POS.loc[i,'1'][j][1]==tag:\n",
    "                train_df_POS.loc[i,'1'].pop(j)\n",
    "            j=j+1\n",
    "            \n",
    "train_df_POS.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>gs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[other, sources, close, to, sale, said, Vivend...</td>\n",
       "      <td>[other, sources, close, to, sale, said, Vivend...</td>\n",
       "      <td>4.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Micron, has, declared, its, first, quarterly,...</td>\n",
       "      <td>[Micron, s, numbers, also, marked, first, quar...</td>\n",
       "      <td>3.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[fines, are, part, failed, Republican, efforts...</td>\n",
       "      <td>[Perry, said, he, backs, Senate, s, efforts, i...</td>\n",
       "      <td>2.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[American, Anglican, Council, represents, Epis...</td>\n",
       "      <td>[American, Anglican, Council, represents, Epis...</td>\n",
       "      <td>3.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[tech-loaded, Nasdaq, composite, rose, 20.96, ...</td>\n",
       "      <td>[technology-laced, Nasdaq, Composite, Index, I...</td>\n",
       "      <td>2.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Amgen, shares, gained, 93, cents, 1.45, perce...</td>\n",
       "      <td>[Shares, Allergan, were, up, 14, cents, 78.40,...</td>\n",
       "      <td>1.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[U.S, prosecutors, have, arrested, more, 130, ...</td>\n",
       "      <td>[More, 130, people, have, been, arrested, 17, ...</td>\n",
       "      <td>4.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Chavez, said, investigators, feel, confident,...</td>\n",
       "      <td>[Albuquerque, Mayor, Martin, Chavez, said, inv...</td>\n",
       "      <td>3.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Authorities, said, scientist, properly, quara...</td>\n",
       "      <td>[scientist, also, quarantined, himself, home, ...</td>\n",
       "      <td>4.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[support, will, come, free, software, upgrade,...</td>\n",
       "      <td>[upgrade, will, be, available, free, download,...</td>\n",
       "      <td>2.600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [other, sources, close, to, sale, said, Vivend...   \n",
       "1  [Micron, has, declared, its, first, quarterly,...   \n",
       "2  [fines, are, part, failed, Republican, efforts...   \n",
       "3  [American, Anglican, Council, represents, Epis...   \n",
       "4  [tech-loaded, Nasdaq, composite, rose, 20.96, ...   \n",
       "5  [Amgen, shares, gained, 93, cents, 1.45, perce...   \n",
       "6  [U.S, prosecutors, have, arrested, more, 130, ...   \n",
       "7  [Chavez, said, investigators, feel, confident,...   \n",
       "8  [Authorities, said, scientist, properly, quara...   \n",
       "9  [support, will, come, free, software, upgrade,...   \n",
       "\n",
       "                                                   1     gs  \n",
       "0  [other, sources, close, to, sale, said, Vivend...  4.000  \n",
       "1  [Micron, s, numbers, also, marked, first, quar...  3.750  \n",
       "2  [Perry, said, he, backs, Senate, s, efforts, i...  2.800  \n",
       "3  [American, Anglican, Council, represents, Epis...  3.400  \n",
       "4  [technology-laced, Nasdaq, Composite, Index, I...  2.400  \n",
       "5  [Shares, Allergan, were, up, 14, cents, 78.40,...  1.333  \n",
       "6  [More, 130, people, have, been, arrested, 17, ...  4.600  \n",
       "7  [Albuquerque, Mayor, Martin, Chavez, said, inv...  3.800  \n",
       "8  [scientist, also, quarantined, himself, home, ...  4.200  \n",
       "9  [upgrade, will, be, available, free, download,...  2.600  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_1 = pd.DataFrame(columns=['0','1','gs'])\n",
    "\n",
    "for i in range(n):\n",
    "    sentence=[]\n",
    "    for j in range(len(train_df_POS.loc[i,'0'])):\n",
    "        sentence.append(train_df_POS.loc[i,'0'][j][0])\n",
    "    train_df_1.loc[i,'0']=sentence\n",
    "    sentence=[]\n",
    "    for k in range(len(train_df_POS.loc[i,'1'])):\n",
    "        sentence.append(train_df_POS.loc[i,'1'][k][0])\n",
    "    train_df_1.loc[i,'1']=sentence\n",
    "\n",
    "train_df_1['gs'] = train_df['gs']\n",
    "train_df_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_overlap(tokens1: List[str], tokens2: List[str], n: int) -> float:\n",
    "    \"\"\"\n",
    "    Computes the n-gram overlap between two tokenized sentences.\n",
    "\n",
    "    Parameters:\n",
    "        tokens1 (List[str]): Tokenized first sentence as a list of strings.\n",
    "        tokens2 (List[str]): Tokenized second sentence as a list of strings.\n",
    "        n (int): The size of n-grams.\n",
    "\n",
    "    Returns:\n",
    "        float: The n-gram overlap ratio.\n",
    "    \"\"\"\n",
    "    def generate_ngrams(tokens: List[str], n: int) -> Set[str]:\n",
    "        \"\"\"\n",
    "        Generates n-grams for a given list of tokens.\n",
    "\n",
    "        Parameters:\n",
    "            tokens (List[str]): The input tokens.\n",
    "            n (int): The size of n-grams.\n",
    "\n",
    "        Returns:\n",
    "            Set[str]: A set of n-grams.\n",
    "        \"\"\"\n",
    "        return set([' '.join(tokens[i:i+n]) for i in range(len(tokens) - n + 1)])\n",
    "\n",
    "    # Generate n-grams for both token lists\n",
    "    ngrams_s1 = generate_ngrams(tokens1, n)\n",
    "    ngrams_s2 = generate_ngrams(tokens2, n)\n",
    "\n",
    "    # Compute the intersection \n",
    "    intersection = ngrams_s1.intersection(ngrams_s2)\n",
    "\n",
    "    # Compute the n gram overlap when posible\n",
    "    if len(intersection)==0:\n",
    "        ngo=0\n",
    "    else:\n",
    "        ngo=2/((len(ngrams_s1)+len(ngrams_s2))/len(intersection))\n",
    "\n",
    "    return float(ngo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntactic_features=pd.DataFrame(columns=['POS_tagging_unigrams','POS_tagging_bigrams','POS_tagging_trigrams'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POS_tagging_unigrams</th>\n",
       "      <th>POS_tagging_bigrams</th>\n",
       "      <th>POS_tagging_trigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>0.514286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.352941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   POS_tagging_unigrams  POS_tagging_bigrams  POS_tagging_trigrams\n",
       "0              0.702703             0.594595              0.514286\n",
       "1              0.571429             0.421053              0.352941\n",
       "2              0.500000             0.250000              0.090909\n",
       "3              0.756757             0.742857              0.727273\n",
       "4              0.230769             0.000000              0.000000"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(n):\n",
    "    # unigrams\n",
    "    syntactic_features.loc[i,'POS_tagging_unigrams'] = n_gram_overlap(train_df_1.loc[i,'0'],train_df_1.loc[i,'1'],1)\n",
    "    # bigrams\n",
    "    syntactic_features.loc[i,'POS_tagging_bigrams'] = n_gram_overlap(train_df_1.loc[i,'0'],train_df_1.loc[i,'1'],2)\n",
    "    # trigrams\n",
    "    syntactic_features.loc[i,'POS_tagging_trigrams'] = n_gram_overlap(train_df_1.loc[i,'0'],train_df_1.loc[i,'1'],3)\n",
    "\n",
    "\n",
    "# Convert all columns in a DataFrame to numeric, coercing errors into NaN.\n",
    "syntactic_features['POS_tagging_unigrams'] = pd.to_numeric(syntactic_features['POS_tagging_unigrams'], errors='coerce') \n",
    "syntactic_features['POS_tagging_bigrams'] = pd.to_numeric(syntactic_features['POS_tagging_bigrams'], errors='coerce') \n",
    "syntactic_features['POS_tagging_trigrams'] = pd.to_numeric(syntactic_features['POS_tagging_trigrams'], errors='coerce') \n",
    "\n",
    "syntactic_features.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5113723483644254)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(syntactic_features['POS_tagging_unigrams'], train_df['gs'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IHLT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
