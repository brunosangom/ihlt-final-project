{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import csv\n",
    "\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('punkt_tab', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each of the training Datasets into a separate DataFrame\n",
    "train_par_df = pd.read_csv('../Datasets/train/STS.input.MSRpar.txt',sep='\\t',header=None, quoting=csv.QUOTE_NONE)\n",
    "train_par_df['gs'] = pd.read_csv('../Datasets/train/STS.gs.MSRpar.txt',sep='\\t',header=None)\n",
    "\n",
    "train_vid_df = pd.read_csv('../Datasets/train/STS.input.MSRvid.txt',sep='\\t',header=None, quoting=csv.QUOTE_NONE)\n",
    "train_vid_df['gs'] = pd.read_csv('../Datasets/train/STS.gs.MSRvid.txt',sep='\\t',header=None)\n",
    "\n",
    "train_europarl_df = pd.read_csv('../Datasets/train/STS.input.SMTeuroparl.txt',sep='\\t',header=None, quoting=csv.QUOTE_NONE)\n",
    "train_europarl_df['gs'] = pd.read_csv('../Datasets/train/STS.gs.SMTeuroparl.txt',sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>gs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>But other sources close to the sale said Viven...</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Micron has declared its first quarterly profit...</td>\n",
       "      <td>Micron's numbers also marked the first quarter...</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The fines are part of failed Republican effort...</td>\n",
       "      <td>Perry said he backs the Senate's efforts, incl...</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>The American Anglican Council, which represent...</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The tech-loaded Nasdaq composite rose 20.96 po...</td>\n",
       "      <td>The technology-laced Nasdaq Composite Index &lt;....</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  But other sources close to the sale said Viven...   \n",
       "1  Micron has declared its first quarterly profit...   \n",
       "2  The fines are part of failed Republican effort...   \n",
       "3  The American Anglican Council, which represent...   \n",
       "4  The tech-loaded Nasdaq composite rose 20.96 po...   \n",
       "\n",
       "                                                   1    gs  \n",
       "0  But other sources close to the sale said Viven...  4.00  \n",
       "1  Micron's numbers also marked the first quarter...  3.75  \n",
       "2  Perry said he backs the Senate's efforts, incl...  2.80  \n",
       "3  The American Anglican Council, which represent...  3.40  \n",
       "4  The technology-laced Nasdaq Composite Index <....  2.40  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the DataFrames\n",
    "train_combined_df = pd.concat([train_par_df, train_vid_df, train_europarl_df], ignore_index=True)\n",
    "\n",
    "train_combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences in the text\n",
    "train_tokenized_0 = [nltk.word_tokenize(sentence) for sentence in train_combined_df[0]]\n",
    "train_tokenized_1 = [nltk.word_tokenize(sentence) for sentence in train_combined_df[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>gs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[But, other, sources, close, to, the, sale, sa...</td>\n",
       "      <td>[But, other, sources, close, to, the, sale, sa...</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Micron, has, declared, its, first, quarterly,...</td>\n",
       "      <td>[Micron, 's, numbers, also, marked, the, first...</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[The, fines, are, part, of, failed, Republican...</td>\n",
       "      <td>[Perry, said, he, backs, the, Senate, 's, effo...</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>[The, American, Anglican, Council, ,, which, r...</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[The, tech-loaded, Nasdaq, composite, rose, 20...</td>\n",
       "      <td>[The, technology-laced, Nasdaq, Composite, Ind...</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  [But, other, sources, close, to, the, sale, sa...   \n",
       "1  [Micron, has, declared, its, first, quarterly,...   \n",
       "2  [The, fines, are, part, of, failed, Republican...   \n",
       "3  [The, American, Anglican, Council, ,, which, r...   \n",
       "4  [The, tech-loaded, Nasdaq, composite, rose, 20...   \n",
       "\n",
       "                                                   1    gs  \n",
       "0  [But, other, sources, close, to, the, sale, sa...  4.00  \n",
       "1  [Micron, 's, numbers, also, marked, the, first...  3.75  \n",
       "2  [Perry, said, he, backs, the, Senate, 's, effo...  2.80  \n",
       "3  [The, American, Anglican, Council, ,, which, r...  3.40  \n",
       "4  [The, technology-laced, Nasdaq, Composite, Ind...  2.40  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the new dataframe\n",
    "train_tokenized_df = pd.DataFrame({\n",
    "    '0': train_tokenized_0,\n",
    "    '1': train_tokenized_1,\n",
    "    'gs': train_combined_df['gs']\n",
    "})\n",
    "\n",
    "train_tokenized_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the train_tokenized sentences to a CSV\n",
    "train_tokenized_df.to_csv('STS_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for test dataset\n",
    "\n",
    "# Load each of the testing Datasets into a separate DataFrame\n",
    "test_par_df = pd.read_csv('../Datasets/test-gold/STS.input.MSRpar.txt',sep='\\t',header=None, quoting=csv.QUOTE_NONE)\n",
    "test_par_df['gs'] = pd.read_csv('../Datasets/test-gold/STS.gs.MSRpar.txt',sep='\\t',header=None)\n",
    "\n",
    "test_vid_df = pd.read_csv('../Datasets/test-gold/STS.input.MSRvid.txt',sep='\\t',header=None, quoting=csv.QUOTE_NONE)\n",
    "test_vid_df['gs'] = pd.read_csv('../Datasets/test-gold/STS.gs.MSRvid.txt',sep='\\t',header=None)\n",
    "\n",
    "test_europarl_df = pd.read_csv('../Datasets/test-gold/STS.input.SMTeuroparl.txt',sep='\\t',header=None, quoting=csv.QUOTE_NONE)\n",
    "test_europarl_df['gs'] = pd.read_csv('../Datasets/test-gold/STS.gs.SMTeuroparl.txt',sep='\\t',header=None)\n",
    "\n",
    "test_wn_df = pd.read_csv('../Datasets/test-gold/STS.input.surprise.OnWN.txt',sep='\\t',header=None, quoting=csv.QUOTE_NONE)\n",
    "test_wn_df['gs'] = pd.read_csv('../Datasets/test-gold/STS.gs.surprise.OnWN.txt',sep='\\t',header=None)\n",
    "\n",
    "test_news_df = pd.read_csv('../Datasets/test-gold/STS.input.surprise.SMTnews.txt',sep='\\t',header=None, quoting=csv.QUOTE_NONE)\n",
    "test_news_df['gs'] = pd.read_csv('../Datasets/test-gold/STS.gs.surprise.SMTnews.txt',sep='\\t',header=None)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "test_combined_df = pd.concat([test_par_df, test_vid_df, test_europarl_df, test_wn_df, test_news_df], ignore_index=True)\n",
    "\n",
    "# Tokenize the sentences in the text\n",
    "test_tokenized_0 = [nltk.word_tokenize(sentence) for sentence in test_combined_df[0]]\n",
    "test_tokenized_1 = [nltk.word_tokenize(sentence) for sentence in test_combined_df[1]]\n",
    "\n",
    "# Create the new dataframe\n",
    "test_tokenized_df = pd.DataFrame({\n",
    "    '0': test_tokenized_0,\n",
    "    '1': test_tokenized_1,\n",
    "    'gs': test_combined_df['gs']\n",
    "})\n",
    "\n",
    "# Save the train_tokenized sentences to a CSV\n",
    "test_tokenized_df.to_csv('STS_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
